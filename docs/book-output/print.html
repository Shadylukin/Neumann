<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Neumann</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="Unified tensor-based runtime for relational, graph, and vector data">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "coal";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Neumann</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/Shadylukin/Neumann" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Neumann is a unified tensor-based runtime that stores relational data, graph
relationships, and vector embeddings in a single mathematical structure.</p>
<h2 id="why-neumann"><a class="header" href="#why-neumann">Why Neumann?</a></h2>
<p>Traditional databases force you to choose: SQL for structured data, graph
databases for relationships, or vector stores for embeddings. Neumann unifies
all three into a single system built on sparse tensor mathematics.</p>
<h3 id="key-benefits"><a class="header" href="#key-benefits">Key Benefits</a></h3>
<ul>
<li><strong>Unified Data Model</strong>: Store tables, graphs, and embeddings in one system</li>
<li><strong>Semantic Operations</strong>: Query across modalities using tensor operations</li>
<li><strong>Distributed by Design</strong>: Built-in Raft consensus with 2PC transactions</li>
<li><strong>Memory Efficient</strong>: Sparse vector representations minimize storage</li>
<li><strong>Consistent</strong>: Strong consistency guarantees with hybrid logical clocks</li>
</ul>
<h2 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h2>
<pre><code class="language-text">+-------------------+
|   neumann_shell   |  &lt;- Interactive CLI
+-------------------+
         |
+-------------------+
|   query_router    |  &lt;- Unified query execution
+-------------------+
         |
+--------+--------+--------+--------+
|        |        |        |        |
v        v        v        v        v
relational graph  vector  vault   cache   blob   chain
_engine  _engine _engine _vault  _cache  _blob  _chain
         |        |        |        |        |        |
         +--------+--------+--------+--------+--------+
                           |
                  +--------+--------+
                  |                 |
              tensor_store    tensor_compress
</code></pre>
<h2 id="quick-example"><a class="header" href="#quick-example">Quick Example</a></h2>
<pre><code class="language-sql">-- Create a table with vector embeddings
CREATE TABLE documents (
    id INT PRIMARY KEY,
    title STRING,
    embedding VECTOR(128)
);

-- Insert with semantic content
INSERT INTO documents VALUES (1, 'Introduction to ML', [0.1, 0.2, ...]);

-- Find similar documents
SELECT title FROM documents
WHERE SIMILAR(embedding, [0.15, 0.18, ...], 0.9);
</code></pre>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<ul>
<li><a href="getting-started/installation.html">Installation</a> - Set up Neumann on your
system</li>
<li><a href="getting-started/quick-start.html">Quick Start</a> - Your first queries in minutes</li>
<li><a href="getting-started/building-from-source.html">Building from Source</a> - Compile from
source</li>
</ul>
<h2 id="documentation-structure"><a class="header" href="#documentation-structure">Documentation Structure</a></h2>
<ul>
<li><strong>Getting Started</strong>: Installation and first steps</li>
<li><strong>Architecture</strong>: Deep dives into each module</li>
<li><strong>Concepts</strong>: Cross-cutting ideas like sparse vectors and consensus</li>
<li><strong>Operations</strong>: Deployment, monitoring, and troubleshooting</li>
<li><strong>Contributing</strong>: How to contribute to Neumann</li>
</ul>
<h2 id="api-reference"><a class="header" href="#api-reference">API Reference</a></h2>
<p>Full API documentation is available in the <a href="api-reference.html">rustdoc output</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>Multiple installation methods are available depending on your needs.</p>
<h2 id="quick-install-recommended"><a class="header" href="#quick-install-recommended">Quick Install (Recommended)</a></h2>
<p>The easiest way to install Neumann is using the install script:</p>
<pre><code class="language-bash">curl -sSfL https://raw.githubusercontent.com/Shadylukin/Neumann/main/install.sh | bash
</code></pre>
<p>This script will:</p>
<ul>
<li>Detect your platform (Linux x86_64, macOS x86_64, macOS ARM64)</li>
<li>Download a pre-built binary if available</li>
<li>Fall back to building from source if needed</li>
<li>Install to <code>/usr/local/bin</code> or <code>~/.local/bin</code></li>
</ul>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th></tr></thead><tbody>
<tr><td><code>NEUMANN_INSTALL_DIR</code></td><td>Custom installation directory</td></tr>
<tr><td><code>NEUMANN_VERSION</code></td><td>Install a specific version (e.g., <code>v0.1.0</code>)</td></tr>
<tr><td><code>NEUMANN_NO_MODIFY_PATH</code></td><td>Set to <code>1</code> to skip PATH modification</td></tr>
</tbody></table>
</div>
<h2 id="homebrew-macoslinux"><a class="header" href="#homebrew-macoslinux">Homebrew (macOS/Linux)</a></h2>
<pre><code class="language-bash">brew tap Shadylukin/tap
brew install neumann
</code></pre>
<h2 id="cargo-cratesio"><a class="header" href="#cargo-cratesio">Cargo (crates.io)</a></h2>
<p>If you have Rust installed:</p>
<pre><code class="language-bash">cargo install neumann_shell
</code></pre>
<h2 id="docker"><a class="header" href="#docker">Docker</a></h2>
<h3 id="interactive-cli"><a class="header" href="#interactive-cli">Interactive CLI</a></h3>
<pre><code class="language-bash">docker run -it shadylukin/neumann:latest
</code></pre>
<h3 id="server-mode"><a class="header" href="#server-mode">Server Mode</a></h3>
<pre><code class="language-bash">docker run -d -p 9200:9200 -v neumann-data:/var/lib/neumann shadylukin/neumann:server
</code></pre>
<h3 id="docker-compose"><a class="header" href="#docker-compose">Docker Compose</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/Shadylukin/Neumann.git
cd Neumann

# Start the server
docker compose up -d neumann-server

# Run the CLI
docker compose run --rm neumann-cli
</code></pre>
<h2 id="from-source"><a class="header" href="#from-source">From Source</a></h2>
<h3 id="requirements"><a class="header" href="#requirements">Requirements</a></h3>
<ul>
<li>Rust 1.75 or later</li>
<li>Cargo (included with Rust)</li>
<li>Git</li>
<li>protobuf compiler (for gRPC)</li>
</ul>
<h3 id="build-steps"><a class="header" href="#build-steps">Build Steps</a></h3>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/Shadylukin/Neumann.git
cd Neumann

# Build in release mode
cargo build --release --package neumann_shell

# Install locally
cargo install --path neumann_shell
</code></pre>
<h3 id="run-tests"><a class="header" href="#run-tests">Run Tests</a></h3>
<pre><code class="language-bash">cargo test
</code></pre>
<h2 id="verify-installation"><a class="header" href="#verify-installation">Verify Installation</a></h2>
<pre><code class="language-bash">neumann --version
</code></pre>
<h2 id="platform-support"><a class="header" href="#platform-support">Platform Support</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Platform</th><th>Binary</th><th>Homebrew</th><th>Docker</th><th>Source</th></tr></thead><tbody>
<tr><td>Linux x86_64</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr>
<tr><td>macOS x86_64</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr>
<tr><td>macOS ARM64 (Apple Silicon)</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr>
<tr><td>Windows x86_64</td><td>No</td><td>No</td><td>Yes</td><td>Experimental</td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="command-not-found-neumann"><a class="header" href="#command-not-found-neumann">“command not found: neumann”</a></h3>
<p>The binary may not be in your PATH. Try:</p>
<pre><code class="language-bash"># Check where it was installed
which neumann || ls ~/.local/bin/neumann

# Add to PATH if needed
export PATH="$HOME/.local/bin:$PATH"
</code></pre>
<h3 id="build-fails-with-protobuf-errors"><a class="header" href="#build-fails-with-protobuf-errors">Build fails with protobuf errors</a></h3>
<p>Install the protobuf compiler:</p>
<pre><code class="language-bash"># macOS
brew install protobuf

# Ubuntu/Debian
sudo apt-get install protobuf-compiler

# Fedora
sudo dnf install protobuf-compiler
</code></pre>
<h3 id="permission-denied-during-install"><a class="header" href="#permission-denied-during-install">Permission denied during install</a></h3>
<p>The installer tries <code>/usr/local/bin</code> first (requires sudo) then falls back to <code>~/.local/bin</code>. You can specify a custom directory:</p>
<pre><code class="language-bash">NEUMANN_INSTALL_DIR=~/bin curl -sSfL .../install.sh | bash
</code></pre>
<h2 id="updating"><a class="header" href="#updating">Updating</a></h2>
<h3 id="quick-install"><a class="header" href="#quick-install">Quick Install</a></h3>
<p>Re-run the install script to get the latest version:</p>
<pre><code class="language-bash">curl -sSfL https://raw.githubusercontent.com/Shadylukin/Neumann/main/install.sh | bash
</code></pre>
<h3 id="homebrew"><a class="header" href="#homebrew">Homebrew</a></h3>
<pre><code class="language-bash">brew upgrade neumann
</code></pre>
<h3 id="cargo"><a class="header" href="#cargo">Cargo</a></h3>
<pre><code class="language-bash">cargo install neumann_shell --force
</code></pre>
<h2 id="uninstalling"><a class="header" href="#uninstalling">Uninstalling</a></h2>
<h3 id="quick-install--cargo"><a class="header" href="#quick-install--cargo">Quick Install / Cargo</a></h3>
<pre><code class="language-bash">rm $(which neumann)
</code></pre>
<h3 id="homebrew-1"><a class="header" href="#homebrew-1">Homebrew</a></h3>
<pre><code class="language-bash">brew uninstall neumann
</code></pre>
<h3 id="docker-1"><a class="header" href="#docker-1">Docker</a></h3>
<pre><code class="language-bash">docker rmi shadylukin/neumann:latest shadylukin/neumann:server
docker volume rm neumann-data
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li><a href="getting-started/quick-start.html">Quick Start</a> - Run your first queries</li>
<li><a href="getting-started/building-from-source.html">Building from Source</a> - Development setup</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h1>
<h2 id="starting-the-shell"><a class="header" href="#starting-the-shell">Starting the Shell</a></h2>
<pre><code class="language-bash">neumann
</code></pre>
<p>You’ll see the interactive prompt:</p>
<pre><code class="language-text">Neumann v0.1.0
Type 'help' for available commands.
neumann&gt;
</code></pre>
<h2 id="basic-operations"><a class="header" href="#basic-operations">Basic Operations</a></h2>
<h3 id="relational-data"><a class="header" href="#relational-data">Relational Data</a></h3>
<pre><code class="language-sql">-- Create a table
CREATE TABLE users (id INT, name STRING, age INT);

-- Insert data
INSERT INTO users VALUES (1, 'Alice', 30);
INSERT INTO users VALUES (2, 'Bob', 25);

-- Query data
SELECT * FROM users WHERE age &gt; 20;
</code></pre>
<h3 id="graph-data"><a class="header" href="#graph-data">Graph Data</a></h3>
<pre><code class="language-sql">-- Create nodes
CREATE NODE Person { name: 'Alice', role: 'Engineer' };
CREATE NODE Person { name: 'Bob', role: 'Manager' };

-- Create edges
CREATE EDGE REPORTS_TO FROM 'alice' TO 'bob';

-- Traverse
MATCH (p:Person)-[:REPORTS_TO]-&gt;(m:Person) RETURN p.name, m.name;
</code></pre>
<h3 id="vector-data"><a class="header" href="#vector-data">Vector Data</a></h3>
<pre><code class="language-sql">-- Store embeddings
INSERT INTO embeddings (id, vec) VALUES (1, [0.1, 0.2, 0.3, 0.4]);
INSERT INTO embeddings (id, vec) VALUES (2, [0.15, 0.25, 0.35, 0.45]);

-- Similarity search
SELECT id FROM embeddings
WHERE SIMILAR(vec, [0.1, 0.2, 0.3, 0.4], 0.9)
LIMIT 10;
</code></pre>
<h2 id="unified-queries"><a class="header" href="#unified-queries">Unified Queries</a></h2>
<p>Neumann allows mixing data models in a single query:</p>
<pre><code class="language-sql">-- Find similar users and their graph connections
SELECT u.name, e.similarity
FROM users u
JOIN embeddings e ON u.id = e.id
WHERE SIMILAR(e.vec, [0.1, 0.2, 0.3, 0.4], 0.8)
AND EXISTS (
  MATCH (u)-[:FRIEND]-&gt;()
);
</code></pre>
<h2 id="persistence"><a class="header" href="#persistence">Persistence</a></h2>
<p>Data is stored in memory by default. Enable WAL for persistence:</p>
<pre><code class="language-bash">neumann --wal-dir ./data
</code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li><a href="getting-started/building-from-source.html">Building from Source</a> - Development setup</li>
<li><a href="getting-started/../architecture/overview.html">Architecture Overview</a> - System design</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-from-source"><a class="header" href="#building-from-source">Building from Source</a></h1>
<h2 id="development-requirements"><a class="header" href="#development-requirements">Development Requirements</a></h2>
<ul>
<li>Rust 1.75+ (stable)</li>
<li>Rust nightly (for fuzzing)</li>
<li>Git</li>
</ul>
<h2 id="clone-and-build"><a class="header" href="#clone-and-build">Clone and Build</a></h2>
<pre><code class="language-bash">git clone https://github.com/Shadylukin/Neumann.git
cd Neumann

# Debug build
cargo build

# Release build (optimized)
cargo build --release
</code></pre>
<h2 id="running-tests"><a class="header" href="#running-tests">Running Tests</a></h2>
<pre><code class="language-bash"># Run all tests
cargo test

# Run tests for a specific crate
cargo test -p tensor_chain

# Run with output
cargo test -- --nocapture
</code></pre>
<h2 id="quality-checks"><a class="header" href="#quality-checks">Quality Checks</a></h2>
<p>All code must pass before commit:</p>
<pre><code class="language-bash"># Formatting
cargo fmt --check

# Lints (warnings as errors)
cargo clippy -- -D warnings

# Documentation builds
cargo doc --no-deps
</code></pre>
<h2 id="fuzzing"><a class="header" href="#fuzzing">Fuzzing</a></h2>
<p>Requires nightly Rust:</p>
<pre><code class="language-bash"># Install cargo-fuzz
cargo install cargo-fuzz

# Run a fuzz target
cd fuzz
cargo +nightly fuzz run parser_parse -- -max_total_time=60
</code></pre>
<h2 id="running-the-shell"><a class="header" href="#running-the-shell">Running the Shell</a></h2>
<pre><code class="language-bash"># Debug mode
cargo run -p neumann_shell

# Release mode
cargo run --release -p neumann_shell
</code></pre>
<h2 id="ide-setup"><a class="header" href="#ide-setup">IDE Setup</a></h2>
<h3 id="vs-code"><a class="header" href="#vs-code">VS Code</a></h3>
<p>Install the rust-analyzer extension. Recommended settings:</p>
<pre><code class="language-json">{
  "rust-analyzer.checkOnSave.command": "clippy",
  "rust-analyzer.cargo.features": "all"
}
</code></pre>
<h3 id="intellijclion"><a class="header" href="#intellijclion">IntelliJ/CLion</a></h3>
<p>Install the Rust plugin. Enable clippy in settings.</p>
<h2 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h2>
<pre><code class="language-text">Neumann/
├── tensor_store/       # Core storage layer
├── relational_engine/  # SQL-like tables
├── graph_engine/       # Graph operations
├── vector_engine/      # Embeddings
├── tensor_chain/       # Distributed consensus
├── neumann_parser/     # Query parsing
├── query_router/       # Query execution
├── neumann_shell/      # CLI interface
├── tensor_compress/    # Compression
├── tensor_vault/       # Encrypted storage
├── tensor_cache/       # LLM caching
├── tensor_blob/        # Blob storage
├── tensor_checkpoint/  # Snapshots
├── tensor_unified/     # Multi-engine facade
├── fuzz/               # Fuzz targets
└── docs/               # Documentation
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture-overview-1"><a class="header" href="#architecture-overview-1">Architecture Overview</a></h1>
<p>Neumann is a unified tensor-based runtime that stores relational data, graph
relationships, and vector embeddings in a single mathematical structure.</p>
<h2 id="system-architecture"><a class="header" href="#system-architecture">System Architecture</a></h2>
<pre class="mermaid">flowchart TB
    subgraph Client Layer
        Shell[neumann_shell]
    end

    subgraph Query Layer
        Router[query_router]
        Parser[neumann_parser]
    end

    subgraph Engine Layer
        RE[relational_engine]
        GE[graph_engine]
        VE[vector_engine]
    end

    subgraph Storage Layer
        TS[tensor_store]
        TC[tensor_compress]
    end

    subgraph Extended Modules
        Vault[tensor_vault]
        Cache[tensor_cache]
        Blob[tensor_blob]
        Check[tensor_checkpoint]
        Unified[tensor_unified]
        Chain[tensor_chain]
    end

    Shell --&gt; Router
    Router --&gt; Parser
    Router --&gt; RE
    Router --&gt; GE
    Router --&gt; VE
    Router --&gt; Vault
    Router --&gt; Cache
    Router --&gt; Blob
    Router --&gt; Chain

    RE --&gt; TS
    GE --&gt; TS
    VE --&gt; TS
    Vault --&gt; TS
    Cache --&gt; TS
    Blob --&gt; TS
    Check --&gt; TS
    Unified --&gt; RE
    Unified --&gt; GE
    Unified --&gt; VE
    Chain --&gt; TS
    Chain --&gt; GE
    Chain --&gt; Check

    TS --&gt; TC
</pre>
<h2 id="module-dependencies"><a class="header" href="#module-dependencies">Module Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Purpose</th><th>Depends On</th></tr></thead><tbody>
<tr><td>tensor_store</td><td>Key-value storage layer</td><td>tensor_compress</td></tr>
<tr><td>relational_engine</td><td>SQL-like tables with indexes</td><td>tensor_store</td></tr>
<tr><td>graph_engine</td><td>Graph nodes and edges</td><td>tensor_store</td></tr>
<tr><td>vector_engine</td><td>Embeddings and similarity search</td><td>tensor_store</td></tr>
<tr><td>tensor_compress</td><td>Compression algorithms</td><td>—</td></tr>
<tr><td>tensor_vault</td><td>Encrypted secret storage</td><td>tensor_store, graph_engine</td></tr>
<tr><td>tensor_cache</td><td>Semantic LLM response caching</td><td>tensor_store</td></tr>
<tr><td>tensor_blob</td><td>S3-style chunked blob storage</td><td>tensor_store</td></tr>
<tr><td>tensor_checkpoint</td><td>Atomic snapshot/restore</td><td>tensor_store</td></tr>
<tr><td>tensor_unified</td><td>Multi-engine unified storage</td><td>all engines</td></tr>
<tr><td>tensor_chain</td><td>Tensor-native blockchain</td><td>tensor_store, graph_engine, tensor_checkpoint</td></tr>
<tr><td>neumann_parser</td><td>Query tokenization and parsing</td><td>—</td></tr>
<tr><td>query_router</td><td>Unified query execution</td><td>all engines, parser</td></tr>
<tr><td>neumann_shell</td><td>Interactive CLI interface</td><td>query_router</td></tr>
</tbody></table>
</div>
<h2 id="key-design-principles"><a class="header" href="#key-design-principles">Key Design Principles</a></h2>
<h3 id="unified-data-model"><a class="header" href="#unified-data-model">Unified Data Model</a></h3>
<p>All data is represented as tensors:</p>
<ul>
<li><strong>Scalars</strong>: Single values (int, float, string, bool)</li>
<li><strong>Vectors</strong>: Dense or sparse embeddings</li>
<li><strong>Pointers</strong>: References to other entities</li>
</ul>
<h3 id="thread-safety"><a class="header" href="#thread-safety">Thread Safety</a></h3>
<p>All engines use DashMap for concurrent access:</p>
<ul>
<li>Sharded locks for write throughput</li>
<li>No lock poisoning</li>
<li>Read operations are lock-free</li>
</ul>
<h3 id="composability"><a class="header" href="#composability">Composability</a></h3>
<p>Engines can be composed:</p>
<ul>
<li>Use relational_engine alone for SQL workloads</li>
<li>Combine with graph_engine for relationship queries</li>
<li>Add vector_engine for similarity search</li>
</ul>
<h2 id="data-flow"><a class="header" href="#data-flow">Data Flow</a></h2>
<ol>
<li><strong>Query Parsing</strong>: neumann_parser tokenizes and parses input</li>
<li><strong>Query Routing</strong>: query_router dispatches to appropriate engine</li>
<li><strong>Execution</strong>: Engine performs operation using tensor_store</li>
<li><strong>Storage</strong>: tensor_store persists data with optional compression</li>
</ol>
<h2 id="distributed-architecture-tensor_chain"><a class="header" href="#distributed-architecture-tensor_chain">Distributed Architecture (tensor_chain)</a></h2>
<p>For distributed deployments:</p>
<pre class="mermaid">flowchart LR
    subgraph Cluster
        L[Leader]
        F1[Follower 1]
        F2[Follower 2]
    end

    C[Client] --&gt; L
    L --&gt; F1
    L --&gt; F2
    F1 -.-&gt; L
    F2 -.-&gt; L
</pre>
<ul>
<li><strong>Raft Consensus</strong>: Leader election and log replication</li>
<li><strong>2PC Transactions</strong>: Cross-shard atomic operations</li>
<li><strong>SWIM Gossip</strong>: Membership and failure detection</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-store-architecture"><a class="header" href="#tensor-store-architecture">Tensor Store Architecture</a></h1>
<p>The tensor_store crate is the foundational storage layer for Neumann. It
provides a unified tensor-based key-value store that holds all data -
relational, graph, and vector - in a single mathematical structure. The store
knows nothing about queries; it purely stores and retrieves tensors by key.</p>
<p>The architecture uses SlabRouter internally, which routes operations to
specialized slabs based on key prefixes. This design eliminates hash table
resize stalls by using BTreeMap-based storage, providing predictable O(log n)
performance without the throughput cliffs caused by hash map resizing.</p>
<h2 id="core-types"><a class="header" href="#core-types">Core Types</a></h2>
<h3 id="tensorvalue"><a class="header" href="#tensorvalue">TensorValue</a></h3>
<p>Represents different types of values a tensor can hold.</p>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Rust Type</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>Scalar(ScalarValue)</code></td><td>enum</td><td>Properties (name, age, active)</td></tr>
<tr><td><code>Vector(Vec&lt;f32&gt;)</code></td><td>dense array</td><td>Embeddings for similarity search</td></tr>
<tr><td><code>Sparse(SparseVector)</code></td><td>compressed</td><td>Sparse embeddings (&gt;70% zeros)</td></tr>
<tr><td><code>Pointer(String)</code></td><td>single ref</td><td>Single relationship to another tensor</td></tr>
<tr><td><code>Pointers(Vec&lt;String&gt;)</code></td><td>multi ref</td><td>Multiple relationships</td></tr>
</tbody></table>
</div>
<p><strong>Automatic Sparsification</strong>: Use <code>TensorValue::from_embedding_auto(dense)</code> to
automatically choose between dense and sparse representation based on sparsity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Automatically uses Sparse if sparsity &gt;= 70%
let val = TensorValue::from_embedding_auto(dense_vec);

// With custom thresholds (value_threshold, sparsity_threshold)
let val = TensorValue::from_embedding(dense_vec, 0.01, 0.8);
<span class="boring">}</span></code></pre></pre>
<p><strong>Vector Operations</strong>: TensorValue supports cross-format operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Dot product works across Dense, Sparse, and mixed
let dot = tensor_a.dot(&amp;tensor_b);

// Cosine similarity with automatic format handling
let sim = tensor_a.cosine_similarity(&amp;tensor_b);
<span class="boring">}</span></code></pre></pre>
<h3 id="scalarvalue"><a class="header" href="#scalarvalue">ScalarValue</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Rust Type</th><th>Example</th></tr></thead><tbody>
<tr><td><code>Null</code></td><td>—</td><td>Missing/undefined value</td></tr>
<tr><td><code>Bool</code></td><td><code>bool</code></td><td><code>true</code>, <code>false</code></td></tr>
<tr><td><code>Int</code></td><td><code>i64</code></td><td><code>42</code>, <code>-1</code></td></tr>
<tr><td><code>Float</code></td><td><code>f64</code></td><td><code>3.14159</code></td></tr>
<tr><td><code>String</code></td><td><code>String</code></td><td><code>"Alice"</code></td></tr>
<tr><td><code>Bytes</code></td><td><code>Vec&lt;u8&gt;</code></td><td>Raw binary data</td></tr>
</tbody></table>
</div>
<h3 id="tensordata"><a class="header" href="#tensordata">TensorData</a></h3>
<p>An entity that holds scalar properties, vector embeddings, and pointers to other
tensors via a <code>HashMap&lt;String, TensorValue&gt;</code> internally.</p>
<h3 id="reserved-field-names"><a class="header" href="#reserved-field-names">Reserved Field Names</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Purpose</th><th>Used By</th></tr></thead><tbody>
<tr><td><code>_out</code></td><td>Outgoing graph edge pointers</td><td>GraphEngine</td></tr>
<tr><td><code>_in</code></td><td>Incoming graph edge pointers</td><td>GraphEngine</td></tr>
<tr><td><code>_embedding</code></td><td>Vector embedding</td><td>VectorEngine</td></tr>
<tr><td><code>_label</code></td><td>Entity type/label</td><td>GraphEngine</td></tr>
<tr><td><code>_type</code></td><td>Discriminator field</td><td>All engines</td></tr>
<tr><td><code>_from</code></td><td>Edge source</td><td>GraphEngine</td></tr>
<tr><td><code>_to</code></td><td>Edge target</td><td>GraphEngine</td></tr>
<tr><td><code>_edge_type</code></td><td>Edge relationship type</td><td>GraphEngine</td></tr>
<tr><td><code>_directed</code></td><td>Edge direction flag</td><td>GraphEngine</td></tr>
<tr><td><code>_table</code></td><td>Table membership</td><td>RelationalEngine</td></tr>
<tr><td><code>_id</code></td><td>Entity ID</td><td>System</td></tr>
</tbody></table>
</div>
<h2 id="architecture-diagram"><a class="header" href="#architecture-diagram">Architecture Diagram</a></h2>
<pre><code class="language-text">TensorStore
  |
  +-- Arc&lt;SlabRouter&gt;
         |
         +-- MetadataSlab (general key-value, BTreeMap-based)
         +-- EntityIndex (sorted vocabulary + hash index)
         +-- EmbeddingSlab (dense f32 arrays)
         +-- GraphTensor (CSR format for edges)
         +-- RelationalSlab (columnar storage)
         +-- CacheRing (LRU/LFU eviction)
         +-- BlobLog (append-only blob storage)
</code></pre>
<h2 id="slabrouter-internals"><a class="header" href="#slabrouter-internals">SlabRouter Internals</a></h2>
<p>SlabRouter is the core routing layer that directs operations to specialized
storage backends based on key prefixes.</p>
<h3 id="key-routing-algorithm"><a class="header" href="#key-routing-algorithm">Key Routing Algorithm</a></h3>
<pre class="mermaid">flowchart TD
    A[put/get/delete key] --&gt; B{Classify Key}
    B --&gt;|emb:*| C[EmbeddingSlab + MetadataSlab]
    B --&gt;|node:* / edge:*| D[GraphTensor via MetadataSlab]
    B --&gt;|table:*| E[RelationalSlab via MetadataSlab]
    B --&gt;|_cache:*| F[CacheRing]
    B --&gt;|Everything else| G[MetadataSlab]
</pre>
<h3 id="key-classification"><a class="header" href="#key-classification">Key Classification</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Prefix</th><th>KeyClass</th><th>Slab</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>emb:*</code></td><td>Embedding</td><td>EmbeddingSlab + EntityIndex</td><td>Embedding vectors with stable ID assignment</td></tr>
<tr><td><code>node:*</code>, <code>edge:*</code></td><td>Graph</td><td>MetadataSlab</td><td>Graph nodes and edges</td></tr>
<tr><td><code>table:*</code></td><td>Table</td><td>MetadataSlab</td><td>Relational rows</td></tr>
<tr><td><code>_cache:*</code></td><td>Cache</td><td>CacheRing</td><td>Cached data with eviction</td></tr>
<tr><td><code>_blob:*</code></td><td>Metadata</td><td>MetadataSlab</td><td>Blob metadata (chunks stored separately)</td></tr>
<tr><td>Everything else</td><td>Metadata</td><td>MetadataSlab</td><td>General key-value storage</td></tr>
</tbody></table>
</div>
<h3 id="slabrouter-operation-flow"><a class="header" href="#slabrouter-operation-flow">SlabRouter Operation Flow</a></h3>
<p><strong>PUT Operation</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn put(&amp;self, key: &amp;str, value: TensorData) {
    match classify_key(key) {
        KeyClass::Embedding =&gt; {
            // 1. Get or create stable entity ID
            let entity_id = self.index.get_or_create(key);
            // 2. Extract and store embedding vector
            if let Some(TensorValue::Vector(vec)) = value.get("_embedding") {
                self.embeddings.set(entity_id, vec);
            }
            // 3. Store full metadata
            self.metadata.set(key, value);
        }
        KeyClass::Cache =&gt; {
            let size = estimate_size(&amp;value);
            self.cache.put(key, value, 1.0, size);
        }
        _ =&gt; self.metadata.set(key, value),
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>GET Operation</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn get(&amp;self, key: &amp;str) -&gt; Result&lt;TensorData&gt; {
    match classify_key(key) {
        KeyClass::Embedding =&gt; {
            // Try to reconstruct from embedding slab + metadata
            if let Some(entity_id) = self.index.get(key) {
                if let Some(vector) = self.embeddings.get(entity_id) {
                    let mut data = self.metadata.get(key).unwrap_or_default();
                    data.set("_embedding", TensorValue::Vector(vector));
                    return Ok(data);
                }
            }
            self.metadata.get(key)
        }
        KeyClass::Cache =&gt; self.cache.get(key),
        _ =&gt; self.metadata.get(key),
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="specialized-slabs"><a class="header" href="#specialized-slabs">Specialized Slabs</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Slab</th><th>Data Structure</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>MetadataSlab</code></td><td><code>RwLock&lt;BTreeMap&lt;String, TensorData&gt;&gt;</code></td><td>General key-value storage</td></tr>
<tr><td><code>EntityIndex</code></td><td>Sorted vocabulary + hash index</td><td>Stable ID assignment</td></tr>
<tr><td><code>EmbeddingSlab</code></td><td>Dense f32 arrays + BTreeMap</td><td>Embedding vectors</td></tr>
<tr><td><code>GraphTensor</code></td><td>CSR format (row pointers + column indices)</td><td>Graph edges</td></tr>
<tr><td><code>RelationalSlab</code></td><td>Columnar storage</td><td>Table rows</td></tr>
<tr><td><code>CacheRing</code></td><td>Ring buffer with LRU/LFU</td><td>Fixed-size cache</td></tr>
<tr><td><code>BlobLog</code></td><td>Append-only segments</td><td>Large binary data</td></tr>
</tbody></table>
</div>
<h2 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h2>
<h3 id="operation-complexity"><a class="header" href="#operation-complexity">Operation Complexity</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>put</code></td><td>O(log n)</td><td>BTreeMap insert</td></tr>
<tr><td><code>get</code></td><td>O(log n) + clone</td><td>Clone prevents reference issues</td></tr>
<tr><td><code>delete</code></td><td>O(log n)</td><td>BTreeMap remove</td></tr>
<tr><td><code>exists</code></td><td>O(log n)</td><td>BTreeMap lookup</td></tr>
<tr><td><code>scan</code></td><td>O(k + log n)</td><td>BTreeMap range, k = result count</td></tr>
<tr><td><code>scan_count</code></td><td>O(k + log n)</td><td>No allocation</td></tr>
<tr><td><code>scan_filter_map</code></td><td>O(k + log n)</td><td>Single-pass filter with selective cloning</td></tr>
<tr><td><code>len</code></td><td>O(1)</td><td>Cached count</td></tr>
<tr><td><code>clear</code></td><td>O(n)</td><td>Clears all data</td></tr>
</tbody></table>
</div>
<h3 id="throughput-comparison"><a class="header" href="#throughput-comparison">Throughput Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>SlabRouter</th><th>Previous (DashMap)</th></tr></thead><tbody>
<tr><td>PUT throughput</td><td>3.1+ M ops/sec</td><td>2.5 M ops/sec</td></tr>
<tr><td>GET throughput</td><td>4.9+ M ops/sec</td><td>4.5 M ops/sec</td></tr>
<tr><td>Throughput variance (CV)</td><td>12% steady-state</td><td>222% during resize</td></tr>
<tr><td>Resize stalls</td><td>None</td><td>99.6% throughput drops</td></tr>
</tbody></table>
</div>
<h3 id="optimized-scan-performance"><a class="header" href="#optimized-scan-performance">Optimized Scan Performance</a></h3>
<p>Use <code>scan_filter_map</code> for selective queries to avoid cloning non-matching
entries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Old path: 5000 clones for 5000 rows, ~2.6ms
let users = store.scan("users:");
let matches: Vec&lt;_&gt; = users.iter()
    .filter_map(|key| store.get(key).ok())
    .filter(|data| /* condition */)
    .collect();

// New path: 250 clones for 5% match rate, ~0.13ms (20x faster)
let matches = store.scan_filter_map("users:", |key, data| {
    if /* condition */ {
        Some(data.clone())
    } else {
        None
    }
});
<span class="boring">}</span></code></pre></pre>
<h2 id="concurrency-model"><a class="header" href="#concurrency-model">Concurrency Model</a></h2>
<p>TensorStore uses tensor-based structures instead of hash maps for predictable
performance:</p>
<ul>
<li><strong>No Resize Stalls</strong>: BTreeMap and sorted arrays grow incrementally</li>
<li><strong>Lock-free Reads</strong>: RwLock allows many concurrent readers</li>
<li><strong>Predictable Writes</strong>: O(log n) inserts, no amortized O(n) resizing</li>
<li><strong>Clone on Read</strong>: <code>get()</code> returns cloned data to avoid holding references</li>
<li><strong>Shareable Storage</strong>: TensorStore clones share the same underlying data via
Arc</li>
</ul>
<h2 id="bloomfilter"><a class="header" href="#bloomfilter">BloomFilter</a></h2>
<p>The BloomFilter provides O(1) probabilistic rejection of non-existent keys,
useful for sparse key spaces where most lookups are misses.</p>
<h3 id="mathematical-foundation"><a class="header" href="#mathematical-foundation">Mathematical Foundation</a></h3>
<p>The Bloom filter uses optimal parameters calculated as:</p>
<p><strong>Bit array size</strong>: <code>m = -n * ln(p) / (ln(2)^2)</code></p>
<ul>
<li>Where n = expected items, p = false positive rate</li>
</ul>
<p><strong>Number of hash functions</strong>: <code>k = (m/n) * ln(2)</code></p>
<ul>
<li>Clamped to range [1, 16]</li>
</ul>
<h3 id="implementation-details"><a class="header" href="#implementation-details">Implementation Details</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BloomFilter {
    bits: Box&lt;[AtomicU64]&gt;,  // Atomic u64 blocks for lock-free access
    num_bits: usize,
    num_hashes: usize,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Hash Function</strong>: Uses SipHash with different seeds for each hash function:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn hash_index&lt;K: Hash&gt;(&amp;self, key: &amp;K, seed: usize) -&gt; usize {
    let mut hasher = SipHasher::new_with_seed(seed as u64);
    key.hash(&amp;mut hasher);
    (hasher.finish() as usize) % self.num_bits
}
<span class="boring">}</span></code></pre></pre>
<h3 id="parameter-tuning-guide"><a class="header" href="#parameter-tuning-guide">Parameter Tuning Guide</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Expected Items</th><th>FP Rate</th><th>Bits</th><th>Hash Functions</th><th>Memory</th></tr></thead><tbody>
<tr><td>10,000</td><td>1%</td><td>95,851</td><td>7</td><td>~12 KB</td></tr>
<tr><td>10,000</td><td>0.1%</td><td>143,776</td><td>10</td><td>~18 KB</td></tr>
<tr><td>100,000</td><td>1%</td><td>958,506</td><td>7</td><td>~117 KB</td></tr>
<tr><td>1,000,000</td><td>1%</td><td>9,585,059</td><td>7</td><td>~1.2 MB</td></tr>
</tbody></table>
</div>
<p><strong>Gotchas</strong>:</p>
<ul>
<li>Bloom filter state is <strong>not persisted</strong> in snapshots; rebuild after load</li>
<li>Thread-safe via AtomicU64 with Relaxed ordering (eventual consistency)</li>
<li>Cannot remove items (use counting bloom filter for that case)</li>
<li>False positive rate increases if more items than expected are inserted</li>
</ul>
<h2 id="hnsw-index"><a class="header" href="#hnsw-index">HNSW Index</a></h2>
<p>Hierarchical Navigable Small World index for approximate nearest neighbor search
with O(log n) complexity.</p>
<h3 id="algorithm-overview"><a class="header" href="#algorithm-overview">Algorithm Overview</a></h3>
<pre class="mermaid">flowchart TD
    subgraph &quot;HNSW Structure&quot;
        L3[Layer 3: Entry Point] --&gt; L2[Layer 2: Skip connections]
        L2 --&gt; L1[Layer 1: More connections]
        L1 --&gt; L0[Layer 0: All nodes, dense connections]
    end

    subgraph &quot;Search Algorithm&quot;
        S1[Start at entry point, top layer] --&gt; S2[Greedy descent to layer 1]
        S2 --&gt; S3[At layer 0: ef-search candidates]
        S3 --&gt; S4[Return top-k results]
    end
</pre>
<h3 id="layer-selection"><a class="header" href="#layer-selection">Layer Selection</a></h3>
<p>New nodes are assigned layers using exponential distribution:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn random_level(&amp;self) -&gt; usize {
    let f = random_float_0_1();
    let level = (-f.ln() * self.config.ml).floor() as usize;
    level.min(32)  // Cap at 32 layers
}
<span class="boring">}</span></code></pre></pre>
<p>Where <code>ml = 1 / ln(m)</code> and m = connections per layer.</p>
<h3 id="hnswconfig-parameters"><a class="header" href="#hnswconfig-parameters">HNSWConfig Parameters</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>m</code></td><td>16</td><td>Max connections per node per layer</td></tr>
<tr><td><code>m0</code></td><td>32</td><td>Max connections at layer 0 (2*m)</td></tr>
<tr><td><code>ef_construction</code></td><td>200</td><td>Candidates during construction</td></tr>
<tr><td><code>ef_search</code></td><td>50</td><td>Candidates during search</td></tr>
<tr><td><code>ml</code></td><td>1/ln(m)</td><td>Level multiplier</td></tr>
<tr><td><code>sparsity_threshold</code></td><td>0.5</td><td>Auto-sparse storage threshold</td></tr>
<tr><td><code>max_nodes</code></td><td>10,000,000</td><td>Capacity limit (prevents memory exhaustion)</td></tr>
</tbody></table>
</div>
<h3 id="configuration-presets"><a class="header" href="#configuration-presets">Configuration Presets</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High recall (slower, more accurate)
HNSWConfig::high_recall()  // m=32, m0=64, ef_construction=400, ef_search=200

// High speed (faster, lower recall)
HNSWConfig::high_speed()   // m=8, m0=16, ef_construction=100, ef_search=20

// Custom configuration
HNSWConfig {
    m: 24,
    m0: 48,
    ef_construction: 300,
    ef_search: 100,
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="simd-accelerated-distance"><a class="header" href="#simd-accelerated-distance">SIMD-Accelerated Distance</a></h3>
<p>Dense vector operations use 8-wide SIMD (f32x8):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn dot_product(a: &amp;[f32], b: &amp;[f32]) -&gt; f32 {
    let chunks = a.len() / 8;
    let mut sum = f32x8::ZERO;

    for i in 0..chunks {
        let offset = i * 8;
        let va = f32x8::from(&amp;a[offset..offset + 8]);
        let vb = f32x8::from(&amp;b[offset..offset + 8]);
        sum += va * vb;
    }

    // Sum lanes and handle remainder
    let arr: [f32; 8] = sum.into();
    let mut result: f32 = arr.iter().sum();
    // ... scalar remainder handling
}
<span class="boring">}</span></code></pre></pre>
<h3 id="neighbor-compression"><a class="header" href="#neighbor-compression">Neighbor Compression</a></h3>
<p>HNSW neighbor lists use delta-varint encoding for 3-8x compression:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct CompressedNeighbors {
    compressed: Vec&lt;u8&gt;,  // Delta-varint encoded neighbor IDs
}

// Decompression: O(n) where n = neighbor count
fn get(&amp;self) -&gt; Vec&lt;usize&gt; {
    decompress_ids(&amp;self.compressed)
}

// Compression: Sort + delta encode
fn set(&amp;mut self, ids: &amp;[usize]) {
    let mut sorted = ids.to_vec();
    sorted.sort_unstable();
    self.compressed = compress_ids(&amp;sorted);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="storage-types"><a class="header" href="#storage-types">Storage Types</a></h3>
<pre class="mermaid">flowchart LR
    subgraph &quot;EmbeddingStorage&quot;
        D[Dense: Vec f32]
        S[Sparse: SparseVector]
        DV[Delta: DeltaVector]
        TT[TensorTrain: TTVectorCached]
    end

    D --&gt; |&quot;sparsity &gt; 50%&quot;| S
    D --&gt; |&quot;clusters around archetype&quot;| DV
    D --&gt; |&quot;high-dim 768+&quot;| TT
</pre>
<div class="table-wrapper"><table><thead><tr><th>Storage Type</th><th>Memory</th><th>Use Case</th><th>Distance Computation</th></tr></thead><tbody>
<tr><td>Dense</td><td>4 bytes/dim</td><td>General purpose</td><td>SIMD dot product</td></tr>
<tr><td>Sparse</td><td>6 bytes/nnz</td><td>&gt;50% zeros</td><td>Sparse-sparse O(nnz)</td></tr>
<tr><td>Delta</td><td>6 bytes/diff</td><td>Clustered embeddings</td><td>Via archetype</td></tr>
<tr><td>TensorTrain</td><td>8-10x compression</td><td>768+ dimensions</td><td>Native TT or reconstruct</td></tr>
</tbody></table>
</div>
<h3 id="edge-cases-and-gotchas"><a class="header" href="#edge-cases-and-gotchas">Edge Cases and Gotchas</a></h3>
<ol>
<li>
<p><strong>Delta vectors cannot be inserted directly</strong> - they require archetype
registry for distance computation. Convert to Dense first.</p>
</li>
<li>
<p><strong>TensorTrain storage</strong> - While stored in TT format, HNSW reconstructs to
dense for fast distance computation during search (native TT distance is
O(r^4) per comparison).</p>
</li>
<li>
<p><strong>Capacity limits</strong> - Default max_nodes=10M prevents memory exhaustion from
fuzzing/adversarial input. Use <code>try_insert</code> for graceful handling.</p>
</li>
<li>
<p><strong>Empty index</strong> - Entry point is <code>usize::MAX</code> when empty; search returns
empty results.</p>
</li>
</ol>
<h2 id="sparsevector"><a class="header" href="#sparsevector">SparseVector</a></h2>
<p>Memory-efficient storage for vectors with many zeros, based on the philosophy
that “zero represents absence of information, not a stored value.”</p>
<h3 id="internal-structure"><a class="header" href="#internal-structure">Internal Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SparseVector {
    dimension: usize,      // Total dimension (shell/boundary)
    positions: Vec&lt;u32&gt;,   // Sorted positions of non-zero values
    values: Vec&lt;f32&gt;,      // Corresponding values
}
<span class="boring">}</span></code></pre></pre>
<h3 id="operation-complexity-1"><a class="header" href="#operation-complexity-1">Operation Complexity</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>from_dense</code></td><td>O(n)</td><td>Filters zeros</td></tr>
<tr><td><code>to_dense</code></td><td>O(n)</td><td>Reconstructs full vector</td></tr>
<tr><td><code>get(index)</code></td><td>O(log nnz)</td><td>Binary search</td></tr>
<tr><td><code>set(index, value)</code></td><td>O(nnz)</td><td>Insert/remove maintains sort</td></tr>
<tr><td><code>dot(sparse)</code></td><td>O(min(nnz_a, nnz_b))</td><td>Merge-join on positions</td></tr>
<tr><td><code>dot_dense(dense)</code></td><td>O(nnz)</td><td>Only access stored positions</td></tr>
<tr><td><code>add(sparse)</code></td><td>O(nnz_a + nnz_b)</td><td>Merge-based</td></tr>
<tr><td><code>cosine_similarity</code></td><td>O(nnz)</td><td>Using cached magnitudes</td></tr>
</tbody></table>
</div>
<h3 id="sparse-arithmetic-operations"><a class="header" href="#sparse-arithmetic-operations">Sparse Arithmetic Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create delta from before/after states (only stores differences)
let delta = SparseVector::from_diff(&amp;before, &amp;after, threshold);

// Subtraction: self - other
let diff = a.sub(&amp;b);

// Weighted average: (w1 * a + w2 * b) / (w1 + w2)
let merged = a.weighted_average(&amp;b, 0.7, 0.3);

// Project out conflicting component
let orthogonal = v.project_orthogonal(&amp;conflict_direction);
<span class="boring">}</span></code></pre></pre>
<h3 id="distance-metrics"><a class="header" href="#distance-metrics">Distance Metrics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Range</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>cosine_similarity</code></td><td>[-1, 1]</td><td>Directional similarity</td></tr>
<tr><td><code>angular_distance</code></td><td>[0, PI]</td><td>Linear for small angles</td></tr>
<tr><td><code>geodesic_distance</code></td><td>[0, PI]</td><td>Arc length on unit sphere</td></tr>
<tr><td><code>jaccard_index</code></td><td>[0, 1]</td><td>Structural overlap (positions)</td></tr>
<tr><td><code>overlap_coefficient</code></td><td>[0, 1]</td><td>Subset containment</td></tr>
<tr><td><code>weighted_jaccard</code></td><td>[0, 1]</td><td>Value-weighted structural overlap</td></tr>
<tr><td><code>euclidean_distance</code></td><td>[0, inf)</td><td>L2 norm of difference</td></tr>
<tr><td><code>manhattan_distance</code></td><td>[0, inf)</td><td>L1 norm of difference</td></tr>
</tbody></table>
</div>
<h3 id="security-naninf-sanitization"><a class="header" href="#security-naninf-sanitization">Security: NaN/Inf Sanitization</a></h3>
<p>All similarity metrics sanitize results to prevent consensus ordering issues:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn cosine_similarity(&amp;self, other: &amp;SparseVector) -&gt; f32 {
    // ... computation ...

    // SECURITY: Sanitize result to valid range
    if result.is_nan() || result.is_infinite() {
        0.0
    } else {
        result.clamp(-1.0, 1.0)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-efficiency"><a class="header" href="#memory-efficiency">Memory Efficiency</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let sparse = SparseVector::from_dense(&amp;dense_vec);

// Metrics
sparse.sparsity()           // Fraction of zeros (0.0 - 1.0)
sparse.memory_bytes()       // Actual memory used
sparse.dense_memory_bytes() // Memory if stored dense
sparse.compression_ratio()  // Dense / Sparse ratio
<span class="boring">}</span></code></pre></pre>
<p>For a 1000-dim vector with 90% zeros:</p>
<ul>
<li>Dense: 4000 bytes</li>
<li>Sparse: ~800 bytes (100 positions <em>4 bytes + 100 values</em> 4 bytes)</li>
<li>Compression ratio: 5x</li>
</ul>
<h2 id="delta-vectors-and-archetype-registry"><a class="header" href="#delta-vectors-and-archetype-registry">Delta Vectors and Archetype Registry</a></h2>
<p>Delta encoding stores vectors as differences from reference “archetype” vectors,
providing significant compression for clustered embeddings.</p>
<h3 id="concept"><a class="header" href="#concept">Concept</a></h3>
<pre class="mermaid">flowchart LR
    subgraph &quot;Delta Encoding&quot;
        A[Archetype Vector] --&gt; |&quot;+ Delta&quot;| R[Reconstructed Vector]
        D[Delta: positions + values] --&gt; R
    end
</pre>
<p>When many embeddings cluster around common patterns:</p>
<ul>
<li>Identify archetype vectors (cluster centroids via k-means)</li>
<li>Store each embedding as: <code>archetype_id + sparse_delta</code></li>
<li>Reconstruct on demand: <code>archetype + delta = original</code></li>
</ul>
<h3 id="deltavector-structure"><a class="header" href="#deltavector-structure">DeltaVector Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DeltaVector {
    archetype_id: usize,       // Reference archetype
    dimension: usize,          // For reconstruction
    positions: Vec&lt;u16&gt;,       // Diff positions (u16 for memory)
    deltas: Vec&lt;f32&gt;,          // Delta values
    cached_magnitude: Option&lt;f32&gt;,  // For fast cosine similarity
}
<span class="boring">}</span></code></pre></pre>
<h3 id="optimized-dot-products"><a class="header" href="#optimized-dot-products">Optimized Dot Products</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// With precomputed archetype dot query
// Total: O(nnz) instead of O(dimension)
let result = delta.dot_dense_with_precomputed(query, archetype_dot_query);

// Between two deltas from SAME archetype
// dot(A, B) = dot(R, R) + dot(R, delta_b) + dot(delta_a, R) + dot(delta_a, delta_b)
let result = a.dot_same_archetype(&amp;b, archetype, archetype_magnitude_sq);
<span class="boring">}</span></code></pre></pre>
<h3 id="archetyperegistry"><a class="header" href="#archetyperegistry">ArchetypeRegistry</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create registry with max 16 archetypes
let mut registry = ArchetypeRegistry::new(16);

// Discover archetypes via k-means clustering
let config = KMeansConfig {
    max_iterations: 100,
    convergence_threshold: 1e-4,
    seed: 42,
    init_method: KMeansInit::KMeansPlusPlus,  // Better but slower
};
registry.discover_archetypes(&amp;embeddings, 5, config);

// Encode vectors as deltas
let delta = registry.encode(&amp;vector, threshold)?;

// Analyze coverage
let stats = registry.analyze_coverage(&amp;vectors, 0.01);
// stats.avg_similarity, stats.avg_compression_ratio, stats.archetype_usage
<span class="boring">}</span></code></pre></pre>
<h3 id="persistence-1"><a class="header" href="#persistence-1">Persistence</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Save to TensorStore
registry.save_to_store(&amp;store)?;

// Load from TensorStore
let registry = ArchetypeRegistry::load_from_store(&amp;store, 16)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="tiered-storage"><a class="header" href="#tiered-storage">Tiered Storage</a></h2>
<p>Two-tier storage with hot (in-memory) and cold (mmap) layers for
memory-efficient storage of large datasets.</p>
<h3 id="architecture"><a class="header" href="#architecture">Architecture</a></h3>
<pre class="mermaid">flowchart TD
    subgraph &quot;Hot Tier (In-Memory)&quot;
        H[MetadataSlab]
        I[ShardAccessTracker]
    end

    subgraph &quot;Cold Tier (Mmap)&quot;
        C[MmapStoreMut]
        CK[cold_keys HashSet]
    end

    GET --&gt; H
    H --&gt;|miss| CK
    CK --&gt;|found| C
    C --&gt;|promote| H

    PUT --&gt; H
    H --&gt;|migrate_cold| C
</pre>
<h3 id="tieredconfig"><a class="header" href="#tieredconfig">TieredConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>cold_dir</code></td><td><code>PathBuf</code></td><td><code>/tmp/tensor_cold</code></td><td>Directory for cold storage files</td></tr>
<tr><td><code>cold_capacity</code></td><td><code>usize</code></td><td>64MB</td><td>Initial cold file size</td></tr>
<tr><td><code>sample_rate</code></td><td><code>u32</code></td><td>100</td><td>Access tracking sampling (100 = 1%)</td></tr>
</tbody></table>
</div>
<h3 id="migration-algorithm"><a class="header" href="#migration-algorithm">Migration Algorithm</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn migrate_cold(&amp;mut self, threshold_ms: u64) -&gt; Result&lt;usize&gt; {
    // 1. Find shards not accessed within threshold
    let cold_shards = self.instrumentation.cold_shards(threshold_ms);

    // 2. Collect keys belonging to cold shards
    let keys_to_migrate: Vec&lt;String&gt; = self.hot.scan("")
        .filter(|(key, _)| {
            let shard = shard_for_key(key);
            cold_shards.contains(&amp;shard)
        })
        .map(|(key, _)| key)
        .collect();

    // 3. Move to cold storage
    for key in keys_to_migrate {
        cold.insert(&amp;key, &amp;tensor)?;
        self.cold_keys.insert(key.clone());
        self.hot.delete(&amp;key);
    }

    cold.flush()?;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="automatic-promotion"><a class="header" href="#automatic-promotion">Automatic Promotion</a></h3>
<p>When cold data is accessed, it’s automatically promoted back to hot:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get(&amp;mut self, key: &amp;str) -&gt; Result&lt;TensorData&gt; {
    // Try hot first
    if let Some(data) = self.hot.get(key) {
        return Ok(data);
    }

    // Try cold
    if self.cold_keys.contains(key) {
        let tensor = self.cold.get(key)?;

        // Promote to hot
        self.hot.set(key, tensor.clone());
        self.cold_keys.remove(key);
        self.migrations_to_hot.fetch_add(1, Ordering::Relaxed);

        return Ok(tensor);
    }

    Err(TensorStoreError::NotFound(key))
}
<span class="boring">}</span></code></pre></pre>
<h3 id="statistics"><a class="header" href="#statistics">Statistics</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let stats = store.stats();
// stats.hot_count, stats.cold_count
// stats.hot_lookups, stats.cold_lookups, stats.cold_hits
// stats.migrations_to_cold, stats.migrations_to_hot
<span class="boring">}</span></code></pre></pre>
<h2 id="access-instrumentation"><a class="header" href="#access-instrumentation">Access Instrumentation</a></h2>
<p>Low-overhead tracking of shard access patterns for intelligent memory tiering.</p>
<h3 id="shardaccesstracker"><a class="header" href="#shardaccesstracker">ShardAccessTracker</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ShardAccessTracker {
    shards: Box&lt;[ShardStats]&gt;,     // Per-shard counters
    shard_count: usize,            // Default: 16
    start_time: Instant,           // For last_access timestamps
    sample_rate: u32,              // 1 = every access, 100 = 1%
    sample_counter: AtomicU64,     // For sampling
}

// Sampling logic
fn should_sample(&amp;self) -&gt; bool {
    if self.sample_rate == 1 { return true; }
    self.sample_counter.fetch_add(1, Relaxed).is_multiple_of(self.sample_rate)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="hotcold-detection"><a class="header" href="#hotcold-detection">Hot/Cold Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get shards sorted by access count (hottest first)
let hot = tracker.hot_shards(5);  // Top 5 hottest

// Get shards not accessed within threshold
let cold = tracker.cold_shards(30_000);  // Not accessed in 30s
<span class="boring">}</span></code></pre></pre>
<h3 id="hnsw-access-stats"><a class="header" href="#hnsw-access-stats">HNSW Access Stats</a></h3>
<p>Specialized instrumentation for HNSW index:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HNSWAccessStats {
    entry_point_accesses: AtomicU64,
    layer0_traversals: AtomicU64,
    upper_layer_traversals: AtomicU64,
    total_searches: AtomicU64,
    distance_calculations: AtomicU64,
}

// Snapshot metrics
let stats = hnsw.access_stats()?;
stats.layer0_ratio()          // Layer 0 work fraction
stats.avg_distances_per_search  // Distance calcs per search
stats.searches_per_second()   // Throughput
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h2>
<h3 id="slabrouterconfig"><a class="header" href="#slabrouterconfig">SlabRouterConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>embedding_dim</code></td><td><code>usize</code></td><td>384</td><td>Embedding dimension for EmbeddingSlab</td></tr>
<tr><td><code>cache_capacity</code></td><td><code>usize</code></td><td>10,000</td><td>Cache capacity for CacheRing</td></tr>
<tr><td><code>cache_strategy</code></td><td><code>EvictionStrategy</code></td><td>Default</td><td>Eviction strategy (LRU/LFU)</td></tr>
<tr><td><code>blob_segment_size</code></td><td><code>usize</code></td><td>64MB</td><td>Segment size for BlobLog</td></tr>
<tr><td><code>graph_merge_threshold</code></td><td><code>usize</code></td><td>10,000</td><td>Merge threshold for GraphTensor</td></tr>
</tbody></table>
</div>
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage Examples</a></h2>
<h3 id="basic-operations-1"><a class="header" href="#basic-operations-1">Basic Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let store = TensorStore::new();

// Store a tensor
let mut user = TensorData::new();
user.set("name", TensorValue::Scalar(ScalarValue::String("Alice".into())));
user.set("age", TensorValue::Scalar(ScalarValue::Int(30)));
user.set("embedding", TensorValue::Vector(vec![0.1, 0.2, 0.3, 0.4]));
store.put("user:1", user)?;

// Retrieve
let data = store.get("user:1")?;

// Scan by prefix
let user_keys = store.scan("user:");
let count = store.scan_count("user:");
<span class="boring">}</span></code></pre></pre>
<h3 id="with-bloom-filter"><a class="header" href="#with-bloom-filter">With Bloom Filter</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Fast rejection of non-existent keys
let store = TensorStore::with_bloom_filter(10_000, 0.01);
store.put("key:1", tensor)?;

// O(1) rejection if key definitely doesn't exist
if store.exists("key:999") { /* ... */ }
<span class="boring">}</span></code></pre></pre>
<h3 id="with-instrumentation"><a class="header" href="#with-instrumentation">With Instrumentation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Enable access tracking with 1% sampling
let store = TensorStore::with_instrumentation(100);

// After operations, check access patterns
let snapshot = store.access_snapshot()?;
println!("Hot shards: {:?}", store.hot_shards(5)?);
println!("Cold shards: {:?}", store.cold_shards(30_000)?);
<span class="boring">}</span></code></pre></pre>
<h3 id="shared-storage-across-engines"><a class="header" href="#shared-storage-across-engines">Shared Storage Across Engines</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let store = TensorStore::new();

// Clone shares the same underlying Arc&lt;SlabRouter&gt;
let store_clone = store.clone();

// Both see the same data
store.put("user:1", user_data)?;
assert!(store_clone.exists("user:1"));

// Use with multiple engines
let vector_engine = VectorEngine::with_store(store.clone());
let graph_engine = GraphEngine::with_store(store.clone());
<span class="boring">}</span></code></pre></pre>
<h3 id="persistence-2"><a class="header" href="#persistence-2">Persistence</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Save snapshot
store.save_snapshot("data.bin")?;

// Load snapshot
let store = TensorStore::load_snapshot("data.bin")?;

// Load with Bloom filter rebuild
let store = TensorStore::load_snapshot_with_bloom_filter(
    "data.bin",
    10_000,   // expected items
    0.01      // false positive rate
)?;

// Compressed snapshot
use tensor_compress::{CompressionConfig, QuantMode};
let config = CompressionConfig {
    vector_quantization: Some(QuantMode::Int8),  // 4x compression
    delta_encoding: true,
    rle_encoding: true,
};
store.save_snapshot_compressed("data.bin", config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="tiered-storage-1"><a class="header" href="#tiered-storage-1">Tiered Storage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::{TieredStore, TieredConfig};

let config = TieredConfig {
    cold_dir: "/data/cold".into(),
    cold_capacity: 64 * 1024 * 1024,
    sample_rate: 100,
};

let mut store = TieredStore::new(config)?;
store.put("user:1", tensor);

// Migrate cold data (not accessed in 30s)
let migrated = store.migrate_cold(30_000)?;

// Check stats
let stats = store.stats();
println!("Hot: {}, Cold: {}", stats.hot_count, stats.cold_count);
<span class="boring">}</span></code></pre></pre>
<h3 id="hnsw-index-1"><a class="header" href="#hnsw-index-1">HNSW Index</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let index = HNSWIndex::with_config(HNSWConfig::default());

// Insert dense, sparse, or auto-select
index.insert(vec![0.1, 0.2, 0.3]);
index.insert_sparse(sparse_vec);
index.insert_auto(mixed_vec);  // Auto-selects dense/sparse

// With capacity checking
match index.try_insert(vec) {
    Ok(id) =&gt; println!("Inserted as node {}", id),
    Err(EmbeddingStorageError::CapacityExceeded { limit, current }) =&gt; {
        println!("Index full: {} / {}", current, limit);
    }
}

// Search with custom ef
let results = index.search_with_ef(&amp;query, 10, 100);
for (id, similarity) in results {
    println!("Node {}: {:.4}", id, similarity);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="delta-encoded-embeddings"><a class="header" href="#delta-encoded-embeddings">Delta-Encoded Embeddings</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut registry = ArchetypeRegistry::new(16);

// Discover archetypes from existing embeddings
registry.discover_archetypes(&amp;embeddings, 5, KMeansConfig::default());

// Encode new vectors as deltas
let results = registry.encode_batch(&amp;embeddings, 0.01);
for (delta, compression_ratio) in results {
    println!("Archetype {}, compression: {:.2}x",
             delta.archetype_id(), compression_ratio);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-types"><a class="header" href="#error-types">Error Types</a></h2>
<h3 id="tensorstoreerror"><a class="header" href="#tensorstoreerror">TensorStoreError</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th></tr></thead><tbody>
<tr><td><code>NotFound(key)</code></td><td><code>get</code> or <code>delete</code> on nonexistent key</td></tr>
</tbody></table>
</div>
<h3 id="snapshoterror"><a class="header" href="#snapshoterror">SnapshotError</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th></tr></thead><tbody>
<tr><td><code>IoError(std::io::Error)</code></td><td>File not found, permission denied, disk full</td></tr>
<tr><td><code>SerializationError(String)</code></td><td>Corrupted file, incompatible format</td></tr>
</tbody></table>
</div>
<h3 id="tierederror"><a class="header" href="#tierederror">TieredError</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th></tr></thead><tbody>
<tr><td><code>Store(TensorStoreError)</code></td><td>Underlying store error</td></tr>
<tr><td><code>Mmap(MmapError)</code></td><td>Memory-mapped file error</td></tr>
<tr><td><code>Io(std::io::Error)</code></td><td>I/O error</td></tr>
<tr><td><code>NotConfigured</code></td><td>Cold storage not configured</td></tr>
</tbody></table>
</div>
<h3 id="embeddingstorageerror"><a class="header" href="#embeddingstorageerror">EmbeddingStorageError</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th></tr></thead><tbody>
<tr><td><code>DeltaRequiresRegistry</code></td><td>Delta storage used without archetype registry</td></tr>
<tr><td><code>ArchetypeNotFound(id)</code></td><td>Referenced archetype not in registry</td></tr>
<tr><td><code>CapacityExceeded { limit, current }</code></td><td>HNSW index at max_nodes limit</td></tr>
<tr><td><code>DeltaNotSupported</code></td><td>Delta vectors inserted into HNSW (unsupported)</td></tr>
</tbody></table>
</div>
<h2 id="related-modules"><a class="header" href="#related-modules">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>relational_engine</code></td><td>Uses TensorStore for table row storage</td></tr>
<tr><td><code>graph_engine</code></td><td>Uses TensorStore for node/edge storage</td></tr>
<tr><td><code>vector_engine</code></td><td>Uses TensorStore + HNSWIndex for embeddings</td></tr>
<tr><td><code>tensor_compress</code></td><td>Provides compression for snapshots</td></tr>
<tr><td><code>tensor_checkpoint</code></td><td>Uses TensorStore snapshots for atomic restore</td></tr>
<tr><td><code>tensor_chain</code></td><td>Uses TensorStore for blockchain state</td></tr>
</tbody></table>
</div>
<h2 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>serde</code></td><td>Serialization</td></tr>
<tr><td><code>bincode</code></td><td>Binary snapshot format</td></tr>
<tr><td><code>tensor_compress</code></td><td>Compression algorithms</td></tr>
<tr><td><code>wide</code></td><td>SIMD operations (f32x8)</td></tr>
<tr><td><code>memmap2</code></td><td>Memory-mapped files</td></tr>
<tr><td><code>fxhash</code></td><td>Fast hashing</td></tr>
<tr><td><code>parking_lot</code></td><td>Efficient locks</td></tr>
<tr><td><code>bitvec</code></td><td>Bit vectors for bloom filter</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="relational-engine"><a class="header" href="#relational-engine">Relational Engine</a></h1>
<p>The Relational Engine (Module 2) provides SQL-like table operations on top of
the Tensor Store. It implements schema enforcement, composable condition
predicates, SIMD-accelerated columnar filtering, and both hash and B-tree
indexes for query acceleration.</p>
<p>Tables, rows, and indexes are stored as tensor data in the underlying Tensor
Store, inheriting its thread safety from DashMap. The engine supports all
standard CRUD operations, six SQL join types, aggregate functions, and batch
operations for bulk inserts.</p>
<h2 id="architecture-1"><a class="header" href="#architecture-1">Architecture</a></h2>
<pre class="mermaid">flowchart TD
    subgraph RelationalEngine
        API[Public API]
        Schema[Schema Validation]
        Cond[Condition Evaluation]
        Hash[Hash Index]
        BTree[B-Tree Index]
        Columnar[Columnar SIMD]
    end

    API --&gt; Schema
    API --&gt; Cond
    Cond --&gt; Hash
    Cond --&gt; BTree
    Cond --&gt; Columnar

    subgraph TensorStore
        Store[(DashMap Storage)]
        Meta[Table Metadata]
        Rows[Row Data]
        Idx[Index Entries]
    end

    Schema --&gt; Meta
    API --&gt; Rows
    Hash --&gt; Idx
    BTree --&gt; Idx
</pre>
<h3 id="query-execution-flow"><a class="header" href="#query-execution-flow">Query Execution Flow</a></h3>
<pre class="mermaid">flowchart TD
    Query[SELECT Query] --&gt; ParseCond[Parse Condition]
    ParseCond --&gt; CheckIdx{Has Index?}

    CheckIdx --&gt;|Hash Index + Eq| HashLookup[O(1) Hash Lookup]
    CheckIdx --&gt;|BTree + Range| BTreeRange[O(log n) Range Scan]
    CheckIdx --&gt;|No Index| FullScan[Full Table Scan]

    HashLookup --&gt; FilterRows[Apply Remaining Conditions]
    BTreeRange --&gt; FilterRows
    FullScan --&gt; SIMDFilter{Columnar Data?}

    SIMDFilter --&gt;|Yes| VectorFilter[SIMD Vectorized Filter]
    SIMDFilter --&gt;|No| RowFilter[Row-by-Row Filter]

    VectorFilter --&gt; Results[Build Result Set]
    RowFilter --&gt; Results
    FilterRows --&gt; Results
</pre>
<h2 id="key-types"><a class="header" href="#key-types">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>RelationalEngine</code></td><td>Main engine struct with TensorStore backend</td></tr>
<tr><td><code>RelationalConfig</code></td><td>Configuration for limits, timeouts, thresholds</td></tr>
<tr><td><code>Schema</code></td><td>Table schema with column definitions and constraints</td></tr>
<tr><td><code>Column</code></td><td>Column name, type, and nullability</td></tr>
<tr><td><code>ColumnType</code></td><td><code>Int</code>, <code>Float</code>, <code>String</code>, <code>Bool</code>, <code>Bytes</code>, <code>Json</code></td></tr>
<tr><td><code>Value</code></td><td>Typed value: <code>Null</code>, <code>Int(i64)</code>, <code>Float(f64)</code>, <code>String(String)</code>, <code>Bool(bool)</code>, <code>Bytes(Vec&lt;u8&gt;)</code>, <code>Json(Value)</code></td></tr>
<tr><td><code>Row</code></td><td>Row with ID and ordered column values</td></tr>
<tr><td><code>Condition</code></td><td>Composable filter predicate tree</td></tr>
<tr><td><code>Constraint</code></td><td>Table constraint: <code>PrimaryKey</code>, <code>Unique</code>, <code>ForeignKey</code>, <code>NotNull</code></td></tr>
<tr><td><code>ForeignKeyConstraint</code></td><td>Foreign key definition with referential actions</td></tr>
<tr><td><code>ReferentialAction</code></td><td><code>Restrict</code>, <code>Cascade</code>, <code>SetNull</code>, <code>SetDefault</code>, <code>NoAction</code></td></tr>
<tr><td><code>RelationalError</code></td><td>Error variants for table/column/index/constraint operations</td></tr>
<tr><td><code>ColumnData</code></td><td>Columnar storage for a single column with null bitmap</td></tr>
<tr><td><code>SelectionVector</code></td><td>Bitmap-based row selection for SIMD operations</td></tr>
<tr><td><code>OrderedKey</code></td><td>B-tree index key with total ordering semantics</td></tr>
<tr><td><code>StreamingCursor</code></td><td>Iterator for batch-based query result streaming</td></tr>
<tr><td><code>CursorBuilder</code></td><td>Builder for customizing streaming cursor options</td></tr>
<tr><td><code>QueryMetrics</code></td><td>Query execution metrics for observability</td></tr>
<tr><td><code>IndexTracker</code></td><td>Tracks index hits/misses to detect missing indexes</td></tr>
</tbody></table>
</div>
<h3 id="column-types"><a class="header" href="#column-types">Column Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Rust Type</th><th>Storage Format</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Int</code></td><td><code>i64</code></td><td>8-byte little-endian</td><td>64-bit signed integer</td></tr>
<tr><td><code>Float</code></td><td><code>f64</code></td><td>8-byte IEEE 754</td><td>64-bit floating point</td></tr>
<tr><td><code>String</code></td><td><code>String</code></td><td>Dictionary-encoded</td><td>UTF-8 string with deduplication</td></tr>
<tr><td><code>Bool</code></td><td><code>bool</code></td><td>Packed bitmap (64 values per u64)</td><td>Boolean</td></tr>
<tr><td><code>Bytes</code></td><td><code>Vec&lt;u8&gt;</code></td><td>Raw bytes</td><td>Binary data</td></tr>
<tr><td><code>Json</code></td><td><code>serde_json::Value</code></td><td>JSON string</td><td>JSON value</td></tr>
</tbody></table>
</div>
<h3 id="conditions"><a class="header" href="#conditions">Conditions</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Condition</th><th>Description</th><th>Index Support</th></tr></thead><tbody>
<tr><td><code>Condition::True</code></td><td>Matches all rows</td><td>N/A</td></tr>
<tr><td><code>Condition::Eq(col, val)</code></td><td>Column equals value</td><td>Hash Index</td></tr>
<tr><td><code>Condition::Ne(col, val)</code></td><td>Column not equals value</td><td>None</td></tr>
<tr><td><code>Condition::Lt(col, val)</code></td><td>Column less than value</td><td>B-Tree Index</td></tr>
<tr><td><code>Condition::Le(col, val)</code></td><td>Column less than or equal</td><td>B-Tree Index</td></tr>
<tr><td><code>Condition::Gt(col, val)</code></td><td>Column greater than value</td><td>B-Tree Index</td></tr>
<tr><td><code>Condition::Ge(col, val)</code></td><td>Column greater than or equal</td><td>B-Tree Index</td></tr>
<tr><td><code>Condition::And(a, b)</code></td><td>Logical AND of two conditions</td><td>Partial (first indexable)</td></tr>
<tr><td><code>Condition::Or(a, b)</code></td><td>Logical OR of two conditions</td><td>None</td></tr>
</tbody></table>
</div>
<p>Conditions can be combined using <code>.and()</code> and <code>.or()</code> methods:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// age &gt;= 18 AND age &lt; 65
let condition = Condition::Ge("age".into(), Value::Int(18))
    .and(Condition::Lt("age".into(), Value::Int(65)));

// status = 'active' OR priority &gt; 5
let condition = Condition::Eq("status".into(), Value::String("active".into()))
    .or(Condition::Gt("priority".into(), Value::Int(5)));
<span class="boring">}</span></code></pre></pre>
<p>The special column <code>_id</code> filters by row ID and can be indexed.</p>
<h3 id="error-types-1"><a class="header" href="#error-types-1">Error Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th></tr></thead><tbody>
<tr><td><code>TableNotFound</code></td><td>Table does not exist</td></tr>
<tr><td><code>TableAlreadyExists</code></td><td>Creating duplicate table</td></tr>
<tr><td><code>ColumnNotFound</code></td><td>Update references unknown column</td></tr>
<tr><td><code>ColumnAlreadyExists</code></td><td>Column already exists in table</td></tr>
<tr><td><code>TypeMismatch</code></td><td>Value type does not match column type</td></tr>
<tr><td><code>NullNotAllowed</code></td><td>NULL in non-nullable column</td></tr>
<tr><td><code>IndexAlreadyExists</code></td><td>Creating duplicate index</td></tr>
<tr><td><code>IndexNotFound</code></td><td>Dropping non-existent index</td></tr>
<tr><td><code>IndexCorrupted</code></td><td>Index data is corrupted</td></tr>
<tr><td><code>StorageError</code></td><td>Underlying Tensor Store error</td></tr>
<tr><td><code>InvalidName</code></td><td>Invalid table or column name</td></tr>
<tr><td><code>SchemaCorrupted</code></td><td>Schema metadata is corrupted</td></tr>
<tr><td><code>TransactionNotFound</code></td><td>Transaction ID not found</td></tr>
<tr><td><code>TransactionInactive</code></td><td>Transaction already committed/aborted</td></tr>
<tr><td><code>LockConflict</code></td><td>Lock conflict with another transaction</td></tr>
<tr><td><code>LockTimeout</code></td><td>Lock acquisition timed out</td></tr>
<tr><td><code>RollbackFailed</code></td><td>Rollback operation failed</td></tr>
<tr><td><code>ResultTooLarge</code></td><td>Result set exceeds maximum size</td></tr>
<tr><td><code>TooManyTables</code></td><td>Maximum table count exceeded</td></tr>
<tr><td><code>TooManyIndexes</code></td><td>Maximum index count exceeded</td></tr>
<tr><td><code>QueryTimeout</code></td><td>Query execution timed out</td></tr>
<tr><td><code>PrimaryKeyViolation</code></td><td>Primary key constraint violated</td></tr>
<tr><td><code>UniqueViolation</code></td><td>Unique constraint violated</td></tr>
<tr><td><code>ForeignKeyViolation</code></td><td>Foreign key constraint violated on insert/update</td></tr>
<tr><td><code>ForeignKeyRestrict</code></td><td>Foreign key prevents delete/update</td></tr>
<tr><td><code>ConstraintNotFound</code></td><td>Constraint does not exist</td></tr>
<tr><td><code>ConstraintAlreadyExists</code></td><td>Constraint already exists</td></tr>
<tr><td><code>ColumnHasConstraint</code></td><td>Column has constraint preventing operation</td></tr>
<tr><td><code>CannotAddColumn</code></td><td>Cannot add column due to constraint</td></tr>
</tbody></table>
</div>
<h2 id="storage-model"><a class="header" href="#storage-model">Storage Model</a></h2>
<p>Tables, rows, and indexes are stored in Tensor Store with specific key patterns:</p>
<div class="table-wrapper"><table><thead><tr><th>Key Pattern</th><th>Content</th></tr></thead><tbody>
<tr><td><code>_meta:table:{name}</code></td><td>Schema metadata</td></tr>
<tr><td><code>{table}:{row_id}</code></td><td>Row data</td></tr>
<tr><td><code>_idx:{table}:{column}</code></td><td>Hash index metadata</td></tr>
<tr><td><code>_idx:{table}:{column}:{hash}</code></td><td>Hash index entries (list of row IDs)</td></tr>
<tr><td><code>_btree:{table}:{column}</code></td><td>B-tree index metadata</td></tr>
<tr><td><code>_btree:{table}:{column}:{sortable_key}</code></td><td>B-tree index entries</td></tr>
<tr><td><code>_col:{table}:{column}:data</code></td><td>Columnar data storage</td></tr>
<tr><td><code>_col:{table}:{column}:ids</code></td><td>Columnar row ID mapping</td></tr>
<tr><td><code>_col:{table}:{column}:nulls</code></td><td>Columnar null bitmap</td></tr>
<tr><td><code>_col:{table}:{column}:meta</code></td><td>Columnar metadata</td></tr>
</tbody></table>
</div>
<p>Schema metadata encodes:</p>
<ul>
<li><code>_columns</code>: Comma-separated column names</li>
<li><code>_col:{name}</code>: Type and nullability for each column</li>
</ul>
<h3 id="row-storage-format"><a class="header" href="#row-storage-format">Row Storage Format</a></h3>
<p>Each row is stored as a <code>TensorData</code> object:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Internal row structure
{
    "_id": Scalar(Int(row_id)),
    "name": Scalar(String("Alice")),
    "age": Scalar(Int(30)),
    "email": Scalar(String("alice@example.com"))
}
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples-1"><a class="header" href="#usage-examples-1">Usage Examples</a></h2>
<h3 id="table-operations"><a class="header" href="#table-operations">Table Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let engine = RelationalEngine::new();

// Create table with schema
let schema = Schema::new(vec![
    Column::new("name", ColumnType::String),
    Column::new("age", ColumnType::Int),
    Column::new("email", ColumnType::String).nullable(),
]);
engine.create_table("users", schema)?;

// Check existence
engine.table_exists("users")?;  // -&gt; bool

// List all tables
let tables = engine.list_tables();  // -&gt; Vec&lt;String&gt;

// Get schema
let schema = engine.get_schema("users")?;

// Drop table (deletes all rows and indexes)
engine.drop_table("users")?;

// Row count
engine.row_count("users")?;  // -&gt; usize
<span class="boring">}</span></code></pre></pre>
<h3 id="crud-operations"><a class="header" href="#crud-operations">CRUD Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// INSERT
let mut values = HashMap::new();
values.insert("name".to_string(), Value::String("Alice".into()));
values.insert("age".to_string(), Value::Int(30));
let row_id = engine.insert("users", values)?;

// BATCH INSERT (59x faster for bulk inserts)
let rows: Vec&lt;HashMap&lt;String, Value&gt;&gt; = (0..1000)
    .map(|i| {
        let mut values = HashMap::new();
        values.insert("name".to_string(), Value::String(format!("User{}", i)));
        values.insert("age".to_string(), Value::Int(20 + i));
        values
    })
    .collect();
let row_ids = engine.batch_insert("users", rows)?;

// SELECT
let rows = engine.select("users", Condition::Eq("age".into(), Value::Int(30)))?;

// UPDATE
let mut updates = HashMap::new();
updates.insert("age".to_string(), Value::Int(31));
let count = engine.update(
    "users",
    Condition::Eq("name".into(), Value::String("Alice".into())),
    updates
)?;

// DELETE
let count = engine.delete_rows("users", Condition::Lt("age".into(), Value::Int(18)))?;
<span class="boring">}</span></code></pre></pre>
<h3 id="constraints"><a class="header" href="#constraints">Constraints</a></h3>
<p>The engine supports four constraint types for data integrity:</p>
<div class="table-wrapper"><table><thead><tr><th>Constraint</th><th>Description</th></tr></thead><tbody>
<tr><td><code>PrimaryKey</code></td><td>Unique + not null, identifies rows uniquely</td></tr>
<tr><td><code>Unique</code></td><td>Values must be unique (NULLs allowed)</td></tr>
<tr><td><code>ForeignKey</code></td><td>References rows in another table</td></tr>
<tr><td><code>NotNull</code></td><td>Column cannot contain NULL values</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::{Constraint, ForeignKeyConstraint, ReferentialAction};

// Create table with constraints
let schema = Schema::with_constraints(
    vec![
        Column::new("id", ColumnType::Int),
        Column::new("email", ColumnType::String),
        Column::new("dept_id", ColumnType::Int).nullable(),
    ],
    vec![
        Constraint::primary_key("pk_users", vec!["id".to_string()]),
        Constraint::unique("uq_email", vec!["email".to_string()]),
    ],
);
engine.create_table("users", schema)?;

// Add constraint after table creation
engine.add_constraint("users", Constraint::not_null("nn_email", "email"))?;

// Add foreign key with referential actions
let fk = ForeignKeyConstraint::new(
    "fk_users_dept",
    vec!["dept_id".to_string()],
    "departments",
    vec!["id".to_string()],
)
.on_delete(ReferentialAction::SetNull)
.on_update(ReferentialAction::Cascade);
engine.add_constraint("users", Constraint::foreign_key(fk))?;

// Get constraints
let constraints = engine.get_constraints("users")?;

// Drop constraint
engine.drop_constraint("users", "uq_email")?;
<span class="boring">}</span></code></pre></pre>
<h4 id="referential-actions"><a class="header" href="#referential-actions">Referential Actions</a></h4>
<p>Foreign keys support these actions on delete/update of referenced rows:</p>
<div class="table-wrapper"><table><thead><tr><th>Action</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Restrict</code> (default)</td><td>Prevent the operation</td></tr>
<tr><td><code>Cascade</code></td><td>Cascade to referencing rows</td></tr>
<tr><td><code>SetNull</code></td><td>Set referencing columns to NULL</td></tr>
<tr><td><code>SetDefault</code></td><td>Set referencing columns to default</td></tr>
<tr><td><code>NoAction</code></td><td>Same as Restrict, checked at commit</td></tr>
</tbody></table>
</div>
<h3 id="alter-table-operations"><a class="header" href="#alter-table-operations">ALTER TABLE Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add a new column (nullable or with default)
engine.add_column("users", Column::new("phone", ColumnType::String).nullable())?;

// Drop a column (fails if column has constraints)
engine.drop_column("users", "phone")?;

// Rename a column (updates constraints automatically)
engine.rename_column("users", "email", "email_address")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="joins"><a class="header" href="#joins">Joins</a></h3>
<p>All six SQL join types are supported using hash join algorithm (O(n+m)):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// INNER JOIN - Only matching rows from both tables
let joined = engine.join("users", "posts", "_id", "user_id")?;
// Returns: Vec&lt;(Row, Row)&gt;

// LEFT JOIN - All rows from left, matching from right (or None)
let joined = engine.left_join("users", "posts", "_id", "user_id")?;
// Returns: Vec&lt;(Row, Option&lt;Row&gt;)&gt;

// RIGHT JOIN - All rows from right, matching from left (or None)
let joined = engine.right_join("users", "posts", "_id", "user_id")?;
// Returns: Vec&lt;(Option&lt;Row&gt;, Row)&gt;

// FULL JOIN - All rows from both tables
let joined = engine.full_join("users", "posts", "_id", "user_id")?;
// Returns: Vec&lt;(Option&lt;Row&gt;, Option&lt;Row&gt;)&gt;

// CROSS JOIN (Cartesian product)
let joined = engine.cross_join("users", "posts")?;
// Returns: Vec&lt;(Row, Row)&gt; with n*m rows

// NATURAL JOIN (on common column names)
let joined = engine.natural_join("users", "user_profiles")?;
// Returns: Vec&lt;(Row, Row)&gt; matching on all common columns
<span class="boring">}</span></code></pre></pre>
<h3 id="aggregate-functions"><a class="header" href="#aggregate-functions">Aggregate Functions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// COUNT(*) - count all rows
let count = engine.count("users", Condition::True)?;

// COUNT(column) - count non-null values
let count = engine.count_column("users", "email", Condition::True)?;

// SUM - returns f64
let total = engine.sum("orders", "amount", Condition::True)?;

// AVG - returns Option&lt;f64&gt; (None if no matching rows)
let avg = engine.avg("orders", "amount", Condition::True)?;

// MIN/MAX - returns Option&lt;Value&gt;
let min = engine.min("products", "price", Condition::True)?;
let max = engine.max("products", "price", Condition::True)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="indexes"><a class="header" href="#indexes">Indexes</a></h2>
<h3 id="hash-indexes"><a class="header" href="#hash-indexes">Hash Indexes</a></h3>
<p>Hash indexes provide O(1) equality lookups for <code>Condition::Eq</code> queries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create hash index
engine.create_index("users", "age")?;

// Check existence
engine.has_index("users", "age");  // -&gt; bool

// Get indexed columns
engine.get_indexed_columns("users");  // -&gt; Vec&lt;String&gt;

// Drop index
engine.drop_index("users", "age")?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Hash Index Implementation Details:</strong></p>
<pre class="mermaid">graph LR
    subgraph &quot;Hash Index Structure&quot;
        Value[Column Value] --&gt; Hash[hash_key()]
        Hash --&gt; Bucket[&quot;_idx:table:col:hash&quot;]
        Bucket --&gt; IDs[&quot;Vec&lt;row_id&gt;&quot;]
    end
</pre>
<p>The hash index uses value-specific hashing:</p>
<div class="table-wrapper"><table><thead><tr><th>Value Type</th><th>Hash Format</th><th>Example</th></tr></thead><tbody>
<tr><td><code>Null</code></td><td><code>"null"</code></td><td><code>"null"</code></td></tr>
<tr><td><code>Int(i)</code></td><td><code>"i:{value}"</code></td><td><code>"i:42"</code></td></tr>
<tr><td><code>Float(f)</code></td><td><code>"f:{bits}"</code></td><td><code>"f:4614253070214989087"</code></td></tr>
<tr><td><code>String(s)</code></td><td><code>"s:{hash}"</code></td><td><code>"s:a1b2c3d4"</code></td></tr>
<tr><td><code>Bool(b)</code></td><td><code>"b:{value}"</code></td><td><code>"b:true"</code></td></tr>
</tbody></table>
</div>
<p>Hash index performance:</p>
<div class="table-wrapper"><table><thead><tr><th>Query Type</th><th>Without Index</th><th>With Index</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Equality (2% match on 5K rows)</td><td>5.96ms</td><td>126us</td><td>47x</td></tr>
<tr><td>Single row by _id (5K rows)</td><td>5.59ms</td><td>3.5us</td><td>1,597x</td></tr>
</tbody></table>
</div>
<h3 id="b-tree-indexes"><a class="header" href="#b-tree-indexes">B-Tree Indexes</a></h3>
<p>B-tree indexes accelerate range queries (<code>Lt</code>, <code>Le</code>, <code>Gt</code>, <code>Ge</code>) with O(log n +
m) complexity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create B-tree index
engine.create_btree_index("users", "age")?;

// Check existence
engine.has_btree_index("users", "age");  // -&gt; bool

// Get B-tree indexed columns
engine.get_btree_indexed_columns("users");  // -&gt; Vec&lt;String&gt;

// Drop index
engine.drop_btree_index("users", "age")?;

// Range queries now use the index
engine.select("users", Condition::Ge("age".into(), Value::Int(18)))?;
<span class="boring">}</span></code></pre></pre>
<p><strong>B-Tree Index Implementation Details:</strong></p>
<p>The B-tree index uses a dual-storage approach:</p>
<ol>
<li><strong>In-memory BTreeMap</strong>: For O(log n) range operations</li>
<li><strong>Persistent TensorStore</strong>: For durability and recovery</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Internal B-tree index structure
btree_indexes: RwLock&lt;HashMap&lt;
    (String, String),           // (table, column)
    BTreeMap&lt;OrderedKey, Vec&lt;u64&gt;&gt;  // value -&gt; row_ids
&gt;&gt;
<span class="boring">}</span></code></pre></pre>
<p><strong>OrderedKey for Total Ordering:</strong></p>
<p>The <code>OrderedKey</code> enum provides correct ordering semantics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum OrderedKey {
    Null,                    // Sorts first
    Bool(bool),              // false &lt; true
    Int(i64),                // Standard integer ordering
    Float(OrderedFloat),     // NaN &lt; all other values
    String(String),          // Lexicographic ordering
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Sortable Key Encoding:</strong></p>
<p>For persistent storage, values are encoded to maintain lexicographic ordering:</p>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Encoding</th><th>Example</th></tr></thead><tbody>
<tr><td><code>Null</code></td><td><code>"0"</code></td><td><code>"0"</code></td></tr>
<tr><td><code>Int(i)</code></td><td><code>"i{hex(i + 2^63)}"</code></td><td><code>"i8000000000000000"</code> for 0</td></tr>
<tr><td><code>Float(f)</code></td><td><code>"f{sortable_bits}"</code></td><td>IEEE 754 with sign handling</td></tr>
<tr><td><code>String(s)</code></td><td><code>"s{s}"</code></td><td><code>"sAlice"</code></td></tr>
<tr><td><code>Bool(b)</code></td><td><code>"b0"</code> or <code>"b1"</code></td><td><code>"b1"</code> for true</td></tr>
</tbody></table>
</div>
<p>Integer encoding shifts the range from <code>[-2^63, 2^63-1]</code> to <code>[0, 2^64-1]</code> for
correct lexicographic ordering of negative numbers.</p>
<p><strong>B-Tree Range Operations:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Internal range lookup
fn btree_range_lookup(&amp;self, table: &amp;str, column: &amp;str,
                      value: &amp;Value, op: RangeOp) -&gt; Option&lt;Vec&lt;u64&gt;&gt; {
    match op {
        RangeOp::Lt =&gt; btree.range(..target),
        RangeOp::Le =&gt; btree.range(..=target),
        RangeOp::Gt =&gt; btree.range((Excluded(target), Unbounded)),
        RangeOp::Ge =&gt; btree.range(target..),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="columnar-architecture"><a class="header" href="#columnar-architecture">Columnar Architecture</a></h2>
<p>The engine uses columnar storage with SIMD-accelerated filtering:</p>
<h3 id="columnar-data-structures"><a class="header" href="#columnar-data-structures">Columnar Data Structures</a></h3>
<pre class="mermaid">graph TD
    subgraph &quot;ColumnData&quot;
        Name[name: String]
        RowIDs[row_ids: Vec&lt;u64&gt;]
        Nulls[nulls: NullBitmap]
        Values[values: ColumnValues]
    end

    subgraph &quot;ColumnValues Variants&quot;
        Int[&quot;Int(Vec&lt;i64&gt;)&quot;]
        Float[&quot;Float(Vec&lt;f64&gt;)&quot;]
        String[&quot;String { dict, indices }&quot;]
        Bool[&quot;Bool(Vec&lt;u64&gt;)&quot;]
    end

    subgraph &quot;NullBitmap Variants&quot;
        None[&quot;None (no nulls)&quot;]
        Dense[&quot;Dense(Vec&lt;u64&gt;)&quot;]
        Sparse[&quot;Sparse(Vec&lt;u64&gt;)&quot;]
    end

    Values --&gt; Int
    Values --&gt; Float
    Values --&gt; String
    Values --&gt; Bool
    Nulls --&gt; None
    Nulls --&gt; Dense
    Nulls --&gt; Sparse
</pre>
<p><strong>Null Bitmap Selection:</strong></p>
<ul>
<li><code>None</code>: When column has no null values</li>
<li><code>Sparse</code>: When nulls are &lt; 10% of rows (stores positions)</li>
<li><code>Dense</code>: When nulls are &gt;= 10% of rows (stores bitmap)</li>
</ul>
<h3 id="simd-filtering"><a class="header" href="#simd-filtering">SIMD Filtering</a></h3>
<p>Column data is stored in contiguous arrays enabling 4-wide SIMD vectorized
comparisons using the <code>wide</code> crate:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// SIMD filter implementation using wide::i64x4
pub fn filter_lt_i64(values: &amp;[i64], threshold: i64, result: &amp;mut [u64]) {
    let chunks = values.len() / 4;
    let threshold_vec = i64x4::splat(threshold);

    for i in 0..chunks {
        let offset = i * 4;
        let v = i64x4::new([
            values[offset],
            values[offset + 1],
            values[offset + 2],
            values[offset + 3],
        ]);
        let cmp = v.cmp_lt(threshold_vec);
        let mask_arr: [i64; 4] = cmp.into();

        for (j, &amp;m) in mask_arr.iter().enumerate() {
            if m != 0 {
                let bit_pos = offset + j;
                result[bit_pos / 64] |= 1u64 &lt;&lt; (bit_pos % 64);
            }
        }
    }

    // Handle remainder with scalar fallback
    let start = chunks * 4;
    for i in start..values.len() {
        if values[i] &lt; threshold {
            result[i / 64] |= 1u64 &lt;&lt; (i % 64);
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Available SIMD Filter Functions:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Operation</th><th>Types</th></tr></thead><tbody>
<tr><td><code>filter_lt_i64</code></td><td>Less than</td><td>i64</td></tr>
<tr><td><code>filter_le_i64</code></td><td>Less than or equal</td><td>i64</td></tr>
<tr><td><code>filter_gt_i64</code></td><td>Greater than</td><td>i64</td></tr>
<tr><td><code>filter_ge_i64</code></td><td>Greater than or equal</td><td>i64</td></tr>
<tr><td><code>filter_eq_i64</code></td><td>Equal</td><td>i64</td></tr>
<tr><td><code>filter_ne_i64</code></td><td>Not equal</td><td>i64</td></tr>
<tr><td><code>filter_lt_f64</code></td><td>Less than</td><td>f64</td></tr>
<tr><td><code>filter_gt_f64</code></td><td>Greater than</td><td>f64</td></tr>
<tr><td><code>filter_eq_f64</code></td><td>Equal (with epsilon)</td><td>f64</td></tr>
</tbody></table>
</div>
<p><strong>Bitmap Operations:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// AND two selection bitmaps
pub fn bitmap_and(a: &amp;[u64], b: &amp;[u64], result: &amp;mut [u64])

// OR two selection bitmaps
pub fn bitmap_or(a: &amp;[u64], b: &amp;[u64], result: &amp;mut [u64])

// Count set bits
pub fn popcount(bitmap: &amp;[u64]) -&gt; usize

// Extract selected indices
pub fn selected_indices(bitmap: &amp;[u64], max_count: usize) -&gt; Vec&lt;usize&gt;
<span class="boring">}</span></code></pre></pre>
<h3 id="selection-vectors"><a class="header" href="#selection-vectors">Selection Vectors</a></h3>
<p>Query results use bitmap-based selection vectors to avoid copying data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SelectionVector {
    bitmap: Vec&lt;u64&gt;,  // Packed bits indicating selected rows
    row_count: usize,
}

impl SelectionVector {
    // Create selection of all rows
    pub fn all(row_count: usize) -&gt; Self;

    // Create empty selection
    pub fn none(row_count: usize) -&gt; Self;

    // Check if row is selected
    pub fn is_selected(&amp;self, idx: usize) -&gt; bool;

    // Count selected rows
    pub fn count(&amp;self) -&gt; usize;

    // AND two selections (intersection)
    pub fn intersect(&amp;self, other: &amp;SelectionVector) -&gt; SelectionVector;

    // OR two selections (union)
    pub fn union(&amp;self, other: &amp;SelectionVector) -&gt; SelectionVector;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="columnar-select-api"><a class="header" href="#columnar-select-api">Columnar Select API</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Materialize columns for SIMD filtering
engine.materialize_columns("users", &amp;["age", "name"])?;

// Check if columnar data exists
engine.has_columnar_data("users", "age");  // -&gt; bool

// Select with columnar scan options
let options = ColumnarScanOptions {
    projection: Some(vec!["name".into()]),  // Only return these columns
    prefer_columnar: true,                   // Use SIMD when available
};

let rows = engine.select_columnar(
    "users",
    Condition::Gt("age".into(), Value::Int(50)),
    options
)?;

// Drop columnar data
engine.drop_columnar_data("users", "age")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="condition-evaluation"><a class="header" href="#condition-evaluation">Condition Evaluation</a></h3>
<p>Two evaluation methods are available:</p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Input</th><th>Performance</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>evaluate(&amp;row)</code></td><td>Row struct</td><td>Legacy, creates intermediate objects</td><td>Row-by-row filtering</td></tr>
<tr><td><code>evaluate_tensor(&amp;tensor)</code></td><td>TensorData</td><td>31% faster, no intermediate allocation</td><td>Direct tensor filtering</td></tr>
</tbody></table>
</div>
<p>The engine automatically chooses the optimal evaluation path:</p>
<pre class="mermaid">flowchart TD
    Cond[Condition] --&gt; CheckColumnar{Columnar Data Available?}
    CheckColumnar --&gt;|Yes| CheckType{Int Column?}
    CheckColumnar --&gt;|No| RowEval[evaluate_tensor per row]

    CheckType --&gt;|Yes| SIMDEval[SIMD Vectorized Filter]
    CheckType --&gt;|No| RowEval

    SIMDEval --&gt; Bitmap[Selection Bitmap]
    RowEval --&gt; Filter[Filter Matching Rows]

    Bitmap --&gt; Materialize[Materialize Results]
    Filter --&gt; Materialize
</pre>
<h2 id="join-algorithm-implementations"><a class="header" href="#join-algorithm-implementations">Join Algorithm Implementations</a></h2>
<h3 id="hash-join-inner-left-right-full"><a class="header" href="#hash-join-inner-left-right-full">Hash Join (INNER, LEFT, RIGHT, FULL)</a></h3>
<p>All equality joins use the hash join algorithm with O(n+m) complexity:</p>
<pre class="mermaid">flowchart LR
    subgraph &quot;Build Phase&quot;
        RightTable[Right Table] --&gt; BuildHash[Build Hash Index]
        BuildHash --&gt; HashIndex[&quot;HashMap&lt;hash, Vec&lt;idx&gt;&gt;&quot;]
    end

    subgraph &quot;Probe Phase&quot;
        LeftTable[Left Table] --&gt; Probe[Probe Hash Index]
        Probe --&gt; HashIndex
        HashIndex --&gt; Match[Find Matching Rows]
    end

    Match --&gt; Results[Join Results]
</pre>
<p><strong>Hash Join Implementation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn join(&amp;self, table_a: &amp;str, table_b: &amp;str,
            on_a: &amp;str, on_b: &amp;str) -&gt; Result&lt;Vec&lt;(Row, Row)&gt;&gt; {
    let rows_a = self.select(table_a, Condition::True)?;
    let rows_b = self.select(table_b, Condition::True)?;

    // Build phase: index the right table
    let mut index: HashMap&lt;String, Vec&lt;usize&gt;&gt; = HashMap::with_capacity(rows_b.len());
    for (i, row) in rows_b.iter().enumerate() {
        if let Some(val) = row.get_with_id(on_b) {
            let hash = val.hash_key();
            index.entry(hash).or_default().push(i);
        }
    }

    // Probe phase: scan left table and probe index
    let mut results = Vec::with_capacity(min(rows_a.len(), rows_b.len()));
    for row_a in &amp;rows_a {
        if let Some(val) = row_a.get_with_id(on_a) {
            let hash = val.hash_key();
            if let Some(indices) = index.get(&amp;hash) {
                for &amp;i in indices {
                    let row_b = &amp;rows_b[i];
                    // Verify actual equality (handles hash collisions)
                    if row_b.get_with_id(on_b).as_ref() == Some(&amp;val) {
                        results.push((row_a.clone(), row_b.clone()));
                    }
                }
            }
        }
    }
    Ok(results)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Parallel Join Optimization:</strong></p>
<p>When left table exceeds <code>PARALLEL_THRESHOLD</code> (1000 rows), joins use Rayon for
parallel probing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if rows_a.len() &gt;= Self::PARALLEL_THRESHOLD {
    rows_a.par_iter()
        .flat_map(|row_a| {
            // Parallel probe of hash index
        })
        .collect()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="natural-join"><a class="header" href="#natural-join">Natural Join</a></h3>
<p>Natural join finds all common column names and joins on their equality:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn natural_join(&amp;self, table_a: &amp;str, table_b: &amp;str) -&gt; Result&lt;Vec&lt;(Row, Row)&gt;&gt; {
    let schema_a = self.get_schema(table_a)?;
    let schema_b = self.get_schema(table_b)?;

    // Find common columns
    let cols_a: HashSet&lt;_&gt; = schema_a.columns.iter().map(|c| c.name.as_str()).collect();
    let cols_b: HashSet&lt;_&gt; = schema_b.columns.iter().map(|c| c.name.as_str()).collect();
    let common_cols: Vec&lt;_&gt; = cols_a.intersection(&amp;cols_b).copied().collect();

    // No common columns = cross join
    if common_cols.is_empty() {
        return self.cross_join(table_a, table_b);
    }

    // Build composite hash key from all common columns
    // ...
}
<span class="boring">}</span></code></pre></pre>
<h2 id="aggregate-function-internals"><a class="header" href="#aggregate-function-internals">Aggregate Function Internals</a></h2>
<h3 id="parallel-aggregation"><a class="header" href="#parallel-aggregation">Parallel Aggregation</a></h3>
<p>For tables exceeding <code>PARALLEL_THRESHOLD</code> (1000 rows), aggregates use parallel
reduction:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn avg(&amp;self, table: &amp;str, column: &amp;str, condition: Condition) -&gt; Result&lt;Option&lt;f64&gt;&gt; {
    let rows = self.select(table, condition)?;

    let (total, count) = if rows.len() &gt;= Self::PARALLEL_THRESHOLD {
        // Parallel map-reduce
        rows.par_iter()
            .map(|row| extract_numeric(row, column))
            .reduce(|| (0.0, 0u64), |(s1, c1), (s2, c2)| (s1 + s2, c1 + c2))
    } else {
        // Sequential accumulation
        let mut total = 0.0;
        let mut count = 0u64;
        for row in &amp;rows {
            // accumulate...
        }
        (total, count)
    };

    if count == 0 { Ok(None) } else { Ok(Some(total / count as f64)) }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="minmax-with-parallel-reduction"><a class="header" href="#minmax-with-parallel-reduction">MIN/MAX with Parallel Reduction</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn min(&amp;self, table: &amp;str, column: &amp;str, condition: Condition) -&gt; Result&lt;Option&lt;Value&gt;&gt; {
    let rows = self.select(table, condition)?;

    if rows.len() &gt;= Self::PARALLEL_THRESHOLD {
        rows.par_iter()
            .filter_map(|row| row.get(column).filter(|v| !matches!(v, Value::Null)))
            .reduce_with(|a, b| {
                if a.partial_cmp_value(&amp;b) == Some(Ordering::Less) { a } else { b }
            })
    } else {
        // Sequential scan
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-characteristics-1"><a class="header" href="#performance-characteristics-1">Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>insert</code></td><td>O(1) + O(k)</td><td>Schema validation + store put + k index updates</td></tr>
<tr><td><code>batch_insert</code></td><td>O(n) + O(n*k)</td><td>Single schema lookup, 59x faster than n inserts</td></tr>
<tr><td><code>select</code> (no index)</td><td>O(n)</td><td>Full table scan with SIMD filter</td></tr>
<tr><td><code>select</code> (hash index)</td><td>O(1)</td><td>Direct lookup via hash index</td></tr>
<tr><td><code>select</code> (btree range)</td><td>O(log n + m)</td><td>B-tree lookup + m matching rows</td></tr>
<tr><td><code>update</code></td><td>O(n) + O(k)</td><td>Scan + conditional update + index maintenance</td></tr>
<tr><td><code>delete_rows</code></td><td>O(n) + O(k)</td><td>Scan + conditional delete + index removal</td></tr>
<tr><td><code>join</code></td><td>O(n+m)</td><td>Hash join for all 6 join types</td></tr>
<tr><td><code>cross_join</code></td><td>O(n*m)</td><td>Cartesian product</td></tr>
<tr><td><code>count/sum/avg/min/max</code></td><td>O(n)</td><td>Single pass over matching rows</td></tr>
<tr><td><code>create_index</code></td><td>O(n)</td><td>Scan all rows to build index</td></tr>
<tr><td><code>materialize_columns</code></td><td>O(n)</td><td>Extract column to contiguous array</td></tr>
</tbody></table>
</div>
<p>Where k = number of indexes on the table, n = rows in left table, m = rows in
right table.</p>
<h3 id="parallel-threshold"><a class="header" href="#parallel-threshold">Parallel Threshold</a></h3>
<p>Operations automatically switch to parallel execution when row count exceeds
<code>PARALLEL_THRESHOLD</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl RelationalEngine {
    const PARALLEL_THRESHOLD: usize = 1000;
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Parallel Operations:</strong></p>
<ul>
<li><code>delete_rows</code> (parallel deletion via Rayon)</li>
<li><code>join</code> (parallel probe phase)</li>
<li><code>sum</code>, <code>avg</code>, <code>min</code>, <code>max</code> (parallel reduction)</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="relationalconfig"><a class="header" href="#relationalconfig">RelationalConfig</a></h3>
<p>The engine can be configured with <code>RelationalConfig</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = RelationalConfig {
    max_tables: Some(1000),              // Maximum tables allowed
    max_indexes_per_table: Some(10),     // Maximum indexes per table
    max_btree_entries: 10_000_000,       // Maximum B-tree index entries
    default_query_timeout_ms: Some(5000),// Default query timeout
    max_query_timeout_ms: Some(300_000), // Maximum allowed timeout (5 min)
    slow_query_threshold_ms: 100,        // Slow query warning threshold
    max_query_result_rows: Some(10_000), // Maximum rows per query
    transaction_timeout_secs: 60,        // Transaction timeout
    lock_timeout_secs: 30,               // Lock acquisition timeout
};
let engine = RelationalEngine::with_config(config);
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>max_tables</code></td><td>None (unlimited)</td><td>Maximum number of tables</td></tr>
<tr><td><code>max_indexes_per_table</code></td><td>None (unlimited)</td><td>Maximum indexes per table</td></tr>
<tr><td><code>max_btree_entries</code></td><td>10,000,000</td><td>Maximum B-tree index entries total</td></tr>
<tr><td><code>default_query_timeout_ms</code></td><td>None</td><td>Default timeout for queries</td></tr>
<tr><td><code>max_query_timeout_ms</code></td><td>300,000 (5 min)</td><td>Maximum allowed query timeout</td></tr>
<tr><td><code>slow_query_threshold_ms</code></td><td>100</td><td>Threshold for slow query warnings</td></tr>
<tr><td><code>max_query_result_rows</code></td><td>None (unlimited)</td><td>Maximum rows returned per query</td></tr>
<tr><td><code>transaction_timeout_secs</code></td><td>60</td><td>Transaction timeout</td></tr>
<tr><td><code>lock_timeout_secs</code></td><td>30</td><td>Lock acquisition timeout</td></tr>
</tbody></table>
</div>
<h3 id="internal-constants"><a class="header" href="#internal-constants">Internal Constants</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Constant</th><th>Value</th><th>Description</th></tr></thead><tbody>
<tr><td><code>PARALLEL_THRESHOLD</code></td><td>1000</td><td>Minimum rows for parallel operations</td></tr>
<tr><td>Null bitmap sparse threshold</td><td>10%</td><td>Use sparse bitmap when nulls &lt; 10%</td></tr>
<tr><td>SIMD vector width</td><td>4</td><td>i64x4/f64x4 operations</td></tr>
</tbody></table>
</div>
<h2 id="observability"><a class="header" href="#observability">Observability</a></h2>
<p>The <code>observability</code> module provides query metrics, slow query detection, and
index usage tracking.</p>
<h3 id="query-metrics"><a class="header" href="#query-metrics">Query Metrics</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::observability::{QueryMetrics, check_slow_query};
use std::time::Duration;

let metrics = QueryMetrics::new("users", "select")
    .with_rows_scanned(10000)
    .with_rows_returned(50)
    .with_index("idx_user_id")
    .with_duration(Duration::from_millis(25));

// Log warning if query exceeds threshold
check_slow_query(&amp;metrics, 100); // threshold in ms
<span class="boring">}</span></code></pre></pre>
<h3 id="index-tracking"><a class="header" href="#index-tracking">Index Tracking</a></h3>
<p>Track index usage to identify missing indexes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::observability::IndexTracker;

let tracker = IndexTracker::new();

// Record when index is used
tracker.record_hit("users", "id");

// Record when index could have been used but wasn't
tracker.record_miss("users", "email");

// Get reports of columns needing indexes
let reports = tracker.report_misses();
for report in reports {
    println!(
        "Table {}, column {}: {} misses, {} hits",
        report.table, report.column, report.miss_count, report.hit_count
    );
}

// Aggregate statistics
let total_hits = tracker.total_hits();
let total_misses = tracker.total_misses();
<span class="boring">}</span></code></pre></pre>
<h3 id="slow-query-warnings"><a class="header" href="#slow-query-warnings">Slow Query Warnings</a></h3>
<p>The <code>check_slow_query</code> function logs a <code>tracing::warn!</code> when queries exceed
the threshold:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::observability::{check_slow_query, warn_full_table_scan};

// Warn if query took &gt; 100ms
check_slow_query(&amp;metrics, 100);

// Warn about full table scans on large tables (&gt; 1000 rows)
warn_full_table_scan("users", "select", 5000);
<span class="boring">}</span></code></pre></pre>
<h2 id="streaming-cursor-api"><a class="header" href="#streaming-cursor-api">Streaming Cursor API</a></h2>
<p>For large result sets, use streaming cursors to avoid loading all rows into
memory at once. The cursor fetches rows in configurable batches.</p>
<h3 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::{StreamingCursor, Condition};

// Create streaming cursor with default batch size (1000)
let cursor = engine.select_streaming("users", Condition::True);

// Iterate over results
for row_result in cursor {
    let row = row_result?;
    println!("User: {:?}", row);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-options"><a class="header" href="#custom-options">Custom Options</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// With custom batch size
let cursor = engine.select_streaming("users", Condition::True)
    .with_batch_size(100)
    .with_max_rows(5000);

// Using the builder
let cursor = engine.select_streaming_builder("users", Condition::True)
    .batch_size(100)
    .max_rows(5000)
    .build();

// Check cursor state
let mut cursor = engine.select_streaming("users", Condition::True);
while let Some(row) = cursor.next() {
    println!("Yielded so far: {}", cursor.rows_yielded());
}
println!("Exhausted: {}", cursor.is_exhausted());
<span class="boring">}</span></code></pre></pre>
<h3 id="cursor-methods"><a class="header" href="#cursor-methods">Cursor Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>with_batch_size(n)</code></td><td>Set rows fetched per batch (default: 1000)</td></tr>
<tr><td><code>with_max_rows(n)</code></td><td>Limit total rows returned</td></tr>
<tr><td><code>rows_yielded()</code></td><td>Number of rows returned so far</td></tr>
<tr><td><code>is_exhausted()</code></td><td>Whether cursor has no more rows</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas-1"><a class="header" href="#edge-cases-and-gotchas-1">Edge Cases and Gotchas</a></h2>
<h3 id="null-handling"><a class="header" href="#null-handling">NULL Handling</a></h3>
<ol>
<li>
<p><strong>NULL in conditions</strong>: Comparisons with NULL columns return <code>false</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// If email is NULL, this returns false (not true!)
Condition::Lt("email".into(), Value::String("z".into()))

<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<pre><code class="language-text">
2. **NULL in joins**: NULL values never match in join conditions:

   ```rust
   // Post with user_id = NULL will not join with any user
   engine.join("users", "posts", "_id", "user_id")
</code></pre>
<ol>
<li><strong>COUNT vs COUNT(column)</strong>:
<ul>
<li><code>count()</code> counts all rows</li>
<li><code>count_column()</code> counts non-null values only</li>
</ul>
</li>
</ol>
<h3 id="type-mismatches"><a class="header" href="#type-mismatches">Type Mismatches</a></h3>
<p>Comparisons between incompatible types return <code>false</code> rather than error:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Age is Int, comparing with String returns 0 matches (not error)
engine.select("users", Condition::Lt("age".into(), Value::String("30".into())));
<span class="boring">}</span></code></pre></pre>
<h3 id="index-maintenance"><a class="header" href="#index-maintenance">Index Maintenance</a></h3>
<p>Indexes are automatically maintained on INSERT, UPDATE, and DELETE:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Creating index AFTER data exists
engine.insert("users", values)?;  // No index update
engine.create_index("users", "age")?;  // Scans all rows

// Creating index BEFORE data exists
engine.create_index("users", "age")?;  // Empty index
engine.insert("users", values)?;  // Updates index
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-insert-atomicity"><a class="header" href="#batch-insert-atomicity">Batch Insert Atomicity</a></h3>
<p><code>batch_insert</code> validates ALL rows upfront before inserting any:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let rows = vec![valid_row, invalid_row];
// Fails on validation - NO rows inserted (not partial insert)
engine.batch_insert("users", rows);
<span class="boring">}</span></code></pre></pre>
<h3 id="b-tree-index-recovery"><a class="header" href="#b-tree-index-recovery">B-Tree Index Recovery</a></h3>
<p>B-tree indexes maintain both in-memory and persistent state. The in-memory
BTreeMap is rebuilt lazily on first access after restart.</p>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="index-selection"><a class="header" href="#index-selection">Index Selection</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Query Pattern</th><th>Recommended Index</th></tr></thead><tbody>
<tr><td><code>WHERE col = value</code></td><td>Hash Index</td></tr>
<tr><td><code>WHERE col &gt; value</code></td><td>B-Tree Index</td></tr>
<tr><td><code>WHERE col BETWEEN a AND b</code></td><td>B-Tree Index</td></tr>
<tr><td><code>WHERE col IN (...)</code></td><td>Hash Index</td></tr>
<tr><td>Unique lookups by ID</td><td>Hash Index on <code>_id</code></td></tr>
</tbody></table>
</div>
<h3 id="columnar-materialization"><a class="header" href="#columnar-materialization">Columnar Materialization</a></h3>
<p>Materialize columns when:</p>
<ul>
<li>Performing many range scans on large tables</li>
<li>Query selectivity is low (scanning most rows)</li>
<li>Column data fits in memory</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Materialize frequently-filtered columns
engine.materialize_columns("events", &amp;["timestamp", "user_id"])?;

// Query uses SIMD acceleration
engine.select_columnar("events",
    Condition::Gt("timestamp".into(), Value::Int(cutoff)),
    ColumnarScanOptions { prefer_columnar: true, .. }
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-operations"><a class="header" href="#batch-operations">Batch Operations</a></h3>
<p>Use <code>batch_insert</code> for bulk loading:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: 1000 individual inserts
for row in rows {
    engine.insert("table", row)?;  // 1000 schema lookups
}

// Good: Single batch insert
engine.batch_insert("table", rows)?;  // 1 schema lookup, 59x faster
<span class="boring">}</span></code></pre></pre>
<h2 id="sql-features-via-query-router"><a class="header" href="#sql-features-via-query-router">SQL Features via Query Router</a></h2>
<p>When using the relational engine through <code>query_router</code>, additional SQL features
are available:</p>
<h3 id="order-by-and-offset"><a class="header" href="#order-by-and-offset">ORDER BY and OFFSET</a></h3>
<pre><code class="language-sql">SELECT * FROM users ORDER BY age ASC;
SELECT * FROM users ORDER BY department DESC, name ASC;
SELECT * FROM users ORDER BY email NULLS FIRST;
SELECT * FROM users ORDER BY created_at DESC LIMIT 10 OFFSET 20;
</code></pre>
<h3 id="group-by-and-having"><a class="header" href="#group-by-and-having">GROUP BY and HAVING</a></h3>
<pre><code class="language-sql">SELECT department, COUNT(*), AVG(salary) FROM employees GROUP BY department;

SELECT product, SUM(quantity) as total
FROM orders
GROUP BY product
HAVING SUM(quantity) &gt; 100;
</code></pre>
<h2 id="related-modules-1"><a class="header" href="#related-modules-1">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>Storage backend for tables, rows, and indexes</td></tr>
<tr><td><code>query_router</code></td><td>Executes SQL queries using RelationalEngine</td></tr>
<tr><td><code>neumann_parser</code></td><td>Parses SQL statements into AST</td></tr>
<tr><td><code>tensor_unified</code></td><td>Multi-engine unified storage layer</td></tr>
</tbody></table>
</div>
<h2 id="feature-summary"><a class="header" href="#feature-summary">Feature Summary</a></h2>
<h3 id="implemented"><a class="header" href="#implemented">Implemented</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Description</th></tr></thead><tbody>
<tr><td>Hash indexes</td><td>O(1) equality lookups</td></tr>
<tr><td>B-tree indexes</td><td>O(log n) range query acceleration</td></tr>
<tr><td>All 6 JOIN types</td><td>INNER, LEFT, RIGHT, FULL, CROSS, NATURAL</td></tr>
<tr><td>Aggregate functions</td><td>COUNT, SUM, AVG, MIN, MAX</td></tr>
<tr><td>ORDER BY</td><td>Multi-column sorting with ASC/DESC, NULLS FIRST/LAST</td></tr>
<tr><td>LIMIT/OFFSET</td><td>Pagination support</td></tr>
<tr><td>GROUP BY + HAVING</td><td>Row grouping with aggregate filtering</td></tr>
<tr><td>Columnar storage</td><td>SIMD-accelerated filtering with selection vectors</td></tr>
<tr><td>Batch operations</td><td>59x faster bulk inserts</td></tr>
<tr><td>Parallel operations</td><td>Rayon-based parallelism for large tables</td></tr>
<tr><td>Dictionary encoding</td><td>String column compression</td></tr>
<tr><td>Transactions</td><td>Row-level ACID with undo log - see <a href="architecture/relational-transactions.html">Transactions</a></td></tr>
<tr><td>Constraints</td><td>PRIMARY KEY, UNIQUE, FOREIGN KEY, NOT NULL</td></tr>
<tr><td>Foreign Keys</td><td>Full referential integrity with CASCADE/SET NULL/RESTRICT</td></tr>
<tr><td>ALTER TABLE</td><td>add_column, drop_column, rename_column</td></tr>
<tr><td>Streaming cursors</td><td>Memory-efficient iteration over large result sets</td></tr>
<tr><td>Observability</td><td>Query metrics, slow query detection, index tracking</td></tr>
</tbody></table>
</div>
<h3 id="future-considerations"><a class="header" href="#future-considerations">Future Considerations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Status</th></tr></thead><tbody>
<tr><td>Query Optimization</td><td>Not implemented</td></tr>
<tr><td>Subqueries</td><td>Not implemented</td></tr>
<tr><td>Window Functions</td><td>Not implemented</td></tr>
<tr><td>Composite Indexes</td><td>Not implemented</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="relational-engine-transactions"><a class="header" href="#relational-engine-transactions">Relational Engine Transactions</a></h1>
<p>Local ACID transactions for single-shard relational operations. This module
provides row-level locking, undo logging for rollback, and timeout-based
deadlock prevention.</p>
<p>Transactions in the relational engine operate within a single shard and do not
coordinate with other nodes. For distributed transactions across multiple
shards, see <a href="architecture/../concepts/distributed-transactions.html">Distributed Transactions</a>.</p>
<h2 id="architecture-2"><a class="header" href="#architecture-2">Architecture</a></h2>
<pre class="mermaid">flowchart TD
    subgraph TransactionManager
        TxMap[Transaction Map]
        TxCounter[TX Counter]
        DefaultTimeout[Default Timeout]
    end

    subgraph RowLockManager
        LockMap[&quot;Locks: (table, row_id) -&gt; RowLock&quot;]
        TxLocks[&quot;TX Locks: tx_id -&gt; Vec&lt;(table, row_id)&gt;&quot;]
        LockTimeout[Lock Timeout]
    end

    subgraph Transaction
        TxId[Transaction ID]
        Phase[TxPhase State]
        UndoLog[&quot;Undo Log: Vec&lt;UndoEntry&gt;&quot;]
        AffectedTables[Affected Tables]
        StartTime[Started At]
    end

    TransactionManager --&gt; RowLockManager
    TransactionManager --&gt; Transaction
    Transaction --&gt; UndoLog
</pre>
<h3 id="component-relationships"><a class="header" href="#component-relationships">Component Relationships</a></h3>
<pre><code class="language-text">+-------------------+
| RelationalEngine  |
+-------------------+
         |
         v
+-------------------+     +------------------+
| TransactionManager| --&gt; | RowLockManager   |
| - begin()         |     | - try_lock()     |
| - commit()        |     | - release()      |
| - rollback()      |     | - cleanup_expired|
+-------------------+     +------------------+
         |
         v
+-------------------+
| Transaction       |
| - tx_id           |
| - phase           |
| - undo_log        |
+-------------------+
</code></pre>
<h2 id="transaction-lifecycle"><a class="header" href="#transaction-lifecycle">Transaction Lifecycle</a></h2>
<p>Transactions follow a 5-state machine with well-defined transitions:</p>
<pre class="mermaid">flowchart LR
    Active --&gt; Committing
    Active --&gt; Aborting
    Committing --&gt; Committed
    Aborting --&gt; Aborted

    style Committed fill:#9f9
    style Aborted fill:#f99
</pre>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th><th>Valid Transitions</th></tr></thead><tbody>
<tr><td><code>Active</code></td><td>Operations allowed, locks acquired</td><td>Committing, Aborting</td></tr>
<tr><td><code>Committing</code></td><td>Finalizing changes</td><td>Committed</td></tr>
<tr><td><code>Committed</code></td><td>Changes permanent (terminal)</td><td>None</td></tr>
<tr><td><code>Aborting</code></td><td>Rolling back via undo log</td><td>Aborted</td></tr>
<tr><td><code>Aborted</code></td><td>Changes reverted (terminal)</td><td>None</td></tr>
</tbody></table>
</div>
<h3 id="lifecycle-flow"><a class="header" href="#lifecycle-flow">Lifecycle Flow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Begin transaction
let tx_id = tx_manager.begin();
// Phase: Active

// Acquire row locks for modifications
lock_manager.try_lock(tx_id, &amp;[("users", 1), ("users", 2)])?;

// Record undo entries for rollback
tx_manager.record_undo(tx_id, UndoEntry::UpdatedRow { ... });

// Option 1: Commit
tx_manager.set_phase(tx_id, TxPhase::Committing);
// Apply changes...
tx_manager.set_phase(tx_id, TxPhase::Committed);
tx_manager.release_locks(tx_id);

// Option 2: Rollback
tx_manager.set_phase(tx_id, TxPhase::Aborting);
for entry in tx_manager.get_undo_log(tx_id).iter().rev() {
    // Apply undo entry...
}
tx_manager.set_phase(tx_id, TxPhase::Aborted);
tx_manager.release_locks(tx_id);
<span class="boring">}</span></code></pre></pre>
<h2 id="undo-log"><a class="header" href="#undo-log">Undo Log</a></h2>
<p>The undo log stores entries needed to reverse each operation on rollback.
Entries are applied in reverse order during rollback.</p>
<h3 id="undoentry-variants"><a class="header" href="#undoentry-variants">UndoEntry Variants</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Action on Rollback</th><th>Stored Data</th></tr></thead><tbody>
<tr><td><code>InsertedRow</code></td><td>Delete the row</td><td>table, slab_row_id, row_id, index_entries</td></tr>
<tr><td><code>UpdatedRow</code></td><td>Restore old values</td><td>table, slab_row_id, row_id, old_values, index_changes</td></tr>
<tr><td><code>DeletedRow</code></td><td>Re-insert the row</td><td>table, slab_row_id, row_id, old_values, index_entries</td></tr>
</tbody></table>
</div>
<h3 id="undo-log-structure"><a class="header" href="#undo-log-structure">Undo Log Structure</a></h3>
<pre><code class="language-text">Transaction Undo Log:
+---------------------------------------------------+
| Entry 0: InsertedRow { table: "users", row_id: 5 }|
+---------------------------------------------------+
| Entry 1: UpdatedRow { table: "users", row_id: 3,  |
|          old_values: [Int(25)], ... }             |
+---------------------------------------------------+
| Entry 2: DeletedRow { table: "orders", row_id: 7, |
|          old_values: [...], index_entries: [...] }|
+---------------------------------------------------+

Rollback order: Entry 2 -&gt; Entry 1 -&gt; Entry 0
</code></pre>
<h3 id="index-change-tracking"><a class="header" href="#index-change-tracking">Index Change Tracking</a></h3>
<p>Updates that modify indexed columns record <code>IndexChange</code> entries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct IndexChange {
    pub column: String,     // Column name
    pub old_value: Value,   // Value before update
    pub new_value: Value,   // Value after update
}
<span class="boring">}</span></code></pre></pre>
<p>On rollback, index entries are reverted:</p>
<ol>
<li>Remove new index entry for the new value</li>
<li>Restore old index entry for the old value</li>
</ol>
<h2 id="row-level-locking"><a class="header" href="#row-level-locking">Row-Level Locking</a></h2>
<p>The <code>RowLockManager</code> provides pessimistic row-level locking with atomic
multi-row acquisition.</p>
<h3 id="lock-acquisition"><a class="header" href="#lock-acquisition">Lock Acquisition</a></h3>
<pre class="mermaid">flowchart TD
    Request[Lock Request] --&gt; Check{All rows available?}
    Check --&gt;|Yes| Acquire[Acquire all locks atomically]
    Check --&gt;|No| Conflict[Return LockConflictInfo]
    Acquire --&gt; Success[Success]

    style Conflict fill:#f99
    style Success fill:#9f9
</pre>
<p>Locks are acquired atomically to prevent partial lock acquisition:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Atomic multi-row locking
let rows = vec![
    ("users".to_string(), 1),
    ("users".to_string(), 2),
    ("orders".to_string(), 5),
];

match lock_manager.try_lock(tx_id, &amp;rows) {
    Ok(()) =&gt; {
        // All locks acquired
    }
    Err(conflict) =&gt; {
        // No locks acquired, conflict info provided
        println!("Blocked by tx {}", conflict.blocking_tx);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="lock-semantics"><a class="header" href="#lock-semantics">Lock Semantics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Property</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Granularity</td><td>Row-level: (table, row_id)</td></tr>
<tr><td>Acquisition</td><td>All-or-nothing atomic</td></tr>
<tr><td>Re-entry</td><td>Same transaction can re-acquire its locks</td></tr>
<tr><td>Timeout</td><td>Configurable, default 30 seconds</td></tr>
<tr><td>Expiration</td><td>Expired locks are treated as available</td></tr>
</tbody></table>
</div>
<h3 id="lock-conflict-detection"><a class="header" href="#lock-conflict-detection">Lock Conflict Detection</a></h3>
<p>When a lock conflict occurs, <code>LockConflictInfo</code> provides details:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct LockConflictInfo {
    pub blocking_tx: u64,   // Transaction holding the lock
    pub table: String,      // Table name
    pub row_id: u64,        // Row ID
}
<span class="boring">}</span></code></pre></pre>
<h3 id="expired-lock-handling"><a class="header" href="#expired-lock-handling">Expired Lock Handling</a></h3>
<p>Locks automatically expire after the configured timeout:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check if lock is expired
if lock.is_expired() {
    // Lock can be acquired by another transaction
}

// Periodic cleanup of expired locks
let cleaned = lock_manager.cleanup_expired();
<span class="boring">}</span></code></pre></pre>
<h2 id="deadline"><a class="header" href="#deadline">Deadline</a></h2>
<p>The <code>Deadline</code> struct provides monotonic time-based timeout checking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create deadline with timeout
let deadline = Deadline::from_timeout_ms(Some(5000));

// Check expiration
if deadline.is_expired() {
    return Err(TimeoutError);
}

// Get remaining time
if let Some(remaining) = deadline.remaining_ms() {
    println!("{} ms remaining", remaining);
}

// Never-expiring deadline
let no_deadline = Deadline::never();
<span class="boring">}</span></code></pre></pre>
<p>Benefits of monotonic time (<code>Instant</code>):</p>
<ul>
<li>Immune to system clock changes</li>
<li>Consistent timeout behavior</li>
<li>No backwards time jumps</li>
</ul>
<h2 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h2>
<h3 id="transaction-manager"><a class="header" href="#transaction-manager">Transaction Manager</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>default_timeout</code></td><td>60 seconds</td><td>Maximum transaction duration</td></tr>
</tbody></table>
</div>
<h3 id="row-lock-manager"><a class="header" href="#row-lock-manager">Row Lock Manager</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>default_timeout</code></td><td>30 seconds</td><td>Maximum time to hold a lock</td></tr>
</tbody></table>
</div>
<h3 id="custom-configuration"><a class="header" href="#custom-configuration">Custom Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::time::Duration;

// Custom transaction timeout
let tx_manager = TransactionManager::with_timeout(
    Duration::from_secs(120)
);

// Custom lock timeout
let lock_manager = RowLockManager::with_default_timeout(
    Duration::from_secs(60)
);
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<h3 id="lock-errors"><a class="header" href="#lock-errors">Lock Errors</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th><th>Recovery</th></tr></thead><tbody>
<tr><td><code>LockConflict</code></td><td>Row locked by another transaction</td><td>Retry with exponential backoff</td></tr>
<tr><td>Lock timeout</td><td>Could not acquire lock in time</td><td>Rollback and retry</td></tr>
</tbody></table>
</div>
<h3 id="transaction-errors"><a class="header" href="#transaction-errors">Transaction Errors</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th><th>Recovery</th></tr></thead><tbody>
<tr><td>Transaction not found</td><td>Invalid transaction ID</td><td>Start new transaction</td></tr>
<tr><td>Transaction expired</td><td>Exceeded timeout</td><td>Transaction auto-aborted</td></tr>
<tr><td>Invalid phase transition</td><td>Illegal state change</td><td>Check transaction state</td></tr>
</tbody></table>
</div>
<h3 id="cleanup-operations"><a class="header" href="#cleanup-operations">Cleanup Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Clean up expired transactions (releases their locks)
let expired_count = tx_manager.cleanup_expired();

// Clean up expired locks only
let expired_locks = lock_manager.cleanup_expired();
<span class="boring">}</span></code></pre></pre>
<h2 id="comparison-with-distributed-transactions"><a class="header" href="#comparison-with-distributed-transactions">Comparison with Distributed Transactions</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>Relational Tx</th><th>Distributed Tx (2PC)</th></tr></thead><tbody>
<tr><td>Scope</td><td>Single shard</td><td>Cross-shard</td></tr>
<tr><td>Protocol</td><td>Local locking</td><td>Prepare/Commit phases</td></tr>
<tr><td>Deadlock detection</td><td>Timeout-based</td><td>Wait-for graph analysis</td></tr>
<tr><td>Coordinator</td><td>None</td><td>DistributedTxCoordinator</td></tr>
<tr><td>Recovery</td><td>Undo log</td><td>WAL + 2PC recovery</td></tr>
<tr><td>Latency</td><td>Low (local)</td><td>Higher (network round-trips)</td></tr>
<tr><td>Isolation</td><td>Row-level locks</td><td>Key-level locks</td></tr>
</tbody></table>
</div>
<p>For cross-shard transactions, use <code>tensor_chain</code>’s
<a href="architecture/../concepts/distributed-transactions.html">Distributed Transactions</a>.</p>
<h2 id="usage-examples-2"><a class="header" href="#usage-examples-2">Usage Examples</a></h2>
<h3 id="basic-transaction"><a class="header" href="#basic-transaction">Basic Transaction</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let engine = RelationalEngine::new();
let tx_manager = engine.tx_manager();

// Begin transaction
let tx_id = tx_manager.begin();

// Perform operations (simplified)
// engine.insert_tx(tx_id, "users", values)?;
// engine.update_tx(tx_id, "users", condition, updates)?;

// Commit
tx_manager.set_phase(tx_id, TxPhase::Committing);
// Apply pending changes...
tx_manager.set_phase(tx_id, TxPhase::Committed);
tx_manager.release_locks(tx_id);
tx_manager.remove(tx_id);
<span class="boring">}</span></code></pre></pre>
<h3 id="rollback-on-error"><a class="header" href="#rollback-on-error">Rollback on Error</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let tx_id = tx_manager.begin();

match perform_operations(tx_id) {
    Ok(()) =&gt; {
        tx_manager.set_phase(tx_id, TxPhase::Committed);
    }
    Err(e) =&gt; {
        tx_manager.set_phase(tx_id, TxPhase::Aborting);

        // Apply undo log in reverse
        if let Some(undo_log) = tx_manager.get_undo_log(tx_id) {
            for entry in undo_log.iter().rev() {
                apply_undo(entry);
            }
        }

        tx_manager.set_phase(tx_id, TxPhase::Aborted);
    }
}

tx_manager.release_locks(tx_id);
tx_manager.remove(tx_id);
<span class="boring">}</span></code></pre></pre>
<h3 id="checking-lock-status"><a class="header" href="#checking-lock-status">Checking Lock Status</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let lock_manager = tx_manager.lock_manager();

// Check if row is locked
if lock_manager.is_locked("users", 42) {
    println!("Row is locked");
}

// Get lock holder
if let Some(holder_tx) = lock_manager.lock_holder("users", 42) {
    println!("Locked by transaction {}", holder_tx);
}

// Count active locks
println!("{} active locks", lock_manager.active_lock_count());
println!("{} locks held by tx {}", lock_manager.locks_held_by(tx_id), tx_id);
<span class="boring">}</span></code></pre></pre>
<h2 id="key-types-1"><a class="header" href="#key-types-1">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TxPhase</code></td><td>5-state transaction phase enum</td></tr>
<tr><td><code>Transaction</code></td><td>Active transaction state</td></tr>
<tr><td><code>UndoEntry</code></td><td>Undo log entry for rollback</td></tr>
<tr><td><code>IndexChange</code></td><td>Index modification record</td></tr>
<tr><td><code>RowLock</code></td><td>Row lock with timeout</td></tr>
<tr><td><code>RowLockManager</code></td><td>Row-level lock manager</td></tr>
<tr><td><code>LockConflictInfo</code></td><td>Lock conflict details</td></tr>
<tr><td><code>Deadline</code></td><td>Monotonic timeout checker</td></tr>
<tr><td><code>TransactionManager</code></td><td>Transaction lifecycle manager</td></tr>
</tbody></table>
</div>
<h2 id="source-references"><a class="header" href="#source-references">Source References</a></h2>
<ul>
<li><code>relational_engine/src/transaction.rs</code> - Transaction implementation</li>
<li><code>relational_engine/src/lib.rs</code> - Integration with RelationalEngine</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graph-engine"><a class="header" href="#graph-engine">Graph Engine</a></h1>
<p>The Graph Engine provides graph operations on top of the Tensor Store. It
implements a labeled property graph model with support for both directed and
undirected edges, BFS traversals, and shortest path finding. The engine
inherits thread safety from TensorStore and supports cross-engine unified
entity connections.</p>
<h2 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Principle</th><th>Description</th></tr></thead><tbody>
<tr><td>Layered Architecture</td><td>Depends only on Tensor Store for persistence</td></tr>
<tr><td>Direction-Aware</td><td>Supports both directed and undirected edges</td></tr>
<tr><td>BFS Traversal</td><td>Breadth-first search for shortest paths</td></tr>
<tr><td>Cycle-Safe</td><td>Handles cyclic graphs without infinite loops via visited set</td></tr>
<tr><td>Unified Entities</td><td>Edges can connect shared entities across engines</td></tr>
<tr><td>Thread Safety</td><td>Inherits from Tensor Store’s DashMap (~16 shards)</td></tr>
<tr><td>Serializable Types</td><td>All types implement serde Serialize/Deserialize</td></tr>
<tr><td>Parallel Optimization</td><td>High-degree node deletion uses rayon for parallelism</td></tr>
</tbody></table>
</div>
<h2 id="key-types-2"><a class="header" href="#key-types-2">Key Types</a></h2>
<h3 id="core-types-1"><a class="header" href="#core-types-1">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>GraphEngine</code></td><td>Main entry point for graph operations</td></tr>
<tr><td><code>Node</code></td><td>Graph node with id, label, and properties</td></tr>
<tr><td><code>Edge</code></td><td>Graph edge with from/to nodes, type, properties, and direction flag</td></tr>
<tr><td><code>Path</code></td><td>Result of path finding containing node and edge sequences</td></tr>
<tr><td><code>Direction</code></td><td>Edge traversal direction (Outgoing, Incoming, Both)</td></tr>
<tr><td><code>PropertyValue</code></td><td>Node/edge property values (Null, Int, Float, String, Bool)</td></tr>
<tr><td><code>GraphError</code></td><td>Error types for graph operations</td></tr>
</tbody></table>
</div>
<h3 id="propertyvalue-variants"><a class="header" href="#propertyvalue-variants">PropertyValue Variants</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Rust Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Null</code></td><td>—</td><td>NULL value</td></tr>
<tr><td><code>Int</code></td><td><code>i64</code></td><td>64-bit signed integer</td></tr>
<tr><td><code>Float</code></td><td><code>f64</code></td><td>64-bit floating point</td></tr>
<tr><td><code>String</code></td><td><code>String</code></td><td>UTF-8 string</td></tr>
<tr><td><code>Bool</code></td><td><code>bool</code></td><td>Boolean</td></tr>
</tbody></table>
</div>
<h3 id="error-types-2"><a class="header" href="#error-types-2">Error Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th></tr></thead><tbody>
<tr><td><code>NodeNotFound(u64)</code></td><td>Node with given ID does not exist</td></tr>
<tr><td><code>EdgeNotFound(u64)</code></td><td>Edge with given ID does not exist</td></tr>
<tr><td><code>PathNotFound</code></td><td>No path exists between the specified nodes</td></tr>
<tr><td><code>StorageError(String)</code></td><td>Underlying Tensor Store error</td></tr>
</tbody></table>
</div>
<h2 id="architecture-3"><a class="header" href="#architecture-3">Architecture</a></h2>
<pre class="mermaid">graph TB
    subgraph GraphEngine
        GE[GraphEngine]
        NC[Node Counter&lt;br/&gt;AtomicU64]
        EC[Edge Counter&lt;br/&gt;AtomicU64]
    end

    subgraph Storage[&quot;Storage Model&quot;]
        NM[&quot;node:{id}&quot;]
        NO[&quot;node:{id}:out&quot;]
        NI[&quot;node:{id}:in&quot;]
        EM[&quot;edge:{id}&quot;]
    end

    subgraph Operations
        CreateNode[create_node]
        CreateEdge[create_edge]
        Neighbors[neighbors]
        Traverse[traverse]
        FindPath[find_path]
    end

    GE --&gt; NC
    GE --&gt; EC
    GE --&gt; TS[TensorStore]

    CreateNode --&gt; NM
    CreateNode --&gt; NO
    CreateNode --&gt; NI
    CreateEdge --&gt; EM
    CreateEdge --&gt; NO
    CreateEdge --&gt; NI

    Neighbors --&gt; NO
    Neighbors --&gt; NI
    Traverse --&gt; Neighbors
    FindPath --&gt; NO
</pre>
<h2 id="internal-architecture"><a class="header" href="#internal-architecture">Internal Architecture</a></h2>
<h3 id="graphengine-struct"><a class="header" href="#graphengine-struct">GraphEngine Struct</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct GraphEngine {
    store: TensorStore,           // Underlying key-value storage
    node_counter: AtomicU64,      // Atomic counter for node IDs
    edge_counter: AtomicU64,      // Atomic counter for edge IDs
}
<span class="boring">}</span></code></pre></pre>
<p>The engine uses atomic counters (SeqCst ordering) to generate unique IDs:</p>
<ul>
<li>Node IDs start at 1 and increment monotonically</li>
<li>Edge IDs are separate from node IDs</li>
<li>Both counters support concurrent ID allocation</li>
</ul>
<h3 id="key-generation-functions"><a class="header" href="#key-generation-functions">Key Generation Functions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn node_key(id: u64) -&gt; String { format!("node:{}", id) }
fn edge_key(id: u64) -&gt; String { format!("edge:{}", id) }
fn outgoing_edges_key(node_id: u64) -&gt; String { format!("node:{}:out", node_id) }
fn incoming_edges_key(node_id: u64) -&gt; String { format!("node:{}:in", node_id) }
<span class="boring">}</span></code></pre></pre>
<h2 id="storage-model-1"><a class="header" href="#storage-model-1">Storage Model</a></h2>
<p>Nodes and edges are stored in Tensor Store using the following key patterns:</p>
<div class="table-wrapper"><table><thead><tr><th>Key Pattern</th><th>Content</th><th>TensorData Fields</th></tr></thead><tbody>
<tr><td><code>node:{id}</code></td><td>Node data</td><td><code>_id</code>, <code>_type="node"</code>, <code>_label</code>, user properties</td></tr>
<tr><td><code>node:{id}:out</code></td><td>List of outgoing edge IDs</td><td><code>e{edge_id}</code> fields</td></tr>
<tr><td><code>node:{id}:in</code></td><td>List of incoming edge IDs</td><td><code>e{edge_id}</code> fields</td></tr>
<tr><td><code>edge:{id}</code></td><td>Edge data</td><td><code>_id</code>, <code>_type="edge"</code>, <code>_from</code>, <code>_to</code>, <code>_edge_type</code>, <code>_directed</code>, user properties</td></tr>
</tbody></table>
</div>
<h3 id="edge-list-storage-format"><a class="header" href="#edge-list-storage-format">Edge List Storage Format</a></h3>
<p>Edge lists are stored as TensorData with dynamically named fields:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Each edge ID stored as: "e{edge_id}" -&gt; edge_id
tensor.set("e1", TensorValue::Scalar(ScalarValue::Int(1)));
tensor.set("e5", TensorValue::Scalar(ScalarValue::Int(5)));
<span class="boring">}</span></code></pre></pre>
<p>This format allows O(1) edge addition but O(n) edge listing. The edge
retrieval scans all keys starting with ‘e’:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn get_edge_list(&amp;self, key: &amp;str) -&gt; Result&lt;Vec&lt;u64&gt;&gt; {
    let tensor = self.store.get(key)?;
    let mut edges = Vec::new();
    for k in tensor.keys() {
        if k.starts_with('e') {
            if let Some(TensorValue::Scalar(ScalarValue::Int(id))) = tensor.get(k) {
                edges.push(*id as u64);
            }
        }
    }
    Ok(edges)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="api-reference-1"><a class="header" href="#api-reference-1">API Reference</a></h2>
<h3 id="engine-construction"><a class="header" href="#engine-construction">Engine Construction</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create new engine with internal store
let engine = GraphEngine::new();

// Create engine with shared store (for cross-engine queries)
let store = TensorStore::new();
let engine = GraphEngine::with_store(store.clone());

// Access underlying store
let store = engine.store();
<span class="boring">}</span></code></pre></pre>
<h3 id="node-operations"><a class="header" href="#node-operations">Node Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create node with properties
let mut props = HashMap::new();
props.insert("name".to_string(), PropertyValue::String("Alice".into()));
props.insert("age".to_string(), PropertyValue::Int(30));
let id = engine.create_node("Person", props)?;

// Get node by ID
let node = engine.get_node(id)?;

// Check node existence
let exists = engine.node_exists(id);

// Delete node (cascades to connected edges)
engine.delete_node(id)?;

// Count nodes in graph
let count = engine.node_count();
<span class="boring">}</span></code></pre></pre>
<h3 id="edge-operations"><a class="header" href="#edge-operations">Edge Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create directed edge
let edge_id = engine.create_edge(from, to, "KNOWS", properties, true)?;

// Create undirected edge
let edge_id = engine.create_edge(from, to, "FRIENDS", properties, false)?;

// Get edge by ID
let edge = engine.get_edge(edge_id)?;
<span class="boring">}</span></code></pre></pre>
<h4 id="undirected-edge-implementation"><a class="header" href="#undirected-edge-implementation">Undirected Edge Implementation</a></h4>
<p>When an undirected edge is created, it is added to <strong>four</strong> edge lists to
enable bidirectional traversal:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if !directed {
    // Add to both nodes' outgoing AND incoming lists
    self.add_edge_to_list(Self::outgoing_edges_key(to), id)?;
    self.add_edge_to_list(Self::incoming_edges_key(from), id)?;
}
<span class="boring">}</span></code></pre></pre>
<p>This enables undirected edges to be traversed from either endpoint regardless
of direction filter.</p>
<h3 id="traversal-operations"><a class="header" href="#traversal-operations">Traversal Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get neighbors (all edge types, both directions)
let neighbors = engine.neighbors(node_id, None, Direction::Both)?;

// Get neighbors filtered by edge type
let friends = engine.neighbors(node_id, Some("FRIENDS"), Direction::Both)?;

// BFS traversal with depth limit
let nodes = engine.traverse(start_id, Direction::Outgoing, max_depth, None)?;

// Traversal filtered by edge type
let deps = engine.traverse(start_id, Direction::Outgoing, 10, Some("DEPENDS_ON"))?;

// Find shortest path (BFS)
let path = engine.find_path(from_id, to_id)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="direction-enum"><a class="header" href="#direction-enum">Direction Enum</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Direction</th><th>Behavior</th></tr></thead><tbody>
<tr><td><code>Outgoing</code></td><td>Follow edges away from the node</td></tr>
<tr><td><code>Incoming</code></td><td>Follow edges toward the node</td></tr>
<tr><td><code>Both</code></td><td>Follow edges in either direction</td></tr>
</tbody></table>
</div>
<h2 id="bfs-traversal-algorithm"><a class="header" href="#bfs-traversal-algorithm">BFS Traversal Algorithm</a></h2>
<p>The <code>traverse</code> method implements breadth-first search with depth limiting and
cycle detection:</p>
<pre class="mermaid">flowchart TD
    Start[Start: traverse] --&gt; Init[Initialize visited set&lt;br/&gt;Initialize result vec&lt;br/&gt;Initialize queue with start, depth=0]
    Init --&gt; Check{Queue empty?}
    Check -- No --&gt; Pop[Pop current_id, depth]
    Pop --&gt; GetNode[Get node, add to result]
    GetNode --&gt; DepthCheck{depth &gt;= max_depth?}
    DepthCheck -- Yes --&gt; Check
    DepthCheck -- No --&gt; GetNeighbors[Get neighbor IDs]
    GetNeighbors --&gt; ForEach[For each neighbor]
    ForEach --&gt; Visited{Already visited?}
    Visited -- Yes --&gt; ForEach
    Visited -- No --&gt; Add[Add to visited&lt;br/&gt;Push to queue with depth+1]
    Add --&gt; ForEach
    Check -- Yes --&gt; Return[Return result]
</pre>
<h3 id="implementation-details-1"><a class="header" href="#implementation-details-1">Implementation Details</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn traverse(
    &amp;self,
    start: u64,
    direction: Direction,
    max_depth: usize,
    edge_type: Option&lt;&amp;str&gt;,
) -&gt; Result&lt;Vec&lt;Node&gt;&gt; {
    if !self.node_exists(start) {
        return Err(GraphError::NodeNotFound(start));
    }

    let mut visited = HashSet::new();
    let mut result = Vec::new();
    let mut queue = VecDeque::new();

    queue.push_back((start, 0usize));
    visited.insert(start);

    while let Some((current_id, depth)) = queue.pop_front() {
        if let Ok(node) = self.get_node(current_id) {
            result.push(node);
        }

        if depth &gt;= max_depth {
            continue;
        }

        let neighbors = self.get_neighbor_ids(current_id, edge_type, direction)?;
        for neighbor_id in neighbors {
            if !visited.contains(&amp;neighbor_id) {
                visited.insert(neighbor_id);
                queue.push_back((neighbor_id, depth + 1));
            }
        }
    }

    Ok(result)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="key-properties"><a class="header" href="#key-properties">Key Properties</a></h3>
<ul>
<li><strong>Cycle-Safe</strong>: The <code>visited</code> HashSet prevents revisiting nodes</li>
<li><strong>Depth-Limited</strong>: The <code>max_depth</code> parameter bounds traversal depth</li>
<li><strong>Level-Order</strong>: BFS naturally visits nodes in level order</li>
<li><strong>Start Node Included</strong>: The starting node is always in the result at depth 0</li>
</ul>
<h2 id="shortest-path-algorithm"><a class="header" href="#shortest-path-algorithm">Shortest Path Algorithm</a></h2>
<p>The <code>find_path</code> method uses BFS to find the shortest (minimum hop) path
between two nodes:</p>
<pre class="mermaid">flowchart TD
    Start[Start: find_path] --&gt; Validate[Validate from and to exist]
    Validate --&gt; SameNode{from == to?}
    SameNode -- Yes --&gt; ReturnSingle[Return path with single node]
    SameNode -- No --&gt; InitBFS[Initialize BFS:&lt;br/&gt;visited set&lt;br/&gt;queue with from&lt;br/&gt;parent map]
    InitBFS --&gt; BFSLoop{Queue empty?}
    BFSLoop -- Yes --&gt; NotFound[Return PathNotFound]
    BFSLoop -- No --&gt; Dequeue[Dequeue current node]
    Dequeue --&gt; GetEdges[Get outgoing edges]
    GetEdges --&gt; ForEdge[For each edge]
    ForEdge --&gt; GetNeighbor[Determine neighbor&lt;br/&gt;considering direction]
    GetNeighbor --&gt; VisitedCheck{Visited?}
    VisitedCheck -- Yes --&gt; ForEdge
    VisitedCheck -- No --&gt; MarkVisited[Mark visited&lt;br/&gt;Record parent + edge]
    MarkVisited --&gt; FoundTarget{neighbor == to?}
    FoundTarget -- Yes --&gt; Reconstruct[Reconstruct path]
    FoundTarget -- No --&gt; Enqueue[Enqueue neighbor]
    Enqueue --&gt; ForEdge
    ForEdge --&gt; BFSLoop
    Reconstruct --&gt; Return[Return Path]
</pre>
<h3 id="implementation-details-2"><a class="header" href="#implementation-details-2">Implementation Details</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn find_path(&amp;self, from: u64, to: u64) -&gt; Result&lt;Path&gt; {
    // Validate endpoints exist
    if !self.node_exists(from) {
        return Err(GraphError::NodeNotFound(from));
    }
    if !self.node_exists(to) {
        return Err(GraphError::NodeNotFound(to));
    }

    // Handle trivial case
    if from == to {
        return Ok(Path {
            nodes: vec![from],
            edges: vec![],
        });
    }

    // BFS for shortest path
    let mut visited = HashSet::new();
    let mut queue = VecDeque::new();
    let mut parent: HashMap&lt;u64, (u64, u64)&gt; = HashMap::new(); // node -&gt; (parent_node, edge_id)

    queue.push_back(from);
    visited.insert(from);

    while let Some(current) = queue.pop_front() {
        let out_edges = self.get_edge_list(&amp;Self::outgoing_edges_key(current))?;

        for edge_id in out_edges {
            if let Ok(edge) = self.get_edge(edge_id) {
                let neighbor = if edge.from == current {
                    edge.to
                } else if !edge.directed &amp;&amp; edge.to == current {
                    edge.from
                } else {
                    continue;
                };

                if !visited.contains(&amp;neighbor) {
                    visited.insert(neighbor);
                    parent.insert(neighbor, (current, edge_id));

                    if neighbor == to {
                        return Ok(self.reconstruct_path(from, to, &amp;parent));
                    }

                    queue.push_back(neighbor);
                }
            }
        }
    }

    Err(GraphError::PathNotFound)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="path-reconstruction"><a class="header" href="#path-reconstruction">Path Reconstruction</a></h3>
<p>The path is reconstructed by following parent pointers backwards from the
target to the source:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn reconstruct_path(&amp;self, from: u64, to: u64, parent: &amp;HashMap&lt;u64, (u64, u64)&gt;) -&gt; Path {
    let mut nodes = Vec::new();
    let mut edges = Vec::new();
    let mut current = to;

    // Walk backwards from target to source
    while current != from {
        nodes.push(current);
        if let Some((p, edge_id)) = parent.get(&amp;current) {
            edges.push(*edge_id);
            current = *p;
        } else {
            break;
        }
    }
    nodes.push(from);

    // Reverse to get source-to-target order
    nodes.reverse();
    edges.reverse();

    Path { nodes, edges }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="parallel-deletion-optimization"><a class="header" href="#parallel-deletion-optimization">Parallel Deletion Optimization</a></h2>
<p>High-degree nodes (&gt;100 edges) use rayon’s parallel iterator for edge deletion:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const PARALLEL_THRESHOLD: usize = 100;

pub fn delete_node(&amp;self, id: u64) -&gt; Result&lt;()&gt; {
    if !self.node_exists(id) {
        return Err(GraphError::NodeNotFound(id));
    }

    // Collect all connected edges
    let out_edges = self.get_edge_list(&amp;Self::outgoing_edges_key(id))?;
    let in_edges = self.get_edge_list(&amp;Self::incoming_edges_key(id))?;
    let all_edges: Vec&lt;u64&gt; = out_edges.into_iter().chain(in_edges).collect();

    // Parallel deletion for high-degree nodes
    if all_edges.len() &gt;= Self::PARALLEL_THRESHOLD {
        all_edges.par_iter().for_each(|edge_id| {
            let _ = self.store.delete(&amp;Self::edge_key(*edge_id));
        });
    } else {
        for edge_id in all_edges {
            let _ = self.store.delete(&amp;Self::edge_key(edge_id));
        }
    }

    // Delete node and edge lists
    self.store.delete(&amp;Self::node_key(id))?;
    self.store.delete(&amp;Self::outgoing_edges_key(id))?;
    self.store.delete(&amp;Self::incoming_edges_key(id))?;

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-characteristics-2"><a class="header" href="#performance-characteristics-2">Performance Characteristics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Edge Count</th><th>Deletion Strategy</th><th>Benefit</th></tr></thead><tbody>
<tr><td>&lt; 100</td><td>Sequential</td><td>Lower overhead for small nodes</td></tr>
<tr><td>&gt;= 100</td><td>Parallel (rayon)</td><td>~2-4x speedup on multi-core systems</td></tr>
</tbody></table>
</div>
<h2 id="unified-entity-api"><a class="header" href="#unified-entity-api">Unified Entity API</a></h2>
<p>The Unified Entity API connects any shared entities (not just graph nodes) for
cross-engine queries. Entity edges use the <code>_out</code> and <code>_in</code> reserved fields
in TensorData, enabling the same entity key to have relational fields, graph
connections, and a vector embedding.</p>
<pre class="mermaid">graph LR
    subgraph Entity[&quot;Entity (TensorData)&quot;]
        Fields[User Fields&lt;br/&gt;name, age, etc.]
        Out[&quot;_out&lt;br/&gt;[edge keys]&quot;]
        In[&quot;_in&lt;br/&gt;[edge keys]&quot;]
        Emb[&quot;_embedding&lt;br/&gt;[vector]&quot;]
    end

    subgraph Engines
        RE[Relational Engine]
        GE[Graph Engine]
        VE[Vector Engine]
    end

    Fields --&gt; RE
    Out --&gt; GE
    In --&gt; GE
    Emb --&gt; VE
</pre>
<h3 id="reserved-fields"><a class="header" href="#reserved-fields">Reserved Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>_out</code></td><td><code>Vec&lt;String&gt;</code></td><td>Outgoing edge keys</td></tr>
<tr><td><code>_in</code></td><td><code>Vec&lt;String&gt;</code></td><td>Incoming edge keys</td></tr>
<tr><td><code>_embedding</code></td><td><code>Vec&lt;f32&gt;</code></td><td>Vector embedding</td></tr>
<tr><td><code>_type</code></td><td><code>String</code></td><td>Entity type</td></tr>
<tr><td><code>_id</code></td><td><code>i64</code></td><td>Entity numeric ID</td></tr>
<tr><td><code>_label</code></td><td><code>String</code></td><td>Entity label</td></tr>
</tbody></table>
</div>
<h3 id="entity-edge-key-format"><a class="header" href="#entity-edge-key-format">Entity Edge Key Format</a></h3>
<p>Entity edges use a different key format from node-based edges:</p>
<pre><code class="language-text">edge:{edge_type}:{edge_id}
</code></pre>
<p>For example: <code>edge:follows:42</code></p>
<h3 id="api-reference-2"><a class="header" href="#api-reference-2">API Reference</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create engine with shared store
let store = TensorStore::new();
let engine = GraphEngine::with_store(store.clone());

// Add directed edge between entities
let edge_key = engine.add_entity_edge("user:1", "user:2", "follows")?;

// Add undirected edge between entities
let edge_key = engine.add_entity_edge_undirected("user:1", "user:2", "friend")?;

// Get neighbors
let neighbors = engine.get_entity_neighbors("user:1")?;
let out_neighbors = engine.get_entity_neighbors_out("user:1")?;
let in_neighbors = engine.get_entity_neighbors_in("user:1")?;

// Get edge lists
let outgoing = engine.get_entity_outgoing("user:1")?;
let incoming = engine.get_entity_incoming("user:1")?;

// Get edge details
let (from, to, edge_type, directed) = engine.get_entity_edge(&amp;edge_key)?;

// Check if entity has edges
let has_edges = engine.entity_has_edges("user:1");

// Delete edge
engine.delete_entity_edge(&amp;edge_key)?;

// Scan for entities with edges
let entities = engine.scan_entities_with_edges();
<span class="boring">}</span></code></pre></pre>
<h3 id="undirected-entity-edges"><a class="header" href="#undirected-entity-edges">Undirected Entity Edges</a></h3>
<p>For undirected entity edges, both entities receive the edge in both <code>_out</code> and
<code>_in</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn add_entity_edge_undirected(
    &amp;self,
    key1: &amp;str,
    key2: &amp;str,
    edge_type: &amp;str,
) -&gt; Result&lt;String&gt; {
    // ... create edge data ...

    // Both entities get the edge in both directions
    let mut entity1 = self.get_or_create_entity(key1);
    entity1.add_outgoing_edge(edge_key.clone());
    entity1.add_incoming_edge(edge_key.clone());

    let mut entity2 = self.get_or_create_entity(key2);
    entity2.add_outgoing_edge(edge_key.clone());
    entity2.add_incoming_edge(edge_key.clone());

    Ok(edge_key)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cross-engine-integration"><a class="header" href="#cross-engine-integration">Cross-Engine Integration</a></h2>
<h3 id="query-router-integration"><a class="header" href="#query-router-integration">Query Router Integration</a></h3>
<p>The Query Router provides unified queries combining graph traversal with
vector similarity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find entities similar to query that are connected to a specific entity
let items = router.find_similar_connected("query:entity", "connected_to:entity", top_k)?;

// Find graph neighbors sorted by embedding similarity
let items = router.find_neighbors_by_similarity("entity:key", &amp;query_vector, top_k)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="tensor-vault-integration"><a class="header" href="#tensor-vault-integration">Tensor Vault Integration</a></h3>
<p>Tensor Vault uses GraphEngine for access control relationships:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Vault {
    store: TensorStore,
    pub graph: Arc&lt;GraphEngine&gt;,  // Shared graph for access edges
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p>Access control edges connect principals to secrets with permission metadata.</p>
<h3 id="tensor-chain-integration"><a class="header" href="#tensor-chain-integration">Tensor Chain Integration</a></h3>
<p>Tensor Chain uses GraphEngine for block linking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Chain {
    graph: Arc&lt;GraphEngine&gt;,  // Stores blocks as nodes, links as edges
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p>Blocks are stored with <code>chain:block:{height}</code> keys and linked via graph edges
with type <code>chain_next</code>.</p>
<h2 id="performance-characteristics-3"><a class="header" href="#performance-characteristics-3">Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>create_node</code></td><td>O(1)</td><td>Store put</td></tr>
<tr><td><code>create_edge</code></td><td>O(1)</td><td>Store put + edge list updates</td></tr>
<tr><td><code>get_node</code></td><td>O(1)</td><td>Store get</td></tr>
<tr><td><code>get_edge</code></td><td>O(1)</td><td>Store get</td></tr>
<tr><td><code>neighbors</code></td><td>O(e)</td><td>e = edges from node</td></tr>
<tr><td><code>traverse</code></td><td>O(n + e)</td><td>BFS over reachable nodes</td></tr>
<tr><td><code>find_path</code></td><td>O(n + e)</td><td>BFS shortest path</td></tr>
<tr><td><code>delete_node</code></td><td>O(e)</td><td>Parallel for e &gt;= 100</td></tr>
<tr><td><code>node_count</code></td><td>O(k)</td><td>k = total keys (scan-based)</td></tr>
<tr><td><code>get_edge_list</code></td><td>O(k)</td><td>k = keys in edge list</td></tr>
</tbody></table>
</div>
<h3 id="memory-characteristics"><a class="header" href="#memory-characteristics">Memory Characteristics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Data</th><th>Storage</th></tr></thead><tbody>
<tr><td>Node</td><td>~50-200 bytes + properties</td></tr>
<tr><td>Edge</td><td>~50-150 bytes + properties</td></tr>
<tr><td>Edge list entry</td><td>~10 bytes per edge</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas-2"><a class="header" href="#edge-cases-and-gotchas-2">Edge Cases and Gotchas</a></h2>
<h3 id="self-loop-edges"><a class="header" href="#self-loop-edges">Self-Loop Edges</a></h3>
<p>Self-loops (edges from a node to itself) are valid but filtered from neighbor
results:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn self_loop_edge() {
    let engine = GraphEngine::new();
    let n1 = engine.create_node("A", HashMap::new()).unwrap();
    engine.create_edge(n1, n1, "SELF", HashMap::new(), true).unwrap();

    // Self-loop doesn't appear in neighbors
    let neighbors = engine.neighbors(n1, None, Direction::Both).unwrap();
    assert_eq!(neighbors.len(), 0);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="same-node-path"><a class="header" href="#same-node-path">Same-Node Path</a></h3>
<p>Finding a path from a node to itself returns a single-node path:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let path = engine.find_path(n1, n1)?;
assert_eq!(path.nodes, vec![n1]);
assert!(path.edges.is_empty());
<span class="boring">}</span></code></pre></pre>
<h3 id="deleted-edge-orphans"><a class="header" href="#deleted-edge-orphans">Deleted Edge Orphans</a></h3>
<p>When deleting a node, connected edges are deleted from storage but may remain
in other nodes’ edge lists. This is a known limitation - the edge retrieval
gracefully handles missing edges.</p>
<h3 id="bytes-property-conversion"><a class="header" href="#bytes-property-conversion">Bytes Property Conversion</a></h3>
<p><code>ScalarValue::Bytes</code> converts to <code>PropertyValue::Null</code> since PropertyValue
doesn’t support binary data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let bytes = ScalarValue::Bytes(vec![1, 2, 3]);
assert_eq!(PropertyValue::from_scalar(&amp;bytes), PropertyValue::Null);
<span class="boring">}</span></code></pre></pre>
<h3 id="node-count-calculation"><a class="header" href="#node-count-calculation">Node Count Calculation</a></h3>
<p>The <code>node_count</code> method uses a formula based on scan counts to account for
edge lists:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn node_count(&amp;self) -&gt; usize {
    // Each node has 3 keys: node:{id}, node:{id}:out, node:{id}:in
    self.store.scan_count("node:") - self.store.scan_count("node:") / 3 * 2
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="use-shared-store-for-cross-engine-queries"><a class="header" href="#use-shared-store-for-cross-engine-queries">Use Shared Store for Cross-Engine Queries</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create shared store first
let store = TensorStore::new();

// Create engines with shared store
let graph = GraphEngine::with_store(store.clone());
let vector = VectorEngine::with_store(store.clone());

// Now entities can have both graph edges and embeddings
<span class="boring">}</span></code></pre></pre>
<h3 id="prefer-entity-api-for-cross-engine-data"><a class="header" href="#prefer-entity-api-for-cross-engine-data">Prefer Entity API for Cross-Engine Data</a></h3>
<p>Use the Unified Entity API when entities need to combine relational, graph,
and vector data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Entity API preserves all fields
engine.add_entity_edge("user:1", "user:2", "follows")?;

// Less flexible: Node API creates graph-only entities
engine.create_node("User", props)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-edge-creation"><a class="header" href="#batch-edge-creation">Batch Edge Creation</a></h3>
<p>When creating many edges, avoid creating them one at a time if possible.
Consider the overhead of multiple store operations.</p>
<h3 id="choose-direction-wisely"><a class="header" href="#choose-direction-wisely">Choose Direction Wisely</a></h3>
<ul>
<li>Use <code>Direction::Outgoing</code> for forward-only traversals (dependency graphs)</li>
<li>Use <code>Direction::Both</code> for symmetric relationships (social graphs)</li>
<li>Use <code>Direction::Incoming</code> for reverse lookups (finding predecessors)</li>
</ul>
<h3 id="set-appropriate-traversal-depth"><a class="header" href="#set-appropriate-traversal-depth">Set Appropriate Traversal Depth</a></h3>
<p>BFS traversal can be expensive on dense graphs. Set <code>max_depth</code> based on
expected graph diameter:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// For typical social networks, 3-6 hops is usually sufficient
let reachable = engine.traverse(start, Direction::Both, 4, None)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples-3"><a class="header" href="#usage-examples-3">Usage Examples</a></h2>
<h3 id="social-network"><a class="header" href="#social-network">Social Network</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let engine = GraphEngine::new();

// Create users
let alice = engine.create_node("User", user_props("Alice"))?;
let bob = engine.create_node("User", user_props("Bob"))?;
let charlie = engine.create_node("User", user_props("Charlie"))?;

// Create friendships (undirected)
engine.create_edge(alice, bob, "FRIENDS", HashMap::new(), false)?;
engine.create_edge(bob, charlie, "FRIENDS", HashMap::new(), false)?;

// Find path from Alice to Charlie
let path = engine.find_path(alice, charlie)?;
// path.nodes = [alice, bob, charlie]

// Get Alice's friends
let friends = engine.neighbors(alice, Some("FRIENDS"), Direction::Both)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="dependency-graph"><a class="header" href="#dependency-graph">Dependency Graph</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let engine = GraphEngine::new();

// Create packages
let app = engine.create_node("Package", package_props("app"))?;
let lib_a = engine.create_node("Package", package_props("lib-a"))?;
let lib_b = engine.create_node("Package", package_props("lib-b"))?;

// Create dependencies (directed)
engine.create_edge(app, lib_a, "DEPENDS_ON", HashMap::new(), true)?;
engine.create_edge(app, lib_b, "DEPENDS_ON", HashMap::new(), true)?;
engine.create_edge(lib_a, lib_b, "DEPENDS_ON", HashMap::new(), true)?;

// Find all dependencies of app
let deps = engine.traverse(app, Direction::Outgoing, 10, Some("DEPENDS_ON"))?;
<span class="boring">}</span></code></pre></pre>
<h3 id="cross-engine-unified-entities"><a class="header" href="#cross-engine-unified-entities">Cross-Engine Unified Entities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Shared store for multiple engines
let store = TensorStore::new();
let graph = GraphEngine::with_store(store.clone());

// Add graph edges between entities
graph.add_entity_edge("user:1", "post:1", "created")?;
graph.add_entity_edge("user:2", "post:1", "liked")?;

// Query relationships
let creators = graph.get_entity_neighbors_in("post:1")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="high-degree-node-operations"><a class="header" href="#high-degree-node-operations">High-Degree Node Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let engine = GraphEngine::new();

// Create a hub with many connections (will use parallel deletion)
let hub = engine.create_node("Hub", HashMap::new())?;
for i in 0..150 {
    let leaf = engine.create_node("Leaf", HashMap::new())?;
    engine.create_edge(hub, leaf, "CONNECTS", HashMap::new(), true)?;
}

// Deletion will use parallel processing (150 &gt; 100 threshold)
engine.delete_node(hub)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h2>
<p>The Graph Engine has minimal configuration as it inherits behavior from
TensorStore:</p>
<div class="table-wrapper"><table><thead><tr><th>Setting</th><th>Value</th><th>Description</th></tr></thead><tbody>
<tr><td>Parallel threshold</td><td>100</td><td>Edge count triggering parallel deletion</td></tr>
<tr><td>ID ordering</td><td>SeqCst</td><td>Atomic ordering for ID generation</td></tr>
</tbody></table>
</div>
<h2 id="dependencies-1"><a class="header" href="#dependencies-1">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>Underlying key-value storage</td></tr>
<tr><td><code>rayon</code></td><td>Parallel iteration for high-degree node deletion</td></tr>
<tr><td><code>serde</code></td><td>Serialization of graph types</td></tr>
</tbody></table>
</div>
<h2 id="related-modules-2"><a class="header" href="#related-modules-2">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><a href="architecture/tensor-store.html">Tensor Store</a></td><td>Storage backend</td></tr>
<tr><td><a href="architecture/tensor-vault.html">Tensor Vault</a></td><td>Uses graph for access control</td></tr>
<tr><td><a href="architecture/tensor-chain.html">Tensor Chain</a></td><td>Uses graph for block linking</td></tr>
<tr><td><a href="architecture/query-router.html">Query Router</a></td><td>Executes graph queries</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="vector-engine"><a class="header" href="#vector-engine">Vector Engine</a></h1>
<p>Module 4 of Neumann. Provides embeddings storage and similarity search with
SIMD-accelerated distance computations.</p>
<p>The Vector Engine builds on <code>tensor_store</code> to provide k-NN search capabilities.
It supports both brute-force O(n) search and HNSW O(log n) approximate search,
with automatic sparse vector optimization for memory efficiency.</p>
<h2 id="design-principles-1"><a class="header" href="#design-principles-1">Design Principles</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Principle</th><th>Description</th></tr></thead><tbody>
<tr><td>Layered Architecture</td><td>Depends only on Tensor Store for persistence</td></tr>
<tr><td>Multiple Distance Metrics</td><td>Cosine, Euclidean, and Dot Product similarity</td></tr>
<tr><td>SIMD Acceleration</td><td>8-wide SIMD for dot products and magnitudes</td></tr>
<tr><td>Dual Search Modes</td><td>Brute-force O(n) or HNSW O(log n)</td></tr>
<tr><td>Unified Entities</td><td>Embeddings can be attached to shared entities</td></tr>
<tr><td>Thread Safety</td><td>Inherits from Tensor Store</td></tr>
<tr><td>Serializable Types</td><td>All types implement <code>serde::Serialize</code>/<code>Deserialize</code></td></tr>
<tr><td>Automatic Sparsity Detection</td><td>Vectors with &gt;50% zeros stored efficiently</td></tr>
</tbody></table>
</div>
<h2 id="architecture-4"><a class="header" href="#architecture-4">Architecture</a></h2>
<pre class="mermaid">graph TB
    subgraph VectorEngine
        VE[VectorEngine]
        SR[SearchResult]
        DM[DistanceMetric]
        VE --&gt; |uses| SR
        VE --&gt; |uses| DM
    end

    subgraph TensorStore
        TS[TensorStore]
        HNSW[HNSWIndex]
        SV[SparseVector]
        SIMD[SIMD Functions]
        ES[EmbeddingStorage]
    end

    VE --&gt; |stores to| TS
    VE --&gt; |builds| HNSW
    VE --&gt; |uses| SV
    VE --&gt; |uses| SIMD

    subgraph Storage
        EMB[&quot;emb:{key}&quot;]
        ENT[&quot;entity:{key}._embedding&quot;]
    end

    TS --&gt; EMB
    TS --&gt; ENT
</pre>
<h2 id="key-types-3"><a class="header" href="#key-types-3">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>VectorEngine</code></td><td>Main engine for storing and searching embeddings</td></tr>
<tr><td><code>VectorEngineConfig</code></td><td>Configuration for engine behavior and memory bounds</td></tr>
<tr><td><code>SearchResult</code></td><td>Result with key and similarity score</td></tr>
<tr><td><code>DistanceMetric</code></td><td>Enum: <code>Cosine</code>, <code>Euclidean</code>, <code>DotProduct</code></td></tr>
<tr><td><code>ExtendedDistanceMetric</code></td><td>Extended metrics for HNSW (9+ variants)</td></tr>
<tr><td><code>VectorError</code></td><td>Error types for vector operations</td></tr>
<tr><td><code>EmbeddingInput</code></td><td>Input for batch store operations</td></tr>
<tr><td><code>BatchResult</code></td><td>Result of batch operations</td></tr>
<tr><td><code>Pagination</code></td><td>Parameters for paginated queries</td></tr>
<tr><td><code>PagedResult&lt;T&gt;</code></td><td>Paginated query result</td></tr>
<tr><td><code>HNSWIndex</code></td><td>Hierarchical navigable small world graph (re-exported from tensor_store)</td></tr>
<tr><td><code>HNSWConfig</code></td><td>HNSW index configuration (re-exported from tensor_store)</td></tr>
<tr><td><code>SparseVector</code></td><td>Memory-efficient sparse embedding storage</td></tr>
<tr><td><code>FilterCondition</code></td><td>Filter for metadata-based search (Eq, Ne, Lt, Gt, And, Or, In, etc.)</td></tr>
<tr><td><code>FilterValue</code></td><td>Value type for filters (Int, Float, String, Bool, Null)</td></tr>
<tr><td><code>FilterStrategy</code></td><td>Strategy selection (Auto, PreFilter, PostFilter)</td></tr>
<tr><td><code>FilteredSearchConfig</code></td><td>Configuration for filtered search behavior</td></tr>
<tr><td><code>VectorCollectionConfig</code></td><td>Configuration for vector collections</td></tr>
<tr><td><code>MetadataValue</code></td><td>Simplified value type for embedding metadata</td></tr>
<tr><td><code>PersistentVectorIndex</code></td><td>Serializable index for disk persistence</td></tr>
</tbody></table>
</div>
<h3 id="vectorerror-variants"><a class="header" href="#vectorerror-variants">VectorError Variants</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Description</th><th>When Triggered</th></tr></thead><tbody>
<tr><td><code>NotFound</code></td><td>Embedding key doesn’t exist</td><td><code>get_embedding</code>, <code>delete_embedding</code></td></tr>
<tr><td><code>DimensionMismatch</code></td><td>Vectors have different dimensions</td><td><code>compute_similarity</code>, exceeds <code>max_dimension</code></td></tr>
<tr><td><code>EmptyVector</code></td><td>Empty vector provided</td><td>Any operation with <code>vec![]</code></td></tr>
<tr><td><code>InvalidTopK</code></td><td>top_k is 0</td><td><code>search_similar</code>, <code>search_with_hnsw</code></td></tr>
<tr><td><code>StorageError</code></td><td>Underlying Tensor Store error</td><td>Storage failures</td></tr>
<tr><td><code>BatchValidationError</code></td><td>Invalid input in batch</td><td><code>batch_store_embeddings</code> validation</td></tr>
<tr><td><code>BatchOperationError</code></td><td>Operation failed in batch</td><td><code>batch_store_embeddings</code> execution</td></tr>
<tr><td><code>ConfigurationError</code></td><td>Invalid configuration</td><td><code>VectorEngineConfig::validate()</code></td></tr>
<tr><td><code>CollectionExists</code></td><td>Collection already exists</td><td><code>create_collection</code> with existing name</td></tr>
<tr><td><code>CollectionNotFound</code></td><td>Collection not found</td><td>Collection operations on missing collection</td></tr>
<tr><td><code>IoError</code></td><td>IO error during persistence</td><td><code>save_to_file</code>, <code>load_from_file</code></td></tr>
<tr><td><code>SerializationError</code></td><td>Serialization error</td><td>Index persistence operations</td></tr>
<tr><td><code>SearchTimeout</code></td><td>Search operation timed out</td><td>Search operations exceeding configured timeout</td></tr>
</tbody></table>
</div>
<h2 id="configuration-3"><a class="header" href="#configuration-3">Configuration</a></h2>
<h3 id="vectorengineconfig"><a class="header" href="#vectorengineconfig">VectorEngineConfig</a></h3>
<p>Configuration for the Vector Engine with memory bounds and performance tuning.</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>default_dimension</code></td><td><code>Option&lt;usize&gt;</code></td><td><code>None</code></td><td>Expected embedding dimension</td></tr>
<tr><td><code>sparse_threshold</code></td><td><code>f32</code></td><td><code>0.5</code></td><td>Sparsity threshold (0.0-1.0)</td></tr>
<tr><td><code>parallel_threshold</code></td><td><code>usize</code></td><td><code>5000</code></td><td>Dataset size for parallel search</td></tr>
<tr><td><code>default_metric</code></td><td><code>DistanceMetric</code></td><td><code>Cosine</code></td><td>Default distance metric</td></tr>
<tr><td><code>max_dimension</code></td><td><code>Option&lt;usize&gt;</code></td><td><code>None</code></td><td>Maximum allowed dimension</td></tr>
<tr><td><code>max_keys_per_scan</code></td><td><code>Option&lt;usize&gt;</code></td><td><code>None</code></td><td>Limit for unbounded scans</td></tr>
<tr><td><code>batch_parallel_threshold</code></td><td><code>usize</code></td><td><code>100</code></td><td>Batch size for parallel processing</td></tr>
<tr><td><code>search_timeout</code></td><td><code>Option&lt;Duration&gt;</code></td><td><code>None</code></td><td>Search operation timeout</td></tr>
</tbody></table>
</div>
<h3 id="configuration-presets-1"><a class="header" href="#configuration-presets-1">Configuration Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>Description</th><th>Key Settings</th></tr></thead><tbody>
<tr><td><code>default()</code></td><td>Balanced for most workloads</td><td>All defaults</td></tr>
<tr><td><code>high_throughput()</code></td><td>Optimized for write-heavy loads</td><td><code>parallel_threshold: 1000</code></td></tr>
<tr><td><code>low_memory()</code></td><td>Memory-constrained environments</td><td><code>max_dimension: 4096</code>, <code>max_keys_per_scan: 10000</code>, <code>search_timeout: 30s</code></td></tr>
</tbody></table>
</div>
<h3 id="builder-methods"><a class="header" href="#builder-methods">Builder Methods</a></h3>
<p>All builder methods are <code>const fn</code> for compile-time configuration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::time::Duration;

let config = VectorEngineConfig::default()
    .with_default_dimension(768)
    .with_sparse_threshold(0.7)
    .with_parallel_threshold(1000)
    .with_default_metric(DistanceMetric::Cosine)
    .with_max_dimension(4096)
    .with_max_keys_per_scan(50_000)
    .with_batch_parallel_threshold(200)
    .with_search_timeout(Duration::from_secs(5));

let engine = VectorEngine::with_config(config)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-bounds"><a class="header" href="#memory-bounds">Memory Bounds</a></h3>
<p>For production deployments, configure memory bounds to prevent resource exhaustion:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Reject embeddings larger than 4096 dimensions
let config = VectorEngineConfig::default()
    .with_max_dimension(4096)
    .with_max_keys_per_scan(10_000);

let engine = VectorEngine::with_config(config)?;

// This will fail with DimensionMismatch
engine.store_embedding("too_big", vec![0.0; 5000])?; // Error!
<span class="boring">}</span></code></pre></pre>
<h3 id="search-timeout"><a class="header" href="#search-timeout">Search Timeout</a></h3>
<p>Configure a timeout for search operations to prevent runaway queries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::time::Duration;
use vector_engine::{VectorEngine, VectorEngineConfig, VectorError};

let config = VectorEngineConfig::default()
    .with_search_timeout(Duration::from_secs(5));

let engine = VectorEngine::with_config(config)?;

match engine.search_similar(&amp;query, 10) {
    Ok(results) =&gt; { /* process results */ },
    Err(VectorError::SearchTimeout { operation, timeout_ms }) =&gt; {
        eprintln!("Search '{}' timed out after {}ms", operation, timeout_ms);
    },
    Err(e) =&gt; { /* handle other errors */ },
}
<span class="boring">}</span></code></pre></pre>
<p>The timeout applies to all search methods. When a timeout occurs, no partial
results are returned to prevent misleading results that may miss better matches.</p>
<h2 id="distance-metrics-1"><a class="header" href="#distance-metrics-1">Distance Metrics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Formula</th><th>Score Range</th><th>Use Case</th><th>HNSW Support</th></tr></thead><tbody>
<tr><td>Cosine</td><td><code>a.b / (‖a‖ * ‖b‖)</code></td><td>-1.0 to 1.0</td><td>Semantic similarity</td><td>Yes</td></tr>
<tr><td>Euclidean</td><td><code>1 / (1 + sqrt(sum((a-b)^2)))</code></td><td>0.0 to 1.0</td><td>Spatial distance</td><td>No (brute-force)</td></tr>
<tr><td>DotProduct</td><td><code>sum(a * b)</code></td><td>unbounded</td><td>Magnitude-aware</td><td>No (brute-force)</td></tr>
</tbody></table>
</div>
<p>All metrics return higher scores for better matches. Euclidean distance is
transformed to similarity score.</p>
<h3 id="extended-distance-metrics-hnsw"><a class="header" href="#extended-distance-metrics-hnsw">Extended Distance Metrics (HNSW)</a></h3>
<p>The <code>ExtendedDistanceMetric</code> enum provides additional metrics for HNSW-based
search via <code>search_with_hnsw_and_metric()</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Description</th><th>Best For</th></tr></thead><tbody>
<tr><td><code>Cosine</code></td><td>Angle-based similarity</td><td>Text embeddings, normalized vectors</td></tr>
<tr><td><code>Euclidean</code></td><td>L2 distance</td><td>Spatial data, absolute distances</td></tr>
<tr><td><code>Angular</code></td><td>Cosine converted to angular</td><td>When angle interpretation needed</td></tr>
<tr><td><code>Manhattan</code></td><td>L1 norm</td><td>Robust to outliers</td></tr>
<tr><td><code>Chebyshev</code></td><td>L-infinity (max diff)</td><td>When max deviation matters</td></tr>
<tr><td><code>Jaccard</code></td><td>Set similarity</td><td>Binary/sparse vectors, TF-IDF</td></tr>
<tr><td><code>Overlap</code></td><td>Minimum overlap coefficient</td><td>Partial matches</td></tr>
<tr><td><code>Geodesic</code></td><td>Spherical distance</td><td>Geographic coordinates</td></tr>
<tr><td><code>Composite</code></td><td>Weighted combination</td><td>Custom similarity functions</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::ExtendedDistanceMetric;

let (index, keys) = engine.build_hnsw_index_default()?;

// Search with Jaccard similarity for sparse vectors
let results = engine.search_with_hnsw_and_metric(
    &amp;index,
    &amp;keys,
    &amp;query,
    10,
    ExtendedDistanceMetric::Jaccard,
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="distance-metric-implementation-details"><a class="header" href="#distance-metric-implementation-details">Distance Metric Implementation Details</a></h3>
<pre class="mermaid">flowchart TD
    Query[Query Vector] --&gt; MetricCheck{Which Metric?}

    MetricCheck --&gt;|Cosine| CosMag[Pre-compute query magnitude]
    CosMag --&gt; CosDot[SIMD dot product]
    CosDot --&gt; CosDiv[Divide by magnitudes]
    CosDiv --&gt; CosScore[Score: dot / mag_a * mag_b]

    MetricCheck --&gt;|Euclidean| EucDiff[Compute differences]
    EucDiff --&gt; EucSum[Sum of squares]
    EucSum --&gt; EucSqrt[Square root]
    EucSqrt --&gt; EucScore[Score: 1 / 1 + distance]

    MetricCheck --&gt;|DotProduct| DotSIMD[SIMD dot product]
    DotSIMD --&gt; DotScore[Score: raw dot product]
</pre>
<h4 id="cosine-similarity-edge-cases"><a class="header" href="#cosine-similarity-edge-cases">Cosine Similarity Edge Cases</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Zero-magnitude vectors return 0.0 similarity
let zero = vec![0.0, 0.0, 0.0];
let normal = vec![1.0, 2.0, 3.0];
VectorEngine::compute_similarity(&amp;zero, &amp;normal)?; // Returns 0.0

// Identical vectors return 1.0
VectorEngine::compute_similarity(&amp;normal, &amp;normal)?; // Returns 1.0

// Opposite vectors return -1.0
let opposite = vec![-1.0, -2.0, -3.0];
VectorEngine::compute_similarity(&amp;normal, &amp;opposite)?; // Returns -1.0

// Orthogonal vectors return 0.0
let a = vec![1.0, 0.0];
let b = vec![0.0, 1.0];
VectorEngine::compute_similarity(&amp;a, &amp;b)?; // Returns 0.0
<span class="boring">}</span></code></pre></pre>
<h4 id="euclidean-distance-transformation"><a class="header" href="#euclidean-distance-transformation">Euclidean Distance Transformation</a></h4>
<p>The engine transforms Euclidean distance to similarity score using <code>1 / (1 + distance)</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Distance</th><th>Similarity Score</th></tr></thead><tbody>
<tr><td>0.0</td><td>1.0 (identical)</td></tr>
<tr><td>1.0</td><td>0.5</td></tr>
<tr><td>2.0</td><td>0.333</td></tr>
<tr><td>9.0</td><td>0.1</td></tr>
<tr><td>Infinity</td><td>0.0</td></tr>
</tbody></table>
</div>
<h2 id="simd-implementation"><a class="header" href="#simd-implementation">SIMD Implementation</a></h2>
<p>The Vector Engine uses 8-wide SIMD operations via the <code>wide</code> crate for
accelerated distance computations.</p>
<h3 id="simd-dot-product-algorithm"><a class="header" href="#simd-dot-product-algorithm">SIMD Dot Product Algorithm</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simplified view of the SIMD implementation
pub fn dot_product(a: &amp;[f32], b: &amp;[f32]) -&gt; f32 {
    let chunks = a.len() / 8;        // Process 8 floats at a time
    let remainder = a.len() % 8;

    let mut sum = f32x8::ZERO;

    // Process 8 elements at a time with SIMD
    for i in 0..chunks {
        let offset = i * 8;
        let va = f32x8::from(&amp;a[offset..offset + 8]);
        let vb = f32x8::from(&amp;b[offset..offset + 8]);
        sum += va * vb;  // Parallel multiply-add
    }

    // Sum SIMD lanes + handle remainder scalar
    let arr: [f32; 8] = sum.into();
    let mut result: f32 = arr.iter().sum();

    // Handle remainder with scalar operations
    let start = chunks * 8;
    for i in 0..remainder {
        result += a[start + i] * b[start + i];
    }

    result
}
<span class="boring">}</span></code></pre></pre>
<h3 id="simd-performance-characteristics"><a class="header" href="#simd-performance-characteristics">SIMD Performance Characteristics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>SIMD Speedup</th><th>Notes</th></tr></thead><tbody>
<tr><td>8</td><td>1x</td><td>Baseline (single SIMD operation)</td></tr>
<tr><td>64</td><td>4-6x</td><td>Full pipeline utilization</td></tr>
<tr><td>384</td><td>6-8x</td><td>Sentence Transformers size</td></tr>
<tr><td>768</td><td>6-8x</td><td>BERT embedding size</td></tr>
<tr><td>1536</td><td>6-8x</td><td>OpenAI ada-002 size</td></tr>
<tr><td>3072</td><td>6-8x</td><td>OpenAI text-embedding-3-large</td></tr>
</tbody></table>
</div>
<p>SIMD operations are cache-friendly due to sequential memory access patterns.</p>
<h2 id="api-reference-3"><a class="header" href="#api-reference-3">API Reference</a></h2>
<h3 id="basic-operations-2"><a class="header" href="#basic-operations-2">Basic Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let engine = VectorEngine::new();

// Store an embedding
engine.store_embedding("doc1", vec![0.1, 0.2, 0.3])?;

// Get an embedding
let vector = engine.get_embedding("doc1")?;

// Delete an embedding
engine.delete_embedding("doc1")?;

// Check existence
engine.exists("doc1");  // -&gt; bool

// Count embeddings
engine.count();  // -&gt; usize

// List all keys
let keys = engine.list_keys();

// Clear all embeddings
engine.clear()?;

// Get dimension (from first embedding)
engine.dimension();  // -&gt; Option&lt;usize&gt;
<span class="boring">}</span></code></pre></pre>
<h3 id="similarity-search"><a class="header" href="#similarity-search">Similarity Search</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find top-k most similar (cosine by default)
let query = vec![0.1, 0.2, 0.3];
let results = engine.search_similar(&amp;query, 5)?;

for result in results {
    println!("Key: {}, Score: {}", result.key, result.score);
}

// Search with specific metric
let results = engine.search_similar_with_metric(
    &amp;query,
    5,
    DistanceMetric::Euclidean
)?;

// Direct similarity computation
let similarity = VectorEngine::compute_similarity(&amp;vec_a, &amp;vec_b)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="filtered-search"><a class="header" href="#filtered-search">Filtered Search</a></h3>
<p>Search with metadata filters to narrow results without post-processing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::{FilterCondition, FilterValue, FilteredSearchConfig, FilterStrategy};

// Build a filter condition
let filter = FilterCondition::Eq("category".to_string(), FilterValue::String("science".to_string()))
    .and(FilterCondition::Gt("year".to_string(), FilterValue::Int(2020)));

// Search with filter (auto strategy)
let results = engine.search_similar_filtered(&amp;query, 10, &amp;filter, None)?;

// Search with explicit pre-filter strategy (best for selective filters)
let config = FilteredSearchConfig::pre_filter();
let results = engine.search_similar_filtered(&amp;query, 10, &amp;filter, Some(config))?;

// Search with post-filter and custom oversample
let config = FilteredSearchConfig::post_filter().with_oversample(5);
let results = engine.search_similar_filtered(&amp;query, 10, &amp;filter, Some(config))?;
<span class="boring">}</span></code></pre></pre>
<h4 id="filter-conditions"><a class="header" href="#filter-conditions">Filter Conditions</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Condition</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>Eq(field, value)</code></td><td>Equality</td><td><code>category = "science"</code></td></tr>
<tr><td><code>Ne(field, value)</code></td><td>Not equal</td><td><code>status != "deleted"</code></td></tr>
<tr><td><code>Lt(field, value)</code></td><td>Less than</td><td><code>price &lt; 100</code></td></tr>
<tr><td><code>Le(field, value)</code></td><td>Less than or equal</td><td><code>price &lt;= 100</code></td></tr>
<tr><td><code>Gt(field, value)</code></td><td>Greater than</td><td><code>year &gt; 2020</code></td></tr>
<tr><td><code>Ge(field, value)</code></td><td>Greater than or equal</td><td><code>year &gt;= 2020</code></td></tr>
<tr><td><code>And(a, b)</code></td><td>Logical AND</td><td>Combined conditions</td></tr>
<tr><td><code>Or(a, b)</code></td><td>Logical OR</td><td>Alternative conditions</td></tr>
<tr><td><code>In(field, values)</code></td><td>Value in list</td><td><code>status IN ["active", "pending"]</code></td></tr>
<tr><td><code>Contains(field, substr)</code></td><td>String contains</td><td><code>title CONTAINS "rust"</code></td></tr>
<tr><td><code>StartsWith(field, prefix)</code></td><td>String prefix</td><td><code>name STARTS WITH "doc:"</code></td></tr>
<tr><td><code>Exists(field)</code></td><td>Field exists</td><td><code>HAS embedding</code></td></tr>
<tr><td><code>True</code></td><td>Always matches</td><td>No filter</td></tr>
</tbody></table>
</div>
<h4 id="filter-strategies"><a class="header" href="#filter-strategies">Filter Strategies</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>When to Use</th><th>Behavior</th></tr></thead><tbody>
<tr><td><code>Auto</code></td><td>Default</td><td>Estimates selectivity and chooses</td></tr>
<tr><td><code>PreFilter</code></td><td>&lt; 10% matches</td><td>Filters first, then searches subset</td></tr>
<tr><td><code>PostFilter</code></td><td>&gt; 10% matches</td><td>Searches with oversample, then filters</td></tr>
</tbody></table>
</div><pre class="mermaid">flowchart TD
    Query[Query + Filter] --&gt; Strategy{Which Strategy?}

    Strategy --&gt;|Auto| Estimate[Estimate Selectivity]
    Estimate --&gt;|&lt; 10%| Pre[Pre-Filter]
    Estimate --&gt;|&gt;= 10%| Post[Post-Filter]

    Strategy --&gt;|PreFilter| Pre
    Strategy --&gt;|PostFilter| Post

    Pre --&gt; Filter1[Filter all keys]
    Filter1 --&gt; Search1[Search filtered subset]
    Search1 --&gt; Result[Top-K Results]

    Post --&gt; Search2[Search with oversample]
    Search2 --&gt; Filter2[Filter candidates]
    Filter2 --&gt; Result
</pre>
<h4 id="filter-helper-methods"><a class="header" href="#filter-helper-methods">Filter Helper Methods</a></h4>
<p>Utilities for working with filters:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Estimate how selective a filter is (0.0 = matches nothing, 1.0 = matches all)
let selectivity = engine.estimate_filter_selectivity(&amp;filter);

// Count how many embeddings match a filter
let matching = engine.count_matching(&amp;filter);

// Get keys of all matching embeddings
let keys = engine.list_keys_matching(&amp;filter);
<span class="boring">}</span></code></pre></pre>
<h3 id="metadata-storage"><a class="header" href="#metadata-storage">Metadata Storage</a></h3>
<p>Store and retrieve metadata alongside embeddings:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::TensorValue;
use std::collections::HashMap;

// Store embedding with metadata
let mut metadata = HashMap::new();
metadata.insert("category".to_string(), TensorValue::from("science"));
metadata.insert("year".to_string(), TensorValue::from(2024i64));
metadata.insert("score".to_string(), TensorValue::from(0.95f64));

engine.store_embedding_with_metadata("doc1", vec![0.1, 0.2, 0.3], metadata)?;

// Get all metadata
let meta = engine.get_metadata("doc1")?;

// Get specific field
let category = engine.get_metadata_field("doc1", "category")?;

// Update metadata (merges with existing)
let mut updates = HashMap::new();
updates.insert("score".to_string(), TensorValue::from(0.98f64));
engine.update_metadata("doc1", updates)?;

// Check if metadata field exists
if engine.has_metadata_field("doc1", "category") {
    // Remove specific metadata field
    engine.remove_metadata_field("doc1", "category")?;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-operations-1"><a class="header" href="#batch-operations-1">Batch Operations</a></h3>
<p>For bulk insert and delete operations with parallel processing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::EmbeddingInput;

// Batch store - validates all inputs first, then stores in parallel
let inputs = vec![
    EmbeddingInput::new("doc1", vec![0.1, 0.2, 0.3]),
    EmbeddingInput::new("doc2", vec![0.2, 0.3, 0.4]),
    EmbeddingInput::new("doc3", vec![0.3, 0.4, 0.5]),
];

let result = engine.batch_store_embeddings(inputs)?;
println!("Stored {} embeddings", result.count);  // -&gt; 3

// Batch delete - returns count of successfully deleted
let keys = vec!["doc1".to_string(), "doc2".to_string()];
let deleted = engine.batch_delete_embeddings(keys)?;
println!("Deleted {} embeddings", deleted);  // -&gt; 2
<span class="boring">}</span></code></pre></pre>
<p>Batches larger than <code>batch_parallel_threshold</code> (default: 100) use parallel
processing via rayon.</p>
<h3 id="pagination"><a class="header" href="#pagination">Pagination</a></h3>
<p>For memory-efficient iteration over large datasets:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::Pagination;

// List keys with pagination
let page = Pagination::new(0, 100);  // skip=0, limit=100
let result = engine.list_keys_paginated(page);
println!("Items: {}, Has more: {}", result.items.len(), result.has_more);

// Get total count with pagination
let page = Pagination::new(0, 100).with_total();
let result = engine.list_keys_paginated(page);
println!("Total: {:?}", result.total_count);  // Some(total)

// Paginated similarity search
let page = Pagination::new(10, 5);  // skip first 10, return 5
let results = engine.search_similar_paginated(&amp;query, 100, page)?;

// Paginated entity search
let results = engine.search_entities_paginated(&amp;query, 100, page)?;
<span class="boring">}</span></code></pre></pre>
<p>Use <code>list_keys_bounded()</code> for production to enforce <code>max_keys_per_scan</code> limits.</p>
<h3 id="search-flow-diagram"><a class="header" href="#search-flow-diagram">Search Flow Diagram</a></h3>
<pre class="mermaid">sequenceDiagram
    participant Client
    participant VE as VectorEngine
    participant TS as TensorStore
    participant SIMD

    Client-&gt;&gt;VE: search_similar(query, k)
    VE-&gt;&gt;VE: Validate query (non-empty, k &gt; 0)
    VE-&gt;&gt;SIMD: Pre-compute query magnitude
    VE-&gt;&gt;TS: scan(&quot;emb:&quot;)
    TS--&gt;&gt;VE: List of embedding keys

    alt Dataset &lt; 5000 vectors
        VE-&gt;&gt;VE: Sequential search
    else Dataset &gt;= 5000 vectors
        VE-&gt;&gt;VE: Parallel search (rayon)
    end

    loop For each embedding
        VE-&gt;&gt;TS: get(key)
        TS--&gt;&gt;VE: TensorData
        VE-&gt;&gt;VE: Extract vector (dense or sparse)
        VE-&gt;&gt;SIMD: cosine_similarity(query, stored)
        VE-&gt;&gt;VE: Collect SearchResult
    end

    VE-&gt;&gt;VE: Sort by score descending
    VE-&gt;&gt;VE: Truncate to top k
    VE--&gt;&gt;Client: Vec&lt;SearchResult&gt;
</pre>
<h3 id="hnsw-index-2"><a class="header" href="#hnsw-index-2">HNSW Index</a></h3>
<p>For large datasets, build an HNSW index for O(log n) search:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Build index with default config
let (index, key_mapping) = engine.build_hnsw_index_default()?;

// Search using the index
let results = engine.search_with_hnsw(&amp;index, &amp;key_mapping, &amp;query, 10)?;

// Build with custom config
let config = HNSWConfig::high_recall();
let (index, key_mapping) = engine.build_hnsw_index(config)?;

// Direct HNSW operations
let index = HNSWIndex::new();
index.insert(vec![1.0, 2.0, 3.0]);
let results = index.search(&amp;query, 10);

// Search with custom ef (recall/speed tradeoff)
let results = index.search_with_ef(&amp;query, 10, 200);
<span class="boring">}</span></code></pre></pre>
<h3 id="hnsw-search-flow"><a class="header" href="#hnsw-search-flow">HNSW Search Flow</a></h3>
<pre class="mermaid">flowchart TD
    Query[Query Vector] --&gt; Entry[Entry Point at Max Layer]

    Entry --&gt; Greedy1[Greedy Search Layer L]
    Greedy1 --&gt; |Find closest| Greedy2[Greedy Search Layer L-1]
    Greedy2 --&gt; |...|GreedyN[Greedy Search until Layer 1]

    GreedyN --&gt; Layer0[Full ef-Search at Layer 0]

    Layer0 --&gt; Candidates[Candidate Pool]
    Candidates --&gt; |BinaryHeap min-heap| Visit[Visit Neighbors]
    Visit --&gt; Distance[Compute Distances]
    Distance --&gt; |Update| Results[Result Pool]
    Results --&gt; |BinaryHeap max-heap| Prune[Keep top ef]

    Prune --&gt; |More candidates?| Visit
    Prune --&gt; |Done| TopK[Return Top K]
</pre>
<h3 id="unified-entity-mode"><a class="header" href="#unified-entity-mode">Unified Entity Mode</a></h3>
<p>Attach embeddings directly to entities for cross-engine queries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let store = TensorStore::new();
let engine = VectorEngine::with_store(store.clone());

// Set embedding on an entity
engine.set_entity_embedding("user:1", vec![0.1, 0.2, 0.3])?;

// Get embedding from an entity
let embedding = engine.get_entity_embedding("user:1")?;

// Check if entity has embedding
engine.entity_has_embedding("user:1");  // -&gt; bool

// Remove embedding (preserves other entity data)
engine.remove_entity_embedding("user:1")?;

// Search entities with embeddings
let results = engine.search_entities(&amp;query, 5)?;

// Scan all entities with embeddings
let entity_keys = engine.scan_entities_with_embeddings();

// Count entities with embeddings
let count = engine.count_entities_with_embeddings();
<span class="boring">}</span></code></pre></pre>
<p>Unified entity embeddings are stored in the <code>_embedding</code> field of the entity’s
TensorData.</p>
<h2 id="collections"><a class="header" href="#collections">Collections</a></h2>
<p>Collections provide isolated namespaces for organizing embeddings by type or
purpose. Each collection can have its own dimension constraints and distance
metric configuration.</p>
<h3 id="creating-and-managing-collections"><a class="header" href="#creating-and-managing-collections">Creating and Managing Collections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::{VectorEngine, VectorCollectionConfig, DistanceMetric};

let engine = VectorEngine::new();

// Create collection with custom config
let config = VectorCollectionConfig::default()
    .with_dimension(768)
    .with_metric(DistanceMetric::Cosine)
    .with_auto_index(5000);  // Auto-build HNSW at 5000 vectors

engine.create_collection("documents", config)?;

// List collections
let collections = engine.list_collections();

// Check if collection exists
engine.collection_exists("documents");  // -&gt; true

// Get collection config
let config = engine.get_collection_config("documents");

// Delete collection (removes all vectors in it)
engine.delete_collection("documents")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="storing-in-collections"><a class="header" href="#storing-in-collections">Storing in Collections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::collections::HashMap;
use tensor_store::TensorValue;

// Store vector in collection
engine.store_in_collection("documents", "doc1", vec![0.1, 0.2, 0.3])?;

// Store with metadata
let mut metadata = HashMap::new();
metadata.insert("title".to_string(), TensorValue::from("Introduction to Rust"));
metadata.insert("author".to_string(), TensorValue::from("Alice"));

engine.store_in_collection_with_metadata(
    "documents",
    "doc1",
    vec![0.1, 0.2, 0.3],
    metadata
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="searching-in-collections"><a class="header" href="#searching-in-collections">Searching in Collections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::{FilterCondition, FilterValue};

// Basic search in collection
let results = engine.search_in_collection("documents", &amp;query, 10)?;

// Filtered search in collection
let filter = FilterCondition::Eq("author".to_string(), FilterValue::String("Alice".to_string()));
let results = engine.search_filtered_in_collection(
    "documents",
    &amp;query,
    10,
    &amp;filter,
    None
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="collection-key-isolation"><a class="header" href="#collection-key-isolation">Collection Key Isolation</a></h3>
<p>Collections use prefixed storage keys to ensure isolation:</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Storage Key Pattern</th></tr></thead><tbody>
<tr><td>Default embeddings</td><td><code>emb:{key}</code></td></tr>
<tr><td>Collection embeddings</td><td><code>coll:{collection}:emb:{key}</code></td></tr>
<tr><td>Entity embeddings</td><td><code>{entity_key}._embedding</code></td></tr>
</tbody></table>
</div>
<h3 id="vectorcollectionconfig"><a class="header" href="#vectorcollectionconfig">VectorCollectionConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>dimension</code></td><td><code>Option&lt;usize&gt;</code></td><td><code>None</code></td><td>Enforced dimension (rejects mismatches)</td></tr>
<tr><td><code>distance_metric</code></td><td><code>DistanceMetric</code></td><td><code>Cosine</code></td><td>Default metric for this collection</td></tr>
<tr><td><code>auto_index</code></td><td><code>bool</code></td><td><code>false</code></td><td>Auto-build HNSW on threshold</td></tr>
<tr><td><code>auto_index_threshold</code></td><td><code>usize</code></td><td><code>1000</code></td><td>Vector count to trigger auto-index</td></tr>
</tbody></table>
</div>
<h2 id="index-persistence"><a class="header" href="#index-persistence">Index Persistence</a></h2>
<p>Save and restore vector indices for fast startup:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::path::Path;

// Save all collections to directory (one JSON file per collection)
let saved = engine.save_all_indices(Path::new("./vector_index"))?;

// Load all indices from directory
let loaded = engine.load_all_indices(Path::new("./vector_index"))?;

// Save single collection to JSON
engine.save_index("documents", Path::new("./documents.json"))?;

// Save single collection to compact binary format
engine.save_index_binary("documents", Path::new("./documents.bin"))?;

// Load single collection from JSON (returns collection name)
let collection = engine.load_index(Path::new("./documents.json"))?;

// Load single collection from binary
let collection = engine.load_index_binary(Path::new("./documents.bin"))?;

// Get a snapshot for manual serialization
let index: PersistentVectorIndex = engine.snapshot_collection("documents");
<span class="boring">}</span></code></pre></pre>
<h3 id="persistentvectorindex-format"><a class="header" href="#persistentvectorindex-format">PersistentVectorIndex Format</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>collection</code></td><td><code>String</code></td><td>Collection name</td></tr>
<tr><td><code>config</code></td><td><code>VectorCollectionConfig</code></td><td>Collection configuration</td></tr>
<tr><td><code>vectors</code></td><td><code>Vec&lt;VectorEntry&gt;</code></td><td>All vectors with metadata</td></tr>
<tr><td><code>created_at</code></td><td><code>u64</code></td><td>Unix timestamp</td></tr>
<tr><td><code>version</code></td><td><code>u32</code></td><td>Format version (currently 1)</td></tr>
</tbody></table>
</div>
<h2 id="storage-model-2"><a class="header" href="#storage-model-2">Storage Model</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Key Pattern</th><th>Content</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>emb:{key}</code></td><td>TensorData with “vector” field</td><td>Default collection embeddings</td></tr>
<tr><td><code>coll:{collection}:emb:{key}</code></td><td>TensorData with “vector” field</td><td>Named collection embeddings</td></tr>
<tr><td><code>{entity_key}</code></td><td>TensorData with “_embedding” field</td><td>Unified entities</td></tr>
</tbody></table>
</div>
<h3 id="automatic-sparse-storage"><a class="header" href="#automatic-sparse-storage">Automatic Sparse Storage</a></h3>
<p>Vectors with &gt;50% zeros are automatically stored as sparse vectors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detection threshold: nnz * 2 &lt;= len (i.e., sparsity &gt;= 50%)
fn should_use_sparse(vector: &amp;[f32]) -&gt; bool {
    let nnz = vector.iter().filter(|&amp;&amp;v| v.abs() &gt; 1e-6).count();
    nnz * 2 &lt;= vector.len()
}

// 97% sparse vector (3 non-zeros in 100 elements)
let mut sparse = vec![0.0f32; 100];
sparse[0] = 1.0;
sparse[50] = 2.0;
sparse[99] = 3.0;

// Stored efficiently as SparseVector
engine.store_embedding("sparse_doc", sparse)?;

// Retrieved as dense for computation
let dense = engine.get_embedding("sparse_doc")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="storage-format-comparison"><a class="header" href="#storage-format-comparison">Storage Format Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Memory per Element</th><th>Best For</th></tr></thead><tbody>
<tr><td>Dense</td><td>4 bytes</td><td>Sparsity &lt; 50%</td></tr>
<tr><td>Sparse</td><td>8 bytes per non-zero (4 pos + 4 val)</td><td>Sparsity &gt; 50%</td></tr>
</tbody></table>
</div>
<p>Example: 1000-dim vector with 100 non-zeros:</p>
<ul>
<li>Dense: 4000 bytes</li>
<li>Sparse: 800 bytes (5x compression)</li>
</ul>
<h2 id="sparse-vector-operations"><a class="header" href="#sparse-vector-operations">Sparse Vector Operations</a></h2>
<h3 id="memory-layout"><a class="header" href="#memory-layout">Memory Layout</a></h3>
<pre><code class="language-text">SparseVector {
    dimension: usize,        // Total vector dimension
    positions: Vec&lt;u32&gt;,     // Sorted indices of non-zeros
    values: Vec&lt;f32&gt;,        // Corresponding values
}
</code></pre>
<h3 id="sparse-dot-product-algorithm"><a class="header" href="#sparse-dot-product-algorithm">Sparse Dot Product Algorithm</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// O(min(nnz_a, nnz_b)) - only overlapping positions contribute
pub fn dot(&amp;self, other: &amp;SparseVector) -&gt; f32 {
    let mut result = 0.0;
    let mut i = 0;
    let mut j = 0;

    // Merge-sort style traversal
    while i &lt; self.positions.len() &amp;&amp; j &lt; other.positions.len() {
        match self.positions[i].cmp(&amp;other.positions[j]) {
            Equal =&gt; {
                result += self.values[i] * other.values[j];
                i += 1; j += 1;
            },
            Less =&gt; i += 1,
            Greater =&gt; j += 1,
        }
    }
    result
}
<span class="boring">}</span></code></pre></pre>
<h3 id="sparse-dense-dot-product"><a class="header" href="#sparse-dense-dot-product">Sparse-Dense Dot Product</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// O(nnz) - only iterate over sparse non-zeros
pub fn dot_dense(&amp;self, dense: &amp;[f32]) -&gt; f32 {
    self.positions.iter()
        .zip(&amp;self.values)
        .map(|(&amp;pos, &amp;val)| val * dense[pos as usize])
        .sum()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="sparse-distance-metrics"><a class="header" href="#sparse-distance-metrics">Sparse Distance Metrics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Complexity</th><th>Description</th></tr></thead><tbody>
<tr><td><code>dot</code></td><td>O(min(nnz_a, nnz_b))</td><td>Sparse-sparse dot product</td></tr>
<tr><td><code>dot_dense</code></td><td>O(nnz)</td><td>Sparse-dense dot product</td></tr>
<tr><td><code>cosine_similarity</code></td><td>O(min(nnz_a, nnz_b))</td><td>Angle-based similarity</td></tr>
<tr><td><code>euclidean_distance</code></td><td>O(nnz_a + nnz_b)</td><td>L2 distance</td></tr>
<tr><td><code>manhattan_distance</code></td><td>O(nnz_a + nnz_b)</td><td>L1 distance</td></tr>
<tr><td><code>jaccard_index</code></td><td>O(min(nnz_a, nnz_b))</td><td>Position overlap</td></tr>
<tr><td><code>angular_distance</code></td><td>O(min(nnz_a, nnz_b))</td><td>Arc-cosine</td></tr>
</tbody></table>
</div>
<h2 id="hnsw-configuration"><a class="header" href="#hnsw-configuration">HNSW Configuration</a></h2>
<h3 id="configuration-parameters"><a class="header" href="#configuration-parameters">Configuration Parameters</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>m</code></td><td>16</td><td>Max connections per node per layer</td></tr>
<tr><td><code>m0</code></td><td>32</td><td>Max connections at layer 0 (2*m)</td></tr>
<tr><td><code>ef_construction</code></td><td>200</td><td>Candidates during index building</td></tr>
<tr><td><code>ef_search</code></td><td>50</td><td>Candidates during search</td></tr>
<tr><td><code>ml</code></td><td>1/ln(m)</td><td>Level multiplier for layer selection</td></tr>
<tr><td><code>sparsity_threshold</code></td><td>0.5</td><td>Auto-sparse threshold</td></tr>
<tr><td><code>max_nodes</code></td><td>10,000,000</td><td>Capacity limit</td></tr>
</tbody></table>
</div>
<h3 id="presets"><a class="header" href="#presets">Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>m</th><th>m0</th><th>ef_construction</th><th>ef_search</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>default()</code></td><td>16</td><td>32</td><td>200</td><td>50</td><td>Balanced</td></tr>
<tr><td><code>high_recall()</code></td><td>32</td><td>64</td><td>400</td><td>200</td><td>Accuracy over speed</td></tr>
<tr><td><code>high_speed()</code></td><td>8</td><td>16</td><td>100</td><td>20</td><td>Speed over accuracy</td></tr>
</tbody></table>
</div>
<h3 id="tuning-guidelines"><a class="header" href="#tuning-guidelines">Tuning Guidelines</a></h3>
<pre class="mermaid">graph TD
    subgraph &quot;Higher m / ef&quot;
        A[More connections per node]
        B[Better recall]
        C[More memory]
        D[Slower insert]
    end

    subgraph &quot;Lower m / ef&quot;
        E[Fewer connections]
        F[Lower recall]
        G[Less memory]
        H[Faster insert]
    end

    A --&gt; B
    A --&gt; C
    A --&gt; D

    E --&gt; F
    E --&gt; G
    E --&gt; H
</pre>
<h4 id="workload-specific-tuning"><a class="header" href="#workload-specific-tuning">Workload-Specific Tuning</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Workload</th><th>Recommended Config</th><th>Rationale</th></tr></thead><tbody>
<tr><td>RAG/Semantic Search</td><td><code>high_recall()</code></td><td>Accuracy critical</td></tr>
<tr><td>Real-time recommendations</td><td><code>high_speed()</code></td><td>Latency critical</td></tr>
<tr><td>Batch processing</td><td><code>default()</code></td><td>Balanced</td></tr>
<tr><td>Small dataset (&lt;10K)</td><td>Brute-force</td><td>HNSW overhead not worth it</td></tr>
<tr><td>Large dataset (&gt;100K)</td><td><code>default()</code> with higher ef_search</td><td>Scale benefits</td></tr>
</tbody></table>
</div>
<h4 id="memory-vs-recall-tradeoff"><a class="header" href="#memory-vs-recall-tradeoff">Memory vs Recall Tradeoff</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Config</th><th>Memory/Node</th><th>Recall@10</th><th>Search Time</th></tr></thead><tbody>
<tr><td>high_speed</td><td>~128 bytes</td><td>~85%</td><td>0.1ms</td></tr>
<tr><td>default</td><td>~256 bytes</td><td>~95%</td><td>0.3ms</td></tr>
<tr><td>high_recall</td><td>~512 bytes</td><td>~99%</td><td>1.0ms</td></tr>
</tbody></table>
</div>
<h2 id="performance-characteristics-4"><a class="header" href="#performance-characteristics-4">Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>store_embedding</code></td><td>O(1)</td><td>Single store put</td></tr>
<tr><td><code>get_embedding</code></td><td>O(1)</td><td>Single store get</td></tr>
<tr><td><code>delete_embedding</code></td><td>O(1)</td><td>Single store delete</td></tr>
<tr><td><code>search_similar</code></td><td>O(n*d)</td><td>Brute-force, n=count, d=dimension</td></tr>
<tr><td><code>search_with_hnsw</code></td><td>O(log n <em>ef</em> m)</td><td>Approximate nearest neighbor</td></tr>
<tr><td><code>build_hnsw_index</code></td><td>O(n <em>log n</em> ef_construction * m)</td><td>Index construction</td></tr>
<tr><td><code>count</code></td><td>O(n)</td><td>Scans all embeddings</td></tr>
<tr><td><code>list_keys</code></td><td>O(n)</td><td>Scans all embeddings</td></tr>
</tbody></table>
</div>
<h3 id="parallel-search-threshold"><a class="header" href="#parallel-search-threshold">Parallel Search Threshold</a></h3>
<p>Automatic parallel iteration for datasets &gt;5000 vectors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const PARALLEL_THRESHOLD: usize = 5000;

if keys.len() &gt;= PARALLEL_THRESHOLD {
    // Use rayon parallel iterator
    keys.par_iter().filter_map(...)
} else {
    // Use sequential iterator
    keys.iter().filter_map(...)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="benchmark-results"><a class="header" href="#benchmark-results">Benchmark Results</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Dataset Size</th><th>Brute-Force</th><th>With HNSW</th><th>Speedup</th></tr></thead><tbody>
<tr><td>200 vectors</td><td>4.17s</td><td>9.3us</td><td>448,000x</td></tr>
<tr><td>1,000 vectors</td><td>~5ms</td><td>~20us</td><td>250x</td></tr>
<tr><td>10,000 vectors</td><td>~50ms</td><td>~50us</td><td>1000x</td></tr>
<tr><td>100,000 vectors</td><td>~500ms</td><td>~100us</td><td>5000x</td></tr>
</tbody></table>
</div>
<h2 id="supported-embedding-dimensions"><a class="header" href="#supported-embedding-dimensions">Supported Embedding Dimensions</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Model</th><th>Dimensions</th><th>Recommended Config</th></tr></thead><tbody>
<tr><td>OpenAI text-embedding-ada-002</td><td>1536</td><td>default</td></tr>
<tr><td>OpenAI text-embedding-3-small</td><td>1536</td><td>default</td></tr>
<tr><td>OpenAI text-embedding-3-large</td><td>3072</td><td>high_recall</td></tr>
<tr><td>BERT base</td><td>768</td><td>default</td></tr>
<tr><td>Sentence Transformers</td><td>384-768</td><td>default</td></tr>
<tr><td>Cohere embed-v3</td><td>1024</td><td>default</td></tr>
<tr><td>Custom/small</td><td>&lt;256</td><td>high_speed</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas-3"><a class="header" href="#edge-cases-and-gotchas-3">Edge Cases and Gotchas</a></h2>
<h3 id="zero-magnitude-vectors"><a class="header" href="#zero-magnitude-vectors">Zero-Magnitude Vectors</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Behavior</th><th>Rationale</th></tr></thead><tbody>
<tr><td>Cosine</td><td>Returns empty results</td><td>Division by zero undefined</td></tr>
<tr><td>DotProduct</td><td>Returns empty results</td><td>Undefined direction</td></tr>
<tr><td>Euclidean</td><td>Works correctly</td><td>Finds vectors closest to origin</td></tr>
</tbody></table>
</div>
<h3 id="dimension-mismatch-handling"><a class="header" href="#dimension-mismatch-handling">Dimension Mismatch Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Mismatched dimensions are silently skipped during search
engine.store_embedding("2d", vec![1.0, 0.0])?;
engine.store_embedding("3d", vec![1.0, 0.0, 0.0])?;

// Search with 2D query only matches 2D vectors
let results = engine.search_similar(&amp;[1.0, 0.0], 10)?;
assert_eq!(results.len(), 1);  // Only "2d" matched
<span class="boring">}</span></code></pre></pre>
<h3 id="hnsw-limitations"><a class="header" href="#hnsw-limitations">HNSW Limitations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Limitation</th><th>Details</th><th>Workaround</th></tr></thead><tbody>
<tr><td>Only cosine similarity</td><td>HNSW uses cosine distance internally</td><td>Use brute-force for other metrics</td></tr>
<tr><td>No deletion</td><td>Cannot remove vectors</td><td>Rebuild index</td></tr>
<tr><td>Static after build</td><td>Index doesn’t update with new vectors</td><td>Rebuild periodically</td></tr>
<tr><td>Memory overhead</td><td>Graph structure adds ~2-4x</td><td>Use for large datasets only</td></tr>
</tbody></table>
</div>
<h3 id="naninfinity-handling"><a class="header" href="#naninfinity-handling">NaN/Infinity Handling</a></h3>
<p>Sparse vector operations sanitize NaN/Inf results:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// cosine_similarity returns 0.0 for NaN/Inf
if result.is_nan() || result.is_infinite() {
    0.0
} else {
    result.clamp(-1.0, 1.0)
}

// cosine_distance_dense returns 1.0 (max distance) for NaN/Inf
if similarity.is_nan() || similarity.is_infinite() {
    1.0  // Maximum distance
} else {
    1.0 - similarity.clamp(-1.0, 1.0)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="memory-optimization"><a class="header" href="#memory-optimization">Memory Optimization</a></h3>
<ol>
<li><strong>Use sparse vectors for high-sparsity data</strong>: Automatic at &gt;50% zeros</li>
<li><strong>Batch insert for HNSW</strong>: Build index once after all data loaded</li>
<li><strong>Choose appropriate HNSW config</strong>: Don’t over-provision m/ef</li>
<li><strong>Monitor memory with <code>HNSWMemoryStats</code></strong>: Track dense vs sparse counts</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let stats = index.memory_stats();
println!("Dense: {}, Sparse: {}, Total bytes: {}",
    stats.dense_count, stats.sparse_count, stats.embedding_bytes);
<span class="boring">}</span></code></pre></pre>
<h3 id="search-performance"><a class="header" href="#search-performance">Search Performance</a></h3>
<ol>
<li><strong>Pre-compute query magnitude</strong>: Done automatically in search</li>
<li><strong>Use HNSW for &gt;10K vectors</strong>: Brute-force for smaller sets</li>
<li><strong>Tune ef_search</strong>: Higher for recall, lower for speed</li>
<li><strong>Parallel threshold</strong>: Automatic at 5000 vectors</li>
</ol>
<h3 id="unified-entity-best-practices"><a class="header" href="#unified-entity-best-practices">Unified Entity Best Practices</a></h3>
<ol>
<li><strong>Use for cross-engine queries</strong>: When embeddings relate to graph/relational
data</li>
<li><strong>Entity key conventions</strong>: Use prefixes like <code>user:</code>, <code>doc:</code>, <code>item:</code></li>
<li><strong>Separate embedding namespace</strong>: Use <code>store_embedding</code> for isolated vectors</li>
</ol>
<h2 id="dependencies-2"><a class="header" href="#dependencies-2">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>Persistence, SparseVector, HNSWIndex, SIMD</td></tr>
<tr><td><code>rayon</code></td><td>Parallel iteration for large datasets</td></tr>
<tr><td><code>serde</code></td><td>Serialization of types</td></tr>
<tr><td><code>tracing</code></td><td>Instrumentation and observability</td></tr>
</tbody></table>
</div>
<p>Note: <code>wide</code> (SIMD f32x8 operations) is a transitive dependency via <code>tensor_store</code>.</p>
<h2 id="related-modules-3"><a class="header" href="#related-modules-3">Related Modules</a></h2>
<ul>
<li><a href="architecture/tensor-store.html">Tensor Store</a> - Underlying storage and HNSW implementation</li>
<li><a href="architecture/query-router.html">Query Router</a> - Executes SIMILAR queries using VectorEngine</li>
<li><a href="architecture/tensor-cache.html">Tensor Cache</a> - Uses vector similarity for semantic caching</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-compress"><a class="header" href="#tensor-compress">Tensor Compress</a></h1>
<p>Module 8 of Neumann. Provides tensor-native compression exploiting the
mathematical structure of high-dimensional embeddings.</p>
<p>The primary compression method is Tensor Train (TT) decomposition, which
decomposes vectors reshaped as tensors into a chain of smaller 3D cores using
successive SVD truncations. This achieves 10-40x compression for 1024+ dimension
vectors while enabling similarity computations directly in compressed space.</p>
<h2 id="design-principles-2"><a class="header" href="#design-principles-2">Design Principles</a></h2>
<ol>
<li><strong>Tensor Mathematics</strong>: Uses Tensor Train decomposition to exploit low-rank
structure</li>
<li><strong>Higher Dimensions Are Lower</strong>: Decomposes vectors into products of smaller
tensors</li>
<li><strong>Streaming I/O</strong>: Process large snapshots without loading entire dataset</li>
<li><strong>Incremental Updates</strong>: Delta snapshots for efficient replication</li>
<li><strong>Pure Rust</strong>: No external LAPACK/BLAS dependencies - fully portable</li>
</ol>
<h2 id="key-types-4"><a class="header" href="#key-types-4">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TTVector</code></td><td>Complete TT-decomposition of a vector with cores, shape, and ranks</td></tr>
<tr><td><code>TTCore</code></td><td>Single 3D tensor core (left_rank x mode_size x right_rank)</td></tr>
<tr><td><code>TTConfig</code></td><td>Configuration for TT decomposition (shape, max_rank, tolerance)</td></tr>
<tr><td><code>CompressionConfig</code></td><td>Snapshot compression settings (tensor mode, delta, RLE)</td></tr>
<tr><td><code>TensorMode</code></td><td>Compression mode enum (currently TensorTrain variant)</td></tr>
<tr><td><code>RleEncoded&lt;T&gt;</code></td><td>Run-length encoded data with values and run lengths</td></tr>
<tr><td><code>DeltaSnapshot</code></td><td>Snapshot containing only changes since a base snapshot</td></tr>
<tr><td><code>DeltaChain</code></td><td>Chain of deltas with efficient lookup and compaction</td></tr>
<tr><td><code>StreamingWriter</code></td><td>Memory-bounded incremental snapshot writer</td></tr>
<tr><td><code>StreamingReader</code></td><td>Iterator-based snapshot reader</td></tr>
<tr><td><code>StreamingTTWriter</code></td><td>Streaming TT-compressed vector writer</td></tr>
<tr><td><code>StreamingTTReader</code></td><td>Streaming TT-compressed vector reader</td></tr>
<tr><td><code>Matrix</code></td><td>Row-major matrix for SVD operations</td></tr>
<tr><td><code>SvdResult</code></td><td>Truncated SVD result (U, S, Vt matrices)</td></tr>
<tr><td><code>TensorView</code></td><td>Zero-copy logical view of tensor data</td></tr>
<tr><td><code>DeltaBuilder</code></td><td>Builder for creating delta snapshots</td></tr>
</tbody></table>
</div>
<h2 id="error-types-3"><a class="header" href="#error-types-3">Error Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TTError::ShapeMismatch</code></td><td>Vector dimension doesn’t match reshape target</td></tr>
<tr><td><code>TTError::EmptyVector</code></td><td>Cannot decompose empty vector</td></tr>
<tr><td><code>TTError::InvalidRank</code></td><td>TT-rank must be &gt;= 1</td></tr>
<tr><td><code>TTError::IncompatibleShapes</code></td><td>TT vectors have different shapes for operation</td></tr>
<tr><td><code>TTError::InvalidShape</code></td><td>Shape contains zero or is empty</td></tr>
<tr><td><code>TTError::InvalidTolerance</code></td><td>Tolerance must be 0 &lt; tol &lt;= 1</td></tr>
<tr><td><code>TTError::Decompose</code></td><td>SVD decomposition failed</td></tr>
<tr><td><code>FormatError::InvalidMagic</code></td><td>File magic bytes don’t match expected</td></tr>
<tr><td><code>FormatError::UnsupportedVersion</code></td><td>Format version is newer than supported</td></tr>
<tr><td><code>FormatError::Serialization</code></td><td>Bincode serialization/deserialization error</td></tr>
<tr><td><code>DeltaError::BaseNotFound</code></td><td>Referenced base snapshot doesn’t exist</td></tr>
<tr><td><code>DeltaError::SequenceGap</code></td><td>Delta sequence numbers have gaps</td></tr>
<tr><td><code>DeltaError::ChainTooLong</code></td><td>Delta chain exceeds maximum length</td></tr>
<tr><td><code>DecomposeError::EmptyMatrix</code></td><td>Cannot decompose empty matrix</td></tr>
<tr><td><code>DecomposeError::DimensionMismatch</code></td><td>Matrix dimensions don’t match for operation</td></tr>
<tr><td><code>DecomposeError::SvdNotConverged</code></td><td>SVD iteration didn’t converge</td></tr>
</tbody></table>
</div>
<h2 id="architecture-5"><a class="header" href="#architecture-5">Architecture</a></h2>
<pre class="mermaid">graph TD
    subgraph tensor_compress
        TT[tensor_train.rs&lt;br/&gt;TT-SVD decomposition]
        DC[decompose.rs&lt;br/&gt;SVD implementation]
        FMT[format.rs&lt;br/&gt;Snapshot format]
        STR[streaming.rs&lt;br/&gt;Streaming I/O]
        STT[streaming_tt.rs&lt;br/&gt;Streaming TT]
        INC[incremental.rs&lt;br/&gt;Delta snapshots]
        DLT[delta.rs&lt;br/&gt;Delta + varint encoding]
        RLE[rle.rs&lt;br/&gt;Run-length encoding]
    end

    TT --&gt; DC
    FMT --&gt; TT
    FMT --&gt; DLT
    FMT --&gt; RLE
    STR --&gt; FMT
    STT --&gt; TT
    INC --&gt; FMT
</pre>
<h2 id="tensor-train-decomposition"><a class="header" href="#tensor-train-decomposition">Tensor Train Decomposition</a></h2>
<h3 id="algorithm-overview-1"><a class="header" href="#algorithm-overview-1">Algorithm Overview</a></h3>
<p>The TT-SVD algorithm (Oseledets 2011) decomposes a vector by:</p>
<ol>
<li><strong>Reshape</strong>: Convert 1D vector to multi-dimensional tensor</li>
<li><strong>Left-to-right sweep</strong>: For each mode k from 1 to n-1:
<ul>
<li>Left-unfold the current tensor into a matrix</li>
<li>Compute truncated SVD: A = U <em>S</em> Vt</li>
<li>Store U as the k-th core</li>
<li>Multiply S * Vt to get the remainder for next iteration</li>
</ul>
</li>
<li><strong>Final core</strong>: The last remainder becomes the final core</li>
</ol>
<pre class="mermaid">graph LR
    subgraph &quot;TT-SVD Algorithm&quot;
        V[Vector 4096-dim] --&gt; R[Reshape to 8x8x8x8]
        R --&gt; U1[Unfold mode 1&lt;br/&gt;64 x 64]
        U1 --&gt; SVD1[SVD truncate&lt;br/&gt;rank=8]
        SVD1 --&gt; C1[Core 1&lt;br/&gt;1x8x8]
        SVD1 --&gt; R2[Remainder&lt;br/&gt;8x512]
        R2 --&gt; SVD2[SVD truncate]
        SVD2 --&gt; C2[Core 2&lt;br/&gt;8x8x8]
        SVD2 --&gt; R3[Remainder]
        R3 --&gt; SVD3[SVD truncate]
        SVD3 --&gt; C3[Core 3&lt;br/&gt;8x8x8]
        SVD3 --&gt; C4[Core 4&lt;br/&gt;8x8x1]
    end
</pre>
<h3 id="compression-example"><a class="header" href="#compression-example">Compression Example</a></h3>
<p>For a 4096-dim embedding reshaped to (8, 8, 8, 8):</p>
<pre><code class="language-text">Original: 4096 floats = 16 KB
TT-cores: 1x8x8 + 8x8x8 + 8x8x8 + 8x8x1 = 64 + 512 + 512 + 64 = 1152 floats
With max_rank=8: 1x8x4 + 4x8x4 + 4x8x4 + 4x8x1 = 32 + 128 + 128 + 32 = 320 floats = 1.25 KB
Compression: 12.8x
</code></pre>
<h3 id="svd-implementation-details"><a class="header" href="#svd-implementation-details">SVD Implementation Details</a></h3>
<p>The module implements two SVD algorithms:</p>
<h4 id="1-power-iteration-with-deflation-small-matrices"><a class="header" href="#1-power-iteration-with-deflation-small-matrices">1. Power Iteration with Deflation (small matrices)</a></h4>
<p>Used when matrix dimensions are &lt;= 32 or rank is close to matrix size:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simplified power iteration
fn power_iteration(a: &amp;Matrix, max_iter: usize, tol: f32) -&gt; (sigma, u, v) {
    // Initialize v randomly (deterministic seed)
    let mut v: Vec&lt;f32&gt; = (0..cols).map(|i| ((i * 7 + 3) % 13) as f32 / 13.0 - 0.5).collect();
    normalize(&amp;mut v);

    for _ in 0..max_iter {
        // u = A * v, then normalize
        u = matmul(a, v);
        new_sigma = normalize(&amp;mut u);

        // v = A^T * u, then normalize
        v = matmul_transpose(a, u);
        normalize(&amp;mut v);

        // Check convergence
        if (new_sigma - sigma).abs() &lt; tol * sigma.max(1.0) {
            return (new_sigma, u, v);
        }
        sigma = new_sigma;
    }
}
<span class="boring">}</span></code></pre></pre>
<p>After finding each singular triplet, the algorithm deflates: A = A - sigma <em>u</em>
vT</p>
<h4 id="2-randomized-svd-large-matrices"><a class="header" href="#2-randomized-svd-large-matrices">2. Randomized SVD (large matrices)</a></h4>
<p>Uses the Halko-Martinsson-Tropp 2011 algorithm for matrices &gt; 32 dimensions:</p>
<pre class="mermaid">graph TD
    subgraph &quot;Randomized SVD Pipeline&quot;
        A[Input Matrix A&lt;br/&gt;m x n] --&gt; OMEGA[Generate Gaussian&lt;br/&gt;Omega n x k+p]
        A --&gt; SAMPLE[Y = A * Omega&lt;br/&gt;m x k+p]
        SAMPLE --&gt; QR[QR decompose Y&lt;br/&gt;Q = orth basis]
        QR --&gt; PROJECT[B = Q^T * A&lt;br/&gt;k+p x n]
        PROJECT --&gt; SMALL_SVD[SVD of small B&lt;br/&gt;power iteration]
        SMALL_SVD --&gt; RECONSTRUCT[U = Q * U_small]
    end
</pre>
<p>Key implementation details:</p>
<ul>
<li><strong>Gaussian matrix generation</strong>: Uses a Linear Congruential Generator (LCG)
with Box-Muller transform for deterministic, portable random numbers</li>
<li><strong>QR orthonormalization</strong>: Modified Gram-Schmidt for numerical stability</li>
<li><strong>Oversampling</strong>: Adds 5 extra columns to improve accuracy</li>
<li><strong>Convergence</strong>: 20 iterations max (sufficient for embedding vectors)</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// LCG parameters from Numerical Recipes
fn lcg_next(state: &amp;mut u64) -&gt; u64 {
    *state = state.wrapping_mul(6_364_136_223_846_793_005)
                  .wrapping_add(1_442_695_040_888_963_407);
    *state
}

// Box-Muller transform for Gaussian
fn box_muller(u1: f32, u2: f32) -&gt; (f32, f32) {
    let r = (-2.0 * u1.ln()).sqrt();
    let theta = 2.0 * PI * u2;
    (r * theta.cos(), r * theta.sin())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="optimal-shape-selection"><a class="header" href="#optimal-shape-selection">Optimal Shape Selection</a></h3>
<p>The module includes hardcoded optimal shapes for common embedding dimensions:</p>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Shape</th><th>Why</th></tr></thead><tbody>
<tr><td>64</td><td>[4, 4, 4]</td><td>3 balanced factors</td></tr>
<tr><td>128</td><td>[4, 4, 8]</td><td>Near-balanced</td></tr>
<tr><td>256</td><td>[4, 8, 8]</td><td>Near-balanced</td></tr>
<tr><td>384</td><td>[4, 8, 12]</td><td>all-MiniLM-L6-v2</td></tr>
<tr><td>512</td><td>[8, 8, 8]</td><td>Perfect cube</td></tr>
<tr><td>768</td><td>[8, 8, 12]</td><td>BERT dimension</td></tr>
<tr><td>1024</td><td>[8, 8, 16]</td><td>Common LLM size</td></tr>
<tr><td>1536</td><td>[8, 12, 16]</td><td>OpenAI ada-002</td></tr>
<tr><td>2048</td><td>[8, 16, 16]</td><td>Near-balanced</td></tr>
<tr><td>3072</td><td>[8, 16, 24]</td><td>Large models</td></tr>
<tr><td>4096</td><td>[8, 8, 8, 8]</td><td>4D balanced</td></tr>
<tr><td>8192</td><td>[8, 8, 8, 16]</td><td>Extra large</td></tr>
</tbody></table>
</div>
<p>For non-standard dimensions, <code>factorize_balanced</code> finds factors close to the nth
root:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn factorize_balanced(n: usize) -&gt; Vec&lt;usize&gt; {
    // Target 2-6 factors based on log2(n)
    let target_factors = (ln(n) / ln(2)).ceil().clamp(2, 6);
    let target_size = n^(1/target_factors);

    // Greedily find factors close to target_size
    // ...
}
<span class="boring">}</span></code></pre></pre>
<h3 id="tt-operations"><a class="header" href="#tt-operations">TT Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th><th>Complexity</th></tr></thead><tbody>
<tr><td><code>tt_decompose</code></td><td>Decompose vector to TT format</td><td>O(n <em>d</em> r^2)</td></tr>
<tr><td><code>tt_decompose_batch</code></td><td>Parallel batch decomposition (4+ vectors)</td><td>O(batch <em>n</em> d * r^2 / threads)</td></tr>
<tr><td><code>tt_reconstruct</code></td><td>Reconstruct vector from TT</td><td>O(d^n * r^2)</td></tr>
<tr><td><code>tt_dot_product</code></td><td>Dot product in TT space</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_dot_product_batch</code></td><td>Batch dot products</td><td>Parallel when &gt;= 4 targets</td></tr>
<tr><td><code>tt_cosine_similarity</code></td><td>Cosine similarity in TT space</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_cosine_similarity_batch</code></td><td>Batch cosine similarities</td><td>Parallel when &gt;= 4 targets</td></tr>
<tr><td><code>tt_euclidean_distance</code></td><td>Euclidean distance in TT space</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_euclidean_distance_batch</code></td><td>Batch Euclidean distances</td><td>Parallel when &gt;= 4 targets</td></tr>
<tr><td><code>tt_norm</code></td><td>L2 norm of TT vector</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_scale</code></td><td>Scale TT vector by constant</td><td>O(cores[0].size)</td></tr>
</tbody></table>
</div>
<p>Where: n = number of modes, d = mode size, r = TT-rank</p>
<h3 id="tt-gram-matrix-computation"><a class="header" href="#tt-gram-matrix-computation">TT Gram Matrix Computation</a></h3>
<p>Computing dot products and norms in TT space uses the Gram matrix approach:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Gram matrix propagation for dot product
fn tt_dot_product(a: &amp;TTVector, b: &amp;TTVector) -&gt; f32 {
    let mut gram = vec![1.0f32];  // Start with 1x1 identity

    for (core_a, core_b) in a.cores.iter().zip(b.cores.iter()) {
        let (r1a, n, r2a) = core_a.shape;
        let (r1b, _, r2b) = core_b.shape;
        let mut new_gram = vec![0.0; r2a * r2b];

        // Contract: new_gram[a,b] = sum_{k,i,j} gram[i,j] * A[i,k,a] * B[j,k,b]
        for a_idx in 0..r2a {
            for b_idx in 0..r2b {
                for k in 0..n {
                    for ia in 0..r1a {
                        for ib in 0..r1b {
                            let g = gram[ia * r1b + ib];
                            new_gram[a_idx * r2b + b_idx] +=
                                g * core_a.get(ia, k, a_idx) * core_b.get(ib, k, b_idx);
                        }
                    }
                }
            }
        }
        gram = new_gram;
    }

    gram[0]  // Final 1x1 Gram matrix
}
<span class="boring">}</span></code></pre></pre>
<h3 id="usage"><a class="header" href="#usage">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{tt_decompose, tt_reconstruct, tt_cosine_similarity, TTConfig};

let embedding: Vec&lt;f32&gt; = get_embedding();  // 4096-dim
let config = TTConfig::for_dim(4096)?;

// Decompose
let tt = tt_decompose(&amp;embedding, &amp;config)?;
println!("Compression: {:.1}x", tt.compression_ratio());
println!("Storage: {} floats", tt.storage_size());
println!("Max rank: {}", tt.max_rank());

// Reconstruct
let restored = tt_reconstruct(&amp;tt);

// Compute similarity without reconstruction
let tt2 = tt_decompose(&amp;other_embedding, &amp;config)?;
let sim = tt_cosine_similarity(&amp;tt, &amp;tt2)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-operations-2"><a class="header" href="#batch-operations-2">Batch Operations</a></h3>
<p>Batch operations use rayon for parallel processing when handling 4+ vectors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{tt_decompose_batch, tt_cosine_similarity_batch, TTConfig};

let vectors: Vec&lt;Vec&lt;f32&gt;&gt; = load_embeddings();
let config = TTConfig::for_dim(4096)?;

// Batch decompose (parallel for 4+ vectors)
let refs: Vec&lt;&amp;[f32]&gt; = vectors.iter().map(|v| v.as_slice()).collect();
let tts = tt_decompose_batch(&amp;refs, &amp;config)?;

// Batch similarity search
let query_tt = &amp;tts[0];
let similarities = tt_cosine_similarity_batch(query_tt, &amp;tts[1..])?;

// Find top-k
let mut indexed: Vec&lt;_&gt; = similarities.iter().enumerate().collect();
indexed.sort_by(|a, b| b.1.partial_cmp(a.1).unwrap());
let top_5: Vec&lt;_&gt; = indexed.iter().take(5).collect();
<span class="boring">}</span></code></pre></pre>
<p>The parallel threshold constant is:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const PARALLEL_THRESHOLD: usize = 4;
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-4"><a class="header" href="#configuration-4">Configuration</a></h2>
<h3 id="ttconfig-presets"><a class="header" href="#ttconfig-presets">TTConfig Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>max_rank</th><th>tolerance</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>for_dim(d)</code></td><td>8</td><td>1e-4</td><td>Balanced compression/accuracy</td></tr>
<tr><td><code>high_compression(d)</code></td><td>4</td><td>1e-2</td><td>Maximize compression (2-3x more)</td></tr>
<tr><td><code>high_accuracy(d)</code></td><td>16</td><td>1e-6</td><td>Maximize accuracy (&lt;0.1% error)</td></tr>
</tbody></table>
</div>
<h3 id="ttconfig-validation"><a class="header" href="#ttconfig-validation">TTConfig Validation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl TTConfig {
    pub fn validate(&amp;self) -&gt; Result&lt;(), TTError&gt; {
        if self.shape.is_empty() {
            return Err(TTError::InvalidShape("empty shape".into()));
        }
        if self.shape.contains(&amp;0) {
            return Err(TTError::InvalidShape("shape contains zero".into()));
        }
        if self.max_rank &lt; 1 {
            return Err(TTError::InvalidRank);
        }
        if self.tolerance &lt;= 0.0 || self.tolerance &gt; 1.0 || !self.tolerance.is_finite() {
            return Err(TTError::InvalidTolerance(self.tolerance));
        }
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="compressionconfig"><a class="header" href="#compressionconfig">CompressionConfig</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CompressionConfig {
    pub tensor_mode: Option&lt;TensorMode&gt;,  // TT compression for vectors
    pub delta_encoding: bool,             // For sorted ID lists
    pub rle_encoding: bool,               // For repeated values
}

// Presets
CompressionConfig::high_compression()  // max_rank=4, all encodings enabled
CompressionConfig::balanced(dim)       // max_rank=8, all encodings enabled
CompressionConfig::high_accuracy(dim)  // max_rank=16, all encodings enabled
<span class="boring">}</span></code></pre></pre>
<h3 id="dimension-presets"><a class="header" href="#dimension-presets">Dimension Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Constant</th><th>Value</th><th>Model</th></tr></thead><tbody>
<tr><td><code>SMALL</code></td><td>64</td><td>MiniLM and small models</td></tr>
<tr><td><code>MEDIUM</code></td><td>384</td><td>all-MiniLM-L6-v2</td></tr>
<tr><td><code>STANDARD</code></td><td>768</td><td>BERT, sentence-transformers</td></tr>
<tr><td><code>LARGE</code></td><td>1536</td><td>OpenAI text-embedding-ada-002</td></tr>
<tr><td><code>XLARGE</code></td><td>4096</td><td>LLaMA and large models</td></tr>
</tbody></table>
</div>
<h2 id="streaming-operations"><a class="header" href="#streaming-operations">Streaming Operations</a></h2>
<h3 id="state-machine"><a class="header" href="#state-machine">State Machine</a></h3>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Created: new()
    Created --&gt; Writing: write_entry() / write_vector()
    Writing --&gt; Writing: write_entry() / write_vector()
    Writing --&gt; Finishing: finish()
    Finishing --&gt; [*]: success

    note right of Created
        Magic bytes written
        entry_count = 0
    end note

    note right of Writing
        Length-prefixed entries
        entry_count incremented
    end note

    note right of Finishing
        Trailer written with:
        - entry_count
        - config
        - data_start offset
    end note
</pre>
<h3 id="file-format"><a class="header" href="#file-format">File Format</a></h3>
<p>Uses a trailer-based header so entry count is known at the end:</p>
<pre><code class="language-text">+------------------------+
| Magic (NEUS/NEUT)  4B  |  Identifies streaming snapshot/TT
+------------------------+
| Entry 1 length     4B  |  Little-endian u32
+------------------------+
| Entry 1 data      var  |  Bincode-serialized entry
+------------------------+
| Entry 2 length     4B  |
+------------------------+
| Entry 2 data      var  |
+------------------------+
| ...                    |
+------------------------+
| Trailer           var  |  Bincode-serialized header
+------------------------+
| Trailer size       8B  |  Little-endian u64
+------------------------+
</code></pre>
<p><strong>Security limits:</strong></p>
<ul>
<li>Maximum trailer size: 1 MB (<code>MAX_TRAILER_SIZE</code>)</li>
<li>Maximum entry size: 100 MB (<code>MAX_ENTRY_SIZE</code>)</li>
</ul>
<h3 id="usage-1"><a class="header" href="#usage-1">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::streaming::{StreamingWriter, StreamingReader};

// Write entries one at a time
let mut writer = StreamingWriter::new(file, config)?;
for entry in entries {
    writer.write_entry(&amp;entry)?;
}
writer.finish()?;

// Read entries one at a time (iterator-based)
let reader = StreamingReader::open(file)?;
println!("Entry count: {}", reader.entry_count());
for entry in reader {
    process(entry?);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="streaming-tt-operations"><a class="header" href="#streaming-tt-operations">Streaming TT Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody>
<tr><td><code>StreamingTTWriter::new</code></td><td>Create TT streaming writer</td></tr>
<tr><td><code>StreamingTTWriter::write_vector</code></td><td>Decompose and write vector</td></tr>
<tr><td><code>StreamingTTWriter::write_tt</code></td><td>Write pre-decomposed TT</td></tr>
<tr><td><code>StreamingTTWriter::finish</code></td><td>Finalize with trailer</td></tr>
<tr><td><code>StreamingTTReader::open</code></td><td>Open TT streaming file</td></tr>
<tr><td><code>streaming_tt_similarity_search</code></td><td>Search streaming TT file</td></tr>
<tr><td><code>convert_vectors_to_streaming_tt</code></td><td>Batch convert vectors</td></tr>
<tr><td><code>read_streaming_tt_all</code></td><td>Load all TT vectors</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::streaming_tt::{StreamingTTWriter, StreamingTTReader,
    streaming_tt_similarity_search};

// Create streaming TT file
let config = TTConfig::for_dim(768)?;
let mut writer = StreamingTTWriter::new(file, config.clone())?;

for vector in vectors {
    writer.write_vector(&amp;vector)?;  // Decompose on-the-fly
}
writer.finish()?;

// Similarity search without loading all into memory
let query_tt = tt_decompose(&amp;query, &amp;config)?;
let top_10 = streaming_tt_similarity_search(file, &amp;query_tt, 10)?;
// Returns Vec&lt;(index, similarity)&gt; sorted by descending similarity
<span class="boring">}</span></code></pre></pre>
<h3 id="merge-and-convert-operations"><a class="header" href="#merge-and-convert-operations">Merge and Convert Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::streaming::{convert_to_streaming, read_streaming_to_snapshot,
    merge_streaming};

// Convert non-streaming snapshot to streaming format
let count = convert_to_streaming(&amp;snapshot, output_file)?;

// Read streaming format into full snapshot (for compatibility)
let snapshot = read_streaming_to_snapshot(file)?;

// Merge multiple streaming snapshots
let count = merge_streaming(vec![file1, file2, file3], output, config)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="incremental-updates"><a class="header" href="#incremental-updates">Incremental Updates</a></h2>
<h3 id="delta-snapshot-architecture"><a class="header" href="#delta-snapshot-architecture">Delta Snapshot Architecture</a></h3>
<pre class="mermaid">graph TD
    subgraph &quot;Delta Chain&quot;
        BASE[Base Snapshot&lt;br/&gt;Seq 0] --&gt; D1[Delta 1&lt;br/&gt;Seq 1-10]
        D1 --&gt; D2[Delta 2&lt;br/&gt;Seq 11-25]
        D2 --&gt; D3[Delta 3&lt;br/&gt;Seq 26-30]
    end

    subgraph &quot;Compaction&quot;
        BASE2[Base] --&gt; COMPACT[Compacted&lt;br/&gt;Snapshot]
        D1_2[Delta 1] --&gt; COMPACT
        D2_2[Delta 2] --&gt; COMPACT
        D3_2[Delta 3] --&gt; COMPACT
    end
</pre>
<h3 id="delta-entry-types"><a class="header" href="#delta-entry-types">Delta Entry Types</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum ChangeType {
    Put,    // Entry was added or updated
    Delete, // Entry was deleted
}

pub struct DeltaEntry {
    pub key: String,
    pub change: ChangeType,
    pub value: Option&lt;CompressedEntry&gt;,  // None for Delete
    pub sequence: u64,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="usage-2"><a class="header" href="#usage-2">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::incremental::{DeltaBuilder, DeltaChain, apply_delta,
    merge_deltas, diff_snapshots};

// Create delta
let mut builder = DeltaBuilder::new("base_snapshot_id", sequence);
builder.put("key1", entry1);
builder.delete("key2");
let delta = builder.build();

// Apply delta
let new_snapshot = apply_delta(&amp;base, &amp;delta)?;

// Chain management
let mut chain = DeltaChain::new(base_snapshot);
chain.push(delta1)?;
chain.push(delta2)?;
let value = chain.get("key1");  // Checks chain then base

// Compact when chain grows long
if chain.should_compact(10) {
    let compacted = chain.compact()?;
}

// Compare two snapshots
let delta = diff_snapshots(&amp;old_snapshot, &amp;new_snapshot, "old_id")?;

// Merge multiple deltas into one
let merged = merge_deltas(&amp;[delta1, delta2, delta3])?;
<span class="boring">}</span></code></pre></pre>
<h3 id="delta-operations"><a class="header" href="#delta-operations">Delta Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody>
<tr><td><code>DeltaBuilder::new</code></td><td>Create delta builder with base ID and start sequence</td></tr>
<tr><td><code>DeltaBuilder::put</code></td><td>Record a put (add/update) change</td></tr>
<tr><td><code>DeltaBuilder::delete</code></td><td>Record a delete change</td></tr>
<tr><td><code>DeltaBuilder::build</code></td><td>Build the delta snapshot</td></tr>
<tr><td><code>apply_delta</code></td><td>Apply delta to base snapshot</td></tr>
<tr><td><code>merge_deltas</code></td><td>Merge multiple deltas (keeps latest state per key)</td></tr>
<tr><td><code>diff_snapshots</code></td><td>Compute delta between two snapshots</td></tr>
<tr><td><code>DeltaChain::get</code></td><td>Get current state of key (checks chain then base)</td></tr>
<tr><td><code>DeltaChain::compact</code></td><td>Compact all deltas into new base</td></tr>
<tr><td><code>DeltaChain::should_compact</code></td><td>Check if compaction is recommended</td></tr>
</tbody></table>
</div>
<h3 id="delta-format"><a class="header" href="#delta-format">Delta Format</a></h3>
<pre><code class="language-text">+------------------------+
| Magic (NEUD)       4B  |
+------------------------+
| Version            2B  |
+------------------------+
| Base ID           var  |  String (length-prefixed)
+------------------------+
| Sequence Range     16B |  (start, end) u64 pair
+------------------------+
| Change Count        8B |
+------------------------+
| Created At          8B |  Unix timestamp
+------------------------+
| Entries           var  |  Bincode-serialized Vec&lt;DeltaEntry&gt;
+------------------------+
</code></pre>
<h2 id="lossless-compression"><a class="header" href="#lossless-compression">Lossless Compression</a></h2>
<h3 id="delta--varint-encoding"><a class="header" href="#delta--varint-encoding">Delta + Varint Encoding</a></h3>
<p>For sorted integer sequences (node IDs, timestamps):</p>
<pre class="mermaid">graph LR
    subgraph &quot;Delta + Varint Pipeline&quot;
        IDS[IDs: 100, 101, 102, 105, 110] --&gt; DELTA[Delta encode:&lt;br/&gt;100, 1, 1, 3, 5]
        DELTA --&gt; VARINT[Varint encode]
        VARINT --&gt; OUT[Bytes: ~7 bytes&lt;br/&gt;vs 40 bytes raw]
    end
</pre>
<p><strong>Algorithm:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Delta encoding: store first value, then differences
pub fn delta_encode(ids: &amp;[u64]) -&gt; Vec&lt;u64&gt; {
    let mut result = vec![ids[0]];
    for window in ids.windows(2) {
        result.push(window[1].saturating_sub(window[0]));
    }
    result
}

// Varint encoding: 7 bits per byte, high bit = continuation
pub fn varint_encode(values: &amp;[u64]) -&gt; Vec&lt;u8&gt; {
    let mut result = Vec::with_capacity(values.len() * 2);
    for &amp;value in values {
        let mut v = value;
        loop {
            let byte = (v &amp; 0x7f) as u8;
            v &gt;&gt;= 7;
            if v == 0 {
                result.push(byte);  // Final byte (no continuation)
                break;
            }
            result.push(byte | 0x80);  // Continuation bit set
        }
    }
    result
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Usage:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{compress_ids, decompress_ids};

let ids: Vec&lt;u64&gt; = (1000..2000).collect();
let compressed = compress_ids(&amp;ids);  // ~100 bytes vs 8000

let restored = decompress_ids(&amp;compressed);
assert_eq!(ids, restored);
<span class="boring">}</span></code></pre></pre>
<p><strong>Varint byte sizes:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Value Range</th><th>Bytes</th></tr></thead><tbody>
<tr><td>0 - 127</td><td>1</td></tr>
<tr><td>128 - 16,383</td><td>2</td></tr>
<tr><td>16,384 - 2,097,151</td><td>3</td></tr>
<tr><td>2,097,152 - 268,435,455</td><td>4</td></tr>
<tr><td>… up to u64::MAX</td><td>10</td></tr>
</tbody></table>
</div>
<h3 id="run-length-encoding"><a class="header" href="#run-length-encoding">Run-Length Encoding</a></h3>
<p>For repeated values:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{rle_encode, rle_decode};

let statuses = vec!["active"; 1000];
let encoded = rle_encode(&amp;statuses);
assert_eq!(encoded.runs(), 1);  // Single run

// Storage: 1 string + 1 u32 = ~12 bytes vs 6000+ bytes
<span class="boring">}</span></code></pre></pre>
<p><strong>Internal representation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RleEncoded&lt;T: Eq&gt; {
    pub values: Vec&lt;T&gt;,      // Unique values in order
    pub run_lengths: Vec&lt;u32&gt;, // Count for each value
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Compression scenarios:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Data Pattern</th><th>Runs</th><th>Compression</th></tr></thead><tbody>
<tr><td>[5, 5, 5, 5, 5] (1000x)</td><td>1</td><td>500x</td></tr>
<tr><td>[1, 2, 3, 4, 5] (all different)</td><td>5</td><td>0.8x (overhead)</td></tr>
<tr><td>[1, 1, 2, 2, 2, 3, 1, 1, 1, 1]</td><td>4</td><td>2.5x</td></tr>
<tr><td>Status column (pending/active/done)</td><td>~300 per 10000</td><td>~33x</td></tr>
</tbody></table>
</div>
<h3 id="sparse-vector-format"><a class="header" href="#sparse-vector-format">Sparse Vector Format</a></h3>
<p>For vectors with &gt;50% zeros:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{compress_sparse, compress_dense_as_sparse,
    should_use_sparse, should_use_sparse_threshold};

// Direct sparse compression
let positions = vec![0, 50, 99];
let values = vec![1.0, 2.0, 3.0];
let compressed = compress_sparse(100, &amp;positions, &amp;values);

// Auto-detect and compress
if should_use_sparse_threshold(&amp;vector, 0.5) {
    let compressed = compress_dense_as_sparse(&amp;vector);
}

// Check if sparse is beneficial
if should_use_sparse(dimension, non_zero_count) {
    // Use sparse format
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Storage calculation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// sparse_storage_size = 8 + 8 + nnz*2 + nnz*4 = 16 + nnz*6
// Dense storage = dimension * 4

// Sparse is better when: 16 + nnz*6 &lt; dimension*4
// Solving: nnz &lt; (dimension*4 - 16) / 6 = dimension*0.67 - 2.67
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Max NNZ for Sparse</th><th>Sparsity Threshold</th></tr></thead><tbody>
<tr><td>100</td><td>64</td><td>64%</td></tr>
<tr><td>1000</td><td>664</td><td>66.4%</td></tr>
<tr><td>4096</td><td>2728</td><td>66.6%</td></tr>
</tbody></table>
</div>
<h2 id="compressed-value-types"><a class="header" href="#compressed-value-types">Compressed Value Types</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum CompressedValue {
    Scalar(CompressedScalar),           // Int, Float, String, Bool, Null
    VectorRaw(Vec&lt;f32&gt;),                // Uncompressed
    VectorTT { cores, original_dim, shape, ranks },  // TT-compressed
    VectorSparse { dimension, positions, values },   // Sparse
    IdList(Vec&lt;u8&gt;),                    // Delta + varint encoded
    RleInt(RleEncoded&lt;i64&gt;),            // RLE encoded integers
    Pointer(String),                    // Single pointer
    Pointers(Vec&lt;String&gt;),              // Multiple pointers
}
<span class="boring">}</span></code></pre></pre>
<h3 id="automatic-format-selection"><a class="header" href="#automatic-format-selection">Automatic Format Selection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn compress_vector(vector: &amp;[f32], key: &amp;str, field_name: &amp;str,
    config: &amp;CompressionConfig) -&gt; Result&lt;CompressedValue, FormatError&gt; {

    // 1. Check for embedding-like keys
    let is_embedding = key.starts_with("emb:") ||
                       field_name == "_embedding" ||
                       field_name == "vector";

    if is_embedding {
        if let Some(TensorMode::TensorTrain(tt_config)) = &amp;config.tensor_mode {
            return Ok(CompressedValue::VectorTT { ... });
        }
    }

    // 2. Check for ID list pattern
    if config.delta_encoding &amp;&amp; looks_like_id_list(vector, field_name) {
        return Ok(CompressedValue::IdList(...));
    }

    // 3. Fall back to raw
    Ok(CompressedValue::VectorRaw(vector.to_vec()))
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance"><a class="header" href="#performance">Performance</a></h2>
<p>Benchmarks on Apple M4 (aarch64, MacBook Air 24GB), release build:</p>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Decompose</th><th>Reconstruct</th><th>Similarity</th><th>Compression</th></tr></thead><tbody>
<tr><td>64</td><td>6.2 us</td><td>29.5 us</td><td>1.1 us</td><td>2.0x</td></tr>
<tr><td>256</td><td>13.4 us</td><td>113.0 us</td><td>1.5 us</td><td>4.6x</td></tr>
<tr><td>768</td><td>26.9 us</td><td>431.7 us</td><td>2.4 us</td><td>10.7x</td></tr>
<tr><td>1536</td><td>62.0 us</td><td>709.8 us</td><td>2.0 us</td><td>16.0x</td></tr>
<tr><td>4096</td><td>464.5 us</td><td>2142.2 us</td><td>2.4 us</td><td>42.7x</td></tr>
</tbody></table>
</div>
<p>Batch operations (768-dim, 1000 vectors):</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Per-vector</th></tr></thead><tbody>
<tr><td><code>tt_decompose_batch</code></td><td>21 ms</td><td>21.0 us</td></tr>
<tr><td><code>tt_cosine_similarity_batch</code></td><td>11.3 ms</td><td>11.4 us</td></tr>
</tbody></table>
</div>
<p>Throughput: <strong>39,318 vectors/sec</strong> (768-dim decomposition)</p>
<h3 id="industry-comparison"><a class="header" href="#industry-comparison">Industry Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Compression</th><th>Recall</th><th>Notes</th></tr></thead><tbody>
<tr><td><strong>Tensor Train (this)</strong></td><td>10-42x</td><td>~99%</td><td>Similarity in compressed space</td></tr>
<tr><td>Scalar Quantization</td><td>4x</td><td>99%+</td><td>Industry default</td></tr>
<tr><td>Product Quantization</td><td>16-64x</td><td>56-90%</td><td>Requires training</td></tr>
<tr><td>Binary Quantization</td><td>32x</td><td>80-95%</td><td>Speed-optimized</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas-4"><a class="header" href="#edge-cases-and-gotchas-4">Edge Cases and Gotchas</a></h2>
<h3 id="vector-content-patterns"><a class="header" href="#vector-content-patterns">Vector Content Patterns</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Pattern</th><th>Compression</th><th>Reconstruction</th><th>Notes</th></tr></thead><tbody>
<tr><td>Constant (all same)</td><td>Excellent (&gt;5x)</td><td>Accurate</td><td>Rank-1 structure</td></tr>
<tr><td>All zeros</td><td>Good</td><td>Accurate</td><td>Degenerate case</td></tr>
<tr><td>Single spike</td><td>Poor</td><td>Moderate</td><td>No low-rank structure</td></tr>
<tr><td>Linear ramp</td><td>Good (&gt;2x)</td><td>Good</td><td>Low-rank</td></tr>
<tr><td>Alternating +1/-1</td><td>Poor</td><td>Moderate</td><td>High-frequency needs high rank</td></tr>
<tr><td>Random dense</td><td>Good</td><td>Good (&gt;0.9 cosine)</td><td>Typical embeddings</td></tr>
<tr><td>90% zeros</td><td>Consider sparse instead</td><td>n/a</td><td>Use <code>compress_dense_as_sparse</code></td></tr>
</tbody></table>
</div>
<h3 id="numerical-edge-cases"><a class="header" href="#numerical-edge-cases">Numerical Edge Cases</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Very small values (denormalized floats)
let tiny: Vec&lt;f32&gt; = (0..64).map(|i| (i as f32) * 1e-38).collect();
// Works, but may lose precision

// Large values (1e6 range)
let large: Vec&lt;f32&gt; = (0..64).map(|i| (i as f32) * 1e6).collect();
// Works, no overflow

// Prime dimensions
let prime_127: Vec&lt;f32&gt; = (0..127).map(|i| (i as f32 * 0.1).sin()).collect();
// Works but may have poor compression
<span class="boring">}</span></code></pre></pre>
<h3 id="streaming-gotchas"><a class="header" href="#streaming-gotchas">Streaming Gotchas</a></h3>
<ol>
<li>
<p><strong>Incomplete files</strong>: Magic bytes are written first, but entry count is in
trailer. If writer crashes before <code>finish()</code>, the file is corrupt.</p>
</li>
<li>
<p><strong>Memory limits</strong>: <code>MAX_ENTRY_SIZE = 100MB</code> and <code>MAX_TRAILER_SIZE = 1MB</code>
prevent allocation attacks. Exceeding these returns an error.</p>
</li>
<li>
<p><strong>Seek requirement</strong>: <code>StreamingReader::open</code> requires <code>Seek</code> to read the
trailer. For non-seekable streams, use <code>read_streaming_to_snapshot</code> which
buffers.</p>
</li>
</ol>
<h3 id="delta-chain-gotchas"><a class="header" href="#delta-chain-gotchas">Delta Chain Gotchas</a></h3>
<ol>
<li>
<p><strong>Chain length</strong>: Default <code>max_chain_len = 100</code>. After this, <code>push()</code> returns
<code>ChainTooLong</code> error. Call <code>compact()</code> periodically.</p>
</li>
<li>
<p><strong>Sequence gaps</strong>: Deltas should have contiguous sequences. The
<code>merge_deltas</code> function only keeps the latest state per key.</p>
</li>
<li>
<p><strong>Base reference</strong>: Deltas store a <code>base_id</code> string but don’t validate it
exists. Your application must track base snapshots.</p>
</li>
</ol>
<h2 id="performance-tips-and-best-practices"><a class="header" href="#performance-tips-and-best-practices">Performance Tips and Best Practices</a></h2>
<h3 id="choosing-configuration"><a class="header" href="#choosing-configuration">Choosing Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// For search/retrieval (similarity queries)
let config = TTConfig::for_dim(dim)?;  // Balanced

// For archival/cold storage
let config = TTConfig::high_compression(dim)?;  // Smaller, slower queries

// For real-time applications
let config = TTConfig::high_accuracy(dim)?;  // Larger, faster queries
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-size-optimization"><a class="header" href="#batch-size-optimization">Batch Size Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Below parallel threshold (4), sequential is faster
// due to thread spawn overhead
let small_batch = tt_decompose_batch(&amp;vectors[..3], &amp;config);  // Sequential

// At threshold, parallel kicks in
let large_batch = tt_decompose_batch(&amp;vectors, &amp;config);  // Parallel if &gt;= 4
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-efficiency-1"><a class="header" href="#memory-efficiency-1">Memory Efficiency</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Load all, then process
let all_vectors = read_streaming_tt_all(file)?;  // Loads all into memory

// Good: Stream process
for tt in StreamingTTReader::open(file)? {
    process(tt?);  // One at a time
}

// Best: Use streaming search
let results = streaming_tt_similarity_search(file, &amp;query_tt, 10)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="delta-compaction-strategy"><a class="header" href="#delta-compaction-strategy">Delta Compaction Strategy</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut chain = DeltaChain::new(base);

// After N deltas or M total changes
if chain.len() &gt;= 10 || total_changes &gt;= 10000 {
    let new_base = chain.compact()?;
    chain = DeltaChain::new(new_base);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="dependencies-3"><a class="header" href="#dependencies-3">Dependencies</a></h2>
<ul>
<li><code>serde</code>: Serialization traits</li>
<li><code>bincode</code>: Binary format</li>
<li><code>thiserror</code>: Error types</li>
<li><code>rayon</code>: Parallel batch operations</li>
</ul>
<p>No external LAPACK/BLAS - pure Rust SVD implementation.</p>
<h2 id="related-modules-4"><a class="header" href="#related-modules-4">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><a href="architecture/tensor-store.html">tensor_store</a></td><td>Uses compression for snapshot I/O</td></tr>
<tr><td><a href="architecture/tensor-chain.html">tensor_chain</a></td><td>Delta compression for state replication</td></tr>
<tr><td><a href="architecture/tensor-checkpoint.html">tensor_checkpoint</a></td><td>Snapshot format integration</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-vault"><a class="header" href="#tensor-vault">Tensor Vault</a></h1>
<p>Tensor Vault provides secure secret storage with AES-256-GCM encryption and
graph-based access control. Designed for multi-agent environments, it implements
a zero-trust architecture where access is determined by graph topology rather
than traditional ACLs.</p>
<p>All secrets are encrypted at rest with authenticated encryption. The vault
maintains a permanent audit trail of all operations and supports features like
rate limiting, TTL-based grants, and namespace isolation for multi-tenant
deployments.</p>
<h2 id="design-principles-3"><a class="header" href="#design-principles-3">Design Principles</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Principle</th><th>Description</th></tr></thead><tbody>
<tr><td>Encryption at Rest</td><td>All secrets encrypted with AES-256-GCM</td></tr>
<tr><td>Topological Access Control</td><td>Access determined by graph path, not ACLs</td></tr>
<tr><td>Zero Trust</td><td>No bypass mode; <code>node:root</code> is the only universal accessor</td></tr>
<tr><td>Memory Safety</td><td>Keys zeroized on drop via <code>zeroize</code> crate</td></tr>
<tr><td>Permanent Audit Trail</td><td>All operations logged with queryable API</td></tr>
<tr><td>Defense in Depth</td><td>Multiple obfuscation layers hide patterns</td></tr>
<tr><td>Multi-Tenant Ready</td><td>Namespace isolation and rate limiting for agent systems</td></tr>
</tbody></table>
</div>
<h2 id="key-types-5"><a class="header" href="#key-types-5">Key Types</a></h2>
<h3 id="core-types-2"><a class="header" href="#core-types-2">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Vault</code></td><td>Main API for encrypted secret storage with graph-based access control</td></tr>
<tr><td><code>VaultConfig</code></td><td>Configuration for key derivation, rate limiting, and versioning</td></tr>
<tr><td><code>VaultError</code></td><td>Error types (AccessDenied, NotFound, CryptoError, etc.)</td></tr>
<tr><td><code>Permission</code></td><td>Access levels: Read, Write, Admin</td></tr>
<tr><td><code>VersionInfo</code></td><td>Metadata about a secret version (version number, timestamp)</td></tr>
<tr><td><code>ScopedVault</code></td><td>Entity-bound view for simplified API usage</td></tr>
<tr><td><code>NamespacedVault</code></td><td>Namespace-prefixed view for multi-tenant isolation</td></tr>
</tbody></table>
</div>
<h3 id="cryptographic-types"><a class="header" href="#cryptographic-types">Cryptographic Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>MasterKey</code></td><td>Derived encryption key with zeroize-on-drop (32 bytes)</td></tr>
<tr><td><code>Cipher</code></td><td>AES-256-GCM encryption wrapper</td></tr>
<tr><td><code>Obfuscator</code></td><td>HMAC-based key obfuscation and AEAD metadata encryption</td></tr>
<tr><td><code>PaddingSize</code></td><td>Padding buckets for length hiding (256B to 64KB)</td></tr>
</tbody></table>
</div>
<h3 id="access-control-types"><a class="header" href="#access-control-types">Access Control Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>AccessController</code></td><td>BFS-based graph path verification</td></tr>
<tr><td><code>GrantTTLTracker</code></td><td>Min-heap tracking grant expirations with persistence</td></tr>
<tr><td><code>RateLimiter</code></td><td>Sliding window rate limiting per entity</td></tr>
<tr><td><code>RateLimitConfig</code></td><td>Configurable limits per operation type</td></tr>
</tbody></table>
</div>
<h3 id="audit-types"><a class="header" href="#audit-types">Audit Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>AuditLog</code></td><td>Query interface for audit entries</td></tr>
<tr><td><code>AuditEntry</code></td><td>Single operation record (entity, key, operation, timestamp)</td></tr>
<tr><td><code>AuditOperation</code></td><td>Operation types: Get, Set, Delete, Rotate, Grant, Revoke, List</td></tr>
</tbody></table>
</div>
<h2 id="architecture-6"><a class="header" href="#architecture-6">Architecture</a></h2>
<pre class="mermaid">graph TB
    subgraph &quot;Tensor Vault&quot;
        API[Vault API]
        AC[AccessController]
        Cipher[Cipher&lt;br/&gt;AES-256-GCM]
        KDF[MasterKey&lt;br/&gt;Argon2id + HKDF]
        Obf[Obfuscator&lt;br/&gt;HMAC + Padding]
        Audit[AuditLog]
        TTL[GrantTTLTracker]
        RL[RateLimiter]
    end

    subgraph &quot;Storage&quot;
        TS[TensorStore]
        GE[GraphEngine]
    end

    API --&gt; AC
    API --&gt; Cipher
    API --&gt; Obf
    API --&gt; Audit
    API --&gt; TTL
    API --&gt; RL

    AC --&gt; GE
    Cipher --&gt; KDF
    Obf --&gt; KDF

    API --&gt; TS
    Audit --&gt; TS
</pre>
<h3 id="data-flow-1"><a class="header" href="#data-flow-1">Data Flow</a></h3>
<ol>
<li><strong>Set Operation</strong>: Plaintext is padded, encrypted with random nonce, metadata
obfuscated, stored via TensorStore</li>
<li><strong>Get Operation</strong>: Rate limit check, access path verified via BFS, ciphertext
decrypted, padding removed, audit logged</li>
<li><strong>Grant Operation</strong>: Permission edge created in GraphEngine, TTL tracked if
specified</li>
<li><strong>Revoke Operation</strong>: Permission edge deleted, expired grants cleaned up</li>
</ol>
<h3 id="set-operation-flow"><a class="header" href="#set-operation-flow">Set Operation Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant C as Client
    participant V as Vault
    participant RL as RateLimiter
    participant AC as AccessController
    participant O as Obfuscator
    participant Ci as Cipher
    participant TS as TensorStore
    participant GE as GraphEngine
    participant A as AuditLog

    C-&gt;&gt;V: set(requester, key, value)
    V-&gt;&gt;RL: check_rate_limit(requester, Set)
    alt Rate Limited
        RL--&gt;&gt;V: RateLimited error
        V--&gt;&gt;C: Error
    end

    alt New Secret
        V-&gt;&gt;V: Check requester == ROOT
        alt Not Root
            V--&gt;&gt;C: AccessDenied
        end
    else Update
        V-&gt;&gt;AC: check_path_with_permission(Write)
    end

    V-&gt;&gt;O: pad_plaintext(value)
    O--&gt;&gt;V: padded_value
    V-&gt;&gt;Ci: encrypt(padded_value)
    Ci--&gt;&gt;V: (ciphertext, nonce)

    V-&gt;&gt;O: generate_storage_id(key, nonce)
    O--&gt;&gt;V: blob_key
    V-&gt;&gt;TS: put(blob_key, ciphertext)

    V-&gt;&gt;O: obfuscate_key(key)
    O--&gt;&gt;V: obfuscated_key
    V-&gt;&gt;O: encrypt_metadata(creator)
    V-&gt;&gt;O: encrypt_metadata(timestamp)
    V-&gt;&gt;TS: put(_vk:obfuscated_key, metadata)

    alt New Secret
        V-&gt;&gt;GE: add_entity_edge(ROOT, secret_node, VAULT_ACCESS_ADMIN)
    end

    V-&gt;&gt;A: record(requester, key, Set)
    V--&gt;&gt;C: Ok(())
</pre>
<h2 id="access-control-model"><a class="header" href="#access-control-model">Access Control Model</a></h2>
<p>Access is determined by graph topology using BFS traversal:</p>
<pre><code class="language-text">node:root ──VAULT_ACCESS_ADMIN──&gt; vault_secret:api_key
                                          ^
user:alice ──VAULT_ACCESS_READ───────────┘
                                          ^
team:devs ──VAULT_ACCESS_WRITE───────────┘
      ^
user:bob ──MEMBER────────────────────────┘
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Requester</th><th>Path</th><th>Access</th></tr></thead><tbody>
<tr><td><code>node:root</code></td><td>Always</td><td>Granted (Admin)</td></tr>
<tr><td><code>user:alice</code></td><td>Direct edge</td><td>Granted (Read only)</td></tr>
<tr><td><code>team:devs</code></td><td>Direct edge</td><td>Granted (Write)</td></tr>
<tr><td><code>user:bob</code></td><td>bob -&gt; team:devs -&gt; secret</td><td>Granted (Write via team)</td></tr>
<tr><td><code>user:carol</code></td><td>No path</td><td>Denied</td></tr>
</tbody></table>
</div>
<h3 id="permission-levels"><a class="header" href="#permission-levels">Permission Levels</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Level</th><th>Capabilities</th></tr></thead><tbody>
<tr><td>Read</td><td><code>get()</code>, <code>list()</code>, <code>get_version()</code>, <code>list_versions()</code></td></tr>
<tr><td>Write</td><td>Read + <code>set()</code> (update), <code>rotate()</code>, <code>rollback()</code></td></tr>
<tr><td>Admin</td><td>Write + <code>delete()</code>, <code>grant()</code>, <code>revoke()</code></td></tr>
</tbody></table>
</div>
<p>Permission propagation follows graph paths. The effective permission is
determined by the <code>VAULT_ACCESS_*</code> edge type at the end of the path.</p>
<h3 id="allowed-traversal-edges"><a class="header" href="#allowed-traversal-edges">Allowed Traversal Edges</a></h3>
<p>Only these edge types can grant transitive access:</p>
<ul>
<li><code>VAULT_ACCESS</code> - Legacy edge type (treated as Admin for backward
compatibility)</li>
<li><code>VAULT_ACCESS_READ</code> - Read-only access</li>
<li><code>VAULT_ACCESS_WRITE</code> - Read + Write access</li>
<li><code>VAULT_ACCESS_ADMIN</code> - Full access including grant/revoke</li>
<li><code>MEMBER</code> - Allows group membership traversal but does NOT grant permission
directly</li>
</ul>
<h3 id="access-control-algorithm"><a class="header" href="#access-control-algorithm">Access Control Algorithm</a></h3>
<p>The <code>AccessController</code> uses BFS to find the best permission level along any
path:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simplified algorithm from access.rs
pub fn get_permission_level(graph: &amp;GraphEngine, source: &amp;str, target: &amp;str) -&gt; Option&lt;Permission&gt; {
    if source == target {
        return Some(Permission::Admin);  // Self-access
    }

    let mut visited = HashSet::new();
    let mut queue = VecDeque::new();
    let mut best_permission: Option&lt;Permission&gt; = None;

    queue.push_back(source.to_string());
    visited.insert(source.to_string());

    while let Some(current) = queue.pop_front() {
        for edge in graph.get_entity_outgoing(&amp;current) {
            let (_, to, edge_type, _) = graph.get_entity_edge(&amp;edge);

            // Only traverse allowed edge types
            if !is_allowed_edge_type(&amp;edge_type) {
                continue;
            }

            // VAULT_ACCESS_* edges grant permission to target
            if edge_type.starts_with("VAULT_ACCESS") &amp;&amp; to == target {
                if let Some(perm) = Permission::from_edge_type(&amp;edge_type) {
                    best_permission = max(best_permission, perm);
                }
            } else if edge_type == "MEMBER" {
                // MEMBER edges allow traversal but NO permission grant
                if !visited.contains(&amp;to) {
                    visited.insert(to.clone());
                    queue.push_back(to);
                }
            }
        }
    }

    best_permission
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Security Note</strong>: <code>MEMBER</code> edges enable traversal through groups but do not
grant permissions. Only <code>VAULT_ACCESS_*</code> edges grant actual permissions. This
prevents privilege escalation via group membership.</p>
<h3 id="access-control-flow"><a class="header" href="#access-control-flow">Access Control Flow</a></h3>
<pre class="mermaid">flowchart TD
    Start([Check Access]) --&gt; IsRoot{Is requester ROOT?}
    IsRoot --&gt;|Yes| Granted([Access Granted - Admin])
    IsRoot --&gt;|No| BFS[Start BFS from requester]

    BFS --&gt; Queue{Queue empty?}
    Queue --&gt;|Yes| CheckBest{Best permission found?}
    Queue --&gt;|No| Pop[Pop next node]

    Pop --&gt; GetEdges[Get outgoing edges]
    GetEdges --&gt; ForEdge{For each edge}

    ForEdge --&gt; IsAllowed{Edge type allowed?}
    IsAllowed --&gt;|No| ForEdge
    IsAllowed --&gt;|Yes| IsVaultAccess{VAULT_ACCESS_* ?}

    IsVaultAccess --&gt;|Yes| IsTarget{Points to target?}
    IsTarget --&gt;|Yes| UpdateBest[Update best permission]
    IsTarget --&gt;|No| ForEdge
    UpdateBest --&gt; ForEdge

    IsVaultAccess --&gt;|No| IsMember{MEMBER edge?}
    IsMember --&gt;|Yes| AddQueue[Add destination to queue]
    IsMember --&gt;|No| ForEdge
    AddQueue --&gt; ForEdge

    ForEdge --&gt;|Done| Queue

    CheckBest --&gt;|Yes| CheckLevel{Permission &gt;= required?}
    CheckBest --&gt;|No| Denied([Access Denied])
    CheckLevel --&gt;|Yes| Granted2([Access Granted])
    CheckLevel --&gt;|No| Insufficient([Insufficient Permission])
</pre>
<h2 id="storage-format"><a class="header" href="#storage-format">Storage Format</a></h2>
<p>Secrets use a two-tier storage model for security:</p>
<h3 id="metadata-tensor"><a class="header" href="#metadata-tensor">Metadata Tensor</a></h3>
<p>Storage key: <code>_vk:{HMAC(key)}</code> (key name obfuscated via HMAC-BLAKE2b)</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>_blob</code></td><td>Pointer</td><td>Reference to current version ciphertext blob</td></tr>
<tr><td><code>_nonce</code></td><td>Bytes</td><td>12-byte encryption nonce for current version</td></tr>
<tr><td><code>_versions</code></td><td>Pointers</td><td>List of all version blob keys (oldest first)</td></tr>
<tr><td><code>_key_enc</code></td><td>Bytes</td><td>AES-GCM encrypted original key name</td></tr>
<tr><td><code>_key_nonce</code></td><td>Bytes</td><td>Nonce for key encryption</td></tr>
<tr><td><code>_creator_obf</code></td><td>Bytes</td><td>AEAD-encrypted creator (nonce prepended)</td></tr>
<tr><td><code>_created_obf</code></td><td>Bytes</td><td>AEAD-encrypted timestamp (nonce prepended)</td></tr>
<tr><td><code>_rotator_obf</code></td><td>Bytes</td><td>AEAD-encrypted last rotator (optional)</td></tr>
<tr><td><code>_rotated_obf</code></td><td>Bytes</td><td>AEAD-encrypted last rotation timestamp (optional)</td></tr>
</tbody></table>
</div>
<h3 id="ciphertext-blob"><a class="header" href="#ciphertext-blob">Ciphertext Blob</a></h3>
<p>Storage key: <code>_vs:{HMAC(key, nonce)}</code> (random-looking storage ID)</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>_data</code></td><td>Bytes</td><td>Padded + encrypted secret</td></tr>
<tr><td><code>_nonce</code></td><td>Bytes</td><td>12-byte encryption nonce</td></tr>
<tr><td><code>_ts</code></td><td>Int</td><td>Unix timestamp (seconds) when version was created</td></tr>
</tbody></table>
</div>
<h3 id="storage-key-structure"><a class="header" href="#storage-key-structure">Storage Key Structure</a></h3>
<pre><code class="language-text">_vault:salt          - Persisted 16-byte salt for key derivation
_vk:&lt;32-hex-chars&gt;   - Metadata tensor (HMAC of secret key)
_vs:&lt;24-hex-chars&gt;   - Ciphertext blob (HMAC of key + nonce)
_va:&lt;timestamp&gt;:&lt;counter&gt; - Audit log entries
_vault_ttl_grants    - Persisted TTL grants (JSON)
vault_secret:&lt;32-hex-chars&gt; - Secret node for graph access control
</code></pre>
<h2 id="encryption"><a class="header" href="#encryption">Encryption</a></h2>
<h3 id="key-derivation"><a class="header" href="#key-derivation">Key Derivation</a></h3>
<p>Master key derived using Argon2id with HKDF-based subkey separation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From key.rs - Argon2id parameters
pub const SALT_SIZE: usize = 16;  // 128-bit salt
pub const KEY_SIZE: usize = 32;   // 256-bit key (AES-256)

// Default VaultConfig values:
// argon2_memory_cost: 65536 (64 MiB)
// argon2_time_cost: 3 (iterations)
// argon2_parallelism: 4 (threads)

// Argon2id configuration
let params = Params::new(
    config.argon2_memory_cost,  // Memory in KiB
    config.argon2_time_cost,    // Iterations
    config.argon2_parallelism,  // Parallelism
    Some(KEY_SIZE),             // Output length
)?;

let argon2 = Argon2::new(Algorithm::Argon2id, Version::V0x13, params);
argon2.hash_password_into(input, salt, &amp;mut key)?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Argon2id Security Properties</strong>:</p>
<ul>
<li>Hybrid algorithm: Argon2i (side-channel resistant) + Argon2d (GPU resistant)</li>
<li>Memory-hard: Requires 64 MiB by default, defeating GPU/ASIC attacks</li>
<li>Time-hard: 3 iterations increase computation time</li>
<li>Parallelism: 4 threads to utilize modern CPUs</li>
</ul>
<h3 id="hkdf-subkey-derivation"><a class="header" href="#hkdf-subkey-derivation">HKDF Subkey Derivation</a></h3>
<p>Each purpose gets a cryptographically independent key via HKDF-SHA256:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From key.rs - Domain-separated subkeys
impl MasterKey {
    pub fn derive_subkey(&amp;self, domain: &amp;[u8]) -&gt; [u8; KEY_SIZE] {
        let hk = Hkdf::&lt;Sha256&gt;::new(None, &amp;self.bytes);
        let mut output = [0u8; KEY_SIZE];
        hk.expand(domain, &amp;mut output).expect("HKDF expand cannot fail for 32 bytes");
        output
    }

    pub fn encryption_key(&amp;self) -&gt; [u8; KEY_SIZE] {
        self.derive_subkey(b"neumann_vault_encryption_v1")
    }

    pub fn obfuscation_key(&amp;self) -&gt; [u8; KEY_SIZE] {
        self.derive_subkey(b"neumann_vault_obfuscation_v1")
    }

    pub fn metadata_key(&amp;self) -&gt; [u8; KEY_SIZE] {
        self.derive_subkey(b"neumann_vault_metadata_v1")
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Key Hierarchy</strong>:</p>
<pre><code class="language-text">Master Password + Salt
        │
        ▼ Argon2id
    MasterKey (32 bytes)
        │
        ├──▶ HKDF("encryption_v1") ──▶ AES-256-GCM key
        ├──▶ HKDF("obfuscation_v1") ──▶ HMAC key for obfuscation
        └──▶ HKDF("metadata_v1") ──▶ AES-256-GCM key for metadata
</code></pre>
<h3 id="salt-persistence"><a class="header" href="#salt-persistence">Salt Persistence</a></h3>
<p>The vault automatically manages salt persistence:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From lib.rs - Salt handling on vault creation
pub fn new(master_key: &amp;[u8], graph: Arc&lt;GraphEngine&gt;, store: TensorStore, config: VaultConfig) -&gt; Result&lt;Self&gt; {
    let derived = if config.salt.is_some() {
        // Explicit salt provided - use it directly
        let (key, _) = MasterKey::derive(master_key, &amp;config)?;
        key
    } else if let Some(persisted_salt) = Self::load_salt(&amp;store) {
        // Use persisted salt for consistency across reopens
        MasterKey::derive_with_salt(master_key, &amp;persisted_salt, &amp;config)?
    } else {
        // Generate new random salt and persist it
        let (key, new_salt) = MasterKey::derive(master_key, &amp;config)?;
        Self::save_salt(&amp;store, new_salt)?;
        key
    };
    // ...
}
<span class="boring">}</span></code></pre></pre>
<h3 id="encryption-process"><a class="header" href="#encryption-process">Encryption Process</a></h3>
<ol>
<li>Pad plaintext to fixed bucket size (256B, 1KB, 4KB, 16KB, 32KB, or 64KB)</li>
<li>Generate random 12-byte nonce</li>
<li>Encrypt with AES-256-GCM</li>
<li>Store ciphertext and nonce separately</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From encryption.rs
pub const NONCE_SIZE: usize = 12;  // 96-bit nonce (AES-GCM standard)

impl Cipher {
    pub fn encrypt(&amp;self, plaintext: &amp;[u8]) -&gt; Result&lt;(Vec&lt;u8&gt;, [u8; NONCE_SIZE])&gt; {
        let cipher = Aes256Gcm::new_from_slice(self.key.as_bytes())?;

        // Generate random nonce - CRITICAL for security
        let mut nonce_bytes = [0u8; NONCE_SIZE];
        rand::thread_rng().fill_bytes(&amp;mut nonce_bytes);
        let nonce = Nonce::from_slice(&amp;nonce_bytes);

        // AES-GCM provides authenticated encryption
        // Output: ciphertext || 16-byte authentication tag
        let ciphertext = cipher.encrypt(nonce, plaintext)?;

        Ok((ciphertext, nonce_bytes))
    }

    pub fn decrypt(&amp;self, ciphertext: &amp;[u8], nonce_bytes: &amp;[u8]) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {
        if nonce_bytes.len() != NONCE_SIZE {
            return Err(VaultError::CryptoError("Invalid nonce size"));
        }

        let cipher = Aes256Gcm::new_from_slice(self.key.as_bytes())?;
        let nonce = Nonce::from_slice(nonce_bytes);

        // Decryption verifies authentication tag
        // Fails if ciphertext was tampered
        cipher.decrypt(nonce, ciphertext)
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>AES-256-GCM Security Properties</strong>:</p>
<ul>
<li>Authenticated encryption: Detects tampering via 128-bit authentication tag</li>
<li>Nonce requirement: Each encryption MUST use a unique nonce</li>
<li>Ciphertext expansion: 16 bytes larger than plaintext (auth tag)</li>
</ul>
<h3 id="obfuscation-layers"><a class="header" href="#obfuscation-layers">Obfuscation Layers</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Layer</th><th>Purpose</th><th>Implementation</th></tr></thead><tbody>
<tr><td>Key Obfuscation</td><td>Hide secret names</td><td>HMAC-BLAKE2b hash of key name</td></tr>
<tr><td>Pointer Indirection</td><td>Hide storage patterns</td><td>Ciphertext in separate blob with random-looking key</td></tr>
<tr><td>Length Padding</td><td>Hide plaintext size</td><td>Pad to fixed bucket sizes</td></tr>
<tr><td>Metadata Encryption</td><td>Hide creator/timestamps</td><td>AES-GCM with per-record random nonces</td></tr>
<tr><td>Blind Indexes</td><td>Searchable encryption</td><td>HMAC-based indexes for pattern matching</td></tr>
</tbody></table>
</div>
<h3 id="padding-bucket-sizes"><a class="header" href="#padding-bucket-sizes">Padding Bucket Sizes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From obfuscation.rs
pub enum PaddingSize {
    Small = 256,        // API keys, tokens
    Medium = 1024,      // Certificates, small configs
    Large = 4096,       // Private keys, large configs
    ExtraLarge = 16384, // Very large secrets
    Huge = 32768,       // Oversized secrets
    Maximum = 65536,    // Maximum supported
}

// Bucket selection (includes 4-byte length prefix + 1 byte min padding)
pub fn for_length(len: usize) -&gt; Option&lt;Self&gt; {
    let min_required = len + 5;  // length prefix + min padding

    if min_required &lt;= 256 { Some(Small) }
    else if min_required &lt;= 1024 { Some(Medium) }
    else if min_required &lt;= 4096 { Some(Large) }
    else if min_required &lt;= 16384 { Some(ExtraLarge) }
    else if min_required &lt;= 32768 { Some(Huge) }
    else if min_required &lt;= 65536 { Some(Maximum) }
    else { None }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="padding-format"><a class="header" href="#padding-format">Padding Format</a></h3>
<pre><code class="language-text">+----------------+-------------------+------------------+
| Length (4B LE) | Plaintext (N B)   | Random Padding   |
+----------------+-------------------+------------------+
|&lt;--------------- Bucket Size (256/1K/4K/...) --------&gt;|
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From obfuscation.rs
pub fn pad_plaintext(plaintext: &amp;[u8]) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {
    let target_size = PaddingSize::for_length(plaintext.len())? as usize;
    let padding_len = target_size - 4 - plaintext.len();  // 4 = length prefix

    let mut padded = Vec::with_capacity(target_size);

    // Store original length as u32 little-endian
    let len_bytes = (plaintext.len() as u32).to_le_bytes();
    padded.extend_from_slice(&amp;len_bytes);

    // Original data
    padded.extend_from_slice(plaintext);

    // Random padding (not zeros - prevents padding oracle attacks)
    let mut rng_bytes = vec![0u8; padding_len];
    rand::thread_rng().fill_bytes(&amp;mut rng_bytes);
    padded.extend_from_slice(&amp;rng_bytes);

    Ok(padded)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="hmac-blake2b-construction"><a class="header" href="#hmac-blake2b-construction">HMAC-BLAKE2b Construction</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From obfuscation.rs - HMAC construction for key obfuscation
fn hmac_hash(&amp;self, data: &amp;[u8], domain: &amp;[u8]) -&gt; [u8; 32] {
    // Inner hash: H((key XOR ipad) || domain || data)
    let mut inner_key = self.obfuscation_key;
    for byte in &amp;mut inner_key {
        *byte ^= 0x36;  // ipad
    }
    let mut inner_hasher = Blake2b::&lt;U32&gt;::new();
    inner_hasher.update(inner_key);
    inner_hasher.update(domain);
    inner_hasher.update(data);
    let inner_hash = inner_hasher.finalize();

    // Outer hash: H((key XOR opad) || inner_hash)
    let mut outer_key = self.obfuscation_key;
    for byte in &amp;mut outer_key {
        *byte ^= 0x5c;  // opad
    }
    let mut outer_hasher = Blake2b::&lt;U32&gt;::new();
    outer_hasher.update(outer_key);
    outer_hasher.update(inner_hash);

    outer_hasher.finalize().into()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="metadata-aead-encryption"><a class="header" href="#metadata-aead-encryption">Metadata AEAD Encryption</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From obfuscation.rs - Per-record AEAD encryption
pub fn encrypt_metadata(&amp;self, data: &amp;[u8]) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {
    let cipher = Aes256Gcm::new_from_slice(&amp;self.metadata_key)?;

    // Random nonce for each encryption
    let mut nonce_bytes = [0u8; 12];
    rand::thread_rng().fill_bytes(&amp;mut nonce_bytes);
    let nonce = Nonce::from_slice(&amp;nonce_bytes);

    let ciphertext = cipher.encrypt(nonce, data)?;

    // Format: nonce || ciphertext
    let mut result = Vec::with_capacity(12 + ciphertext.len());
    result.extend_from_slice(&amp;nonce_bytes);
    result.extend(ciphertext);
    Ok(result)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="rate-limiting"><a class="header" href="#rate-limiting">Rate Limiting</a></h2>
<p>Rate limiting uses a sliding window algorithm to prevent brute-force attacks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From rate_limit.rs
pub struct RateLimiter {
    // (entity, operation) -&gt; timestamps of recent requests
    history: DashMap&lt;(String, String), VecDeque&lt;Instant&gt;&gt;,
    config: RateLimitConfig,
}

impl RateLimiter {
    pub fn check_and_record(&amp;self, entity: &amp;str, op: Operation) -&gt; Result&lt;(), String&gt; {
        let limit = op.limit(&amp;self.config);
        if limit == u32::MAX {
            return Ok(());  // Unlimited
        }

        let key = (entity.to_string(), op.as_str().to_string());
        let now = Instant::now();
        let window_start = now - self.config.window;

        let mut entry = self.history.entry(key).or_default();
        let timestamps = entry.value_mut();

        // Remove expired entries outside window
        while let Some(front) = timestamps.front() {
            if *front &lt; window_start {
                timestamps.pop_front();
            } else {
                break;
            }
        }

        let count = timestamps.len() as u32;
        if count &gt;= limit {
            Err(format!("Rate limit exceeded: {} {} calls in {:?}", count, op, self.config.window))
        } else {
            timestamps.push_back(now);  // Record this request
            Ok(())
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="sliding-window-visualization"><a class="header" href="#sliding-window-visualization">Sliding Window Visualization</a></h3>
<pre><code class="language-text">Window: 60 seconds
Limit: 5 requests

Timeline:
|--[req1]--[req2]---[req3]--[req4]---[req5]---|
|&lt;------------------ Window -----------------&gt;|
                                               ^
                                               Now (6th request blocked)

After 10 seconds:
                    |--[req2]---[req3]--[req4]---[req5]---|
   [req1] expired   |&lt;------------------ Window ---------&gt;|
                                                           ^
                                                           Now (6th request allowed)
</code></pre>
<h3 id="rate-limit-configuration-presets"><a class="header" href="#rate-limit-configuration-presets">Rate Limit Configuration Presets</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Default configuration
impl Default for RateLimitConfig {
    fn default() -&gt; Self {
        Self {
            max_gets: 60,    // 60 get() calls per minute
            max_lists: 10,   // 10 list() calls per minute
            max_sets: 30,    // 30 set() calls per minute
            max_grants: 20,  // 20 grant() calls per minute
            window: Duration::from_secs(60),
        }
    }
}

// Strict configuration for testing
pub fn strict() -&gt; Self {
    Self {
        max_gets: 5,
        max_lists: 2,
        max_sets: 3,
        max_grants: 2,
        window: Duration::from_secs(60),
    }
}

// No rate limiting
pub fn unlimited() -&gt; Self {
    Self {
        max_gets: u32::MAX,
        max_lists: u32::MAX,
        max_sets: u32::MAX,
        max_grants: u32::MAX,
        window: Duration::from_secs(60),
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Note</strong>: <code>node:root</code> is exempt from rate limiting.</p>
<h2 id="ttl-grant-tracking"><a class="header" href="#ttl-grant-tracking">TTL Grant Tracking</a></h2>
<p>TTL grants use a min-heap for efficient expiration tracking:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From ttl.rs
pub struct GrantTTLTracker {
    // Priority queue of expiration times (min-heap)
    heap: Mutex&lt;BinaryHeap&lt;GrantTTLEntry&gt;&gt;,
}

struct GrantTTLEntry {
    expires_at: Instant,
    entity: String,
    secret_key: String,
}

// Reverse ordering for min-heap (earliest expiration first)
impl Ord for GrantTTLEntry {
    fn cmp(&amp;self, other: &amp;Self) -&gt; Ordering {
        other.expires_at.cmp(&amp;self.expires_at)  // Reversed!
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="ttl-operations"><a class="header" href="#ttl-operations">TTL Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add a grant with TTL
pub fn add(&amp;self, entity: &amp;str, secret_key: &amp;str, ttl: Duration) {
    let entry = GrantTTLEntry {
        expires_at: Instant::now() + ttl,
        entity: entity.to_string(),
        secret_key: secret_key.to_string(),
    };
    self.heap.lock().unwrap().push(entry);
}

// Efficient expiration check - O(1) to peek, O(log n) to pop
pub fn get_expired(&amp;self) -&gt; Vec&lt;(String, String)&gt; {
    let now = Instant::now();
    let mut expired = Vec::new();
    let mut heap = self.heap.lock().unwrap();

    // Pop all expired entries (they're at the top due to min-heap)
    while let Some(entry) = heap.peek() {
        if entry.expires_at &lt;= now {
            if let Some(entry) = heap.pop() {
                expired.push((entry.entity, entry.secret_key));
            }
        } else {
            break;  // No more expired entries
        }
    }

    expired
}
<span class="boring">}</span></code></pre></pre>
<h3 id="ttl-persistence"><a class="header" href="#ttl-persistence">TTL Persistence</a></h3>
<p>TTL grants survive vault restarts via TensorStore persistence:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From ttl.rs
const TTL_STORAGE_KEY: &amp;str = "_vault_ttl_grants";

#[derive(Serialize, Deserialize)]
pub struct PersistedGrant {
    pub expires_at_ms: i64,  // Unix timestamp
    pub entity: String,
    pub secret_key: String,
}

pub fn persist(&amp;self, store: &amp;TensorStore) -&gt; Result&lt;()&gt; {
    let grants: Vec&lt;PersistedGrant&gt; = self.heap.lock().unwrap()
        .iter()
        .map(|e| PersistedGrant {
            expires_at_ms: instant_to_unix_ms(e.expires_at),
            entity: e.entity.clone(),
            secret_key: e.secret_key.clone(),
        })
        .collect();

    let data = serde_json::to_vec(&amp;grants)?;
    store.put(TTL_STORAGE_KEY, tensor_with_bytes(data))?;
    Ok(())
}

pub fn load(store: &amp;TensorStore) -&gt; Result&lt;Self&gt; {
    let tracker = Self::new();
    let grants: Vec&lt;PersistedGrant&gt; = load_from_store(store)?;

    for grant in grants {
        // Skip already expired grants
        if !grant.is_expired() {
            tracker.add_with_expiration(
                &amp;grant.entity,
                &amp;grant.secret_key,
                unix_ms_to_instant(grant.expires_at_ms),
            );
        }
    }

    Ok(tracker)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cleanup-strategy"><a class="header" href="#cleanup-strategy">Cleanup Strategy</a></h3>
<p>Expired grants are cleaned up opportunistically during <code>get()</code> operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From lib.rs
pub fn get(&amp;self, requester: &amp;str, key: &amp;str) -&gt; Result&lt;String&gt; {
    // Opportunistic cleanup of expired grants
    self.cleanup_expired_grants();

    // ... rest of get operation
}

pub fn cleanup_expired_grants(&amp;self) -&gt; usize {
    let expired = self.ttl_tracker.get_expired();
    let mut revoked = 0;

    for (entity, key) in expired {
        let secret_node = self.secret_node_key(&amp;key);

        // Delete the VAULT_ACCESS_* edge
        if let Ok(edges) = self.graph.get_entity_outgoing(&amp;entity) {
            for edge_key in edges {
                if let Ok((_, to, edge_type, _)) = self.graph.get_entity_edge(&amp;edge_key) {
                    if to == secret_node &amp;&amp; edge_type.starts_with("VAULT_ACCESS") {
                        if self.graph.delete_entity_edge(&amp;edge_key).is_ok() {
                            revoked += 1;
                        }
                    }
                }
            }
        }
    }

    revoked
}
<span class="boring">}</span></code></pre></pre>
<h2 id="audit-logging"><a class="header" href="#audit-logging">Audit Logging</a></h2>
<h3 id="audit-entry-storage"><a class="header" href="#audit-entry-storage">Audit Entry Storage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From audit.rs
const AUDIT_PREFIX: &amp;str = "_va:";
static AUDIT_COUNTER: AtomicU64 = AtomicU64::new(0);

pub fn record(&amp;self, entity: &amp;str, secret_key: &amp;str, operation: &amp;AuditOperation) {
    let timestamp = now_millis();
    let counter = AUDIT_COUNTER.fetch_add(1, Ordering::SeqCst);
    let key = format!("{AUDIT_PREFIX}{timestamp}:{counter}");

    let mut tensor = TensorData::new();
    tensor.set("_entity", entity);
    tensor.set("_secret", secret_key);  // Already obfuscated by caller
    tensor.set("_op", operation.as_str());
    tensor.set("_ts", timestamp);

    // Additional fields for grant/revoke
    match operation {
        AuditOperation::Grant { to, permission } =&gt; {
            tensor.set("_target", to);
            tensor.set("_permission", permission);
        },
        AuditOperation::Revoke { from } =&gt; {
            tensor.set("_target", from);
        },
        _ =&gt; {},
    }

    // Best effort - audit failures don't block operations
    let _ = self.store.put(&amp;key, tensor);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="audit-query-methods"><a class="header" href="#audit-query-methods">Audit Query Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th><th>Time Complexity</th></tr></thead><tbody>
<tr><td><code>by_secret(key)</code></td><td>All entries for a secret</td><td>O(n) scan + filter</td></tr>
<tr><td><code>by_entity(entity)</code></td><td>All entries by requester</td><td>O(n) scan + filter</td></tr>
<tr><td><code>since(timestamp)</code></td><td>Entries since timestamp</td><td>O(n) scan + filter</td></tr>
<tr><td><code>between(start, end)</code></td><td>Entries in time range</td><td>O(n) scan + filter</td></tr>
<tr><td><code>recent(limit)</code></td><td>Last N entries</td><td>O(n log n) sort + truncate</td></tr>
</tbody></table>
</div>
<p><strong>Note</strong>: Secret keys are obfuscated in audit logs to prevent leaking plaintext
names.</p>
<h2 id="usage-examples-4"><a class="header" href="#usage-examples-4">Usage Examples</a></h2>
<h3 id="basic-operations-3"><a class="header" href="#basic-operations-3">Basic Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_vault::{Vault, VaultConfig, Permission};
use graph_engine::GraphEngine;
use tensor_store::TensorStore;
use std::sync::Arc;

// Initialize vault
let graph = Arc::new(GraphEngine::new());
let store = TensorStore::new();
let vault = Vault::new(b"master_password", graph, store, VaultConfig::default())?;

// Store a secret (root only)
vault.set(Vault::ROOT, "api_key", "sk-secret123")?;

// Grant access with permission level
vault.grant_with_permission(Vault::ROOT, "user:alice", "api_key", Permission::Read)?;

// Retrieve secret
let value = vault.get("user:alice", "api_key")?;

// Revoke access
vault.revoke(Vault::ROOT, "user:alice", "api_key")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="permission-based-access"><a class="header" href="#permission-based-access">Permission-Based Access</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Grant different permission levels
vault.grant_with_permission(Vault::ROOT, "user:reader", "secret", Permission::Read)?;
vault.grant_with_permission(Vault::ROOT, "user:writer", "secret", Permission::Write)?;
vault.grant_with_permission(Vault::ROOT, "user:admin", "secret", Permission::Admin)?;

// Reader can only get/list
vault.get("user:reader", "secret")?;  // OK
vault.set("user:reader", "secret", "new")?;  // InsufficientPermission

// Writer can update
vault.rotate("user:writer", "secret", "new_value")?;  // OK
vault.delete("user:writer", "secret")?;  // InsufficientPermission

// Admin can do everything
vault.grant_with_permission("user:admin", "user:new", "secret", Permission::Read)?;  // OK
vault.delete("user:admin", "secret")?;  // OK
<span class="boring">}</span></code></pre></pre>
<h3 id="ttl-grants"><a class="header" href="#ttl-grants">TTL Grants</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::time::Duration;

// Grant temporary access (1 hour)
vault.grant_with_ttl(
    Vault::ROOT,
    "agent:temp",
    "api_key",
    Permission::Read,
    Duration::from_secs(3600),
)?;

// Access works during TTL
vault.get("agent:temp", "api_key")?;  // OK

// After 1 hour, access is automatically revoked
// (cleanup happens opportunistically on next vault operation)
<span class="boring">}</span></code></pre></pre>
<h3 id="namespace-isolation"><a class="header" href="#namespace-isolation">Namespace Isolation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create namespaced vault for multi-tenant isolation
let backend = vault.namespace("team:backend", "user:alice");
let frontend = vault.namespace("team:frontend", "user:bob");

// Keys are automatically prefixed
backend.set("db_password", "secret1")?;   // Stored as "team:backend:db_password"
frontend.set("api_key", "secret2")?;      // Stored as "team:frontend:api_key"

// Cross-namespace access blocked
frontend.get("db_password")?;  // AccessDenied
<span class="boring">}</span></code></pre></pre>
<h3 id="secret-versioning"><a class="header" href="#secret-versioning">Secret Versioning</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Each set/rotate creates a new version
vault.set(Vault::ROOT, "api_key", "v1")?;
vault.rotate(Vault::ROOT, "api_key", "v2")?;
vault.rotate(Vault::ROOT, "api_key", "v3")?;

// Get version info
let version = vault.current_version(Vault::ROOT, "api_key")?;  // 3
let versions = vault.list_versions(Vault::ROOT, "api_key")?;
// [VersionInfo { version: 1, created_at: ... }, ...]

// Get specific version
let old_value = vault.get_version(Vault::ROOT, "api_key", 1)?;  // "v1"

// Rollback (creates new version with old content)
vault.rollback(Vault::ROOT, "api_key", 1)?;
vault.get(Vault::ROOT, "api_key")?;  // "v1"
vault.current_version(Vault::ROOT, "api_key")?;  // 4 (rollback creates new version)
<span class="boring">}</span></code></pre></pre>
<h3 id="audit-queries"><a class="header" href="#audit-queries">Audit Queries</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Query by secret
let entries = vault.audit_log("api_key");

// Query by entity
let alice_actions = vault.audit_by_entity("user:alice");

// Query by time
let recent = vault.audit_since(timestamp_millis);
let last_10 = vault.audit_recent(10);

// Audit entries include operation details
for entry in entries {
    match &amp;entry.operation {
        AuditOperation::Grant { to, permission } =&gt; {
            println!("Granted {} to {} at {}", permission, to, entry.timestamp);
        },
        AuditOperation::Get =&gt; {
            println!("{} read secret at {}", entry.entity, entry.timestamp);
        },
        _ =&gt; {},
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="scoped-vault"><a class="header" href="#scoped-vault">Scoped Vault</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create a scoped view for a specific entity
let alice = vault.scope("user:alice");

// All operations use alice as the requester
alice.get("api_key")?;  // Same as vault.get("user:alice", "api_key")
alice.list("*")?;       // Same as vault.list("user:alice", "*")
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-options-1"><a class="header" href="#configuration-options-1">Configuration Options</a></h2>
<h3 id="vaultconfig"><a class="header" href="#vaultconfig">VaultConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>salt</code></td><td><code>Option&lt;[u8; 16]&gt;</code></td><td>None</td><td>Salt for key derivation (random if not provided, persisted)</td></tr>
<tr><td><code>argon2_memory_cost</code></td><td><code>u32</code></td><td>65536</td><td>Memory cost in KiB (64MB)</td></tr>
<tr><td><code>argon2_time_cost</code></td><td><code>u32</code></td><td>3</td><td>Iteration count</td></tr>
<tr><td><code>argon2_parallelism</code></td><td><code>u32</code></td><td>4</td><td>Thread count</td></tr>
<tr><td><code>rate_limit</code></td><td><code>Option&lt;RateLimitConfig&gt;</code></td><td>None</td><td>Rate limiting (disabled if None)</td></tr>
<tr><td><code>max_versions</code></td><td><code>usize</code></td><td>5</td><td>Maximum versions to retain per secret</td></tr>
</tbody></table>
</div>
<h3 id="ratelimitconfig"><a class="header" href="#ratelimitconfig">RateLimitConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>max_gets</code></td><td><code>u32</code></td><td>60</td><td>Maximum get() calls per window</td></tr>
<tr><td><code>max_lists</code></td><td><code>u32</code></td><td>10</td><td>Maximum list() calls per window</td></tr>
<tr><td><code>max_sets</code></td><td><code>u32</code></td><td>30</td><td>Maximum set() calls per window</td></tr>
<tr><td><code>max_grants</code></td><td><code>u32</code></td><td>20</td><td>Maximum grant() calls per window</td></tr>
<tr><td><code>window</code></td><td><code>Duration</code></td><td>60s</td><td>Sliding window duration</td></tr>
</tbody></table>
</div>
<h3 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th></tr></thead><tbody>
<tr><td><code>NEUMANN_VAULT_KEY</code></td><td>Base64-encoded 32-byte master key</td></tr>
</tbody></table>
</div>
<h2 id="shell-commands"><a class="header" href="#shell-commands">Shell Commands</a></h2>
<pre><code class="language-text">VAULT INIT                              Initialize vault from NEUMANN_VAULT_KEY
VAULT IDENTITY 'node:alice'             Set current identity
VAULT NAMESPACE 'team:backend'          Set current namespace

VAULT SET 'api_key' 'sk-123'            Store encrypted secret
VAULT GET 'api_key'                     Retrieve secret
VAULT GET 'api_key' VERSION 2           Get specific version
VAULT DELETE 'api_key'                  Delete secret
VAULT LIST 'prefix:*'                   List accessible secrets
VAULT ROTATE 'api_key' 'new'            Rotate secret value
VAULT VERSIONS 'api_key'                List version history
VAULT ROLLBACK 'api_key' VERSION 2      Rollback to version

VAULT GRANT 'user:bob' ON 'api_key'              Grant admin access
VAULT GRANT 'user:bob' ON 'api_key' READ         Grant read-only access
VAULT GRANT 'user:bob' ON 'api_key' WRITE        Grant write access
VAULT GRANT 'user:bob' ON 'api_key' TTL 3600     Grant with 1-hour expiry
VAULT REVOKE 'user:bob' ON 'api_key'             Revoke access

VAULT AUDIT 'api_key'                   View audit log for secret
VAULT AUDIT BY 'user:alice'             View audit log for entity
VAULT AUDIT RECENT 10                   View last 10 operations
</code></pre>
<h2 id="security-considerations"><a class="header" href="#security-considerations">Security Considerations</a></h2>
<h3 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h3>
<ol>
<li><strong>Use strong master passwords</strong>: At least 128 bits of entropy</li>
<li><strong>Rotate secrets regularly</strong>: Use <code>rotate()</code> to maintain version history</li>
<li><strong>Grant minimal permissions</strong>: Use Read when Write/Admin not needed</li>
<li><strong>Use TTL grants for temporary access</strong>: Prevents forgotten grants</li>
<li><strong>Enable rate limiting in production</strong>: Prevents brute-force attacks</li>
<li><strong>Use namespaces for multi-tenant</strong>: Enforces isolation</li>
<li><strong>Review audit logs</strong>: Monitor for suspicious access patterns</li>
</ol>
<h3 id="edge-cases-and-gotchas-5"><a class="header" href="#edge-cases-and-gotchas-5">Edge Cases and Gotchas</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Scenario</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Grant to non-existent entity</td><td>Succeeds (edge created, entity may exist later)</td></tr>
<tr><td>Revoke non-existent grant</td><td>Succeeds silently (idempotent)</td></tr>
<tr><td>Get non-existent secret</td><td>Returns <code>NotFound</code> error</td></tr>
<tr><td>Set by non-root without Write</td><td>Returns <code>AccessDenied</code> or <code>InsufficientPermission</code></td></tr>
<tr><td>TTL grant cleanup</td><td>Opportunistic on <code>get()</code> - may not be immediate</td></tr>
<tr><td>Version limit exceeded</td><td>Oldest versions automatically deleted</td></tr>
<tr><td>Plaintext &gt; 64KB</td><td>Returns <code>CryptoError</code></td></tr>
<tr><td>Invalid UTF-8 in secret</td><td><code>get()</code> returns <code>CryptoError</code></td></tr>
<tr><td>Concurrent modifications</td><td>Thread-safe via DashMap sharding</td></tr>
<tr><td>MEMBER edge to secret</td><td>Path exists but NO permission granted</td></tr>
</tbody></table>
</div>
<h3 id="threat-model"><a class="header" href="#threat-model">Threat Model</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Threat</th><th>Mitigation</th></tr></thead><tbody>
<tr><td>Password brute-force</td><td>Argon2id memory-hard KDF (64MB, 3 iterations)</td></tr>
<tr><td>Offline dictionary attack</td><td>Random 128-bit salt, stored in TensorStore</td></tr>
<tr><td>Ciphertext tampering</td><td>AES-GCM authentication tag (128-bit)</td></tr>
<tr><td>Nonce reuse</td><td>Random 96-bit nonce per encryption</td></tr>
<tr><td>Key leakage</td><td>Keys zeroized on drop, subkeys via HKDF</td></tr>
<tr><td>Pattern analysis</td><td>Key obfuscation, padding, metadata encryption</td></tr>
<tr><td>Access enumeration</td><td>Rate limiting, audit logging</td></tr>
<tr><td>Privilege escalation</td><td>MEMBER edges don’t grant permissions</td></tr>
<tr><td>Replay attacks</td><td>Per-operation nonces, timestamps in metadata</td></tr>
</tbody></table>
</div>
<h2 id="performance-1"><a class="header" href="#performance-1">Performance</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>Key derivation (Argon2id)</td><td>~80ms</td><td>64MB memory cost</td></tr>
<tr><td>set (1KB)</td><td>~29us</td><td>Includes encryption + versioning</td></tr>
<tr><td>get (1KB)</td><td>~24us</td><td>Includes decryption + audit</td></tr>
<tr><td>set (10KB)</td><td>~93us</td><td>Scales with data size</td></tr>
<tr><td>get (10KB)</td><td>~91us</td><td>Scales with data size</td></tr>
<tr><td>Access check (shallow)</td><td>~6us</td><td>Direct edge</td></tr>
<tr><td>Access check (deep, 10 hops)</td><td>~17us</td><td>BFS traversal</td></tr>
<tr><td>grant</td><td>~18us</td><td>Creates graph edge</td></tr>
<tr><td>revoke</td><td>~1.1ms</td><td>Edge deletion + TTL cleanup</td></tr>
<tr><td>list (100 secrets)</td><td>~291us</td><td>Pattern matching + access check</td></tr>
<tr><td>list (1000 secrets)</td><td>~2.7ms</td><td>Scales linearly</td></tr>
</tbody></table>
</div>
<h2 id="related-modules-5"><a class="header" href="#related-modules-5">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><a href="architecture/tensor-store.html">Tensor Store</a></td><td>Underlying key-value storage for encrypted secrets</td></tr>
<tr><td><a href="architecture/graph-engine.html">Graph Engine</a></td><td>Access control edges and audit trail</td></tr>
<tr><td><a href="architecture/query-router.html">Query Router</a></td><td>VAULT command execution</td></tr>
<tr><td><a href="architecture/neumann-shell.html">Neumann Shell</a></td><td>Interactive vault commands</td></tr>
</tbody></table>
</div>
<h2 id="dependencies-4"><a class="header" href="#dependencies-4">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>aes-gcm</code></td><td>AES-256-GCM encryption</td></tr>
<tr><td><code>argon2</code></td><td>Key derivation</td></tr>
<tr><td><code>hkdf</code></td><td>Subkey derivation</td></tr>
<tr><td><code>blake2</code></td><td>HMAC and obfuscation hashing</td></tr>
<tr><td><code>rand</code></td><td>Nonce generation</td></tr>
<tr><td><code>zeroize</code></td><td>Secure memory cleanup</td></tr>
<tr><td><code>dashmap</code></td><td>Concurrent rate limit tracking</td></tr>
<tr><td><code>serde</code></td><td>TTL grant persistence</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-cache-architecture"><a class="header" href="#tensor-cache-architecture">Tensor Cache Architecture</a></h1>
<p>Semantic caching for LLM responses with cost tracking and background eviction.
Module 10 of Neumann.</p>
<p>The tensor_cache module provides multi-layer caching optimized for LLM
workloads. It combines O(1) exact hash lookups with O(log n) semantic similarity
search via HNSW indices. All cache entries are stored as <code>TensorData</code> in a
shared <code>TensorStore</code>, following the tensor-native paradigm used by
<code>tensor_vault</code> and <code>tensor_blob</code>.</p>
<h2 id="design-principles-4"><a class="header" href="#design-principles-4">Design Principles</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Principle</th><th>Description</th></tr></thead><tbody>
<tr><td>Multi-Layer Caching</td><td>Exact O(1), Semantic O(log n), Embedding O(1) lookups</td></tr>
<tr><td>Cost-Aware</td><td>Tracks tokens and estimates savings using tiktoken</td></tr>
<tr><td>Background Eviction</td><td>Async eviction with configurable strategies</td></tr>
<tr><td>TTL Expiration</td><td>Time-based entry expiration with min-heap tracking</td></tr>
<tr><td>Thread-Safe</td><td>All operations are concurrent via DashMap</td></tr>
<tr><td>Zero Allocation Lookup</td><td>Embeddings stored inline, not as pointers</td></tr>
<tr><td>Sparse-Aware</td><td>Automatic sparse storage for vectors with &gt;50% zeros</td></tr>
</tbody></table>
</div>
<h2 id="key-types-6"><a class="header" href="#key-types-6">Key Types</a></h2>
<h3 id="core-types-3"><a class="header" href="#core-types-3">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Cache</code></td><td>Main API - multi-layer LLM response cache</td></tr>
<tr><td><code>CacheConfig</code></td><td>Configuration (capacity, TTL, eviction, metrics)</td></tr>
<tr><td><code>CacheHit</code></td><td>Successful cache lookup result</td></tr>
<tr><td><code>CacheStats</code></td><td>Thread-safe statistics with atomic counters</td></tr>
<tr><td><code>StatsSnapshot</code></td><td>Point-in-time snapshot for reporting</td></tr>
<tr><td><code>CacheLayer</code></td><td>Enum: <code>Exact</code>, <code>Semantic</code>, <code>Embedding</code></td></tr>
<tr><td><code>CacheError</code></td><td>Error types for cache operations</td></tr>
</tbody></table>
</div>
<h3 id="configuration-types"><a class="header" href="#configuration-types">Configuration Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>EvictionStrategy</code></td><td><code>LRU</code>, <code>LFU</code>, <code>CostBased</code>, <code>Hybrid</code></td></tr>
<tr><td><code>EvictionManager</code></td><td>Background eviction task controller</td></tr>
<tr><td><code>EvictionScorer</code></td><td>Calculates eviction priority scores</td></tr>
<tr><td><code>EvictionHandle</code></td><td>Handle for controlling background eviction</td></tr>
<tr><td><code>EvictionConfig</code></td><td>Interval, batch size, and strategy settings</td></tr>
</tbody></table>
</div>
<h3 id="token-counting"><a class="header" href="#token-counting">Token Counting</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TokenCounter</code></td><td>GPT-4 compatible token counting via tiktoken</td></tr>
<tr><td><code>ModelPricing</code></td><td>Predefined pricing for GPT-4, Claude 3, etc.</td></tr>
</tbody></table>
</div>
<h3 id="index-types-internal"><a class="header" href="#index-types-internal">Index Types (Internal)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>CacheIndex</code></td><td>HNSW wrapper with key-to-node mapping</td></tr>
<tr><td><code>IndexSearchResult</code></td><td>Semantic search result with similarity score</td></tr>
</tbody></table>
</div>
<h2 id="architecture-diagram-1"><a class="header" href="#architecture-diagram-1">Architecture Diagram</a></h2>
<pre><code class="language-text">+--------------------------------------------------+
|                  Cache (Public API)               |
|   - get(prompt, embedding) -&gt; CacheHit           |
|   - put(prompt, embedding, response, ...)        |
|   - stats(), evict(), clear()                    |
+--------------------------------------------------+
            |           |           |
    +-------+    +------+    +------+
    |            |           |
+--------+  +----------+  +-----------+
| Exact  |  | Semantic |  | Embedding |
| Cache  |  |  Cache   |  |   Cache   |
| O(1)   |  | O(log n) |  |   O(1)    |
+--------+  +----------+  +-----------+
    |            |           |
    +-------+----+----+------+
            |
    +------------------+
    |   CacheIndex     |
    |  (HNSW wrapper)  |
    +------------------+
            |
    +------------------+
    |   tensor_store   |
    |     hnsw.rs      |
    +------------------+
</code></pre>
<h2 id="multi-layer-cache-lookup-algorithm"><a class="header" href="#multi-layer-cache-lookup-algorithm">Multi-Layer Cache Lookup Algorithm</a></h2>
<p>The cache lookup algorithm is designed to maximize hit rates while minimizing
latency. It follows a hierarchical approach, checking faster layers first before
falling back to more expensive operations.</p>
<h3 id="lookup-flow-diagram"><a class="header" href="#lookup-flow-diagram">Lookup Flow Diagram</a></h3>
<pre class="mermaid">flowchart TD
    A[get prompt, embedding] --&gt; B{Exact Cache Hit?}
    B --&gt;|Yes| C[Return CacheHit layer=Exact]
    B --&gt;|No| D[Record Exact Miss]
    D --&gt; E{Embedding Provided?}
    E --&gt;|No| F[Return None]
    E --&gt;|Yes| G{Auto-Select Metric?}
    G --&gt;|Yes| H{Sparsity &gt;= Threshold?}
    G --&gt;|No| I[Use Configured Metric]
    H --&gt;|Yes| J[Use Jaccard]
    H --&gt;|No| I
    J --&gt; K[HNSW Search with Metric]
    I --&gt; K
    K --&gt; L{Results Above Threshold?}
    L --&gt;|No| M[Record Semantic Miss]
    M --&gt; F
    L --&gt;|Yes| N{Entry Expired?}
    N --&gt;|Yes| M
    N --&gt;|No| O[Return CacheHit layer=Semantic]
</pre>
<h3 id="exact-cache-lookup-o1"><a class="header" href="#exact-cache-lookup-o1">Exact Cache Lookup (O(1))</a></h3>
<p>The exact cache uses a hash-based key derived from the prompt text:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Key generation using DefaultHasher
fn exact_key(prompt: &amp;str) -&gt; String {
    let mut hasher = DefaultHasher::new();
    prompt.hash(&amp;mut hasher);
    let hash = hasher.finish();
    format!("_cache:exact:{:016x}", hash)
}
<span class="boring">}</span></code></pre></pre>
<p>The lookup sequence:</p>
<ol>
<li>Generate hash key from prompt</li>
<li>Query <code>TensorStore</code> with key</li>
<li>Check expiration timestamp</li>
<li>Return hit or proceed to semantic lookup</li>
</ol>
<h3 id="semantic-cache-lookup-olog-n"><a class="header" href="#semantic-cache-lookup-olog-n">Semantic Cache Lookup (O(log n))</a></h3>
<p>The semantic cache uses HNSW (Hierarchical Navigable Small World) graphs for
approximate nearest neighbor search:</p>
<pre class="mermaid">flowchart LR
    A[Query Vector] --&gt; B[HNSW Entry Point]
    B --&gt; C[Layer 2: Coarse Search]
    C --&gt; D[Layer 1: Refined Search]
    D --&gt; E[Layer 0: Fine Search]
    E --&gt; F[Top-k Candidates]
    F --&gt; G[Re-score with Metric]
    G --&gt; H[Filter by Threshold]
    H --&gt; I[Return Best Match]
</pre>
<p><strong>Re-scoring Strategy</strong>: The HNSW index retrieves candidates using cosine
similarity, then re-scores them with the requested metric. This allows using
different metrics without rebuilding the index:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Retrieve more candidates than needed for re-scoring
let ef = (k * 3).max(10);
let candidates = index.search(query, ef);

// Re-score with specified metric
let similarity = match &amp;embedding {
    EmbeddingStorage::Dense(dense) =&gt; {
        let stored_sparse = SparseVector::from_dense(dense);
        let raw = metric.compute(&amp;query_sparse, &amp;stored_sparse);
        metric.to_similarity(raw)
    }
    EmbeddingStorage::Sparse(sparse) =&gt; {
        let raw = metric.compute(&amp;query_sparse, sparse);
        metric.to_similarity(raw)
    }
    // ...handles Delta and TensorTrain storage types
};
<span class="boring">}</span></code></pre></pre>
<h3 id="automatic-metric-selection"><a class="header" href="#automatic-metric-selection">Automatic Metric Selection</a></h3>
<p>When <code>auto_select_metric</code> is enabled, the cache automatically selects the
optimal distance metric based on embedding sparsity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn select_metric(&amp;self, embedding: &amp;[f32]) -&gt; DistanceMetric {
    if !self.config.auto_select_metric {
        return self.config.distance_metric.clone();
    }

    let sparse = SparseVector::from_dense(embedding);
    if sparse.sparsity() &gt;= self.config.sparsity_metric_threshold {
        DistanceMetric::Jaccard  // Better for sparse vectors
    } else {
        self.config.distance_metric.clone()  // Default (usually Cosine)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cache-layers"><a class="header" href="#cache-layers">Cache Layers</a></h2>
<h3 id="exact-cache-o1"><a class="header" href="#exact-cache-o1">Exact Cache (O(1))</a></h3>
<p>Hash-based lookup for identical queries. Keys are generated from prompt text
using <code>DefaultHasher</code>. Stored with prefix <code>_cache:exact:</code>.</p>
<p><strong>When to use</strong>: Repetitive queries with exact same prompts (e.g., FAQ systems,
chatbots with canned responses).</p>
<h3 id="semantic-cache-olog-n"><a class="header" href="#semantic-cache-olog-n">Semantic Cache (O(log n))</a></h3>
<p>HNSW-based similarity search for semantically similar queries. Uses configurable
distance metrics (Cosine, Jaccard, Euclidean, Angular). Stored with prefix
<code>_cache:sem:</code>.</p>
<p><strong>When to use</strong>: Natural language queries with variations (e.g., “What’s the
weather?” vs “How’s the weather today?”).</p>
<h3 id="embedding-cache-o1"><a class="header" href="#embedding-cache-o1">Embedding Cache (O(1))</a></h3>
<p>Stores precomputed embeddings to avoid redundant embedding API calls. Keys
combine source and content hash. Stored with prefix <code>_cache:emb:</code>.</p>
<p><strong>When to use</strong>: When embedding computation is expensive and the same content is
embedded multiple times.</p>
<h2 id="storage-format-1"><a class="header" href="#storage-format-1">Storage Format</a></h2>
<p>Cache entries are stored as <code>TensorData</code> with standardized fields:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>_response</code></td><td>String</td><td>Cached response text</td></tr>
<tr><td><code>_embedding</code></td><td>Vector/Sparse</td><td>Embedding (semantic/embedding layers)</td></tr>
<tr><td><code>_embedding_dim</code></td><td>Int</td><td>Embedding dimension</td></tr>
<tr><td><code>_input_tokens</code></td><td>Int</td><td>Input token count</td></tr>
<tr><td><code>_output_tokens</code></td><td>Int</td><td>Output token count</td></tr>
<tr><td><code>_model</code></td><td>String</td><td>Model identifier</td></tr>
<tr><td><code>_layer</code></td><td>String</td><td>Cache layer (exact/semantic/embedding)</td></tr>
<tr><td><code>_created_at</code></td><td>Int</td><td>Creation timestamp (millis)</td></tr>
<tr><td><code>_expires_at</code></td><td>Int</td><td>Expiration timestamp (millis)</td></tr>
<tr><td><code>_access_count</code></td><td>Int</td><td>Access count for LFU</td></tr>
<tr><td><code>_last_access</code></td><td>Int</td><td>Last access timestamp for LRU</td></tr>
<tr><td><code>_version</code></td><td>String</td><td>Optional version tag</td></tr>
<tr><td><code>_source</code></td><td>String</td><td>Embedding source identifier</td></tr>
<tr><td><code>_content_hash</code></td><td>Int</td><td>Content hash for deduplication</td></tr>
</tbody></table>
</div>
<h3 id="sparse-storage-optimization"><a class="header" href="#sparse-storage-optimization">Sparse Storage Optimization</a></h3>
<p>Embeddings with high sparsity (&gt;50% zeros) are automatically stored in sparse
format to reduce memory usage:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn should_use_sparse(vector: &amp;[f32]) -&gt; bool {
    if vector.is_empty() {
        return false;
    }
    let nnz = vector.iter().filter(|&amp;&amp;v| v.abs() &gt; 1e-6).count();
    // Use sparse if non-zero count &lt;= half of total length
    nnz * 2 &lt;= vector.len()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="distance-metrics-2"><a class="header" href="#distance-metrics-2">Distance Metrics</a></h2>
<p>Configurable distance metrics for semantic similarity:</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Best For</th><th>Range</th><th>Formula</th></tr></thead><tbody>
<tr><td>Cosine</td><td>Dense embeddings (default)</td><td>[-1, 1]</td><td><code>dot(a,b) / (‖a‖ * ‖b‖)</code></td></tr>
<tr><td>Angular</td><td>Linear angle relationships</td><td>[0, PI]</td><td><code>acos(cosine_sim)</code></td></tr>
<tr><td>Jaccard</td><td>Sparse/binary embeddings</td><td>[0, 1]</td><td><code>‖A ∩ B‖ / ‖A ∪ B‖</code></td></tr>
<tr><td>Euclidean</td><td>Absolute distances</td><td>[0, inf)</td><td><code>sqrt(sum((a-b)^2))</code></td></tr>
<tr><td>WeightedJaccard</td><td>Sparse with magnitudes</td><td>[0, 1]</td><td>Weighted set similarity</td></tr>
</tbody></table>
</div>
<p><strong>Auto-selection</strong>: When <code>auto_select_metric</code> is true, the cache automatically
selects Jaccard for sparse embeddings (sparsity &gt;= threshold, default 70%) and
the configured metric otherwise.</p>
<h2 id="eviction-strategies"><a class="header" href="#eviction-strategies">Eviction Strategies</a></h2>
<h3 id="strategy-comparison"><a class="header" href="#strategy-comparison">Strategy Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>Description</th><th>Score Formula</th><th>Best For</th></tr></thead><tbody>
<tr><td>LRU</td><td>Evicts entries that haven’t been accessed recently</td><td><code>-last_access_secs</code></td><td>General purpose</td></tr>
<tr><td>LFU</td><td>Evicts entries with lowest access count</td><td><code>access_count</code></td><td>Stable workloads</td></tr>
<tr><td>CostBased</td><td>Evicts entries with lowest cost savings per byte</td><td><code>cost_per_hit / size_bytes</code></td><td>Cost optimization</td></tr>
<tr><td>Hybrid</td><td>Combines all strategies with configurable weights</td><td>Weighted combination</td><td>Production systems</td></tr>
</tbody></table>
</div>
<h3 id="hybrid-eviction-score-algorithm"><a class="header" href="#hybrid-eviction-score-algorithm">Hybrid Eviction Score Algorithm</a></h3>
<p>The Hybrid strategy combines recency, frequency, and cost factors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn score(
    &amp;self,
    last_access_secs: f64,
    access_count: u64,
    cost_per_hit: f64,
    size_bytes: usize,
) -&gt; f64 {
    match self.strategy {
        EvictionStrategy::LRU =&gt; -last_access_secs,
        EvictionStrategy::LFU =&gt; access_count as f64,
        EvictionStrategy::CostBased =&gt; {
            if size_bytes == 0 { 0.0 }
            else { cost_per_hit / size_bytes as f64 }
        }
        EvictionStrategy::Hybrid { lru_weight, lfu_weight, cost_weight } =&gt; {
            let total = f64::from(lru_weight) + f64::from(lfu_weight) + f64::from(cost_weight);
            let recency_w = f64::from(lru_weight) / total;
            let frequency_w = f64::from(lfu_weight) / total;
            let cost_w = f64::from(cost_weight) / total;

            let age_minutes = last_access_secs / 60.0;
            let recency_score = 1.0 / (1.0 + age_minutes);    // Decays with age
            let frequency_score = (1.0 + access_count as f64).log2();  // Log scale
            let cost_score = cost_per_hit;

            recency_score * recency_w + frequency_score * frequency_w + cost_score * cost_w
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Lower scores are evicted first</strong>. The hybrid formula:</p>
<ul>
<li><code>recency_score</code>: Decays as <code>1/(1 + age_in_minutes)</code> - newer entries score
higher</li>
<li><code>frequency_score</code>: Grows logarithmically with access count - frequently
accessed entries score higher</li>
<li><code>cost_score</code>: Direct cost per hit - higher cost savings score higher</li>
</ul>
<h3 id="background-eviction-flow"><a class="header" href="#background-eviction-flow">Background Eviction Flow</a></h3>
<pre class="mermaid">flowchart TD
    A[EvictionManager::start] --&gt; B[Spawn Tokio Task]
    B --&gt; C[Initialize Interval Timer]
    C --&gt; D{Select Event}
    D --&gt;|Timer Tick| E[Call evict_fn batch_size]
    D --&gt;|Shutdown Signal| F[Set running=false]
    E --&gt; G{Evicted &gt; 0?}
    G --&gt;|Yes| H[Record Eviction Stats]
    G --&gt;|No| D
    H --&gt; D
    F --&gt; I[Break Loop]
</pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Starting background eviction
let handle = manager.start(move |batch_size| {
    cache.evict(batch_size)
});

// Later: graceful shutdown
handle.shutdown().await;
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-5"><a class="header" href="#configuration-5">Configuration</a></h2>
<h3 id="default-configuration"><a class="header" href="#default-configuration">Default Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>CacheConfig {
    exact_capacity: 10_000,
    semantic_capacity: 5_000,
    embedding_capacity: 50_000,
    default_ttl: Duration::from_secs(3600),
    max_ttl: Duration::from_secs(86400),
    semantic_threshold: 0.92,
    embedding_dim: 1536,
    eviction_strategy: EvictionStrategy::Hybrid {
        lru_weight: 40,
        lfu_weight: 30,
        cost_weight: 30
    },
    eviction_interval: Duration::from_secs(60),
    eviction_batch_size: 100,
    input_cost_per_1k: 0.0015,
    output_cost_per_1k: 0.002,
    inline_threshold: 4096,
    distance_metric: DistanceMetric::Cosine,
    auto_select_metric: true,
    sparsity_metric_threshold: 0.7,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-presets-2"><a class="header" href="#configuration-presets-2">Configuration Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>Use Case</th><th>Exact Capacity</th><th>Semantic Capacity</th><th>Embedding Capacity</th><th>Eviction Batch</th></tr></thead><tbody>
<tr><td><code>default()</code></td><td>General purpose</td><td>10,000</td><td>5,000</td><td>50,000</td><td>100</td></tr>
<tr><td><code>high_throughput()</code></td><td>High-traffic server</td><td>50,000</td><td>20,000</td><td>100,000</td><td>500</td></tr>
<tr><td><code>low_memory()</code></td><td>Memory-constrained</td><td>1,000</td><td>500</td><td>5,000</td><td>50</td></tr>
<tr><td><code>development()</code></td><td>Dev/testing</td><td>100</td><td>50</td><td>200</td><td>10</td></tr>
<tr><td><code>sparse_embeddings()</code></td><td>Sparse vectors</td><td>10,000</td><td>5,000</td><td>50,000</td><td>100</td></tr>
</tbody></table>
</div>
<h3 id="configuration-validation"><a class="header" href="#configuration-validation">Configuration Validation</a></h3>
<p>The config validates on cache creation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn validate(&amp;self) -&gt; Result&lt;(), String&gt; {
    if self.semantic_threshold &lt; 0.0 || self.semantic_threshold &gt; 1.0 {
        return Err("semantic_threshold must be between 0.0 and 1.0");
    }
    if self.embedding_dim == 0 {
        return Err("embedding_dim must be greater than 0");
    }
    if self.eviction_batch_size == 0 {
        return Err("eviction_batch_size must be greater than 0");
    }
    if self.default_ttl &gt; self.max_ttl {
        return Err("default_ttl cannot exceed max_ttl");
    }
    if self.sparsity_metric_threshold &lt; 0.0 || self.sparsity_metric_threshold &gt; 1.0 {
        return Err("sparsity_metric_threshold must be between 0.0 and 1.0");
    }
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples-5"><a class="header" href="#usage-examples-5">Usage Examples</a></h2>
<h3 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_cache::{Cache, CacheConfig};

let mut config = CacheConfig::default();
config.embedding_dim = 3;
let cache = Cache::with_config(config).unwrap();

// Store a response
let embedding = vec![0.1, 0.2, 0.3];
cache.put("What is 2+2?", &amp;embedding, "4", "gpt-4", None).unwrap();

// Look up (tries exact first, then semantic)
if let Some(hit) = cache.get("What is 2+2?", Some(&amp;embedding)) {
    println!("Cached: {}", hit.response);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="explicit-metric-queries"><a class="header" href="#explicit-metric-queries">Explicit Metric Queries</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_cache::DistanceMetric;

let hit = cache.get_with_metric(
    "query",
    Some(&amp;embedding),
    Some(&amp;DistanceMetric::Euclidean),
);

if let Some(hit) = hit {
    println!("Metric used: {:?}", hit.metric_used);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="embedding-cache-with-compute-fallback"><a class="header" href="#embedding-cache-with-compute-fallback">Embedding Cache with Compute Fallback</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get cached embedding or compute on miss
let embedding = cache.get_or_compute_embedding(
    "openai",           // source
    "Hello, world!",    // content
    "text-embedding-3-small",  // model
    || {
        // Compute function called only on cache miss
        Ok(compute_embedding("Hello, world!"))
    }
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="token-counting-and-cost-estimation"><a class="header" href="#token-counting-and-cost-estimation">Token Counting and Cost Estimation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_cache::{TokenCounter, ModelPricing};

// Count tokens in text
let tokens = TokenCounter::count("Hello, world!");

// Count tokens in chat messages (includes overhead)
let messages = vec![("user", "Hello"), ("assistant", "Hi there!")];
let total = TokenCounter::count_messages(&amp;messages);

// Estimate cost with custom rates
let cost = TokenCounter::estimate_cost(1000, 500, 0.01, 0.03);

// Use predefined model pricing
let pricing = ModelPricing::GPT4O;
let cost = pricing.estimate(1000, 500);

// Lookup pricing by model name
if let Some(pricing) = ModelPricing::for_model("gpt-4o-mini") {
    println!("Cost: ${:.4}", pricing.estimate(1000, 500));
}
<span class="boring">}</span></code></pre></pre>
<h3 id="statistics-and-monitoring"><a class="header" href="#statistics-and-monitoring">Statistics and Monitoring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let stats = cache.stats_snapshot();

// Hit rates by layer
println!("Exact hit rate: {:.2}%", stats.hit_rate(CacheLayer::Exact) * 100.0);
println!("Semantic hit rate: {:.2}%", stats.hit_rate(CacheLayer::Semantic) * 100.0);

// Tokens and cost saved
println!("Input tokens saved: {}", stats.tokens_saved_in);
println!("Output tokens saved: {}", stats.tokens_saved_out);
println!("Cost saved: ${:.2}", stats.cost_saved_dollars);

// Cache utilization
println!("Total entries: {}", stats.total_entries());
println!("Evictions: {}", stats.evictions);
println!("Expirations: {}", stats.expirations);
println!("Uptime: {} seconds", stats.uptime_secs);
<span class="boring">}</span></code></pre></pre>
<h3 id="shared-tensorstore-integration"><a class="header" href="#shared-tensorstore-integration">Shared TensorStore Integration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::TensorStore;
use tensor_cache::{Cache, CacheConfig};

// Share store with other engines
let store = TensorStore::new();
let cache = Cache::with_store(store.clone(), CacheConfig::default())?;

// Other engines can use the same store
let vault = Vault::with_store(store.clone(), VaultConfig::default())?;
<span class="boring">}</span></code></pre></pre>
<h2 id="token-counting-implementation"><a class="header" href="#token-counting-implementation">Token Counting Implementation</a></h2>
<p>The <code>TokenCounter</code> uses tiktoken’s <code>cl100k_base</code> encoding, which is compatible
with GPT-4, GPT-3.5-turbo, and text-embedding-ada-002.</p>
<h3 id="lazy-encoder-initialization"><a class="header" href="#lazy-encoder-initialization">Lazy Encoder Initialization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>static CL100K_ENCODER: OnceLock&lt;Option&lt;CoreBPE&gt;&gt; = OnceLock::new();

impl TokenCounter {
    fn encoder() -&gt; Option&lt;&amp;'static CoreBPE&gt; {
        CL100K_ENCODER
            .get_or_init(|| tiktoken_rs::cl100k_base().ok())
            .as_ref()
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="fallback-estimation"><a class="header" href="#fallback-estimation">Fallback Estimation</a></h3>
<p>If tiktoken is unavailable, falls back to character-based estimation (~4 chars
per token for English text):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const fn estimate_tokens(text: &amp;str) -&gt; usize {
    text.len().div_ceil(4)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="message-token-counting"><a class="header" href="#message-token-counting">Message Token Counting</a></h3>
<p>Chat messages include overhead tokens per message (role markers, separators):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn count_message(role: &amp;str, content: &amp;str) -&gt; usize {
    Self::encoder().map_or_else(
        || Self::estimate_tokens(role) + Self::estimate_tokens(content) + 4,
        |enc| {
            let role_tokens = enc.encode_ordinary(role).len();
            let content_tokens = enc.encode_ordinary(content).len();
            role_tokens + content_tokens + 4  // 4 tokens overhead per message
        },
    )
}

pub fn count_messages(messages: &amp;[(&amp;str, &amp;str)]) -&gt; usize {
    let mut total = 0;
    for (role, content) in messages {
        total += Self::count_message(role, content);
    }
    total + 3  // 3 tokens for assistant reply priming
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cost-calculation-formulas"><a class="header" href="#cost-calculation-formulas">Cost Calculation Formulas</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Basic cost calculation
pub fn estimate_cost(
    input_tokens: usize,
    output_tokens: usize,
    input_rate: f64,   // $/1000 tokens
    output_rate: f64,  // $/1000 tokens
) -&gt; f64 {
    (input_tokens as f64 / 1000.0) * input_rate +
    (output_tokens as f64 / 1000.0) * output_rate
}

// For atomic operations (avoids floating point accumulation errors)
pub fn estimate_cost_microdollars(...) -&gt; u64 {
    let dollars = Self::estimate_cost(...);
    (dollars * 1_000_000.0) as u64
}
<span class="boring">}</span></code></pre></pre>
<h2 id="model-pricing"><a class="header" href="#model-pricing">Model Pricing</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Model</th><th>Input/1K</th><th>Output/1K</th><th>Notes</th></tr></thead><tbody>
<tr><td>GPT-4o</td><td>$0.005</td><td>$0.015</td><td>Best for complex tasks</td></tr>
<tr><td>GPT-4o mini</td><td>$0.00015</td><td>$0.0006</td><td>Cost-effective</td></tr>
<tr><td>GPT-4 Turbo</td><td>$0.01</td><td>$0.03</td><td>High capability</td></tr>
<tr><td>GPT-3.5 Turbo</td><td>$0.0005</td><td>$0.0015</td><td>Budget option</td></tr>
<tr><td>Claude 3 Opus</td><td>$0.015</td><td>$0.075</td><td>Highest quality</td></tr>
<tr><td>Claude 3 Sonnet</td><td>$0.003</td><td>$0.015</td><td>Balanced</td></tr>
<tr><td>Claude 3 Haiku</td><td>$0.00025</td><td>$0.00125</td><td>Fast and cheap</td></tr>
</tbody></table>
</div>
<h3 id="model-name-matching"><a class="header" href="#model-name-matching">Model Name Matching</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn for_model(model: &amp;str) -&gt; Option&lt;Self&gt; {
    let model_lower = model.to_lowercase();
    if model_lower.contains("gpt-4o-mini") {
        Some(Self::GPT4O_MINI)
    } else if model_lower.contains("gpt-4o") {
        Some(Self::GPT4O)
    } else if model_lower.contains("gpt-4-turbo") {
        Some(Self::GPT4_TURBO)
    } else if model_lower.contains("gpt-3.5") {
        Some(Self::GPT35_TURBO)
    } else if model_lower.contains("claude-3-opus") || model_lower.contains("claude-opus") {
        Some(Self::CLAUDE3_OPUS)
    } else if model_lower.contains("claude-3-sonnet") || model_lower.contains("claude-sonnet") {
        Some(Self::CLAUDE3_SONNET)
    } else if model_lower.contains("claude-3-haiku") || model_lower.contains("claude-haiku") {
        Some(Self::CLAUDE3_HAIKU)
    } else {
        None
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="semantic-search-index-internals"><a class="header" href="#semantic-search-index-internals">Semantic Search Index Internals</a></h2>
<h3 id="cacheindex-structure"><a class="header" href="#cacheindex-structure">CacheIndex Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CacheIndex {
    index: RwLock&lt;HNSWIndex&gt;,           // HNSW graph
    config: HNSWConfig,                  // For recreation on clear
    key_to_node: DashMap&lt;String, usize&gt;, // Cache key -&gt; HNSW node
    node_to_key: DashMap&lt;usize, String&gt;, // HNSW node -&gt; Cache key
    dimension: usize,                    // Expected embedding dimension
    entry_count: AtomicUsize,            // Entry count
    distance_metric: DistanceMetric,     // Default metric
}
<span class="boring">}</span></code></pre></pre>
<h3 id="insert-strategies"><a class="header" href="#insert-strategies">Insert Strategies</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Dense embedding insert
pub fn insert(&amp;self, key: &amp;str, embedding: &amp;[f32]) -&gt; Result&lt;usize&gt;;

// Sparse embedding insert (memory efficient)
pub fn insert_sparse(&amp;self, key: &amp;str, embedding: &amp;SparseVector) -&gt; Result&lt;usize&gt;;

// Auto-select based on sparsity threshold
pub fn insert_auto(
    &amp;self,
    key: &amp;str,
    embedding: &amp;[f32],
    sparsity_threshold: f32,
) -&gt; Result&lt;usize&gt;;
<span class="boring">}</span></code></pre></pre>
<h3 id="key-orphaning-on-re-insert"><a class="header" href="#key-orphaning-on-re-insert">Key Orphaning on Re-insert</a></h3>
<p>When a key is re-inserted, the old HNSW node is orphaned (not deleted) because
HNSW doesn’t support efficient deletion:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let is_new = !self.key_to_node.contains_key(key);
if !is_new {
    // Remove mapping but leave HNSW node (will be ignored in search)
    self.key_to_node.remove(key);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-statistics"><a class="header" href="#memory-statistics">Memory Statistics</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn memory_stats(&amp;self) -&gt; Option&lt;HNSWMemoryStats&gt; {
    self.index.read().ok().map(|index| index.memory_stats())
}
// Returns: dense_count, sparse_count, delta_count, embedding_bytes, etc.
<span class="boring">}</span></code></pre></pre>
<h2 id="error-types-4"><a class="header" href="#error-types-4">Error Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Description</th><th>Recovery</th></tr></thead><tbody>
<tr><td><code>NotFound</code></td><td>Cache entry not found</td><td>Check key exists</td></tr>
<tr><td><code>DimensionMismatch</code></td><td>Embedding dimension does not match config</td><td>Verify embedding size</td></tr>
<tr><td><code>StorageError</code></td><td>Underlying tensor store error</td><td>Check store health</td></tr>
<tr><td><code>SerializationError</code></td><td>Serialization/deserialization failed</td><td>Verify data format</td></tr>
<tr><td><code>TokenizerError</code></td><td>Token counting failed</td><td>Falls back to estimation</td></tr>
<tr><td><code>CacheFull</code></td><td>Cache capacity exceeded</td><td>Run eviction or increase capacity</td></tr>
<tr><td><code>InvalidConfig</code></td><td>Invalid configuration provided</td><td>Fix config values</td></tr>
<tr><td><code>Cancelled</code></td><td>Operation was cancelled</td><td>Retry operation</td></tr>
<tr><td><code>LockPoisoned</code></td><td>Internal lock was poisoned</td><td>Restart cache</td></tr>
</tbody></table>
</div>
<h3 id="error-conversion"><a class="header" href="#error-conversion">Error Conversion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl From&lt;tensor_store::TensorStoreError&gt; for CacheError {
    fn from(e: TensorStoreError) -&gt; Self {
        Self::StorageError(e.to_string())
    }
}

impl From&lt;bincode::Error&gt; for CacheError {
    fn from(e: bincode::Error) -&gt; Self {
        Self::SerializationError(e.to_string())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-2"><a class="header" href="#performance-2">Performance</a></h2>
<h3 id="benchmarks-10000-entries-128-dim-embeddings"><a class="header" href="#benchmarks-10000-entries-128-dim-embeddings">Benchmarks (10,000 entries, 128-dim embeddings)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>Exact lookup (hit)</td><td>~50ns</td><td>Hash lookup + TensorStore get</td></tr>
<tr><td>Exact lookup (miss)</td><td>~30ns</td><td>Hash lookup only</td></tr>
<tr><td>Semantic lookup</td><td>~5us</td><td>HNSW search + re-scoring</td></tr>
<tr><td>Put (exact + semantic)</td><td>~10us</td><td>Two stores + HNSW insert</td></tr>
<tr><td>Eviction (100 entries)</td><td>~200us</td><td>Batch deletion</td></tr>
<tr><td>Clear (full index)</td><td>~1ms</td><td>HNSW recreation</td></tr>
</tbody></table>
</div>
<h3 id="distance-metric-performance-128-dim-1000-entries"><a class="header" href="#distance-metric-performance-128-dim-1000-entries">Distance Metric Performance (128-dim, 1000 entries)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Search Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>Cosine</td><td>21 us</td><td>Default, best for dense</td></tr>
<tr><td>Jaccard</td><td>18 us</td><td>Best for sparse</td></tr>
<tr><td>Angular</td><td>23 us</td><td>+acos overhead</td></tr>
<tr><td>Euclidean</td><td>19 us</td><td>Absolute distance</td></tr>
</tbody></table>
</div>
<h3 id="auto-selection-overhead"><a class="header" href="#auto-selection-overhead">Auto-Selection Overhead</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>Sparsity check</td><td>~50 ns</td></tr>
<tr><td>Metric selection</td><td>~10 ns</td></tr>
</tbody></table>
</div>
<h3 id="memory-efficiency-2"><a class="header" href="#memory-efficiency-2">Memory Efficiency</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Storage Type</th><th>Memory per Entry</th><th>Best For</th></tr></thead><tbody>
<tr><td>Dense Vector</td><td>4 * dim bytes</td><td>Low sparsity (&lt;50% zeros)</td></tr>
<tr><td>Sparse Vector</td><td>8 * nnz bytes</td><td>High sparsity (&gt;50% zeros)</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas-6"><a class="header" href="#edge-cases-and-gotchas-6">Edge Cases and Gotchas</a></h2>
<h3 id="ttl-behavior"><a class="header" href="#ttl-behavior">TTL Behavior</a></h3>
<ul>
<li>Entries with <code>expires_at = 0</code> never expire</li>
<li>Expired entries return <code>None</code> on lookup but remain in storage until cleanup</li>
<li><code>cleanup_expired()</code> must be called explicitly or via background eviction</li>
</ul>
<h3 id="capacity-limits"><a class="header" href="#capacity-limits">Capacity Limits</a></h3>
<ul>
<li><code>put()</code> fails with <code>CacheFull</code> when capacity is reached</li>
<li>Capacity is checked per-layer (exact, semantic, embedding)</li>
<li>No automatic eviction on put - must be explicit</li>
</ul>
<h3 id="hash-collisions"><a class="header" href="#hash-collisions">Hash Collisions</a></h3>
<ul>
<li>Extremely unlikely with 64-bit hashes (~1 in 18 quintillion)</li>
<li>If collision occurs, exact cache will return wrong response</li>
<li>Semantic cache provides fallback for semantically different queries</li>
</ul>
<h3 id="metric-re-scoring"><a class="header" href="#metric-re-scoring">Metric Re-scoring</a></h3>
<ul>
<li>HNSW always uses cosine similarity for graph navigation</li>
<li>Re-scoring with different metrics may change result order</li>
<li>Retrieves 3x candidates to account for re-ranking</li>
</ul>
<h3 id="sparse-storage-threshold"><a class="header" href="#sparse-storage-threshold">Sparse Storage Threshold</a></h3>
<ul>
<li>Uses sparse format when <code>nnz * 2 &lt;= len</code> (50% zeros)</li>
<li>Different from auto-metric selection threshold (default 70%)</li>
<li>Both thresholds are configurable</li>
</ul>
<h2 id="performance-tips-and-best-practices-1"><a class="header" href="#performance-tips-and-best-practices-1">Performance Tips and Best Practices</a></h2>
<h3 id="configuration-tuning"><a class="header" href="#configuration-tuning">Configuration Tuning</a></h3>
<ol>
<li><strong>Semantic Threshold</strong>: Start with 0.92, lower to 0.85 for fuzzy matching</li>
<li><strong>Eviction Weights</strong>: Increase <code>cost_weight</code> if API costs matter most</li>
<li><strong>Batch Size</strong>: Larger batches (500+) for high-throughput systems</li>
<li><strong>TTL</strong>: Match to your content freshness requirements</li>
</ol>
<h3 id="memory-optimization-1"><a class="header" href="#memory-optimization-1">Memory Optimization</a></h3>
<ol>
<li>Use <code>sparse_embeddings()</code> preset for sparse data</li>
<li>Set <code>inline_threshold</code> based on typical response sizes</li>
<li>Enable <code>auto_select_metric</code> for mixed workloads</li>
<li>Monitor <code>memory_stats()</code> to track sparse vs dense ratio</li>
</ol>
<h3 id="hit-rate-optimization"><a class="header" href="#hit-rate-optimization">Hit Rate Optimization</a></h3>
<ol>
<li>Normalize prompts before caching (lowercase, trim whitespace)</li>
<li>Use versioning for model/prompt template changes</li>
<li>Set appropriate semantic threshold for your domain</li>
<li>Consider domain-specific embeddings</li>
</ol>
<h3 id="cost-tracking"><a class="header" href="#cost-tracking">Cost Tracking</a></h3>
<ol>
<li>Use <code>estimate_cost_microdollars()</code> for atomic accumulation</li>
<li>Record cost per cache hit for ROI analysis</li>
<li>Compare <code>tokens_saved</code> against capacity costs</li>
</ol>
<h2 id="shell-commands-1"><a class="header" href="#shell-commands-1">Shell Commands</a></h2>
<pre><code class="language-text">CACHE INIT     Initialize semantic cache
CACHE STATS    Show cache statistics
CACHE CLEAR    Clear all cache entries
</code></pre>
<h2 id="api-reference-4"><a class="header" href="#api-reference-4">API Reference</a></h2>
<h3 id="cache-methods"><a class="header" href="#cache-methods">Cache Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>new()</code></td><td>Create with default config</td></tr>
<tr><td><code>with_config(config)</code></td><td>Create with custom config</td></tr>
<tr><td><code>with_store(store, config)</code></td><td>Create with shared TensorStore</td></tr>
<tr><td><code>get(prompt, embedding)</code></td><td>Look up cached response</td></tr>
<tr><td><code>get_with_metric(prompt, embedding, metric)</code></td><td>Look up with explicit metric</td></tr>
<tr><td><code>put(prompt, embedding, response, model, ttl)</code></td><td>Store response</td></tr>
<tr><td><code>get_embedding(source, content)</code></td><td>Get cached embedding</td></tr>
<tr><td><code>put_embedding(source, content, embedding, model)</code></td><td>Store embedding</td></tr>
<tr><td><code>get_or_compute_embedding(source, content, model, compute)</code></td><td>Get or compute embedding</td></tr>
<tr><td><code>get_simple(key)</code></td><td>Simple key-value lookup</td></tr>
<tr><td><code>put_simple(key, value)</code></td><td>Simple key-value store</td></tr>
<tr><td><code>invalidate(prompt)</code></td><td>Remove exact entry</td></tr>
<tr><td><code>invalidate_version(version)</code></td><td>Remove entries by version</td></tr>
<tr><td><code>invalidate_embeddings(source)</code></td><td>Remove embeddings by source</td></tr>
<tr><td><code>evict(count)</code></td><td>Manually evict entries</td></tr>
<tr><td><code>cleanup_expired()</code></td><td>Remove expired entries</td></tr>
<tr><td><code>clear()</code></td><td>Clear all entries</td></tr>
<tr><td><code>stats()</code></td><td>Get statistics reference</td></tr>
<tr><td><code>stats_snapshot()</code></td><td>Get statistics snapshot</td></tr>
<tr><td><code>config()</code></td><td>Get configuration reference</td></tr>
<tr><td><code>len()</code></td><td>Total cached entries</td></tr>
<tr><td><code>is_empty()</code></td><td>Check if cache is empty</td></tr>
</tbody></table>
</div>
<h3 id="cachehit-fields"><a class="header" href="#cachehit-fields">CacheHit Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>response</code></td><td><code>String</code></td><td>Cached response text</td></tr>
<tr><td><code>layer</code></td><td><code>CacheLayer</code></td><td>Which layer matched</td></tr>
<tr><td><code>similarity</code></td><td><code>Option&lt;f32&gt;</code></td><td>Similarity score (semantic only)</td></tr>
<tr><td><code>input_tokens</code></td><td><code>usize</code></td><td>Input tokens saved</td></tr>
<tr><td><code>output_tokens</code></td><td><code>usize</code></td><td>Output tokens saved</td></tr>
<tr><td><code>cost_saved</code></td><td><code>f64</code></td><td>Estimated cost saved (dollars)</td></tr>
<tr><td><code>metric_used</code></td><td><code>Option&lt;DistanceMetric&gt;</code></td><td>Metric used (semantic only)</td></tr>
</tbody></table>
</div>
<h3 id="statssnapshot-fields"><a class="header" href="#statssnapshot-fields">StatsSnapshot Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>exact_hits</code></td><td><code>u64</code></td><td>Exact cache hits</td></tr>
<tr><td><code>exact_misses</code></td><td><code>u64</code></td><td>Exact cache misses</td></tr>
<tr><td><code>semantic_hits</code></td><td><code>u64</code></td><td>Semantic cache hits</td></tr>
<tr><td><code>semantic_misses</code></td><td><code>u64</code></td><td>Semantic cache misses</td></tr>
<tr><td><code>embedding_hits</code></td><td><code>u64</code></td><td>Embedding cache hits</td></tr>
<tr><td><code>embedding_misses</code></td><td><code>u64</code></td><td>Embedding cache misses</td></tr>
<tr><td><code>tokens_saved_in</code></td><td><code>u64</code></td><td>Total input tokens saved</td></tr>
<tr><td><code>tokens_saved_out</code></td><td><code>u64</code></td><td>Total output tokens saved</td></tr>
<tr><td><code>cost_saved_dollars</code></td><td><code>f64</code></td><td>Total cost saved</td></tr>
<tr><td><code>evictions</code></td><td><code>u64</code></td><td>Total evictions</td></tr>
<tr><td><code>expirations</code></td><td><code>u64</code></td><td>Total expirations</td></tr>
<tr><td><code>exact_size</code></td><td><code>usize</code></td><td>Current exact cache size</td></tr>
<tr><td><code>semantic_size</code></td><td><code>usize</code></td><td>Current semantic cache size</td></tr>
<tr><td><code>embedding_size</code></td><td><code>usize</code></td><td>Current embedding cache size</td></tr>
<tr><td><code>uptime_secs</code></td><td><code>u64</code></td><td>Cache uptime in seconds</td></tr>
</tbody></table>
</div>
<h2 id="dependencies-5"><a class="header" href="#dependencies-5">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>HNSW index implementation, TensorStore</td></tr>
<tr><td><code>tiktoken-rs</code></td><td>GPT-compatible token counting</td></tr>
<tr><td><code>dashmap</code></td><td>Concurrent hash maps</td></tr>
<tr><td><code>tokio</code></td><td>Async runtime for background eviction</td></tr>
<tr><td><code>uuid</code></td><td>Unique ID generation</td></tr>
<tr><td><code>thiserror</code></td><td>Error type derivation</td></tr>
<tr><td><code>serde</code></td><td>Configuration serialization</td></tr>
<tr><td><code>bincode</code></td><td>Binary serialization</td></tr>
</tbody></table>
</div>
<h2 id="related-modules-6"><a class="header" href="#related-modules-6">Related Modules</a></h2>
<ul>
<li><code>tensor_store</code> - Backing storage and HNSW index</li>
<li><code>query_router</code> - Cache integration for query execution</li>
<li><code>neumann_shell</code> - CLI commands for cache management</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-blob-architecture"><a class="header" href="#tensor-blob-architecture">Tensor Blob Architecture</a></h1>
<p>S3-style object storage for large artifacts using content-addressable chunked
storage with tensor-native metadata. Artifacts are split into SHA-256 hashed
chunks for automatic deduplication, with metadata stored in the tensor store for
integration with graph, relational, and vector queries.</p>
<p>All I/O operations are async via Tokio. Large files are streamed through
<code>BlobWriter</code> and <code>BlobReader</code> without loading entirely into memory. Background
garbage collection removes orphaned chunks automatically.</p>
<h2 id="key-types-7"><a class="header" href="#key-types-7">Key Types</a></h2>
<h3 id="core-types-4"><a class="header" href="#core-types-4">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>BlobStore</code></td><td>Main API for storing, retrieving, and managing artifacts</td></tr>
<tr><td><code>BlobConfig</code></td><td>Configuration for chunk size, GC intervals, and limits</td></tr>
<tr><td><code>BlobWriter</code></td><td>Streaming upload with incremental chunking and hash computation</td></tr>
<tr><td><code>BlobReader</code></td><td>Streaming download with chunk-by-chunk reads and verification</td></tr>
<tr><td><code>Chunk</code></td><td>Content-addressed data segment with SHA-256 hash</td></tr>
<tr><td><code>Chunker</code></td><td>Splits data into fixed-size content-addressable chunks</td></tr>
<tr><td><code>StreamingHasher</code></td><td>Incremental SHA-256 computation for large files</td></tr>
<tr><td><code>GarbageCollector</code></td><td>Background task for cleaning orphaned chunks</td></tr>
</tbody></table>
</div>
<h3 id="metadata-types"><a class="header" href="#metadata-types">Metadata Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>ArtifactMetadata</code></td><td>Full metadata including filename, size, checksum, links, tags</td></tr>
<tr><td><code>PutOptions</code></td><td>Upload options: content type, creator, links, tags, custom metadata, embedding</td></tr>
<tr><td><code>MetadataUpdates</code></td><td>Partial updates for filename, content type, custom fields</td></tr>
<tr><td><code>SimilarArtifact</code></td><td>Search result with artifact ID, filename, and similarity score</td></tr>
<tr><td><code>WriteState</code></td><td>Internal state tracking artifact metadata during streaming upload</td></tr>
</tbody></table>
</div>
<h3 id="statistics-types"><a class="header" href="#statistics-types">Statistics Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>BlobStats</code></td><td>Storage statistics: artifact count, chunk count, dedup ratio, orphaned chunks</td></tr>
<tr><td><code>GcStats</code></td><td>GC results: chunks deleted, bytes freed</td></tr>
<tr><td><code>RepairStats</code></td><td>Repair results: artifacts checked, chunks verified, refs fixed, orphans deleted</td></tr>
</tbody></table>
</div>
<h3 id="error-types-5"><a class="header" href="#error-types-5">Error Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Description</th></tr></thead><tbody>
<tr><td><code>NotFound</code></td><td>Artifact does not exist</td></tr>
<tr><td><code>ChunkMissing</code></td><td>Referenced chunk not found in storage</td></tr>
<tr><td><code>ChecksumMismatch</code></td><td>Data corruption detected during verification</td></tr>
<tr><td><code>EmptyData</code></td><td>Cannot store empty artifact</td></tr>
<tr><td><code>InvalidConfig</code></td><td>Invalid configuration parameter (e.g., zero chunk size)</td></tr>
<tr><td><code>InvalidArtifactId</code></td><td>Malformed artifact ID format</td></tr>
<tr><td><code>StorageError</code></td><td>Underlying tensor store error</td></tr>
<tr><td><code>GraphError</code></td><td>Graph engine integration error (feature-gated)</td></tr>
<tr><td><code>VectorError</code></td><td>Vector engine integration error (feature-gated)</td></tr>
<tr><td><code>IoError</code></td><td>I/O error during streaming operations</td></tr>
<tr><td><code>GcError</code></td><td>Garbage collection failure</td></tr>
<tr><td><code>AlreadyExists</code></td><td>Artifact with given ID already exists</td></tr>
<tr><td><code>DimensionMismatch</code></td><td>Embedding dimension mismatch</td></tr>
</tbody></table>
</div>
<h2 id="architecture-diagram-2"><a class="header" href="#architecture-diagram-2">Architecture Diagram</a></h2>
<pre><code class="language-sql">+--------------------------------------------------+
|                BlobStore (Public API)            |
|   - put, get, delete, exists                     |
|   - metadata, update_metadata                    |
|   - link, unlink, tag, untag                     |
|   - verify, repair, gc, full_gc                  |
+--------------------------------------------------+
            |              |              |
    +-------+      +-------+      +-------+
    |              |              |
+--------+   +-----------+   +----------+
| Writer |   |  Reader   |   |    GC    |
| Stream |   |  Stream   |   | (Tokio)  |
+--------+   +-----------+   +----------+
    |              |              |
    +-------+------+------+-------+
            |
    +------------------+
    |     Chunker      |
    |   SHA-256 hash   |
    +------------------+
            |
    +------------------+
    |   tensor_store   |
    | _blob:meta:*     |
    | _blob:chunk:*    |
    +------------------+
</code></pre>
<h2 id="storage-format-2"><a class="header" href="#storage-format-2">Storage Format</a></h2>
<h3 id="artifact-metadata"><a class="header" href="#artifact-metadata">Artifact Metadata</a></h3>
<p>Stored at <code>_blob:meta:{artifact_id}</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>_type</code></td><td>String</td><td>Always <code>"blob_artifact"</code></td></tr>
<tr><td><code>_id</code></td><td>String</td><td>Unique artifact identifier (UUID v4)</td></tr>
<tr><td><code>_filename</code></td><td>String</td><td>Original filename</td></tr>
<tr><td><code>_content_type</code></td><td>String</td><td>MIME type</td></tr>
<tr><td><code>_size</code></td><td>Int</td><td>Total size in bytes</td></tr>
<tr><td><code>_checksum</code></td><td>String</td><td>SHA-256 hash of full content (<code>sha256:{hex}</code>)</td></tr>
<tr><td><code>_chunk_size</code></td><td>Int</td><td>Size of each chunk (except possibly last)</td></tr>
<tr><td><code>_chunk_count</code></td><td>Int</td><td>Number of chunks</td></tr>
<tr><td><code>_chunks</code></td><td>Pointers</td><td>Ordered list of chunk keys</td></tr>
<tr><td><code>_created</code></td><td>Int</td><td>Unix timestamp (seconds)</td></tr>
<tr><td><code>_modified</code></td><td>Int</td><td>Unix timestamp (seconds)</td></tr>
<tr><td><code>_created_by</code></td><td>String</td><td>Creator identity</td></tr>
<tr><td><code>_linked_to</code></td><td>Pointers</td><td>Linked entity IDs</td></tr>
<tr><td><code>_tags</code></td><td>Pointers</td><td>Applied tags (prefixed with <code>tag:</code>)</td></tr>
<tr><td><code>_meta:*</code></td><td>String</td><td>Custom metadata fields</td></tr>
<tr><td><code>_embedding</code></td><td>Vector/Sparse</td><td>Optional embedding (sparse if &gt;50% zeros)</td></tr>
<tr><td><code>_embedded_model</code></td><td>String</td><td>Embedding model name</td></tr>
</tbody></table>
</div>
<h3 id="chunk-data"><a class="header" href="#chunk-data">Chunk Data</a></h3>
<p>Stored at <code>_blob:chunk:sha256:{hex}</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>_type</code></td><td>String</td><td>Always <code>"blob_chunk"</code></td></tr>
<tr><td><code>_data</code></td><td>Bytes</td><td>Raw chunk data</td></tr>
<tr><td><code>_size</code></td><td>Int</td><td>Chunk size in bytes</td></tr>
<tr><td><code>_refs</code></td><td>Int</td><td>Reference count for deduplication</td></tr>
<tr><td><code>_created</code></td><td>Int</td><td>Unix timestamp (seconds)</td></tr>
</tbody></table>
</div>
<h2 id="content-addressable-chunking-algorithm"><a class="header" href="#content-addressable-chunking-algorithm">Content-Addressable Chunking Algorithm</a></h2>
<p>The chunker uses a fixed-size chunking strategy with SHA-256 content addressing:</p>
<pre class="mermaid">flowchart TD
    A[Input Data] --&gt; B[Split into fixed-size chunks]
    B --&gt; C{For each chunk}
    C --&gt; D[Compute SHA-256 hash]
    D --&gt; E{Chunk exists?}
    E --&gt;|Yes| F[Increment ref count]
    E --&gt;|No| G[Store new chunk]
    F --&gt; H[Record chunk key]
    G --&gt; H
    H --&gt; C
    C --&gt;|Done| I[Compute full-file checksum]
    I --&gt; J[Store metadata with chunk list]
</pre>
<h3 id="chunker-implementation"><a class="header" href="#chunker-implementation">Chunker Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Chunker splits data into fixed-size segments
pub struct Chunker {
    chunk_size: usize,  // Default: 1MB (1,048,576 bytes)
}

impl Chunker {
    // Split data into chunks using Rust's chunks() iterator
    pub fn chunk&lt;'a&gt;(&amp;'a self, data: &amp;'a [u8]) -&gt; impl Iterator&lt;Item = Chunk&gt; + 'a {
        data.chunks(self.chunk_size).map(|chunk_data| {
            let hash = compute_hash(chunk_data);
            Chunk {
                hash,
                data: chunk_data.to_vec(),
                size: chunk_data.len(),
            }
        })
    }

    // Count chunks without allocating (useful for progress estimation)
    pub fn chunk_count(&amp;self, data_len: usize) -&gt; usize {
        if data_len == 0 { 0 } else { data_len.div_ceil(self.chunk_size) }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="chunk-key-format"><a class="header" href="#chunk-key-format">Chunk Key Format</a></h3>
<p>Chunk keys follow a deterministic format for content addressing:</p>
<pre><code class="language-text">_blob:chunk:sha256:{64_hex_chars}
</code></pre>
<p>Example:</p>
<pre><code class="language-text">_blob:chunk:sha256:b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9
</code></pre>
<h3 id="sha-256-checksum-computation"><a class="header" href="#sha-256-checksum-computation">SHA-256 Checksum Computation</a></h3>
<p>The system uses the <code>sha2</code> crate for cryptographic hashing:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use sha2::{Digest, Sha256};

// Single-shot hash for chunk content
pub fn compute_hash(data: &amp;[u8]) -&gt; String {
    let mut hasher = Sha256::new();
    hasher.update(data);
    let result = hasher.finalize();
    format!("sha256:{:x}", result)  // Lowercase hex encoding
}

// Streaming hash for large files (used by BlobWriter)
pub struct StreamingHasher {
    hasher: Sha256,
}

impl StreamingHasher {
    pub fn new() -&gt; Self {
        Self { hasher: Sha256::new() }
    }

    pub fn update(&amp;mut self, data: &amp;[u8]) {
        self.hasher.update(data);
    }

    pub fn finalize(self) -&gt; String {
        let result = self.hasher.finalize();
        format!("sha256:{:x}", result)
    }
}

// Multi-segment hash (for verification)
pub fn compute_hash_streaming&lt;'a&gt;(segments: impl Iterator&lt;Item = &amp;'a [u8]&gt;) -&gt; String {
    let mut hasher = Sha256::new();
    for segment in segments {
        hasher.update(segment);
    }
    let result = hasher.finalize();
    format!("sha256:{:x}", result)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="content-addressable-deduplication"><a class="header" href="#content-addressable-deduplication">Content-Addressable Deduplication</a></h2>
<p>Chunks are keyed by SHA-256 hash, enabling automatic deduplication:</p>
<ol>
<li>When writing data, the chunker splits it into fixed-size segments (default
1MB)</li>
<li>Each chunk is hashed with SHA-256 to produce a unique key</li>
<li>If the chunk already exists, only the reference count is incremented</li>
<li>Identical data across different artifacts shares the same physical chunks</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let data = vec![0u8; 10_000];

// Store same data twice
blob.put("file1.bin", &amp;data, PutOptions::default()).await?;
blob.put("file2.bin", &amp;data, PutOptions::default()).await?;

let stats = blob.stats().await?;
// stats.chunk_count = 1 (deduplicated)
// stats.dedup_ratio &gt; 0.0
<span class="boring">}</span></code></pre></pre>
<h3 id="deduplication-ratio-calculation"><a class="header" href="#deduplication-ratio-calculation">Deduplication Ratio Calculation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let dedup_ratio = if total_bytes &gt; 0 {
    1.0 - (unique_bytes as f64 / total_bytes as f64)
} else {
    0.0
};
<span class="boring">}</span></code></pre></pre>
<p>A ratio of 0.5 means 50% space savings through deduplication.</p>
<h2 id="streaming-upload-state-machine"><a class="header" href="#streaming-upload-state-machine">Streaming Upload State Machine</a></h2>
<p>The <code>BlobWriter</code> manages incremental uploads with proper buffering:</p>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Created: new()
    Created --&gt; Buffering: write()
    Buffering --&gt; Buffering: write() [buffer &lt; chunk_size]
    Buffering --&gt; ChunkReady: write() [buffer &gt;= chunk_size]
    ChunkReady --&gt; StoreChunk: drain buffer
    StoreChunk --&gt; CheckExists: compute hash
    CheckExists --&gt; IncrementRefs: chunk exists
    CheckExists --&gt; StoreNew: chunk new
    IncrementRefs --&gt; Buffering
    StoreNew --&gt; Buffering
    Buffering --&gt; FlushFinal: finish()
    FlushFinal --&gt; StoreMetadata: store remaining buffer
    StoreMetadata --&gt; [*]: return artifact_id
</pre>
<h3 id="blobwriter-internal-state"><a class="header" href="#blobwriter-internal-state">BlobWriter Internal State</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BlobWriter {
    store: TensorStore,
    chunker: Chunker,
    state: WriteState,      // Artifact metadata (filename, content_type, etc.)
    chunks: Vec&lt;String&gt;,    // Ordered list of chunk keys
    total_size: usize,      // Running total of bytes written
    hasher: StreamingHasher, // Incremental full-file hash
    buffer: Vec&lt;u8&gt;,        // Incomplete chunk buffer
}
<span class="boring">}</span></code></pre></pre>
<h3 id="write-operation-flow"><a class="header" href="#write-operation-flow">Write Operation Flow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn write(&amp;mut self, data: &amp;[u8]) -&gt; Result&lt;()&gt; {
    if data.is_empty() { return Ok(()); }

    // 1. Update full-file hash (computed independently of chunking)
    self.hasher.update(data);
    self.total_size += data.len();

    // 2. Add to internal buffer
    self.buffer.extend_from_slice(data);

    // 3. Process complete chunks (may be multiple if large write)
    while self.buffer.len() &gt;= self.chunker.chunk_size() {
        let chunk_data: Vec&lt;u8&gt; = self.buffer.drain(..self.chunker.chunk_size()).collect();
        let chunk = Chunk::new(chunk_data);
        self.store_chunk(chunk).await?;
    }

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="finish-operation"><a class="header" href="#finish-operation">Finish Operation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn finish(mut self) -&gt; Result&lt;String&gt; {
    // 1. Flush remaining buffer as final (possibly smaller) chunk
    if !self.buffer.is_empty() {
        let chunk = Chunk::new(std::mem::take(&amp;mut self.buffer));
        self.store_chunk(chunk).await?;
    }

    // 2. Finalize full-file checksum
    let checksum = self.hasher.finalize();

    // 3. Build and store metadata tensor
    let mut tensor = TensorData::new();
    tensor.set("_type", "blob_artifact");
    tensor.set("_id", self.state.artifact_id.clone());
    tensor.set("_checksum", checksum);
    tensor.set("_chunks", TensorValue::Pointers(self.chunks));
    // ... additional fields ...

    let meta_key = format!("_blob:meta:{}", self.state.artifact_id);
    self.store.put(&amp;meta_key, tensor)?;

    Ok(self.state.artifact_id)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="streaming-download-state-machine"><a class="header" href="#streaming-download-state-machine">Streaming Download State Machine</a></h2>
<p>The <code>BlobReader</code> manages incremental downloads with chunk-level iteration:</p>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Initialized: new()
    Initialized --&gt; LoadMetadata: read chunk list
    LoadMetadata --&gt; Ready: chunks loaded
    Ready --&gt; ReadChunk: next_chunk()
    ReadChunk --&gt; ChunkLoaded: fetch from store
    ChunkLoaded --&gt; Ready: return data
    Ready --&gt; [*]: all chunks read
    Ready --&gt; Verify: verify()
    Verify --&gt; HashAll: reset and hash all chunks
    HashAll --&gt; Compare: compare checksums
    Compare --&gt; [*]: return bool
</pre>
<h3 id="blobreader-internal-state"><a class="header" href="#blobreader-internal-state">BlobReader Internal State</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BlobReader {
    store: TensorStore,
    chunks: Vec&lt;String&gt;,       // Ordered list of chunk keys
    current_chunk: usize,      // Index of next chunk to read
    current_data: Option&lt;Vec&lt;u8&gt;&gt;, // Cached current chunk for read()
    current_offset: usize,     // Offset within current_data
    total_size: usize,         // Total artifact size
    bytes_read: usize,         // Bytes read so far
    checksum: String,          // Expected checksum for verification
}
<span class="boring">}</span></code></pre></pre>
<h3 id="read-modes"><a class="header" href="#read-modes">Read Modes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Mode 1: Chunk-at-a-time (best for processing in batches)
while let Some(chunk) = reader.next_chunk().await? {
    process_chunk(&amp;chunk);
}

// Mode 2: Read all into memory (convenient for small files)
let data = reader.read_all().await?;

// Mode 3: Buffer-based reading (for streaming to other APIs)
let mut buf = vec![0u8; 4096];
loop {
    let n = reader.read(&amp;mut buf).await?;
    if n == 0 { break; }
    output.write_all(&amp;buf[..n])?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="garbage-collection-reference-counting"><a class="header" href="#garbage-collection-reference-counting">Garbage Collection Reference Counting</a></h2>
<p>The GC system uses reference counting with two operational modes:</p>
<h3 id="reference-count-management"><a class="header" href="#reference-count-management">Reference Count Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// When storing a chunk (in BlobWriter::store_chunk)
if self.store.exists(&amp;chunk_key) {
    // Chunk already exists - just increment ref count
    increment_chunk_refs(&amp;self.store, &amp;chunk_key)?;
} else {
    // New chunk - store with ref count of 1
    let mut tensor = TensorData::new();
    tensor.set("_refs", TensorValue::Scalar(ScalarValue::Int(1)));
    // ... store chunk data ...
}

// When deleting an artifact
pub fn delete_artifact(store: &amp;TensorStore, artifact_id: &amp;str) -&gt; Result&lt;()&gt; {
    let tensor = store.get(&amp;meta_key)?;
    if let Some(chunks) = get_pointers(&amp;tensor, "_chunks") {
        for chunk_key in chunks {
            decrement_chunk_refs(store, &amp;chunk_key)?;  // Saturating at 0
        }
    }
    store.delete(&amp;meta_key)?;
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="incremental-gc-gc"><a class="header" href="#incremental-gc-gc">Incremental GC (<code>gc()</code>)</a></h3>
<p>Processes a limited batch of chunks per cycle, respecting age requirements:</p>
<pre class="mermaid">flowchart TD
    A[Start GC Cycle] --&gt; B[Scan chunk keys]
    B --&gt; C{Take batch_size chunks}
    C --&gt; D{For each chunk}
    D --&gt; E{refs == 0?}
    E --&gt;|No| D
    E --&gt;|Yes| F{age &gt; min_age?}
    F --&gt;|No| D
    F --&gt;|Yes| G[Delete chunk]
    G --&gt; H[Track freed bytes]
    H --&gt; D
    D --&gt;|Done| I[Return GcStats]
</pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn gc_cycle(&amp;self) -&gt; GcStats {
    let mut deleted = 0;
    let mut freed_bytes = 0;

    let now = current_timestamp();
    let min_created = now.saturating_sub(self.config.min_age.as_secs());

    let chunk_keys = self.store.scan("_blob:chunk:");

    for chunk_key in chunk_keys.into_iter().take(self.config.batch_size) {
        if let Ok(tensor) = self.store.get(&amp;chunk_key) {
            let refs = get_int(&amp;tensor, "_refs").unwrap_or(0);
            let created = get_int(&amp;tensor, "_created").unwrap_or(0) as u64;

            // Zero refs AND old enough
            if refs == 0 &amp;&amp; created &lt; min_created {
                let size = get_int(&amp;tensor, "_size").unwrap_or(0) as usize;
                if self.store.delete(&amp;chunk_key).is_ok() {
                    deleted += 1;
                    freed_bytes += size;
                }
            }
        }
    }

    GcStats { deleted, freed_bytes }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="full-gc-full_gc"><a class="header" href="#full-gc-full_gc">Full GC (<code>full_gc()</code>)</a></h3>
<p>Rebuilds reference counts from scratch and deletes all unreferenced chunks:</p>
<pre class="mermaid">flowchart TD
    A[Start Full GC] --&gt; B[Build reference set from all artifacts]
    B --&gt; C[Scan all artifact metadata]
    C --&gt; D[Extract chunk lists]
    D --&gt; E[Add to HashSet]
    E --&gt; C
    C --&gt;|Done| F[Scan all chunks]
    F --&gt; G{Chunk in reference set?}
    G --&gt;|Yes| F
    G --&gt;|No| H[Delete chunk]
    H --&gt; I[Track freed bytes]
    I --&gt; F
    F --&gt;|Done| J[Return GcStats]
</pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn full_gc(&amp;self) -&gt; Result&lt;GcStats&gt; {
    // Phase 1: Build reference set from all artifacts
    let mut referenced: HashSet&lt;String&gt; = HashSet::new();
    for meta_key in self.store.scan("_blob:meta:") {
        if let Ok(tensor) = self.store.get(&amp;meta_key) {
            if let Some(chunks) = get_pointers(&amp;tensor, "_chunks") {
                referenced.extend(chunks);
            }
        }
    }

    // Phase 2: Delete unreferenced chunks (ignores age requirement)
    let mut deleted = 0;
    let mut freed_bytes = 0;
    for chunk_key in self.store.scan("_blob:chunk:") {
        if !referenced.contains(&amp;chunk_key) {
            if let Ok(tensor) = self.store.get(&amp;chunk_key) {
                let size = get_int(&amp;tensor, "_size").unwrap_or(0) as usize;
                if self.store.delete(&amp;chunk_key).is_ok() {
                    deleted += 1;
                    freed_bytes += size;
                }
            }
        }
    }

    Ok(GcStats { deleted, freed_bytes })
}
<span class="boring">}</span></code></pre></pre>
<h3 id="background-gc-task"><a class="header" href="#background-gc-task">Background GC Task</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn start(self: Arc&lt;Self&gt;) -&gt; JoinHandle&lt;()&gt; {
    let gc = Arc::clone(&amp;self);
    tokio::spawn(async move {
        gc.run().await;
    })
}

async fn run(&amp;self) {
    let mut interval = interval(self.config.check_interval);
    let mut shutdown_rx = self.shutdown_tx.subscribe();

    loop {
        tokio::select! {
            _ = interval.tick() =&gt; {
                let _ = self.gc_cycle().await;
            }
            _ = shutdown_rx.recv() =&gt; {
                break;
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integrity-repair-algorithm"><a class="header" href="#integrity-repair-algorithm">Integrity Repair Algorithm</a></h2>
<p>The repair operation fixes reference count inconsistencies and removes orphans:</p>
<pre class="mermaid">flowchart TD
    A[Start Repair] --&gt; B[Phase 1: Build true reference counts]
    B --&gt; C[Scan all artifacts]
    C --&gt; D[Count chunk references]
    D --&gt; E[Build HashMap chunk -&gt; count]
    E --&gt; F[Phase 2: Verify and fix chunks]
    F --&gt; G[Scan all chunks]
    G --&gt; H{Current refs == expected?}
    H --&gt;|Yes| I{Expected refs == 0?}
    H --&gt;|No| J[Update refs to expected]
    J --&gt; I
    I --&gt;|Yes| K[Mark as orphan]
    I --&gt;|No| G
    K --&gt; G
    G --&gt;|Done| L[Phase 3: Delete orphans]
    L --&gt; M[Delete marked chunks]
    M --&gt; N[Return RepairStats]
</pre>
<h3 id="repair-implementation"><a class="header" href="#repair-implementation">Repair Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn repair(store: &amp;TensorStore) -&gt; Result&lt;RepairStats&gt; {
    let mut stats = RepairStats::default();

    // Phase 1: Build true reference counts from all artifacts
    let mut true_refs: HashMap&lt;String, i64&gt; = HashMap::new();
    for meta_key in store.scan("_blob:meta:") {
        stats.artifacts_checked += 1;
        if let Ok(tensor) = store.get(&amp;meta_key) {
            if let Some(chunks) = get_pointers(&amp;tensor, "_chunks") {
                for chunk_key in chunks {
                    *true_refs.entry(chunk_key).or_insert(0) += 1;
                }
            }
        }
    }

    // Phase 2: Verify and fix reference counts
    let mut orphan_keys = Vec::new();
    for chunk_key in store.scan("_blob:chunk:") {
        stats.chunks_verified += 1;
        if let Ok(mut tensor) = store.get(&amp;chunk_key) {
            let current_refs = get_int(&amp;tensor, "_refs").unwrap_or(0);
            let expected_refs = true_refs.get(&amp;chunk_key).copied().unwrap_or(0);

            if current_refs != expected_refs {
                tensor.set("_refs", TensorValue::Scalar(ScalarValue::Int(expected_refs)));
                store.put(&amp;chunk_key, tensor)?;
                stats.refs_fixed += 1;
            }

            if expected_refs == 0 {
                orphan_keys.push(chunk_key);
            }
        }
    }

    // Phase 3: Delete orphans
    for orphan_key in orphan_keys {
        if store.delete(&amp;orphan_key).is_ok() {
            stats.orphans_deleted += 1;
        }
    }

    Ok(stats)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="artifact-verification"><a class="header" href="#artifact-verification">Artifact Verification</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn verify_artifact(store: &amp;TensorStore, artifact_id: &amp;str) -&gt; Result&lt;bool&gt; {
    let meta_key = format!("_blob:meta:{artifact_id}");
    let tensor = store.get(&amp;meta_key)?;

    let expected_checksum = get_string(&amp;tensor, "_checksum")?;
    let chunks = get_pointers(&amp;tensor, "_chunks")?;

    // Recompute checksum by hashing all chunks in order
    let mut hasher = StreamingHasher::new();
    for chunk_key in &amp;chunks {
        let chunk_tensor = store.get(chunk_key)?;
        let chunk_data = get_bytes(&amp;chunk_tensor, "_data")?;
        hasher.update(&amp;chunk_data);
    }

    let actual_checksum = hasher.finalize();
    Ok(actual_checksum == expected_checksum)
}

// Verify individual chunk integrity
pub fn verify_chunk(store: &amp;TensorStore, chunk_key: &amp;str) -&gt; Result&lt;bool&gt; {
    let expected_hash = chunk_key.strip_prefix("_blob:chunk:")?;
    let tensor = store.get(chunk_key)?;
    let data = get_bytes(&amp;tensor, "_data")?;
    let actual_hash = compute_hash(&amp;data);
    Ok(actual_hash == expected_hash)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples-6"><a class="header" href="#usage-examples-6">Usage Examples</a></h2>
<h3 id="basic-storage"><a class="header" href="#basic-storage">Basic Storage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_blob::{BlobStore, BlobConfig, PutOptions};
use tensor_store::TensorStore;

let store = TensorStore::new();
let blob = BlobStore::new(store, BlobConfig::default()).await?;

// Store an artifact
let artifact_id = blob.put(
    "report.pdf",
    &amp;file_bytes,
    PutOptions::new()
        .with_created_by("user:alice")
        .with_tag("quarterly")
        .with_link("task:123"),
).await?;

// Retrieve it
let data = blob.get(&amp;artifact_id).await?;

// Get metadata
let meta = blob.metadata(&amp;artifact_id).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="streaming-api"><a class="header" href="#streaming-api">Streaming API</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Streaming upload (memory-efficient for large files)
let mut writer = blob.writer("large_file.bin", PutOptions::default()).await?;
for chunk in file_chunks {
    writer.write(&amp;chunk).await?;
}
let artifact_id = writer.finish().await?;

// Streaming download
let mut reader = blob.reader(&amp;artifact_id).await?;
while let Some(chunk) = reader.next_chunk().await? {
    process_chunk(&amp;chunk);
}

// Verify integrity after download
let mut reader = blob.reader(&amp;artifact_id).await?;
let valid = reader.verify().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="entity-linking-and-tagging"><a class="header" href="#entity-linking-and-tagging">Entity Linking and Tagging</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Link artifact to entities
blob.link(&amp;artifact_id, "user:alice").await?;
blob.link(&amp;artifact_id, "task:123").await?;

// Find artifacts linked to an entity
let artifacts = blob.artifacts_for("user:alice").await?;

// Add tags
blob.tag(&amp;artifact_id, "important").await?;

// Find artifacts by tag
let important_files = blob.by_tag("important").await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="semantic-search-with-vector-feature"><a class="header" href="#semantic-search-with-vector-feature">Semantic Search (with <code>vector</code> feature)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Set embedding for artifact
blob.set_embedding(&amp;artifact_id, embedding, "text-embedding-3-small").await?;

// Find similar artifacts
let similar = blob.similar(&amp;artifact_id, 10).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-options-2"><a class="header" href="#configuration-options-2">Configuration Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>chunk_size</code></td><td>1 MB (1,048,576 bytes)</td><td>Size of each chunk in bytes</td></tr>
<tr><td><code>max_artifact_size</code></td><td>None (unlimited)</td><td>Maximum artifact size limit</td></tr>
<tr><td><code>max_artifacts</code></td><td>None (unlimited)</td><td>Maximum number of artifacts</td></tr>
<tr><td><code>gc_interval</code></td><td>5 minutes (300s)</td><td>Background GC check frequency</td></tr>
<tr><td><code>gc_batch_size</code></td><td>100</td><td>Chunks processed per GC cycle</td></tr>
<tr><td><code>gc_min_age</code></td><td>1 minute (60s)</td><td>Minimum age before GC eligible</td></tr>
<tr><td><code>default_content_type</code></td><td><code>application/octet-stream</code></td><td>Default MIME type</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = BlobConfig::new()
    .with_chunk_size(1024 * 1024)
    .with_gc_interval(Duration::from_secs(300))
    .with_gc_batch_size(100)
    .with_gc_min_age(Duration::from_secs(3600))
    .with_max_artifact_size(100 * 1024 * 1024);
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-validation-1"><a class="header" href="#configuration-validation-1">Configuration Validation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Configuration is validated on BlobStore::new()
pub fn validate(&amp;self) -&gt; Result&lt;()&gt; {
    if self.chunk_size == 0 {
        return Err(BlobError::InvalidConfig("chunk_size must be &gt; 0"));
    }
    if self.gc_batch_size == 0 {
        return Err(BlobError::InvalidConfig("gc_batch_size must be &gt; 0"));
    }
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="garbage-collection"><a class="header" href="#garbage-collection">Garbage Collection</a></h2>
<p>Two GC modes are available:</p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th><th>Age Requirement</th><th>Reference Source</th></tr></thead><tbody>
<tr><td><code>gc()</code></td><td>Incremental GC: processes <code>batch_size</code> chunks per cycle</td><td>Respects <code>min_age</code></td><td>Uses stored <code>_refs</code> field</td></tr>
<tr><td><code>full_gc()</code></td><td>Full GC: recounts all references from artifacts</td><td>Ignores age</td><td>Rebuilds from artifact metadata</td></tr>
</tbody></table>
</div>
<p>Background GC runs automatically when started:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>blob.start().await?;     // Start background GC
// ... use blob store ...
blob.shutdown().await?;  // Graceful shutdown (waits for current cycle)
<span class="boring">}</span></code></pre></pre>
<h2 id="blobstore-api"><a class="header" href="#blobstore-api">BlobStore API</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>new(store, config)</code></td><td>Create with configuration (validates config)</td></tr>
<tr><td><code>start()</code></td><td>Start background GC task</td></tr>
<tr><td><code>shutdown()</code></td><td>Graceful shutdown (sends signal and awaits task)</td></tr>
<tr><td><code>store()</code></td><td>Get reference to underlying TensorStore</td></tr>
<tr><td><code>put(filename, data, options)</code></td><td>Store bytes, return artifact ID</td></tr>
<tr><td><code>get(artifact_id)</code></td><td>Retrieve all bytes</td></tr>
<tr><td><code>delete(artifact_id)</code></td><td>Delete artifact and decrement chunk refs</td></tr>
<tr><td><code>exists(artifact_id)</code></td><td>Check if artifact exists</td></tr>
<tr><td><code>writer(filename, options)</code></td><td>Create streaming upload writer</td></tr>
<tr><td><code>reader(artifact_id)</code></td><td>Create streaming download reader</td></tr>
<tr><td><code>metadata(artifact_id)</code></td><td>Get artifact metadata</td></tr>
<tr><td><code>update_metadata(artifact_id, updates)</code></td><td>Apply metadata updates</td></tr>
<tr><td><code>set_meta(artifact_id, key, value)</code></td><td>Set custom metadata field</td></tr>
<tr><td><code>get_meta(artifact_id, key)</code></td><td>Get custom metadata field</td></tr>
<tr><td><code>link(artifact_id, entity)</code></td><td>Link to entity</td></tr>
<tr><td><code>unlink(artifact_id, entity)</code></td><td>Remove link</td></tr>
<tr><td><code>links(artifact_id)</code></td><td>Get linked entities</td></tr>
<tr><td><code>artifacts_for(entity)</code></td><td>Find artifacts by linked entity</td></tr>
<tr><td><code>tag(artifact_id, tag)</code></td><td>Add tag</td></tr>
<tr><td><code>untag(artifact_id, tag)</code></td><td>Remove tag</td></tr>
<tr><td><code>by_tag(tag)</code></td><td>Find artifacts by tag</td></tr>
<tr><td><code>list(prefix)</code></td><td>List artifacts with optional prefix filter</td></tr>
<tr><td><code>by_content_type(type)</code></td><td>Find by content type</td></tr>
<tr><td><code>by_creator(creator)</code></td><td>Find by creator</td></tr>
<tr><td><code>verify(artifact_id)</code></td><td>Verify checksum integrity</td></tr>
<tr><td><code>repair()</code></td><td>Repair broken references</td></tr>
<tr><td><code>gc()</code></td><td>Run incremental GC</td></tr>
<tr><td><code>full_gc()</code></td><td>Run full GC</td></tr>
<tr><td><code>stats()</code></td><td>Get storage statistics</td></tr>
<tr><td><code>set_embedding(id, vec, model)</code></td><td>Set artifact embedding (feature-gated)</td></tr>
<tr><td><code>similar(id, k)</code></td><td>Find k similar artifacts (feature-gated)</td></tr>
<tr><td><code>search_by_embedding(vec, k)</code></td><td>Search by embedding vector (feature-gated)</td></tr>
</tbody></table>
</div>
<h2 id="blobwriter-api"><a class="header" href="#blobwriter-api">BlobWriter API</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>write(data)</code></td><td>Write chunk of data (buffers until chunk_size reached)</td></tr>
<tr><td><code>finish()</code></td><td>Finalize, flush buffer, store metadata, return artifact ID</td></tr>
<tr><td><code>bytes_written()</code></td><td>Total bytes written so far</td></tr>
<tr><td><code>chunks_written()</code></td><td>Chunks stored so far (not including buffered data)</td></tr>
</tbody></table>
</div>
<h2 id="blobreader-api"><a class="header" href="#blobreader-api">BlobReader API</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>next_chunk()</code></td><td>Read next chunk, returns <code>None</code> when done</td></tr>
<tr><td><code>read_all()</code></td><td>Read all remaining data into buffer</td></tr>
<tr><td><code>read(buf)</code></td><td>Read into buffer, returns bytes read (for streaming)</td></tr>
<tr><td><code>verify()</code></td><td>Verify checksum against stored value (resets read position)</td></tr>
<tr><td><code>checksum()</code></td><td>Get expected checksum</td></tr>
<tr><td><code>total_size()</code></td><td>Total artifact size</td></tr>
<tr><td><code>bytes_read()</code></td><td>Bytes read so far</td></tr>
<tr><td><code>chunk_count()</code></td><td>Number of chunks</td></tr>
</tbody></table>
</div>
<h2 id="shell-commands-2"><a class="header" href="#shell-commands-2">Shell Commands</a></h2>
<pre><code class="language-text">BLOB PUT 'filename' 'data'              Store inline data
BLOB PUT 'filename' FROM 'path'         Store from file path
BLOB GET 'artifact_id'                  Retrieve data
BLOB GET 'artifact_id' TO 'path'        Write to file
BLOB DELETE 'artifact_id'               Delete artifact
BLOB INFO 'artifact_id'                 Show metadata
BLOB VERIFY 'artifact_id'               Verify integrity

BLOB LINK 'artifact_id' TO 'entity'     Link to entity
BLOB UNLINK 'artifact_id' FROM 'entity' Remove link
BLOB TAG 'artifact_id' 'tag'            Add tag
BLOB UNTAG 'artifact_id' 'tag'          Remove tag

BLOB META SET 'artifact_id' 'key' 'value'  Set custom metadata
BLOB META GET 'artifact_id' 'key'          Get custom metadata

BLOB GC                                 Run incremental GC
BLOB GC FULL                            Full garbage collection
BLOB REPAIR                             Repair broken references
BLOB STATS                              Show storage statistics

BLOBS                                   List all artifacts
BLOBS FOR 'entity'                      Find by linked entity
BLOBS BY TAG 'tag'                      Find by tag
BLOBS WHERE TYPE = 'content/type'       Find by content type
BLOBS SIMILAR TO 'artifact_id' LIMIT n  Find similar (requires embeddings)
</code></pre>
<h2 id="edge-cases-and-gotchas-7"><a class="header" href="#edge-cases-and-gotchas-7">Edge Cases and Gotchas</a></h2>
<h3 id="empty-data"><a class="header" href="#empty-data">Empty Data</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Empty data is rejected
let result = blob.put("empty.txt", b"", PutOptions::default()).await;
assert!(matches!(result, Err(BlobError::EmptyData)));
<span class="boring">}</span></code></pre></pre>
<h3 id="size-limits"><a class="header" href="#size-limits">Size Limits</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Exceeding max_artifact_size returns InvalidConfig error
let config = BlobConfig::new().with_max_artifact_size(1024);
let blob = BlobStore::new(store, config).await?;

let result = blob.put("large.bin", &amp;vec![0u8; 2048], PutOptions::default()).await;
// Returns Err(BlobError::InvalidConfig("data size 2048 exceeds max 1024"))
<span class="boring">}</span></code></pre></pre>
<h3 id="concurrent-deduplication"><a class="header" href="#concurrent-deduplication">Concurrent Deduplication</a></h3>
<p>The reference counting is not fully atomic. If two writers simultaneously store
the same chunk:</p>
<ul>
<li>Both may check <code>exists()</code> and find it missing</li>
<li>Both may store the chunk with <code>refs = 1</code></li>
<li>One write will overwrite the other</li>
<li>Result: ref count may be 1 instead of 2</li>
</ul>
<p><strong>Mitigation</strong>: For high-concurrency scenarios, use <code>full_gc()</code> periodically to
rebuild accurate reference counts.</p>
<h3 id="gc-timing"><a class="header" href="#gc-timing">GC Timing</a></h3>
<ul>
<li>Incremental GC respects <code>min_age</code> to avoid deleting chunks from in-progress
uploads</li>
<li>A writer that takes longer than <code>min_age</code> to complete may have chunks
collected</li>
<li><strong>Recommendation</strong>: Set <code>gc_min_age</code> longer than your maximum expected upload
time</li>
</ul>
<h3 id="checksum-vs-chunk-hash"><a class="header" href="#checksum-vs-chunk-hash">Checksum vs Chunk Hash</a></h3>
<ul>
<li><strong>Checksum</strong> (<code>_checksum</code>): SHA-256 of the entire file content</li>
<li><strong>Chunk hash</strong> (in key): SHA-256 of individual chunk data</li>
<li>These are different values and cannot be compared directly</li>
</ul>
<h3 id="sparse-embedding-detection"><a class="header" href="#sparse-embedding-detection">Sparse Embedding Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Embeddings with &gt;50% zeros are stored in sparse format
pub(crate) fn should_use_sparse(vector: &amp;[f32]) -&gt; bool {
    if vector.is_empty() { return false; }
    let nnz = vector.iter().filter(|&amp;&amp;v| v.abs() &gt; 1e-6).count();
    nnz * 2 &lt;= vector.len()  // Use sparse if nnz &lt;= 50%
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-tips-and-best-practices-2"><a class="header" href="#performance-tips-and-best-practices-2">Performance Tips and Best Practices</a></h2>
<h3 id="chunk-size-selection"><a class="header" href="#chunk-size-selection">Chunk Size Selection</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Chunk Size</th><th>Best For</th><th>Trade-offs</th></tr></thead><tbody>
<tr><td>256 KB</td><td>Many small files, high dedup potential</td><td>More metadata overhead</td></tr>
<tr><td>1 MB (default)</td><td>General purpose</td><td>Good balance</td></tr>
<tr><td>4 MB</td><td>Large media files, sequential access</td><td>Less dedup, fewer chunks</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Benchmark different chunk sizes for your workload
let config = BlobConfig::new().with_chunk_size(512 * 1024); // 512KB
<span class="boring">}</span></code></pre></pre>
<h3 id="streaming-for-large-files"><a class="header" href="#streaming-for-large-files">Streaming for Large Files</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Loads entire file into memory
let data = std::fs::read("large_file.bin")?;
blob.put("large_file.bin", &amp;data, PutOptions::default()).await?;

// Good: Streams file in chunks
let mut writer = blob.writer("large_file.bin", PutOptions::default()).await?;
let file = std::fs::File::open("large_file.bin")?;
let mut reader = std::io::BufReader::new(file);
let mut buffer = vec![0u8; 64 * 1024]; // 64KB read buffer
loop {
    let n = reader.read(&amp;mut buffer)?;
    if n == 0 { break; }
    writer.write(&amp;buffer[..n]).await?;
}
let artifact_id = writer.finish().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="gc-tuning"><a class="header" href="#gc-tuning">GC Tuning</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High-throughput: More aggressive GC
let config = BlobConfig::new()
    .with_gc_interval(Duration::from_secs(60))   // Check every minute
    .with_gc_batch_size(500)                      // Process more per cycle
    .with_gc_min_age(Duration::from_secs(300));   // 5 minute grace period

// Low-priority background: Less aggressive
let config = BlobConfig::new()
    .with_gc_interval(Duration::from_secs(3600)) // Check hourly
    .with_gc_batch_size(50)                       // Small batches
    .with_gc_min_age(Duration::from_secs(86400)); // 24 hour grace period
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-operations-3"><a class="header" href="#batch-operations-3">Batch Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// For multiple related artifacts, batch metadata updates
for artifact_id in artifact_ids {
    blob.tag(&amp;artifact_id, "batch-processed").await?;
}

// Use full_gc() after bulk deletions
for artifact_id in to_delete {
    blob.delete(&amp;artifact_id).await?;
}
blob.full_gc().await?; // Clean up all orphans at once
<span class="boring">}</span></code></pre></pre>
<h3 id="verification-strategy"><a class="header" href="#verification-strategy">Verification Strategy</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Verify on read (paranoid mode)
let mut reader = blob.reader(&amp;artifact_id).await?;
let data = reader.read_all().await?;
if !reader.verify().await? {
    return Err("Corruption detected");
}

// Periodic verification (background task)
for artifact_id in blob.list(None).await? {
    if !blob.verify(&amp;artifact_id).await? {
        log::warn!("Corruption in artifact: {}", artifact_id);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="related-modules-7"><a class="header" href="#related-modules-7">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>Underlying key-value storage for chunks and metadata</td></tr>
<tr><td><code>query_router</code></td><td>Executes BLOB commands from parsed queries</td></tr>
<tr><td><code>neumann_shell</code></td><td>Interactive CLI for blob operations</td></tr>
<tr><td><code>vector_engine</code></td><td>Optional semantic search via embeddings</td></tr>
<tr><td><code>graph_engine</code></td><td>Optional entity linking via graph edges</td></tr>
</tbody></table>
</div>
<h2 id="dependencies-6"><a class="header" href="#dependencies-6">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>Key-value storage layer</td></tr>
<tr><td><code>tokio</code></td><td>Async runtime for streaming and background GC</td></tr>
<tr><td><code>sha2</code></td><td>SHA-256 hashing for content addressing</td></tr>
<tr><td><code>uuid</code></td><td>Artifact ID generation (UUID v4)</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-checkpoint"><a class="header" href="#tensor-checkpoint">Tensor Checkpoint</a></h1>
<p>Tensor Checkpoint provides point-in-time snapshots of the database state for
recovery operations. It enables users to create manual checkpoints before
important operations, automatically checkpoint before destructive operations,
and rollback to any previous checkpoint. Checkpoints are stored as blob
artifacts in tensor_blob for content-addressable storage with automatic
deduplication.</p>
<p>The module integrates with the query router to provide SQL-like commands
(<code>CHECKPOINT</code>, <code>CHECKPOINTS</code>, <code>ROLLBACK TO</code>) and supports interactive
confirmation prompts for destructive operations with configurable retention
policies.</p>
<h2 id="module-structure"><a class="header" href="#module-structure">Module Structure</a></h2>
<pre><code class="language-text">tensor_checkpoint/
  src/
    lib.rs          # CheckpointManager, CheckpointConfig
    state.rs        # CheckpointState, DestructiveOp, metadata types
    storage.rs      # Blob storage integration
    retention.rs    # Count-based purge logic
    preview.rs      # Destructive operation previews
    error.rs        # Error types
</code></pre>
<h2 id="key-types-8"><a class="header" href="#key-types-8">Key Types</a></h2>
<h3 id="core-types-5"><a class="header" href="#core-types-5">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>CheckpointManager</code></td><td>Main API for checkpoint operations</td></tr>
<tr><td><code>CheckpointConfig</code></td><td>Configuration (retention, auto-checkpoint, interactive mode)</td></tr>
<tr><td><code>CheckpointState</code></td><td>Full checkpoint data with snapshot and metadata</td></tr>
<tr><td><code>CheckpointInfo</code></td><td>Lightweight checkpoint listing info</td></tr>
<tr><td><code>CheckpointTrigger</code></td><td>Context for auto-checkpoints (command, operation, preview)</td></tr>
</tbody></table>
</div>
<h3 id="state-types"><a class="header" href="#state-types">State Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>DestructiveOp</code></td><td>Enum of destructive operations that trigger auto-checkpoints</td></tr>
<tr><td><code>OperationPreview</code></td><td>Summary and sample data for confirmation prompts</td></tr>
<tr><td><code>CheckpointMetadata</code></td><td>Statistics for validation (tables, nodes, embeddings)</td></tr>
<tr><td><code>RelationalMeta</code></td><td>Table and row counts</td></tr>
<tr><td><code>GraphMeta</code></td><td>Node and edge counts</td></tr>
<tr><td><code>VectorMeta</code></td><td>Embedding count</td></tr>
</tbody></table>
</div>
<h3 id="error-types-6"><a class="header" href="#error-types-6">Error Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Description</th><th>Common Cause</th></tr></thead><tbody>
<tr><td><code>NotFound</code></td><td>Checkpoint not found by ID or name</td><td>Typo in checkpoint name or ID was pruned by retention</td></tr>
<tr><td><code>Storage</code></td><td>Blob storage error</td><td>Disk full, permissions issue</td></tr>
<tr><td><code>Serialization</code></td><td>Bincode serialization error</td><td>Corrupt in-memory state</td></tr>
<tr><td><code>Deserialization</code></td><td>Bincode deserialization error</td><td>Corrupt checkpoint file</td></tr>
<tr><td><code>Blob</code></td><td>Underlying blob store error</td><td>BlobStore not initialized</td></tr>
<tr><td><code>Snapshot</code></td><td>TensorStore snapshot error</td><td>Store locked or corrupted</td></tr>
<tr><td><code>Cancelled</code></td><td>Operation cancelled by user</td><td>User rejected confirmation prompt</td></tr>
<tr><td><code>InvalidId</code></td><td>Invalid checkpoint identifier</td><td>Empty or malformed ID string</td></tr>
<tr><td><code>Retention</code></td><td>Retention enforcement error</td><td>Failed to delete old checkpoints</td></tr>
</tbody></table>
</div>
<h2 id="architecture-7"><a class="header" href="#architecture-7">Architecture</a></h2>
<pre class="mermaid">flowchart TB
    subgraph Commands
        CP[CHECKPOINT]
        CPS[CHECKPOINTS]
        RB[ROLLBACK TO]
    end

    subgraph CheckpointManager
        Create[create / create_auto]
        List[list]
        Rollback[rollback]
        Delete[delete]
        Confirm[request_confirmation]
        Preview[generate_preview]
    end

    subgraph Storage Layer
        CS[CheckpointStorage]
        RM[RetentionManager]
        PG[PreviewGenerator]
    end

    subgraph Dependencies
        Blob[tensor_blob::BlobStore]
        Store[tensor_store::TensorStore]
    end

    CP --&gt; Create
    CPS --&gt; List
    RB --&gt; Rollback

    Create --&gt; CS
    Create --&gt; RM
    List --&gt; CS
    Rollback --&gt; CS
    Delete --&gt; CS

    Confirm --&gt; PG
    Preview --&gt; PG

    CS --&gt; Blob
    Create --&gt; Store
    Rollback --&gt; Store
</pre>
<h3 id="checkpoint-creation-flow"><a class="header" href="#checkpoint-creation-flow">Checkpoint Creation Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant User
    participant Manager as CheckpointManager
    participant Store as TensorStore
    participant Storage as CheckpointStorage
    participant Retention as RetentionManager
    participant Blob as BlobStore

    User-&gt;&gt;Manager: create(name, store)
    Manager-&gt;&gt;Manager: Generate UUID
    Manager-&gt;&gt;Manager: collect_metadata(store)
    Manager-&gt;&gt;Store: snapshot_bytes()
    Store--&gt;&gt;Manager: Vec&lt;u8&gt;
    Manager-&gt;&gt;Manager: Create CheckpointState
    Manager-&gt;&gt;Storage: store(state, blob)
    Storage-&gt;&gt;Storage: bincode::serialize(state)
    Storage-&gt;&gt;Blob: put(filename, data, options)
    Blob--&gt;&gt;Storage: artifact_id
    Storage--&gt;&gt;Manager: artifact_id
    Manager-&gt;&gt;Retention: enforce(blob)
    Retention-&gt;&gt;Storage: list(blob)
    Storage--&gt;&gt;Retention: Vec&lt;CheckpointInfo&gt;
    Retention-&gt;&gt;Retention: Sort by created_at DESC
    Retention-&gt;&gt;Storage: delete(oldest beyond limit)
    Retention--&gt;&gt;Manager: deleted_count
    Manager--&gt;&gt;User: checkpoint_id
</pre>
<h3 id="rollback-flow"><a class="header" href="#rollback-flow">Rollback Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant User
    participant Manager as CheckpointManager
    participant Storage as CheckpointStorage
    participant Blob as BlobStore
    participant Store as TensorStore

    User-&gt;&gt;Manager: rollback(id_or_name, store)
    Manager-&gt;&gt;Storage: load(id_or_name, blob)
    Storage-&gt;&gt;Storage: find_by_id_or_name()
    Storage-&gt;&gt;Storage: list() and match
    Storage-&gt;&gt;Blob: get(artifact_id)
    Blob--&gt;&gt;Storage: checkpoint_bytes
    Storage-&gt;&gt;Storage: bincode::deserialize()
    Storage--&gt;&gt;Manager: CheckpointState
    Manager-&gt;&gt;Store: restore_from_bytes(state.store_snapshot)
    Store-&gt;&gt;Store: SlabRouter::from_bytes()
    Store-&gt;&gt;Store: clear() current data
    Store-&gt;&gt;Store: copy all entries from new router
    Store--&gt;&gt;Manager: Ok(())
    Manager--&gt;&gt;User: Success
</pre>
<h2 id="storage-format-3"><a class="header" href="#storage-format-3">Storage Format</a></h2>
<p>Checkpoints are stored as blob artifacts using content-addressable storage:</p>
<div class="table-wrapper"><table><thead><tr><th>Property</th><th>Value</th></tr></thead><tbody>
<tr><td>Tag</td><td><code>_system:checkpoint</code></td></tr>
<tr><td>Content-Type</td><td><code>application/x-neumann-checkpoint</code></td></tr>
<tr><td>Format</td><td>bincode-serialized <code>CheckpointState</code></td></tr>
<tr><td>Filename</td><td><code>checkpoint_{id}.ncp</code></td></tr>
<tr><td>Creator</td><td><code>system:checkpoint</code></td></tr>
</tbody></table>
</div>
<h3 id="checkpoint-state-structure"><a class="header" href="#checkpoint-state-structure">Checkpoint State Structure</a></h3>
<p>The <code>CheckpointState</code> is serialized using bincode for efficient binary encoding:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Serialize, Deserialize)]
pub struct CheckpointState {
    pub id: String,           // UUID v4
    pub name: String,         // User-provided or auto-generated
    pub created_at: u64,      // Unix timestamp (seconds)
    pub trigger: Option&lt;CheckpointTrigger&gt;,  // For auto-checkpoints
    pub store_snapshot: Vec&lt;u8&gt;,  // Serialized SlabRouterSnapshot
    pub metadata: CheckpointMetadata,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="snapshot-serialization-format"><a class="header" href="#snapshot-serialization-format">Snapshot Serialization Format</a></h3>
<p>The <code>store_snapshot</code> field contains a V3 format snapshot:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// V3 snapshot structure (bincode serialized)
pub struct V3Snapshot {
    pub header: SnapshotHeader,     // Magic bytes, version, entry count
    pub router: SlabRouterSnapshot, // All slab data
}

pub struct SlabRouterSnapshot {
    pub index: EntityIndexSnapshot,      // Key-to-entity mapping
    pub embeddings: EmbeddingSlabSnapshot,
    pub graph: GraphTensorSnapshot,
    pub relations: RelationalSlabSnapshot,
    pub metadata: MetadataSlabSnapshot,
    pub cache: CacheRingSnapshot&lt;TensorData&gt;,
    pub blobs: BlobLogSnapshot,
}
<span class="boring">}</span></code></pre></pre>
<p>Custom metadata stored with each artifact:</p>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>checkpoint_id</code></td><td>String</td><td>UUID identifier</td></tr>
<tr><td><code>checkpoint_name</code></td><td>String</td><td>User-provided or auto-generated name</td></tr>
<tr><td><code>created_at</code></td><td>String</td><td>Unix timestamp (parsed to u64)</td></tr>
<tr><td><code>trigger</code></td><td>String</td><td>Operation name (for auto-checkpoints only)</td></tr>
</tbody></table>
</div>
<h3 id="metadata-collection-algorithm"><a class="header" href="#metadata-collection-algorithm">Metadata Collection Algorithm</a></h3>
<p>When creating a checkpoint, metadata is collected by scanning the store:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn collect_metadata(&amp;self, store: &amp;TensorStore) -&gt; CheckpointMetadata {
    let store_key_count = store.len();

    // Count relational tables by scanning _schema: prefix
    let table_keys: Vec&lt;_&gt; = store.scan("_schema:");
    let table_count = table_keys.len();
    let mut total_rows = 0;
    for key in &amp;table_keys {
        if let Some(table_name) = key.strip_prefix("_schema:") {
            total_rows += store.scan_count(&amp;format!("{table_name}:"));
        }
    }

    // Count graph entities
    let node_count = store.scan_count("node:");
    let edge_count = store.scan_count("edge:");

    // Count embeddings
    let embedding_count = store.scan_count("_embed:");

    CheckpointMetadata::new(
        RelationalMeta::new(table_count, total_rows),
        GraphMeta::new(node_count, edge_count),
        VectorMeta::new(embedding_count),
        store_key_count,
    )
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-6"><a class="header" href="#configuration-6">Configuration</a></h2>
<h3 id="checkpointconfig"><a class="header" href="#checkpointconfig">CheckpointConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>max_checkpoints</code></td><td><code>usize</code></td><td>10</td><td>Maximum checkpoints before pruning</td></tr>
<tr><td><code>auto_checkpoint</code></td><td><code>bool</code></td><td>true</td><td>Enable auto-checkpoints before destructive ops</td></tr>
<tr><td><code>interactive_confirm</code></td><td><code>bool</code></td><td>true</td><td>Require confirmation for destructive ops</td></tr>
<tr><td><code>preview_sample_size</code></td><td><code>usize</code></td><td>5</td><td>Number of sample rows in previews</td></tr>
</tbody></table>
</div>
<h3 id="builder-pattern"><a class="header" href="#builder-pattern">Builder Pattern</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = CheckpointConfig::default()
    .with_max_checkpoints(20)
    .with_auto_checkpoint(true)
    .with_interactive_confirm(false)
    .with_preview_sample_size(10);
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-presets-3"><a class="header" href="#configuration-presets-3">Configuration Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>max_checkpoints</th><th>auto_checkpoint</th><th>interactive_confirm</th><th>Use Case</th></tr></thead><tbody>
<tr><td>Default</td><td>10</td><td>true</td><td>true</td><td>Interactive CLI usage</td></tr>
<tr><td>Automated</td><td>20</td><td>true</td><td>false</td><td>Batch processing scripts</td></tr>
<tr><td>Minimal</td><td>3</td><td>false</td><td>false</td><td>Memory-constrained environments</td></tr>
<tr><td>Safe</td><td>50</td><td>true</td><td>true</td><td>Production with high retention</td></tr>
</tbody></table>
</div>
<h2 id="destructive-operations"><a class="header" href="#destructive-operations">Destructive Operations</a></h2>
<p>Operations that trigger auto-checkpoints when <code>auto_checkpoint</code> is enabled:</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Variant</th><th>Fields</th><th>Affected Count</th></tr></thead><tbody>
<tr><td>DELETE</td><td><code>Delete</code></td><td><code>table</code>, <code>row_count</code></td><td><code>row_count</code></td></tr>
<tr><td>DROP TABLE</td><td><code>DropTable</code></td><td><code>table</code>, <code>row_count</code></td><td><code>row_count</code></td></tr>
<tr><td>DROP INDEX</td><td><code>DropIndex</code></td><td><code>table</code>, <code>column</code></td><td>1</td></tr>
<tr><td>NODE DELETE</td><td><code>NodeDelete</code></td><td><code>node_id</code>, <code>edge_count</code></td><td>1 + <code>edge_count</code></td></tr>
<tr><td>EMBED DELETE</td><td><code>EmbedDelete</code></td><td><code>key</code></td><td>1</td></tr>
<tr><td>VAULT DELETE</td><td><code>VaultDelete</code></td><td><code>key</code></td><td>1</td></tr>
<tr><td>BLOB DELETE</td><td><code>BlobDelete</code></td><td><code>artifact_id</code>, <code>size</code></td><td>1</td></tr>
<tr><td>CACHE CLEAR</td><td><code>CacheClear</code></td><td><code>entry_count</code></td><td><code>entry_count</code></td></tr>
</tbody></table>
</div>
<h3 id="destructiveop-implementation"><a class="header" href="#destructiveop-implementation">DestructiveOp Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DestructiveOp {
    Delete { table: String, row_count: usize },
    DropTable { table: String, row_count: usize },
    DropIndex { table: String, column: String },
    NodeDelete { node_id: u64, edge_count: usize },
    EmbedDelete { key: String },
    VaultDelete { key: String },
    BlobDelete { artifact_id: String, size: usize },
    CacheClear { entry_count: usize },
}

impl DestructiveOp {
    pub fn operation_name(&amp;self) -&gt; &amp;'static str {
        match self {
            DestructiveOp::Delete { .. } =&gt; "DELETE",
            DestructiveOp::DropTable { .. } =&gt; "DROP TABLE",
            // ... etc
        }
    }

    pub fn affected_count(&amp;self) -&gt; usize {
        match self {
            DestructiveOp::Delete { row_count, .. } =&gt; *row_count,
            DestructiveOp::NodeDelete { edge_count, .. } =&gt; 1 + edge_count,
            DestructiveOp::DropIndex { .. } =&gt; 1,
            // ... etc
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="sql-commands"><a class="header" href="#sql-commands">SQL Commands</a></h2>
<h3 id="checkpoint"><a class="header" href="#checkpoint">CHECKPOINT</a></h3>
<pre><code class="language-sql">-- Named checkpoint
CHECKPOINT 'before-migration'

-- Auto-generated name (checkpoint-{timestamp})
CHECKPOINT
</code></pre>
<h3 id="checkpoints"><a class="header" href="#checkpoints">CHECKPOINTS</a></h3>
<pre><code class="language-sql">-- List all checkpoints
CHECKPOINTS

-- List last N checkpoints
CHECKPOINTS LIMIT 10
</code></pre>
<p>Returns: <code>ID</code>, <code>Name</code>, <code>Created</code>, <code>Type</code> (manual/auto)</p>
<h3 id="rollback-to"><a class="header" href="#rollback-to">ROLLBACK TO</a></h3>
<pre><code class="language-sql">-- By name
ROLLBACK TO 'checkpoint-name'

-- By ID
ROLLBACK TO 'uuid-string'
</code></pre>
<h2 id="api-reference-5"><a class="header" href="#api-reference-5">API Reference</a></h2>
<h3 id="checkpointmanager"><a class="header" href="#checkpointmanager">CheckpointManager</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl CheckpointManager {
    /// Create manager with blob storage and configuration
    pub async fn new(
        blob: Arc&lt;Mutex&lt;BlobStore&gt;&gt;,
        config: CheckpointConfig
    ) -&gt; Self;

    /// Create a manual checkpoint
    pub async fn create(
        &amp;self,
        name: Option&lt;&amp;str&gt;,
        store: &amp;TensorStore
    ) -&gt; Result&lt;String&gt;;

    /// Create an auto-checkpoint before destructive operation
    pub async fn create_auto(
        &amp;self,
        command: &amp;str,
        op: DestructiveOp,
        preview: OperationPreview,
        store: &amp;TensorStore
    ) -&gt; Result&lt;String&gt;;

    /// Rollback to a checkpoint by ID or name
    pub async fn rollback(
        &amp;self,
        id_or_name: &amp;str,
        store: &amp;TensorStore
    ) -&gt; Result&lt;()&gt;;

    /// List checkpoints, most recent first
    pub async fn list(
        &amp;self,
        limit: Option&lt;usize&gt;
    ) -&gt; Result&lt;Vec&lt;CheckpointInfo&gt;&gt;;

    /// Delete a checkpoint by ID or name
    pub async fn delete(&amp;self, id_or_name: &amp;str) -&gt; Result&lt;()&gt;;

    /// Generate preview for a destructive operation
    pub fn generate_preview(
        &amp;self,
        op: &amp;DestructiveOp,
        sample_data: Vec&lt;String&gt;
    ) -&gt; OperationPreview;

    /// Request user confirmation for an operation
    pub fn request_confirmation(
        &amp;self,
        op: &amp;DestructiveOp,
        preview: &amp;OperationPreview
    ) -&gt; bool;

    /// Set custom confirmation handler
    pub fn set_confirmation_handler(
        &amp;mut self,
        handler: Arc&lt;dyn ConfirmationHandler&gt;
    );

    /// Check if auto-checkpoint is enabled
    pub fn auto_checkpoint_enabled(&amp;self) -&gt; bool;

    /// Check if interactive confirmation is enabled
    pub fn interactive_confirm_enabled(&amp;self) -&gt; bool;

    /// Access the current configuration
    pub fn config(&amp;self) -&gt; &amp;CheckpointConfig;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="confirmationhandler"><a class="header" href="#confirmationhandler">ConfirmationHandler</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait ConfirmationHandler: Send + Sync {
    fn confirm(&amp;self, op: &amp;DestructiveOp, preview: &amp;OperationPreview) -&gt; bool;
}
<span class="boring">}</span></code></pre></pre>
<p>Built-in implementations:</p>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Behavior</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>AutoConfirm</code></td><td>Always returns true</td><td>Automated scripts, testing</td></tr>
<tr><td><code>AutoReject</code></td><td>Always returns false</td><td>Testing cancellation paths</td></tr>
</tbody></table>
</div>
<h3 id="checkpointstorage"><a class="header" href="#checkpointstorage">CheckpointStorage</a></h3>
<p>Internal storage layer for checkpoint persistence:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl CheckpointStorage {
    /// Store a checkpoint state to blob storage
    pub async fn store(state: &amp;CheckpointState, blob: &amp;BlobStore) -&gt; Result&lt;String&gt;;

    /// Load a checkpoint by ID or name
    pub async fn load(checkpoint_id: &amp;str, blob: &amp;BlobStore) -&gt; Result&lt;CheckpointState&gt;;

    /// List all checkpoints (sorted by created_at descending)
    pub async fn list(blob: &amp;BlobStore) -&gt; Result&lt;Vec&lt;CheckpointInfo&gt;&gt;;

    /// Delete a checkpoint by artifact ID
    pub async fn delete(artifact_id: &amp;str, blob: &amp;BlobStore) -&gt; Result&lt;()&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="previewgenerator"><a class="header" href="#previewgenerator">PreviewGenerator</a></h3>
<p>Generates human-readable previews for destructive operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl PreviewGenerator {
    pub fn new(sample_size: usize) -&gt; Self;

    pub fn generate(&amp;self, op: &amp;DestructiveOp, sample_data: Vec&lt;String&gt;) -&gt; OperationPreview;
}

// Utility functions
pub fn format_warning(op: &amp;DestructiveOp) -&gt; String;
pub fn format_confirmation_prompt(op: &amp;DestructiveOp, preview: &amp;OperationPreview) -&gt; String;
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples-7"><a class="header" href="#usage-examples-7">Usage Examples</a></h2>
<h3 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_checkpoint::{CheckpointManager, CheckpointConfig};
use tensor_blob::{BlobStore, BlobConfig};
use tensor_store::TensorStore;

// Initialize
let store = TensorStore::new();
let blob = BlobStore::new(store.clone(), BlobConfig::default()).await?;
let blob = Arc::new(Mutex::new(blob));

let config = CheckpointConfig::default();
let manager = CheckpointManager::new(blob, config).await;

// Create checkpoint
let id = manager.create(Some("before-migration"), &amp;store).await?;

// ... make changes ...

// Rollback if needed
manager.rollback("before-migration", &amp;store).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="with-query-router"><a class="header" href="#with-query-router">With Query Router</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use query_router::QueryRouter;

let mut router = QueryRouter::new();
router.init_blob()?;
router.init_checkpoint()?;

// Execute checkpoint commands via SQL
router.execute_parsed("CHECKPOINT 'backup'")?;
router.execute_parsed("CHECKPOINTS")?;
router.execute_parsed("ROLLBACK TO 'backup'")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-confirmation-handler"><a class="header" href="#custom-confirmation-handler">Custom Confirmation Handler</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_checkpoint::{ConfirmationHandler, DestructiveOp, OperationPreview};
use std::io::{self, Write};

struct InteractiveHandler;

impl ConfirmationHandler for InteractiveHandler {
    fn confirm(&amp;self, op: &amp;DestructiveOp, preview: &amp;OperationPreview) -&gt; bool {
        println!("{}", tensor_checkpoint::format_confirmation_prompt(op, preview));
        io::stdout().flush().unwrap();

        let mut input = String::new();
        io::stdin().read_line(&amp;mut input).unwrap();
        input.trim().to_lowercase() == "yes"
    }
}

// Usage
manager.set_confirmation_handler(Arc::new(InteractiveHandler));
<span class="boring">}</span></code></pre></pre>
<h3 id="auto-checkpoint-with-rejection"><a class="header" href="#auto-checkpoint-with-rejection">Auto-Checkpoint with Rejection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_checkpoint::{AutoReject, CheckpointConfig};

// Create config with auto-checkpoint enabled
let config = CheckpointConfig::default()
    .with_auto_checkpoint(true)
    .with_interactive_confirm(true);

let mut manager = CheckpointManager::new(blob, config).await;
manager.set_confirmation_handler(Arc::new(AutoReject));

// DELETE will be rejected, no checkpoint created, operation cancelled
let result = router.execute("DELETE FROM users WHERE age &gt; 50");
assert!(result.is_err());  // Operation cancelled by user
<span class="boring">}</span></code></pre></pre>
<h2 id="retention-management"><a class="header" href="#retention-management">Retention Management</a></h2>
<p>Checkpoints are automatically pruned when <code>max_checkpoints</code> is exceeded:</p>
<h3 id="retention-algorithm"><a class="header" href="#retention-algorithm">Retention Algorithm</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn enforce(&amp;self, blob: &amp;BlobStore) -&gt; Result&lt;usize&gt; {
    let checkpoints = CheckpointStorage::list(blob).await?;

    if checkpoints.len() &lt;= self.max_checkpoints {
        return Ok(0);
    }

    let to_remove = checkpoints.len() - self.max_checkpoints;
    let mut removed = 0;

    // Checkpoints are sorted by created_at descending, oldest are at end
    for checkpoint in checkpoints.iter().rev().take(to_remove) {
        if CheckpointStorage::delete(&amp;checkpoint.artifact_id, blob)
            .await
            .is_ok()
        {
            removed += 1;
        }
    }

    Ok(removed)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="retention-timing"><a class="header" href="#retention-timing">Retention Timing</a></h3>
<p>Retention is enforced after every checkpoint creation:</p>
<ol>
<li>Create new checkpoint</li>
<li>Store in blob storage</li>
<li>Call <code>retention.enforce()</code></li>
<li>Return checkpoint ID</li>
</ol>
<p>This ensures the checkpoint count never exceeds <code>max_checkpoints + 1</code> at any
point.</p>
<h3 id="retention-edge-cases"><a class="header" href="#retention-edge-cases">Retention Edge Cases</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Scenario</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Creation fails</td><td>Retention not called, count unchanged</td></tr>
<tr><td>Retention delete fails</td><td>Logged but not fatal, continues deleting</td></tr>
<tr><td>max_checkpoints = 0</td><td>All checkpoints deleted after creation</td></tr>
<tr><td>max_checkpoints = 1</td><td>Only newest checkpoint retained</td></tr>
</tbody></table>
</div>
<h2 id="interactive-confirmation"><a class="header" href="#interactive-confirmation">Interactive Confirmation</a></h2>
<p>When <code>interactive_confirm</code> is enabled, destructive operations display a preview:</p>
<pre><code class="language-sql">WARNING: About to delete 5 row(s) from table 'users'
Will delete 5 row(s) from table 'users'

Affected data sample:
  1. id=1, name='Alice'
  2. id=2, name='Bob'
  ... and 3 more

Type 'yes' to proceed, anything else to cancel:
</code></pre>
<h3 id="preview-generation"><a class="header" href="#preview-generation">Preview Generation</a></h3>
<p>The preview generator formats human-readable summaries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_summary(&amp;self, op: &amp;DestructiveOp) -&gt; String {
    match op {
        DestructiveOp::Delete { table, row_count } =&gt; {
            format!("Will delete {row_count} row(s) from table '{table}'")
        },
        DestructiveOp::DropTable { table, row_count } =&gt; {
            format!("Will drop table '{table}' containing {row_count} row(s)")
        },
        DestructiveOp::BlobDelete { artifact_id, size } =&gt; {
            let size_str = format_bytes(*size);
            format!("Will delete blob artifact '{artifact_id}' ({size_str})")
        },
        // ... etc
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="size-formatting"><a class="header" href="#size-formatting">Size Formatting</a></h3>
<p>Blob sizes are formatted for readability:</p>
<div class="table-wrapper"><table><thead><tr><th>Bytes</th><th>Display</th></tr></thead><tbody>
<tr><td>&lt; 1024</td><td>“N bytes”</td></tr>
<tr><td>&gt;= 1 KB</td><td>“N.NN KB”</td></tr>
<tr><td>&gt;= 1 MB</td><td>“N.NN MB”</td></tr>
<tr><td>&gt;= 1 GB</td><td>“N.NN GB”</td></tr>
</tbody></table>
</div>
<h2 id="rollback-algorithm"><a class="header" href="#rollback-algorithm">Rollback Algorithm</a></h2>
<p>The rollback process completely replaces the store contents:</p>
<h3 id="algorithm-steps"><a class="header" href="#algorithm-steps">Algorithm Steps</a></h3>
<ol>
<li><strong>Locate Checkpoint</strong>: Search by ID first, then by name</li>
<li><strong>Load State</strong>: Deserialize <code>CheckpointState</code> from blob storage</li>
<li><strong>Deserialize Snapshot</strong>: Convert <code>store_snapshot</code> bytes to <code>SlabRouter</code></li>
<li><strong>Clear Current Data</strong>: Remove all entries from current store</li>
<li><strong>Copy Restored Data</strong>: Iterate and copy all entries from restored router</li>
</ol>
<h3 id="rollback-implementation"><a class="header" href="#rollback-implementation">Rollback Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub async fn rollback(&amp;self, id_or_name: &amp;str, store: &amp;TensorStore) -&gt; Result&lt;()&gt; {
    let blob = self.blob.lock().await;
    let state = CheckpointStorage::load(id_or_name, &amp;blob).await?;

    store
        .restore_from_bytes(&amp;state.store_snapshot)
        .map_err(|e| CheckpointError::Snapshot(e.to_string()))?;

    Ok(())
}

// In TensorStore
pub fn restore_from_bytes(&amp;self, bytes: &amp;[u8]) -&gt; SnapshotResult&lt;()&gt; {
    let new_router = SlabRouter::from_bytes(bytes)?;

    // Clear current and copy data from new router
    self.router.clear();
    for key in new_router.scan("") {
        if let Ok(value) = new_router.get(&amp;key) {
            let _ = self.router.put(&amp;key, value);
        }
    }

    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="rollback-characteristics"><a class="header" href="#rollback-characteristics">Rollback Characteristics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Atomicity</td><td>Not atomic - partial restore possible on failure</td></tr>
<tr><td>Isolation</td><td>No locking - concurrent operations may see partial state</td></tr>
<tr><td>Duration</td><td>O(n) where n = number of entries</td></tr>
<tr><td>Memory</td><td>Requires 2x memory during restore (old + new)</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas-8"><a class="header" href="#edge-cases-and-gotchas-8">Edge Cases and Gotchas</a></h2>
<h3 id="name-vs-id-lookup"><a class="header" href="#name-vs-id-lookup">Name vs ID Lookup</a></h3>
<p>Checkpoints can be referenced by either name or ID:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn find_by_id_or_name(id_or_name: &amp;str, blob: &amp;BlobStore) -&gt; Result&lt;String&gt; {
    let checkpoints = Self::list(blob).await?;

    for cp in checkpoints {
        // Exact match on ID or name
        if cp.id == id_or_name || cp.name == id_or_name {
            return Ok(cp.artifact_id);
        }
    }

    Err(CheckpointError::NotFound(id_or_name.to_string()))
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Gotcha</strong>: If a checkpoint is named with a valid UUID format, it may conflict
with ID lookup.</p>
<h3 id="auto-generated-names"><a class="header" href="#auto-generated-names">Auto-Generated Names</a></h3>
<p>When no name is provided:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let name = name.map(String::from).unwrap_or_else(|| {
    let now = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map(|d| d.as_secs())
        .unwrap_or(0);
    format!("checkpoint-{now}")
});
<span class="boring">}</span></code></pre></pre>
<p>Auto-checkpoint names follow the pattern: <code>auto-before-{operation-name}</code></p>
<h3 id="timestamp-edge-cases"><a class="header" href="#timestamp-edge-cases">Timestamp Edge Cases</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Scenario</th><th>Behavior</th></tr></thead><tbody>
<tr><td>System time before epoch</td><td>Timestamp becomes 0</td></tr>
<tr><td>Rapid checkpoint creation</td><td>May have same second timestamp</td></tr>
<tr><td>Clock drift</td><td>Checkpoints may be out of order</td></tr>
</tbody></table>
</div>
<h3 id="blob-store-dependency"><a class="header" href="#blob-store-dependency">Blob Store Dependency</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn init_checkpoint(&amp;mut self) -&gt; Result&lt;()&gt; {
    self.init_checkpoint_with_config(CheckpointConfig::default())
}

pub fn init_checkpoint_with_config(&amp;mut self, config: CheckpointConfig) -&gt; Result&lt;()&gt; {
    let blob = self
        .blob
        .as_ref()
        .ok_or_else(|| {
            RouterError::CheckpointError(
                "Blob store must be initialized first".to_string()
            )
        })?;
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Gotcha</strong>: Always call <code>init_blob()</code> before <code>init_checkpoint()</code>.</p>
<h2 id="performance-tips"><a class="header" href="#performance-tips">Performance Tips</a></h2>
<h3 id="checkpoint-creation-performance"><a class="header" href="#checkpoint-creation-performance">Checkpoint Creation Performance</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Factor</th><th>Impact</th><th>Recommendation</th></tr></thead><tbody>
<tr><td>Store size</td><td>O(n) serialization</td><td>Keep hot data separate</td></tr>
<tr><td>Retention limit</td><td>More deletions on creation</td><td>Set appropriate <code>max_checkpoints</code></td></tr>
<tr><td>Blob storage</td><td>Network latency for remote</td><td>Use local storage for fast checkpoints</td></tr>
</tbody></table>
</div>
<h3 id="memory-considerations"><a class="header" href="#memory-considerations">Memory Considerations</a></h3>
<ul>
<li>Full snapshot is held in memory during creation</li>
<li>Rollback requires 2x memory temporarily</li>
<li>Large embeddings significantly increase checkpoint size</li>
</ul>
<h3 id="optimization-strategies"><a class="header" href="#optimization-strategies">Optimization Strategies</a></h3>
<ol>
<li>
<p><strong>Incremental Checkpoints</strong> (not yet supported)</p>
<ul>
<li>Currently full snapshots only</li>
<li>Future: delta-based checkpoints</li>
</ul>
</li>
<li>
<p><strong>Selective Checkpointing</strong></p>
<ul>
<li>Use separate stores for hot vs. cold data</li>
<li>Only checkpoint critical data</li>
</ul>
</li>
<li>
<p><strong>Compression</strong></p>
<ul>
<li>TensorStore supports compressed snapshots for file I/O</li>
<li>Checkpoint uses bincode (no compression)</li>
</ul>
</li>
</ol>
<h3 id="benchmarks"><a class="header" href="#benchmarks">Benchmarks</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Store Size</th><th>Checkpoint Time</th><th>Rollback Time</th><th>Memory</th></tr></thead><tbody>
<tr><td>1K entries</td><td>~5ms</td><td>~3ms</td><td>~100KB</td></tr>
<tr><td>10K entries</td><td>~50ms</td><td>~30ms</td><td>~1MB</td></tr>
<tr><td>100K entries</td><td>~500ms</td><td>~300ms</td><td>~10MB</td></tr>
<tr><td>1M entries</td><td>~5s</td><td>~3s</td><td>~100MB</td></tr>
</tbody></table>
</div>
<h2 id="related-modules-8"><a class="header" href="#related-modules-8">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>tensor_blob</code></td><td>Storage backend for checkpoint data</td></tr>
<tr><td><code>tensor_store</code></td><td>Source of snapshots and restore target</td></tr>
<tr><td><code>query_router</code></td><td>SQL command integration</td></tr>
<tr><td><code>neumann_shell</code></td><td>Interactive confirmation handling</td></tr>
</tbody></table>
</div>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<ul>
<li>Full snapshots only (no incremental checkpoints)</li>
<li>Single-node operation (no distributed checkpoints)</li>
<li>In-memory restore (entire snapshot loaded)</li>
<li>No automatic scheduling (manual or trigger-based only)</li>
<li>Not atomic (partial restore possible on failure)</li>
<li>No encryption (checkpoints stored in plaintext)</li>
<li>Bloom filter state not preserved (rebuilt on load if needed)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-unified"><a class="header" href="#tensor-unified">Tensor Unified</a></h1>
<p>Cross-engine operations and unified entity management for Neumann. Provides a
single interface for queries that span relational, graph, and vector engines
with async-first design and thread safety inherited from TensorStore.</p>
<h2 id="design-principles-5"><a class="header" href="#design-principles-5">Design Principles</a></h2>
<ol>
<li><strong>Cross-Engine Abstraction</strong>: Single interface for operations spanning
multiple engines</li>
<li><strong>Unified Entities</strong>: Entities can have relational fields, graph connections,
and embeddings</li>
<li><strong>Composable Queries</strong>: Combine vector similarity with graph connectivity</li>
<li><strong>Async-First</strong>: All cross-engine operations support async execution</li>
<li><strong>Thread Safety</strong>: Inherits from underlying engines via TensorStore</li>
</ol>
<h2 id="architecture-8"><a class="header" href="#architecture-8">Architecture</a></h2>
<pre><code class="language-text">                    +------------------+
                    | UnifiedEngine    |
                    +------------------+
                           |
        +------------------+------------------+
        |                  |                  |
        v                  v                  v
+---------------+  +---------------+  +---------------+
|  Relational   |  |    Graph      |  |    Vector     |
|    Engine     |  |    Engine     |  |    Engine     |
+---------------+  +---------------+  +---------------+
        |                  |                  |
        +------------------+------------------+
                           |
                    +------v------+
                    | TensorStore |
                    +-------------+
</code></pre>
<p>All engines share the same TensorStore instance, enabling cross-engine queries
without data duplication.</p>
<h3 id="internal-engine-coordination"><a class="header" href="#internal-engine-coordination">Internal Engine Coordination</a></h3>
<pre class="mermaid">sequenceDiagram
    participant Client
    participant UnifiedEngine
    participant VectorEngine
    participant GraphEngine
    participant TensorStore

    Client-&gt;&gt;UnifiedEngine: create_entity(&quot;user:1&quot;, fields, embedding)
    UnifiedEngine-&gt;&gt;VectorEngine: set_entity_embedding(&quot;user:1&quot;, embedding)
    VectorEngine-&gt;&gt;TensorStore: put(&quot;user:1&quot;, TensorData{_embedding: ...})
    UnifiedEngine-&gt;&gt;TensorStore: get(&quot;user:1&quot;)
    TensorStore--&gt;&gt;UnifiedEngine: TensorData
    UnifiedEngine-&gt;&gt;TensorStore: put(&quot;user:1&quot;, TensorData{fields + _embedding})
    UnifiedEngine--&gt;&gt;Client: Ok(())
</pre>
<h2 id="key-types-9"><a class="header" href="#key-types-9">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>UnifiedEngine</code></td><td>Main entry point for cross-engine operations</td></tr>
<tr><td><code>UnifiedResult</code></td><td>Query result containing description and items</td></tr>
<tr><td><code>UnifiedItem</code></td><td>Single item with source, id, data, embedding, and score</td></tr>
<tr><td><code>UnifiedError</code></td><td>Error type wrapping engine-specific errors</td></tr>
<tr><td><code>FindPattern</code></td><td>Pattern for FIND queries (Nodes or Edges)</td></tr>
<tr><td><code>DistanceMetric</code></td><td>Similarity metric (Cosine, Euclidean, DotProduct)</td></tr>
<tr><td><code>EntityInput</code></td><td>Tuple type for batch operations: (key, fields, embedding)</td></tr>
<tr><td><code>Unified</code></td><td>Trait for converting engine types to UnifiedItem</td></tr>
<tr><td><code>FilterCondition</code></td><td>Re-exported from vector_engine for filtered search</td></tr>
<tr><td><code>FilterValue</code></td><td>Re-exported from vector_engine for filter values</td></tr>
<tr><td><code>VectorCollectionConfig</code></td><td>Re-exported from vector_engine for collection config</td></tr>
</tbody></table>
</div>
<h3 id="unifieditem"><a class="header" href="#unifieditem">UnifiedItem</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct UnifiedItem {
    pub source: String,                    // "relational", "graph", "vector", or combined
    pub id: String,                        // Entity key
    pub data: HashMap&lt;String, String&gt;,     // Entity fields
    pub embedding: Option&lt;Vec&lt;f32&gt;&gt;,       // Optional embedding
    pub score: Option&lt;f32&gt;,                // Similarity score if applicable
}
<span class="boring">}</span></code></pre></pre>
<p>The <code>source</code> field indicates which engine(s) produced the result:</p>
<ul>
<li><code>"graph"</code> - Result from graph operations (nodes, edges)</li>
<li><code>"vector"</code> - Result from vector similarity search</li>
<li><code>"unified"</code> - Result from cross-engine entity retrieval</li>
<li><code>"vector+graph"</code> - Result from <code>find_similar_connected</code> (similarity +
connectivity)</li>
<li><code>"graph+vector"</code> - Result from <code>find_neighbors_by_similarity</code> (connectivity +
similarity)</li>
</ul>
<h3 id="unifiederror"><a class="header" href="#unifiederror">UnifiedError</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Cause</th></tr></thead><tbody>
<tr><td><code>RelationalError</code></td><td>Error from relational engine</td></tr>
<tr><td><code>GraphError</code></td><td>Error from graph engine</td></tr>
<tr><td><code>VectorError</code></td><td>Error from vector engine</td></tr>
<tr><td><code>NotFound</code></td><td>Entity not found</td></tr>
<tr><td><code>InvalidOperation</code></td><td>Invalid operation attempted</td></tr>
</tbody></table>
</div>
<p>Error conversion is automatic via <code>From</code> implementations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl From&lt;graph_engine::GraphError&gt; for UnifiedError {
    fn from(e: graph_engine::GraphError) -&gt; Self {
        UnifiedError::GraphError(e.to_string())
    }
}

impl From&lt;vector_engine::VectorError&gt; for UnifiedError {
    fn from(e: vector_engine::VectorError) -&gt; Self {
        UnifiedError::VectorError(e.to_string())
    }
}

impl From&lt;relational_engine::RelationalError&gt; for UnifiedError {
    fn from(e: relational_engine::RelationalError) -&gt; Self {
        UnifiedError::RelationalError(e.to_string())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="entity-storage-format"><a class="header" href="#entity-storage-format">Entity Storage Format</a></h2>
<p>Unified entities use reserved field prefixes in <code>TensorData</code> to store
cross-engine data within a single key-value entry:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>_out</code></td><td><code>Pointers(Vec&lt;String&gt;)</code></td><td>Outgoing edge keys</td></tr>
<tr><td><code>_in</code></td><td><code>Pointers(Vec&lt;String&gt;)</code></td><td>Incoming edge keys</td></tr>
<tr><td><code>_embedding</code></td><td><code>Vector(Vec&lt;f32&gt;)</code> or <code>Sparse(SparseVector)</code></td><td>Embedding vector</td></tr>
<tr><td><code>_label</code></td><td><code>Scalar(String)</code></td><td>Entity type/label</td></tr>
<tr><td><code>_type</code></td><td><code>Scalar(String)</code></td><td>Discriminator (“node”, “edge”, “row”)</td></tr>
<tr><td><code>_id</code></td><td><code>Scalar(Int)</code></td><td>Numeric entity ID</td></tr>
<tr><td><code>_from</code></td><td><code>Scalar(String)</code></td><td>Edge source key</td></tr>
<tr><td><code>_to</code></td><td><code>Scalar(String)</code></td><td>Edge target key</td></tr>
<tr><td><code>_edge_type</code></td><td><code>Scalar(String)</code></td><td>Edge type</td></tr>
<tr><td><code>_directed</code></td><td><code>Scalar(Bool)</code></td><td>Whether edge is directed</td></tr>
<tr><td><code>_table</code></td><td><code>Scalar(String)</code></td><td>Table name for relational rows</td></tr>
</tbody></table>
</div>
<h3 id="entity-storage-example"><a class="header" href="#entity-storage-example">Entity Storage Example</a></h3>
<pre><code class="language-text">Key: "user:alice"
TensorData:
  _embedding: Vector([0.1, 0.2, 0.3, 0.4])
  _out: Pointers(["edge:follows:1", "edge:likes:2"])
  _in: Pointers(["edge:follows:3"])
  name: Scalar(String("Alice"))
  role: Scalar(String("admin"))

Key: "edge:follows:1"
TensorData:
  _type: Scalar(String("edge"))
  _from: Scalar(String("user:alice"))
  _to: Scalar(String("user:bob"))
  _edge_type: Scalar(String("follows"))
  _directed: Scalar(Bool(true))
</code></pre>
<h3 id="sparse-vector-auto-detection"><a class="header" href="#sparse-vector-auto-detection">Sparse Vector Auto-Detection</a></h3>
<p>Embeddings are automatically stored in sparse format when &gt;50% of values are
zero:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn should_use_sparse(vector: &amp;[f32]) -&gt; bool {
    if vector.is_empty() {
        return false;
    }
    let nnz = vector.iter().filter(|&amp;&amp;v| v.abs() &gt; 1e-6).count();
    // Sparse if nnz &lt;= len/2
    nnz * 2 &lt;= vector.len()
}
<span class="boring">}</span></code></pre></pre>
<h2 id="initialization"><a class="header" href="#initialization">Initialization</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_unified::UnifiedEngine;
use tensor_store::TensorStore;

// Create with new store
let engine = UnifiedEngine::new();

// Create with shared store
let store = TensorStore::new();
let engine = UnifiedEngine::with_store(store);

// Create with existing engines
let engine = UnifiedEngine::with_engines(store, relational, graph, vector);
<span class="boring">}</span></code></pre></pre>
<h3 id="internal-structure-1"><a class="header" href="#internal-structure-1">Internal Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct UnifiedEngine {
    store: TensorStore,
    relational: Arc&lt;RelationalEngine&gt;,
    graph: Arc&lt;GraphEngine&gt;,
    vector: Arc&lt;VectorEngine&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>The <code>Arc</code> wrappers enable:</p>
<ul>
<li>Thread-safe sharing across async tasks</li>
<li>Zero-copy cloning of the engine</li>
<li>Independent engine access when needed</li>
</ul>
<h2 id="entity-operations"><a class="header" href="#entity-operations">Entity Operations</a></h2>
<h3 id="creating-entities"><a class="header" href="#creating-entities">Creating Entities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::collections::HashMap;

// Create an entity with fields and optional embedding
let mut fields = HashMap::new();
fields.insert("name".to_string(), "Alice".to_string());
fields.insert("role".to_string(), "admin".to_string());

engine.create_entity(
    "user:1",
    fields,
    Some(vec![0.1, 0.2, 0.3, 0.4])  // Optional embedding
).await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Internal flow:</strong></p>
<pre class="mermaid">flowchart TD
    A[create_entity] --&gt; B{Has embedding?}
    B --&gt;|Yes| C[VectorEngine::set_entity_embedding]
    C --&gt; D[Store to TensorData._embedding]
    B --&gt;|No| E[Get existing TensorData or new]
    D --&gt; E
    E --&gt; F[For each field]
    F --&gt; G[Set field as TensorValue::Scalar]
    G --&gt; H[TensorStore::put]
</pre>
<h3 id="connecting-entities"><a class="header" href="#connecting-entities">Connecting Entities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Connect entities via graph edge
let edge_id = engine.connect_entities("user:1", "user:2", "follows").await?;
<span class="boring">}</span></code></pre></pre>
<p>Edge creation updates three TensorData entries:</p>
<ol>
<li>Creates new edge entry with <code>_from</code>, <code>_to</code>, <code>_edge_type</code>, <code>_directed</code></li>
<li>Adds edge key to source entity’s <code>_out</code> field</li>
<li>Adds edge key to target entity’s <code>_in</code> field</li>
</ol>
<h3 id="retrieving-entities"><a class="header" href="#retrieving-entities">Retrieving Entities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get entity with all data and embedding
let item = engine.get_entity("user:1").await?;
println!("Fields: {:?}", item.data);
println!("Embedding: {:?}", item.embedding);
<span class="boring">}</span></code></pre></pre>
<p><strong>Gotcha:</strong> Returns <code>UnifiedError::NotFound</code> if the entity has neither fields
nor embedding.</p>
<h2 id="cross-engine-queries"><a class="header" href="#cross-engine-queries">Cross-Engine Queries</a></h2>
<h3 id="find-similar-connected"><a class="header" href="#find-similar-connected">Find Similar Connected</a></h3>
<p>Find entities similar to a query that are also connected via graph edges:</p>
<pre class="mermaid">flowchart LR
    A[Query Entity] --&gt; B[Get embedding]
    B --&gt; C[Vector search top_k*2]
    C --&gt; D[Get connected neighbors]
    D --&gt; E[HashSet intersection]
    E --&gt; F[Take top_k]
    F --&gt; G[Return UnifiedItems]
</pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find entities similar to query AND connected to target
let results = engine.find_similar_connected(
    "user:1",      // Query entity (uses its embedding)
    "hub:main",    // Find entities connected to this
    10             // Top-k results
).await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Algorithm details:</strong></p>
<ol>
<li>Retrieves embedding from <code>query_key</code> via <code>VectorEngine::get_entity_embedding</code></li>
<li>Searches for top <code>k*2</code> similar entities (over-fetches for filtering)</li>
<li>Gets neighbors of <code>connected_to</code> via <code>GraphEngine::get_entity_neighbors</code></li>
<li>Builds HashSet of connected neighbors for O(1) lookup</li>
<li>Filters similar results to only those in the neighbor set</li>
<li>Returns top-k results with source <code>"vector+graph"</code></li>
</ol>
<p><strong>Edge case:</strong> If <code>query_key</code> has no embedding, returns <code>VectorError::NotFound</code>.</p>
<h3 id="find-similar-connected-with-filter"><a class="header" href="#find-similar-connected-with-filter">Find Similar Connected with Filter</a></h3>
<p>Enhanced version that combines vector similarity, graph connectivity, and
metadata filtering:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::{FilterCondition, FilterValue};

// Build a filter for metadata
let filter = FilterCondition::Eq(
    "category".to_string(),
    FilterValue::String("article".to_string())
);

// Find entities similar to query, connected to hub, matching filter
let results = engine.find_similar_connected_filtered(
    "user:1",      // Query entity (uses its embedding)
    "hub:main",    // Find entities connected to this
    Some(&amp;filter), // Optional metadata filter
    10             // Top-k results
).await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Algorithm:</strong></p>
<ol>
<li>Gets query embedding from <code>query_key</code></li>
<li>Gets connected neighbor keys from graph</li>
<li>Builds combined filter: <code>key IN neighbors AND user_filter</code></li>
<li>Uses pre-filter strategy for high selectivity</li>
<li>Returns filtered results with source <code>"vector+graph"</code></li>
</ol>
<p>The filtered version eliminates post-processing by pushing filters into the
vector search, improving performance for selective queries.</p>
<h3 id="find-neighbors-by-similarity"><a class="header" href="#find-neighbors-by-similarity">Find Neighbors by Similarity</a></h3>
<p>Find graph neighbors sorted by similarity to a query vector:</p>
<pre class="mermaid">flowchart LR
    A[Entity Key] --&gt; B[Get neighbors via graph]
    B --&gt; C[For each neighbor]
    C --&gt; D[Get embedding]
    D --&gt; E{Dimension match?}
    E --&gt;|Yes| F[Compute cosine similarity]
    E --&gt;|No| G[Skip]
    F --&gt; H[Collect results]
    H --&gt; I[Sort by score desc]
    I --&gt; J[Truncate to top_k]
</pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find neighbors of an entity sorted by similarity to a vector
let results = engine.find_neighbors_by_similarity(
    "user:1",                    // Entity to get neighbors of
    &amp;[0.1, 0.2, 0.3, 0.4],      // Query vector
    10                           // Top-k results
).await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Algorithm details:</strong></p>
<ol>
<li>Gets all neighbors (both directions) via <code>GraphEngine::get_entity_neighbors</code></li>
<li>For each neighbor:
<ul>
<li>Attempts to get embedding via <code>VectorEngine::get_entity_embedding</code></li>
<li>Skips if no embedding or dimension mismatch</li>
<li>Computes cosine similarity with query vector</li>
</ul>
</li>
<li>Sorts results by score descending</li>
<li>Truncates to top-k</li>
<li>Returns results with source <code>"graph+vector"</code></li>
</ol>
<p><strong>Gotcha:</strong> Neighbors without embeddings are silently skipped.</p>
<h2 id="unified-entity-storage"><a class="header" href="#unified-entity-storage">Unified Entity Storage</a></h2>
<p>The unified entity storage methods provide a streamlined API for storing entity
fields as vector metadata, eliminating double-storage overhead.</p>
<h3 id="creating-unified-entities"><a class="header" href="#creating-unified-entities">Creating Unified Entities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::collections::HashMap;

let mut fields = HashMap::new();
fields.insert("title".to_string(), "Introduction to Rust".to_string());
fields.insert("author".to_string(), "Alice".to_string());

// Store entity with fields as vector metadata
engine.create_entity_unified(
    "doc:1",
    fields,
    Some(vec![0.1, 0.2, 0.3, 0.4])
).await?;

// Without embedding, stores to TensorStore only
engine.create_entity_unified("doc:2", fields, None).await?;
<span class="boring">}</span></code></pre></pre>
<p>When an embedding is provided, fields are stored as vector metadata alongside
the embedding. This enables filtered search without requiring a separate storage
lookup.</p>
<h3 id="retrieving-unified-entities"><a class="header" href="#retrieving-unified-entities">Retrieving Unified Entities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Get entity with fields from vector metadata
let item = engine.get_entity_unified("doc:1").await?;

println!("Title: {:?}", item.data.get("title"));
println!("Embedding: {:?}", item.embedding);
<span class="boring">}</span></code></pre></pre>
<p>The retrieval first attempts to load from vector metadata. If not found, it
falls back to the standard TensorStore lookup.</p>
<h2 id="collection-based-entity-organization"><a class="header" href="#collection-based-entity-organization">Collection-Based Entity Organization</a></h2>
<p>Collections provide type-based organization for entities, enabling scoped
searches and dimension enforcement.</p>
<h3 id="creating-entities-in-collections"><a class="header" href="#creating-entities-in-collections">Creating Entities in Collections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::VectorCollectionConfig;
use std::collections::HashMap;

// Create a collection for documents
let config = VectorCollectionConfig::default()
    .with_dimension(768)
    .with_metric(DistanceMetric::Cosine);

engine.create_entity_collection("documents", config)?;

// Store entity in collection
let mut fields = HashMap::new();
fields.insert("title".to_string(), "ML Paper".to_string());

engine.create_entity_in_collection(
    "documents",
    "paper:1",
    fields,
    vec![0.1; 768]
).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="searching-in-collections-1"><a class="header" href="#searching-in-collections-1">Searching in Collections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::FilterCondition;

// Basic search in collection
let results = engine.find_similar_in_collection(
    "documents",
    &amp;query_embedding,
    None,  // No filter
    10
).await?;

// Filtered search in collection
let filter = FilterCondition::Eq("author".to_string(), "Alice".into());
let results = engine.find_similar_in_collection(
    "documents",
    &amp;query_embedding,
    Some(&amp;filter),
    10
).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="managing-collections"><a class="header" href="#managing-collections">Managing Collections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// List all entity collections
let collections = engine.list_entity_collections();

// Delete a collection
engine.delete_entity_collection("documents")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="collection-isolation"><a class="header" href="#collection-isolation">Collection Isolation</a></h3>
<p>Collections ensure entity isolation:</p>
<ul>
<li>Each collection has its own key namespace</li>
<li>Dimension mismatches are rejected per-collection config</li>
<li>Searches only see entities within the specified collection</li>
<li>Deleting a collection removes all entities in it</li>
</ul>
<h3 id="find-nodes-and-edges"><a class="header" href="#find-nodes-and-edges">Find Nodes and Edges</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find all nodes with optional label filter
let nodes = engine.find_nodes(Some("person"), None).await?;

// Find all edges with optional type filter
let edges = engine.find_edges(Some("follows"), None).await?;

// Find with pattern and limit
let pattern = FindPattern::Nodes { label: Some("document".to_string()) };
let result = engine.find(&amp;pattern, Some(10)).await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="find-pattern-matching-implementation"><a class="header" href="#find-pattern-matching-implementation">Find Pattern Matching Implementation</a></h2>
<p>The <code>find_nodes</code> and <code>find_edges</code> methods scan the TensorStore for matching
entities:</p>
<h3 id="node-scanning-algorithm"><a class="header" href="#node-scanning-algorithm">Node Scanning Algorithm</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn scan_nodes(&amp;self, label_filter: Option&lt;&amp;str&gt;) -&gt; Result&lt;Vec&lt;Node&gt;&gt; {
    let keys = self.store.scan("node:");  // Prefix scan

    for key in keys {
        // Filter out edge lists (node:123:out, node:123:in)
        if key.contains(":out") || key.contains(":in") {
            continue;
        }

        // Parse node ID from key "node:{id}"
        if let Some(id_str) = key.strip_prefix("node:") {
            if let Ok(id) = id_str.parse::&lt;u64&gt;() {
                // Fetch and optionally filter by label
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="condition-matching"><a class="header" href="#condition-matching">Condition Matching</a></h3>
<p>Conditions are evaluated against node/edge properties:</p>
<div class="table-wrapper"><table><thead><tr><th>Condition</th><th>Node Fields</th><th>Edge Fields</th></tr></thead><tbody>
<tr><td><code>Eq("id", ...)</code></td><td>Matches <code>node.id</code></td><td>Matches <code>edge.id</code></td></tr>
<tr><td><code>Eq("label", ...)</code></td><td>Matches <code>node.label</code></td><td>N/A</td></tr>
<tr><td><code>Eq("type", ...)</code></td><td>N/A</td><td>Matches <code>edge.edge_type</code></td></tr>
<tr><td><code>Eq("edge_type", ...)</code></td><td>N/A</td><td>Matches <code>edge.edge_type</code> (alias)</td></tr>
<tr><td><code>Eq("from", ...)</code></td><td>N/A</td><td>Matches <code>edge.from</code></td></tr>
<tr><td><code>Eq("to", ...)</code></td><td>N/A</td><td>Matches <code>edge.to</code></td></tr>
<tr><td><code>Eq(property, ...)</code></td><td>Matches <code>node.properties[property]</code></td><td>Matches <code>edge.properties[property]</code></td></tr>
<tr><td><code>And(a, b)</code></td><td>Both must match</td><td>Both must match</td></tr>
<tr><td><code>Or(a, b)</code></td><td>Either must match</td><td>Either must match</td></tr>
<tr><td>Other conditions</td><td>Returns <code>true</code> (pass-through)</td><td>Returns <code>true</code> (pass-through)</td></tr>
</tbody></table>
</div>
<p><strong>Gotcha:</strong> Conditions other than <code>Eq</code>, <code>And</code>, <code>Or</code> return <code>true</code> (not yet
implemented for graph entities).</p>
<h2 id="batch-operations-4"><a class="header" href="#batch-operations-4">Batch Operations</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Store multiple embeddings
let items = vec![
    ("doc1".to_string(), vec![0.1, 0.2, 0.3]),
    ("doc2".to_string(), vec![0.4, 0.5, 0.6]),
];
let count = engine.embed_batch(items).await?;

// Create multiple entities
let entities: Vec&lt;EntityInput&gt; = vec![
    ("e1".to_string(), HashMap::from([("name".to_string(), "A".to_string())]), None),
    ("e2".to_string(), HashMap::from([("name".to_string(), "B".to_string())]), Some(vec![0.1, 0.2])),
];
let count = engine.create_entities_batch(entities).await?;
<span class="boring">}</span></code></pre></pre>
<p><strong>Note:</strong> Batch operations process sequentially (not parallel). Failed
individual operations are counted as failures but don’t abort the batch.</p>
<h2 id="unified-trait"><a class="header" href="#unified-trait">Unified Trait</a></h2>
<p>Types implementing the <code>Unified</code> trait can be converted to <code>UnifiedItem</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Unified {
    fn as_unified(&amp;self) -&gt; UnifiedItem;
    fn source_engine(&amp;self) -&gt; &amp;'static str;
    fn unified_id(&amp;self) -&gt; String;
}
<span class="boring">}</span></code></pre></pre>
<p>Implemented for:</p>
<ul>
<li><code>graph_engine::Node</code> - Converts label and properties to data fields</li>
<li><code>graph_engine::Edge</code> - Converts from, to, type, and properties to data fields</li>
<li><code>vector_engine::SearchResult</code> - Converts key and score</li>
</ul>
<h3 id="implementation-examples"><a class="header" href="#implementation-examples">Implementation Examples</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Unified for Node {
    fn as_unified(&amp;self) -&gt; UnifiedItem {
        let mut item = UnifiedItem::new("graph", self.id.to_string());
        item.set("label", &amp;self.label);
        for (k, v) in &amp;self.properties {
            item.set(k.clone(), format!("{:?}", v));  // Debug format for PropertyValue
        }
        item
    }

    fn source_engine(&amp;self) -&gt; &amp;'static str { "graph" }
    fn unified_id(&amp;self) -&gt; String { self.id.to_string() }
}

impl Unified for SearchResult {
    fn as_unified(&amp;self) -&gt; UnifiedItem {
        UnifiedItem::new("vector", &amp;self.key).with_score(self.score)
    }

    fn source_engine(&amp;self) -&gt; &amp;'static str { "vector" }
    fn unified_id(&amp;self) -&gt; String { self.key.clone() }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="query-language"><a class="header" href="#query-language">Query Language</a></h2>
<p>Cross-engine operations are exposed via the query language:</p>
<h3 id="entity-creation"><a class="header" href="#entity-creation">Entity Creation</a></h3>
<pre><code class="language-sql">-- Create entity with fields and embedding
ENTITY CREATE 'user:1' {name: 'Alice', role: 'admin'} EMBEDDING [0.1, 0.2, 0.3]

-- Create entity with fields only
ENTITY CREATE 'user:2' {name: 'Bob'}

-- Connect entities
ENTITY CONNECT 'user:1' -&gt; 'user:2' : follows
</code></pre>
<h3 id="cross-engine-similarity"><a class="header" href="#cross-engine-similarity">Cross-Engine Similarity</a></h3>
<pre><code class="language-sql">-- Find similar entities that are also connected to a hub
SIMILAR 'query:key' CONNECTED TO 'hub:entity' LIMIT 10

-- Find neighbors sorted by similarity
NEIGHBORS 'entity:key' BY SIMILAR [0.1, 0.2, 0.3] LIMIT 10
</code></pre>
<h2 id="queryrouter-integration"><a class="header" href="#queryrouter-integration">QueryRouter Integration</a></h2>
<p>QueryRouter integrates with UnifiedEngine for cross-engine operations. When
created with <code>with_shared_store()</code>, the router automatically initializes an
internal UnifiedEngine:</p>
<pre class="mermaid">classDiagram
    class QueryRouter {
        -relational: Arc~RelationalEngine~
        -graph: Arc~GraphEngine~
        -vector: Arc~VectorEngine~
        -unified: Option~UnifiedEngine~
        -hnsw_index: Option~HNSWIndex~
        +with_shared_store(store) QueryRouter
        +unified() Option~UnifiedEngine~
        +find_similar_connected()
        +find_neighbors_by_similarity()
    }

    class UnifiedEngine {
        -store: TensorStore
        -relational: Arc~RelationalEngine~
        -graph: Arc~GraphEngine~
        -vector: Arc~VectorEngine~
    }

    QueryRouter --&gt; UnifiedEngine : contains
    QueryRouter --&gt; RelationalEngine : shares Arc
    QueryRouter --&gt; GraphEngine : shares Arc
    QueryRouter --&gt; VectorEngine : shares Arc
    UnifiedEngine --&gt; RelationalEngine : shares Arc
    UnifiedEngine --&gt; GraphEngine : shares Arc
    UnifiedEngine --&gt; VectorEngine : shares Arc
</pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use query_router::QueryRouter;
use tensor_store::TensorStore;

// Create router with shared store - this initializes UnifiedEngine
let store = TensorStore::new();
let router = QueryRouter::with_shared_store(store);

// Verify UnifiedEngine is available
assert!(router.unified().is_some());

// Cross-engine Rust API methods delegate to UnifiedEngine
let results = router.find_neighbors_by_similarity("entity:1", &amp;[0.1, 0.2], 10)?;
let results = router.find_similar_connected("query:1", "hub:1", 5)?;

// Query language commands also use the integrated engines
router.execute_parsed("ENTITY CREATE 'doc:1' {title: 'Hello'} EMBEDDING [0.1, 0.2]")?;
router.execute_parsed("ENTITY CONNECT 'user:1' -&gt; 'doc:1' : authored")?;
router.execute_parsed("SIMILAR 'query:doc' CONNECTED TO 'user:1' LIMIT 5")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="hnsw-optimization-path"><a class="header" href="#hnsw-optimization-path">HNSW Optimization Path</a></h3>
<p>When QueryRouter has an HNSW index, <code>find_similar_connected</code> uses it instead of
brute-force search:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use HNSW index if available, otherwise fall back to brute-force
let similar = if let Some((ref index, ref keys)) = self.hnsw_index {
    self.vector.search_with_hnsw(index, keys, &amp;query_embedding, top_k * 2)
} else {
    self.vector.search_entities(&amp;query_embedding, top_k * 2)
};
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-3"><a class="header" href="#performance-3">Performance</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>create_entity</code></td><td>O(1)</td><td>Single store put + optional embedding</td></tr>
<tr><td><code>connect_entities</code></td><td>O(1)</td><td>Three store operations (edge + 2 entity updates)</td></tr>
<tr><td><code>get_entity</code></td><td>O(1)</td><td>Single store get + optional embedding lookup</td></tr>
<tr><td><code>find_similar_connected</code></td><td>O(k log n)</td><td>HNSW search + graph intersection</td></tr>
<tr><td><code>find_similar_connected</code> (brute)</td><td>O(n)</td><td>Linear scan when no HNSW index</td></tr>
<tr><td><code>find_similar_connected_filtered</code></td><td>O(m)</td><td>Pre-filter search, m = matching keys</td></tr>
<tr><td><code>create_entity_unified</code></td><td>O(1)</td><td>Single store with metadata</td></tr>
<tr><td><code>get_entity_unified</code></td><td>O(1)</td><td>Metadata lookup with fallback</td></tr>
<tr><td><code>create_entity_in_collection</code></td><td>O(1)</td><td>Collection-scoped store</td></tr>
<tr><td><code>find_similar_in_collection</code></td><td>O(c)</td><td>c = collection size</td></tr>
<tr><td><code>find_neighbors_by_similarity</code></td><td>O(d * k)</td><td>Neighbor fetch + k similarity computations</td></tr>
<tr><td><code>find_nodes</code></td><td>O(n)</td><td>Full scan with prefix filter</td></tr>
<tr><td><code>find_edges</code></td><td>O(e)</td><td>Full scan with prefix filter</td></tr>
<tr><td><code>embed_batch</code></td><td>O(b)</td><td>Sequential embedding storage</td></tr>
<tr><td><code>create_entities_batch</code></td><td>O(b)</td><td>Sequential entity creation</td></tr>
</tbody></table>
</div>
<p>Where:</p>
<ul>
<li>n = number of entities with embeddings</li>
<li>d = average degree (number of neighbors)</li>
<li>k = top-k results requested</li>
<li>e = number of edges</li>
<li>b = batch size</li>
</ul>
<h3 id="benchmarks-1"><a class="header" href="#benchmarks-1">Benchmarks</a></h3>
<p>From <code>tensor_unified_bench.rs</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>10 items</th><th>100 items</th><th>1000 items</th></tr></thead><tbody>
<tr><td><code>create_entity</code></td><td>~50us</td><td>~500us</td><td>~5ms</td></tr>
<tr><td><code>embed_batch</code></td><td>~30us</td><td>~300us</td><td>~3ms</td></tr>
<tr><td><code>find_nodes</code></td><td>~10us</td><td>~100us</td><td>~1ms</td></tr>
<tr><td><code>UnifiedItem::new</code></td><td>~50ns</td><td>—</td><td>—</td></tr>
<tr><td><code>UnifiedItem::with_data</code></td><td>~200ns</td><td>—</td><td>—</td></tr>
</tbody></table>
</div>
<h2 id="thread-safety-1"><a class="header" href="#thread-safety-1">Thread Safety</a></h2>
<p>UnifiedEngine is thread-safe via:</p>
<ul>
<li><code>Arc&lt;VectorEngine&gt;</code>, <code>Arc&lt;GraphEngine&gt;</code>, <code>Arc&lt;RelationalEngine&gt;</code></li>
<li>All underlying engines share thread-safe TensorStore (DashMap)</li>
<li>No lock poisoning (parking_lot semantics)</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Clone for UnifiedEngine {
    fn clone(&amp;self) -&gt; Self {
        Self {
            store: self.store.clone(),           // Arc&lt;DashMap&gt; clone
            relational: Arc::clone(&amp;self.relational),
            graph: Arc::clone(&amp;self.graph),
            vector: Arc::clone(&amp;self.vector),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Safe concurrent patterns:</strong></p>
<ul>
<li>Multiple readers on same entity</li>
<li>Multiple writers on different entities</li>
<li>Mixed reads/writes (DashMap shard locking)</li>
</ul>
<p><strong>Gotcha:</strong> Concurrent writes to the same entity may interleave fields. Use
transactions for atomicity.</p>
<h2 id="configuration-7"><a class="header" href="#configuration-7">Configuration</a></h2>
<p>UnifiedEngine uses the configuration of its underlying engines:</p>
<ul>
<li><code>TensorStore</code>: Storage configuration</li>
<li><code>VectorEngine</code>: HNSW index parameters, similarity metrics</li>
<li><code>GraphEngine</code>: Graph traversal settings</li>
<li><code>RelationalEngine</code>: Table and index configuration</li>
</ul>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="entity-key-naming"><a class="header" href="#entity-key-naming">Entity Key Naming</a></h3>
<p>Use prefixed keys to distinguish entity types:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>"user:123"      // User entities
"doc:456"       // Document entities
"hub:main"      // Hub/aggregate entities
"edge:follows:1" // Edge entities (auto-generated)
<span class="boring">}</span></code></pre></pre>
<h3 id="embedding-dimensions"><a class="header" href="#embedding-dimensions">Embedding Dimensions</a></h3>
<p>Ensure consistent embedding dimensions across entities:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: All entities use 384-dimensional embeddings
engine.create_entity("doc:1", fields, Some(vec![0.0; 384])).await?;
engine.create_entity("doc:2", fields, Some(vec![0.0; 384])).await?;

// Bad: Dimension mismatch causes similarity search to skip entities
engine.create_entity("doc:1", fields, Some(vec![0.0; 384])).await?;
engine.create_entity("doc:2", fields, Some(vec![0.0; 768])).await?;  // Different dimension!
<span class="boring">}</span></code></pre></pre>
<h3 id="cross-engine-query-optimization"><a class="header" href="#cross-engine-query-optimization">Cross-Engine Query Optimization</a></h3>
<p>For <code>find_similar_connected</code>:</p>
<ol>
<li>Build HNSW index for large vector sets (&gt;5000 entities)</li>
<li>Ensure <code>connected_to</code> entity has edges (empty neighbors returns empty
results)</li>
<li>Request <code>top_k * 2</code> internally to account for filtering</li>
</ol>
<p>For <code>find_neighbors_by_similarity</code>:</p>
<ol>
<li>Ensure neighbors have embeddings (no embedding = skipped)</li>
<li>Use same dimension for query vector as stored embeddings</li>
<li>Consider degree distribution (high-degree nodes = more similarity
computations)</li>
</ol>
<h2 id="related-modules-9"><a class="header" href="#related-modules-9">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>Shared storage backend, provides <code>TensorData</code> and <code>fields</code> constants</td></tr>
<tr><td><code>relational_engine</code></td><td>Relational data, conditions for filtering</td></tr>
<tr><td><code>graph_engine</code></td><td>Graph connectivity, entity edges, neighbor queries</td></tr>
<tr><td><code>vector_engine</code></td><td>Embeddings, similarity search, HNSW index, <code>FilterCondition</code>, <code>FilterValue</code>, <code>VectorCollectionConfig</code></td></tr>
<tr><td><code>query_router</code></td><td>Query execution, language integration, HNSW optimization, re-exports filter types</td></tr>
</tbody></table>
</div>
<h2 id="dependencies-7"><a class="header" href="#dependencies-7">Dependencies</a></h2>
<ul>
<li><code>tensor_store</code>: Core storage</li>
<li><code>relational_engine</code>: Table operations</li>
<li><code>graph_engine</code>: Graph operations</li>
<li><code>vector_engine</code>: Vector search</li>
<li><code>tokio</code>: Async runtime (multi-threaded)</li>
<li><code>futures</code>: Async utilities</li>
<li><code>serde</code>: Serialization for results and items</li>
<li><code>serde_json</code>: JSON output for <code>UnifiedResult</code></li>
</ul>
<h2 id="example-code-intelligence-system"><a class="header" href="#example-code-intelligence-system">Example: Code Intelligence System</a></h2>
<p>From <code>examples/code_search.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust">use std::collections::HashMap;
use tensor_unified::UnifiedEngine;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let engine = UnifiedEngine::new();

    // Store functions with embeddings representing semantic meaning
    let mut props = HashMap::new();
    props.insert("type".to_string(), "function".to_string());
    props.insert("language".to_string(), "rust".to_string());

    // "process_data" - embedding represents data processing semantics
    engine.create_entity(
        "func:process_data",
        props.clone(),
        Some(vec![1.0, 0.9, 0.0, 0.0])
    ).await?;

    // "validate_input" - embedding represents validation semantics
    engine.create_entity(
        "func:validate_input",
        props.clone(),
        Some(vec![0.0, 0.1, 0.9, 0.9])
    ).await?;

    // Create call graph relationship
    engine.connect_entities(
        "func:process_data",
        "func:validate_input",
        "CALLS"
    ).await?;

    // Find functions similar to "data processing" that call validate_input
    let results = engine.find_similar_connected(
        "func:process_data",   // Query by this function's embedding
        "func:validate_input", // Must be connected to validation
        5
    ).await?;

    for item in results {
        println!("Found: {} (Score: {:.4})", item.id, item.score.unwrap_or(0.0));
    }

    Ok(())
}</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-chain-architecture"><a class="header" href="#tensor-chain-architecture">Tensor Chain Architecture</a></h1>
<p>Tensor-native blockchain with semantic conflict detection, hierarchical
codebook-based validation, and Tensor-Raft distributed consensus. This is the
most complex module in Neumann, providing distributed transaction coordination
across a cluster of nodes.</p>
<p>Tensor Chain treats transactions as geometric objects in embedding space.
Changes are represented as delta vectors, enabling similarity-based conflict
detection and automatic merging of orthogonal transactions. The module
integrates Raft consensus for leader election, two-phase commit (2PC) for
cross-shard transactions, SWIM gossip for failure detection, and wait-for graph
analysis for deadlock detection.</p>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="raft-consensus"><a class="header" href="#raft-consensus">Raft Consensus</a></h3>
<p>Tensor-Raft extends the standard Raft consensus protocol with tensor-native
optimizations:</p>
<ul>
<li><strong>Similarity Fast-Path</strong>: Followers can skip full validation when block
embeddings are similar (&gt;0.95 cosine) to recent blocks from the same leader</li>
<li><strong>Geometric Tie-Breaking</strong>: During elections with equal logs, candidates with
similar state embeddings to the cluster centroid are preferred</li>
<li><strong>Pre-Vote Phase</strong>: Prevents disruptive elections by requiring majority
agreement before incrementing term</li>
<li><strong>Automatic Heartbeat</strong>: Background task spawned on leader election maintains
quorum</li>
</ul>
<p>The leader replicates log entries containing blocks to followers. Entries are
committed when a quorum (majority) acknowledges them. Committed entries are
applied to the chain state machine.</p>
<h4 id="raft-state-machine"><a class="header" href="#raft-state-machine">Raft State Machine</a></h4>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Follower: Node startup

    Follower --&gt; Candidate: Election timeout
    Follower --&gt; Follower: AppendEntries from leader
    Follower --&gt; Follower: Higher term seen

    Candidate --&gt; Leader: Received quorum votes
    Candidate --&gt; Follower: Higher term seen
    Candidate --&gt; Candidate: Election timeout (split vote)

    Leader --&gt; Follower: Higher term seen
    Leader --&gt; Follower: Lost quorum (heartbeat failure)

    note right of Follower
        Receives log entries
        Grants votes
        Resets election timer on heartbeat
    end note

    note right of Candidate
        Increments term
        Votes for self
        Requests votes from peers
    end note

    note right of Leader
        Proposes blocks
        Sends heartbeats
        Handles client requests
        Tracks replication progress
    end note
</pre>
<h4 id="pre-vote-protocol"><a class="header" href="#pre-vote-protocol">Pre-Vote Protocol</a></h4>
<p>Pre-vote prevents disruptive elections from partitioned nodes:</p>
<pre><code class="language-text">Node A (partitioned, stale)              Healthy Cluster
    |                                         |
    |-- PreVote(term=5) ---------------------&gt;|
    |                                         |
    |&lt;-- PreVoteResponse(granted=false) ------|
    |                                         |
    | Does NOT increment term                 |
    | (prevents term inflation)               |
</code></pre>
<p>A pre-vote is granted only if:</p>
<ol>
<li>Candidate’s term &gt;= our term</li>
<li>Election timeout has elapsed (no recent leader heartbeat)</li>
<li>Candidate’s log is at least as up-to-date as ours</li>
</ol>
<h4 id="log-replication-flow"><a class="header" href="#log-replication-flow">Log Replication Flow</a></h4>
<pre class="mermaid">sequenceDiagram
    participant C as Client
    participant L as Leader
    participant F1 as Follower 1
    participant F2 as Follower 2

    C-&gt;&gt;L: propose(block)

    par Replicate to followers
        L-&gt;&gt;F1: AppendEntries(entries, prev_index, commit)
        L-&gt;&gt;F2: AppendEntries(entries, prev_index, commit)
    end

    F1-&gt;&gt;L: AppendEntriesResponse(success, match_index)
    F2-&gt;&gt;L: AppendEntriesResponse(success, match_index)

    Note over L: Quorum achieved (2/3)
    L-&gt;&gt;L: Update commit_index
    L-&gt;&gt;L: Apply to state machine

    par Notify commit
        L-&gt;&gt;F1: AppendEntries(commit_index updated)
        L-&gt;&gt;F2: AppendEntries(commit_index updated)
    end

    L-&gt;&gt;C: commit_success
</pre>
<h4 id="quorum-calculation"><a class="header" href="#quorum-calculation">Quorum Calculation</a></h4>
<p>Quorum requires a strict majority of voting members:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn quorum_size(total_nodes: usize) -&gt; usize {
    (total_nodes / 2) + 1
}

// Examples:
// 3 nodes: quorum = 2
// 5 nodes: quorum = 3
// 7 nodes: quorum = 4
<span class="boring">}</span></code></pre></pre>
<h4 id="fast-path-validation"><a class="header" href="#fast-path-validation">Fast-Path Validation</a></h4>
<p>When enabled, followers can skip expensive block validation for similar blocks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FastPathValidator {
    similarity_threshold: f32,  // Default: 0.95
    min_history: usize,         // Default: 3 blocks
}

// Validation logic:
// 1. Check if we have enough history from this leader
// 2. Compute cosine similarity with recent embeddings
// 3. If similarity &gt; threshold for all recent blocks:
//    - Skip full validation
//    - Record acceptance in stats
// 4. Otherwise: perform full validation
<span class="boring">}</span></code></pre></pre>
<h3 id="two-phase-commit-2pc"><a class="header" href="#two-phase-commit-2pc">Two-Phase Commit (2PC)</a></h3>
<p>Cross-shard distributed transactions use 2PC with delta-based conflict
detection:</p>
<p><strong>Phase 1 - PREPARE</strong>: Coordinator sends <code>TxPrepareMsg</code> to each participant
shard. Participants acquire locks, compute delta embeddings, and vote <code>Yes</code>,
<code>No</code>, or <code>Conflict</code>.</p>
<p><strong>Phase 2 - COMMIT/ABORT</strong>: If all votes are <code>Yes</code> and cross-shard deltas are
orthogonal (cosine &lt; 0.1), coordinator sends <code>TxCommitMsg</code>. Otherwise, sends
<code>TxAbortMsg</code> with retry.</p>
<p>Orthogonal transactions (operating on independent data dimensions) can commit in
parallel without coordination, reducing contention.</p>
<h4 id="2pc-coordinator-state-machine"><a class="header" href="#2pc-coordinator-state-machine">2PC Coordinator State Machine</a></h4>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Preparing: begin()

    Preparing --&gt; Prepared: All votes YES + deltas orthogonal
    Preparing --&gt; Aborting: Any vote NO/Conflict
    Preparing --&gt; Aborting: Timeout
    Preparing --&gt; Aborting: Cross-shard conflict detected

    Prepared --&gt; Committing: commit()
    Prepared --&gt; Aborting: abort()

    Committing --&gt; Committed: All ACKs received
    Committing --&gt; Committed: Timeout (presumed commit)

    Aborting --&gt; Aborted: All ACKs received
    Aborting --&gt; Aborted: Timeout (presumed abort)

    Committed --&gt; [*]
    Aborted --&gt; [*]
</pre>
<h4 id="2pc-participant-state-machine"><a class="header" href="#2pc-participant-state-machine">2PC Participant State Machine</a></h4>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Idle

    Idle --&gt; LockAcquiring: TxPrepareMsg received

    LockAcquiring --&gt; Locked: Locks acquired
    LockAcquiring --&gt; VoteNo: Lock conflict

    Locked --&gt; ConflictCheck: Compute delta

    ConflictCheck --&gt; VoteYes: No conflicts
    ConflictCheck --&gt; VoteConflict: Semantic conflict

    VoteYes --&gt; WaitingDecision: Send YES vote
    VoteNo --&gt; [*]: Send NO vote
    VoteConflict --&gt; [*]: Send CONFLICT vote

    WaitingDecision --&gt; Committed: TxCommitMsg
    WaitingDecision --&gt; Aborted: TxAbortMsg
    WaitingDecision --&gt; Aborted: Timeout

    Committed --&gt; [*]: Release locks, apply ops
    Aborted --&gt; [*]: Release locks, rollback
</pre>
<h4 id="lock-ordering-deadlock-prevention"><a class="header" href="#lock-ordering-deadlock-prevention">Lock Ordering (Deadlock Prevention)</a></h4>
<p>The coordinator follows strict lock ordering to prevent internal deadlocks:</p>
<pre><code class="language-text">Lock acquisition order:
1. pending           - Transaction state map
2. lock_manager.locks     - Key-level locks
3. lock_manager.tx_locks  - Per-transaction lock sets
4. pending_aborts    - Abort queue

CRITICAL: Never acquire pending_aborts while holding pending
</code></pre>
<h4 id="wal-recovery-protocol"><a class="header" href="#wal-recovery-protocol">WAL Recovery Protocol</a></h4>
<p>The coordinator uses write-ahead logging for crash recovery:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Recovery state machine:
// 1. Replay WAL to reconstruct pending transactions
// 2. For each transaction, determine recovery action:

match tx.phase {
    TxPhase::Preparing =&gt; {
        // Incomplete prepare - abort (presumed abort)
        tx.phase = TxPhase::Aborting;
    }
    TxPhase::Prepared =&gt; {
        // All YES votes recorded - check if can commit
        if all_yes_votes &amp;&amp; deltas_orthogonal {
            tx.phase = TxPhase::Committing;
        } else {
            tx.phase = TxPhase::Aborting;
        }
    }
    TxPhase::Committing =&gt; {
        // Continue commit - presumed commit
        complete_commit(tx);
    }
    TxPhase::Aborting =&gt; {
        // Continue abort
        complete_abort(tx);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="swim-gossip-protocol"><a class="header" href="#swim-gossip-protocol">SWIM Gossip Protocol</a></h3>
<p>Scalable membership management replaces O(N) sequential pings with O(log N)
epidemic propagation:</p>
<ul>
<li><strong>Peer Sampling</strong>: Select k peers per round (default: 3) using geometric
routing</li>
<li><strong>LWW-CRDT State</strong>: Last-Writer-Wins conflict resolution with Lamport
timestamps</li>
<li><strong>Suspicion Protocol</strong>: Direct ping failure triggers indirect probes via
intermediaries. Suspicion timer (5s default) allows refutation before marking
node as failed</li>
</ul>
<h4 id="gossip-message-types"><a class="header" href="#gossip-message-types">Gossip Message Types</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum GossipMessage {
    /// Sync message with piggy-backed node states
    Sync {
        sender: NodeId,
        states: Vec&lt;GossipNodeState&gt;,
        sender_time: u64,  // Lamport timestamp
    },

    /// Suspect a node of failure
    Suspect {
        reporter: NodeId,
        suspect: NodeId,
        incarnation: u64,
    },

    /// Refute suspicion by proving aliveness
    Alive {
        node_id: NodeId,
        incarnation: u64,  // Incremented to refute
    },

    /// Indirect ping request (SWIM protocol)
    PingReq {
        origin: NodeId,
        target: NodeId,
        sequence: u64,
    },

    /// Indirect ping response
    PingAck {
        origin: NodeId,
        target: NodeId,
        sequence: u64,
        success: bool,
    },
}
<span class="boring">}</span></code></pre></pre>
<h4 id="lww-crdt-state-merging"><a class="header" href="#lww-crdt-state-merging">LWW-CRDT State Merging</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// State supersession rules:
impl GossipNodeState {
    pub fn supersedes(&amp;self, other: &amp;GossipNodeState) -&gt; bool {
        // Incarnation takes precedence
        if self.incarnation != other.incarnation {
            self.incarnation &gt; other.incarnation
        } else {
            // Same incarnation: higher timestamp wins
            self.timestamp &gt; other.timestamp
        }
    }
}

// Merge algorithm:
pub fn merge(&amp;mut self, incoming: &amp;[GossipNodeState]) -&gt; Vec&lt;NodeId&gt; {
    let mut changed = Vec::new();

    for state in incoming {
        match self.states.get(&amp;state.node_id) {
            Some(existing) if state.supersedes(existing) =&gt; {
                self.states.insert(state.node_id.clone(), state.clone());
                changed.push(state.node_id.clone());
            }
            None =&gt; {
                self.states.insert(state.node_id.clone(), state.clone());
                changed.push(state.node_id.clone());
            }
            _ =&gt; {} // Existing state is newer, ignore
        }
    }

    // Sync Lamport time to max + 1
    if let Some(max_ts) = incoming.iter().map(|s| s.timestamp).max() {
        self.lamport_time = self.lamport_time.max(max_ts) + 1;
    }

    changed
}
<span class="boring">}</span></code></pre></pre>
<h4 id="swim-failure-detection-flow"><a class="header" href="#swim-failure-detection-flow">SWIM Failure Detection Flow</a></h4>
<pre class="mermaid">sequenceDiagram
    participant A as Node A
    participant B as Node B (suspect)
    participant C as Node C (intermediary)
    participant D as Node D (intermediary)

    A-&gt;&gt;B: Direct Ping
    Note over B: No response (timeout)

    par Indirect probes
        A-&gt;&gt;C: PingReq(target=B)
        A-&gt;&gt;D: PingReq(target=B)
    end

    C-&gt;&gt;B: Ping (on behalf of A)
    D-&gt;&gt;B: Ping (on behalf of A)

    alt B responds to C
        B-&gt;&gt;C: Pong
        C-&gt;&gt;A: PingAck(success=true)
        Note over A: B is healthy
    else All indirect pings fail
        C-&gt;&gt;A: PingAck(success=false)
        D-&gt;&gt;A: PingAck(success=false)
        Note over A: Start suspicion timer (5s)
        A-&gt;&gt;A: Broadcast Suspect(B)

        alt B refutes within 5s
            B-&gt;&gt;A: Alive(incarnation++)
            Note over A: Cancel suspicion
        else Timer expires
            Note over A: Mark B as Failed
        end
    end
</pre>
<h4 id="incarnation-number-protocol"><a class="header" href="#incarnation-number-protocol">Incarnation Number Protocol</a></h4>
<pre><code class="language-text">Scenario: Node B receives Suspect about itself

B's current incarnation: 5
Suspect message incarnation: 5

B increments: incarnation = 6
B broadcasts: Alive { node_id: B, incarnation: 6 }

All nodes receiving Alive update B's state:
- incarnation: 6
- health: Healthy
- timestamp: &lt;lamport_time++&gt;
</code></pre>
<h3 id="deadlock-detection"><a class="header" href="#deadlock-detection">Deadlock Detection</a></h3>
<p>Wait-for graph tracks transaction dependencies for cycle detection:</p>
<ol>
<li>Edge <code>A -&gt; B</code> added when transaction A blocks waiting for B to release locks</li>
<li>Periodic DFS traversal detects cycles (deadlocks)</li>
<li>Victim selected based on policy (youngest, oldest, lowest priority, or most
locks)</li>
<li>Victim transaction aborted to break the cycle</li>
</ol>
<h4 id="wait-for-graph-structure"><a class="header" href="#wait-for-graph-structure">Wait-For Graph Structure</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct WaitForGraph {
    /// Maps tx_id -&gt; set of tx_ids it is waiting for
    edges: HashMap&lt;u64, HashSet&lt;u64&gt;&gt;,

    /// Reverse edges for O(1) removal: holder -&gt; waiters
    reverse_edges: HashMap&lt;u64, HashSet&lt;u64&gt;&gt;,

    /// Timestamp when wait started (for victim selection)
    wait_started: HashMap&lt;u64, EpochMillis&gt;,

    /// Priority values (lower = higher priority)
    priorities: HashMap&lt;u64, u32&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h4 id="tarjans-dfs-cycle-detection-algorithm"><a class="header" href="#tarjans-dfs-cycle-detection-algorithm">Tarjan’s DFS Cycle Detection Algorithm</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn dfs_detect(
    &amp;self,
    node: u64,
    edges: &amp;HashMap&lt;u64, HashSet&lt;u64&gt;&gt;,
    visited: &amp;mut HashSet&lt;u64&gt;,
    rec_stack: &amp;mut HashSet&lt;u64&gt;,  // Current recursion path
    path: &amp;mut Vec&lt;u64&gt;,           // Explicit path for extraction
    cycles: &amp;mut Vec&lt;Vec&lt;u64&gt;&gt;,
) {
    visited.insert(node);
    rec_stack.insert(node);
    path.push(node);

    if let Some(neighbors) = edges.get(&amp;node) {
        for &amp;neighbor in neighbors {
            if !visited.contains(&amp;neighbor) {
                // Continue DFS on unvisited
                self.dfs_detect(neighbor, edges, visited, rec_stack, path, cycles);
            } else if rec_stack.contains(&amp;neighbor) {
                // Back-edge to ancestor = cycle found!
                if let Some(cycle_start) = path.iter().position(|&amp;n| n == neighbor) {
                    cycles.push(path[cycle_start..].to_vec());
                }
            }
        }
    }

    path.pop();
    rec_stack.remove(&amp;node);
}
<span class="boring">}</span></code></pre></pre>
<h4 id="victim-selection-policies"><a class="header" href="#victim-selection-policies">Victim Selection Policies</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Policy</th><th>Selection Criteria</th><th>Trade-off</th></tr></thead><tbody>
<tr><td><code>Youngest</code></td><td>Most recent wait start (highest timestamp)</td><td>Minimizes wasted work, may starve long transactions</td></tr>
<tr><td><code>Oldest</code></td><td>Earliest wait start (lowest timestamp)</td><td>Prevents starvation, wastes more completed work</td></tr>
<tr><td><code>LowestPriority</code></td><td>Highest priority value</td><td>Business-rule based, requires priority assignment</td></tr>
<tr><td><code>MostLocks</code></td><td>Transaction holding most locks</td><td>Maximizes freed resources, may abort complex transactions</td></tr>
</tbody></table>
</div>
<h3 id="ed25519-signing-and-identity"><a class="header" href="#ed25519-signing-and-identity">Ed25519 Signing and Identity</a></h3>
<p>Cryptographic identity binding ensures message authenticity and enables
geometric routing:</p>
<h4 id="identity-generation-and-nodeid-derivation"><a class="header" href="#identity-generation-and-nodeid-derivation">Identity Generation and NodeId Derivation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Identity {
    signing_key: SigningKey,  // Ed25519 private key (zeroized on drop)
}

impl Identity {
    pub fn generate() -&gt; Self {
        let signing_key = SigningKey::generate(&amp;mut OsRng);
        Self { signing_key }
    }

    /// NodeId = BLAKE2b-128(domain || public_key)
    /// 16 bytes = 32 hex characters
    pub fn node_id(&amp;self) -&gt; NodeId {
        let mut hasher = Blake2b::&lt;U16&gt;::new();
        hasher.update(b"neumann_node_id_v1");
        hasher.update(self.signing_key.verifying_key().as_bytes());
        hex::encode(hasher.finalize())
    }

    /// Embedding = BLAKE2b-512(domain || public_key) -&gt; 16 f32 coords
    /// Normalized to [-1, 1] for geometric operations
    pub fn to_embedding(&amp;self) -&gt; SparseVector {
        let mut hasher = Blake2b::&lt;U64&gt;::new();
        hasher.update(b"neumann_node_embedding_v1");
        hasher.update(self.signing_key.verifying_key().as_bytes());
        let hash = hasher.finalize();

        // 64 bytes -&gt; 16 f32 coordinates
        let coords: Vec&lt;f32&gt; = hash.chunks(4)
            .map(|c| {
                let bits = u32::from_le_bytes([c[0], c[1], c[2], c[3]]);
                (bits as f64 / u32::MAX as f64 * 2.0 - 1.0) as f32
            })
            .collect();

        SparseVector::from_dense(&amp;coords)
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="signed-message-envelope"><a class="header" href="#signed-message-envelope">Signed Message Envelope</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SignedMessage {
    pub sender: NodeId,           // Derived from public key
    pub public_key: [u8; 32],     // Ed25519 verifying key
    pub payload: Vec&lt;u8&gt;,         // Message content
    pub signature: Vec&lt;u8&gt;,       // 64-byte Ed25519 signature
    pub sequence: u64,            // Replay protection
    pub timestamp_ms: u64,        // Freshness check
}

// Signature covers: sender || sequence || timestamp || payload
// This binds identity, ordering, and content together
<span class="boring">}</span></code></pre></pre>
<h4 id="replay-protection"><a class="header" href="#replay-protection">Replay Protection</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SequenceTracker {
    sequences: DashMap&lt;NodeId, (u64, Instant)&gt;,
    config: SequenceTrackerConfig,
}

impl SequenceTracker {
    pub fn check_and_record(
        &amp;self,
        sender: &amp;NodeId,
        sequence: u64,
        timestamp_ms: u64,
    ) -&gt; Result&lt;()&gt; {
        // 1. Reject messages from the future (allow 1 min clock skew)
        if timestamp_ms &gt; now_ms + 60_000 {
            return Err("message timestamp is in the future");
        }

        // 2. Reject stale messages (default: 5 min max age)
        if now_ms &gt; timestamp_ms + self.config.max_age_ms {
            return Err("message too old");
        }

        // 3. Check sequence number is strictly increasing
        let entry = self.sequences.entry(sender.clone()).or_insert((0, now));
        if sequence &lt;= entry.0 {
            return Err("replay detected: sequence &lt;= last seen");
        }

        *entry = (sequence, now);
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="message-validation-pipeline"><a class="header" href="#message-validation-pipeline">Message Validation Pipeline</a></h3>
<p>All incoming messages pass through validation before processing:</p>
<pre class="mermaid">flowchart TB
    subgraph Validation[&quot;Message Validation Pipeline&quot;]
        Input[&quot;Incoming Message&quot;]
        NodeIdCheck[&quot;Validate NodeId Format&quot;]
        TypeDispatch[&quot;Dispatch by Type&quot;]

        TermCheck[&quot;Validate Term Bounds&quot;]
        ShardCheck[&quot;Validate Shard ID&quot;]
        TimeoutCheck[&quot;Validate Timeout&quot;]
        EmbeddingCheck[&quot;Validate Embedding&quot;]
        SignatureCheck[&quot;Validate Signature&quot;]

        Accept[&quot;Accept Message&quot;]
        Reject[&quot;Reject with Error&quot;]
    end

    Input --&gt; NodeIdCheck
    NodeIdCheck --&gt;|Invalid| Reject
    NodeIdCheck --&gt;|Valid| TypeDispatch

    TypeDispatch --&gt;|Raft| TermCheck
    TypeDispatch --&gt;|2PC| ShardCheck
    TypeDispatch --&gt;|Signed| SignatureCheck

    TermCheck --&gt;|Invalid| Reject
    TermCheck --&gt;|Valid| EmbeddingCheck

    ShardCheck --&gt;|Invalid| Reject
    ShardCheck --&gt;|Valid| TimeoutCheck

    TimeoutCheck --&gt;|Invalid| Reject
    TimeoutCheck --&gt;|Valid| EmbeddingCheck

    EmbeddingCheck --&gt;|Invalid| Reject
    EmbeddingCheck --&gt;|Valid| Accept

    SignatureCheck --&gt;|Invalid| Reject
    SignatureCheck --&gt;|Valid| Accept
</pre>
<h4 id="embedding-validation"><a class="header" href="#embedding-validation">Embedding Validation</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct EmbeddingValidator {
    max_dimension: usize,    // Default: 65,536
    max_magnitude: f32,      // Default: 1,000,000
}

impl EmbeddingValidator {
    pub fn validate(&amp;self, embedding: &amp;SparseVector, field: &amp;str) -&gt; Result&lt;()&gt; {
        // 1. Dimension bounds
        if embedding.dimension() == 0 {
            return Err("dimension cannot be zero");
        }
        if embedding.dimension() &gt; self.max_dimension {
            return Err("dimension exceeds maximum");
        }

        // 2. NaN/Inf detection (prevents computation errors)
        for (i, value) in embedding.values().iter().enumerate() {
            if value.is_nan() {
                return Err(format!("NaN value at position {}", i));
            }
            if value.is_infinite() {
                return Err(format!("infinite value at position {}", i));
            }
        }

        // 3. Magnitude bounds (prevents DoS via huge vectors)
        if embedding.magnitude() &gt; self.max_magnitude {
            return Err("magnitude exceeds maximum");
        }

        // 4. Position validity (sorted, within bounds)
        let positions = embedding.positions();
        for (i, &amp;pos) in positions.iter().enumerate() {
            if pos as usize &gt;= embedding.dimension() {
                return Err("position out of bounds");
            }
            if i &gt; 0 &amp;&amp; positions[i - 1] &gt;= pos {
                return Err("positions not strictly sorted");
            }
        }

        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="semantic-conflict-detection"><a class="header" href="#semantic-conflict-detection">Semantic Conflict Detection</a></h3>
<p>The consensus manager uses hybrid detection combining angular and structural
similarity:</p>
<h4 id="conflict-classification-algorithm"><a class="header" href="#conflict-classification-algorithm">Conflict Classification Algorithm</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn detect_conflict(&amp;self, d1: &amp;DeltaVector, d2: &amp;DeltaVector) -&gt; ConflictResult {
    let cosine = d1.cosine_similarity(d2);
    let jaccard = d1.structural_similarity(d2);  // Jaccard index
    let overlapping_keys = d1.overlapping_keys(d2);
    let all_keys_overlap = overlapping_keys.len() == d1.affected_keys.len()
        &amp;&amp; overlapping_keys.len() == d2.affected_keys.len();

    // Classification hierarchy:
    let (class, action) = if cosine &gt;= 0.99 &amp;&amp; all_keys_overlap {
        // Identical: same direction, same keys
        (ConflictClass::Identical, MergeAction::Deduplicate)

    } else if cosine &lt;= -0.95 &amp;&amp; all_keys_overlap {
        // Opposite: cancel out (A + (-A) = 0)
        (ConflictClass::Opposite, MergeAction::Cancel)

    } else if cosine.abs() &lt; 0.1 &amp;&amp; jaccard &lt; 0.5 {
        // Truly orthogonal: different directions AND different positions
        (ConflictClass::Orthogonal, MergeAction::VectorAdd)

    } else if cosine &gt;= 0.7 {
        // Angular conflict: pointing same direction
        (ConflictClass::Conflicting, MergeAction::Reject)

    } else if jaccard &gt;= 0.5 {
        // Structural conflict: same positions modified
        // Catches conflicts that cosine misses
        (ConflictClass::Conflicting, MergeAction::Reject)

    } else if !overlapping_keys.is_empty() {
        // Key overlap without structural/angular conflict
        (ConflictClass::Ambiguous, MergeAction::Reject)

    } else {
        // Low conflict: merge with weighted average
        (ConflictClass::LowConflict, MergeAction::WeightedAverage {
            weight1: 50, weight2: 50
        })
    };

    ConflictResult { class, cosine, jaccard, overlapping_keys, action, .. }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="merge-operations"><a class="header" href="#merge-operations">Merge Operations</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl DeltaVector {
    /// Vector addition for orthogonal deltas
    pub fn add(&amp;self, other: &amp;DeltaVector) -&gt; DeltaVector {
        let delta = self.delta.add(&amp;other.delta);
        let keys = self.affected_keys.union(&amp;other.affected_keys).cloned().collect();
        DeltaVector::from_sparse(delta, keys, 0)
    }

    /// Weighted average for low-conflict deltas
    pub fn weighted_average(&amp;self, other: &amp;DeltaVector, w1: f32, w2: f32) -&gt; DeltaVector {
        let total = w1 + w2;
        if total == 0.0 {
            return DeltaVector::zero(0);
        }
        let delta = self.delta.weighted_average(&amp;other.delta, w1, w2);
        let keys = self.affected_keys.union(&amp;other.affected_keys).cloned().collect();
        DeltaVector::from_sparse(delta, keys, 0)
    }

    /// Project out conflicting component
    pub fn project_non_conflicting(&amp;self, conflict_direction: &amp;SparseVector) -&gt; DeltaVector {
        let delta = self.delta.project_orthogonal(conflict_direction);
        DeltaVector::from_sparse(delta, self.affected_keys.clone(), self.tx_id)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="types-reference"><a class="header" href="#types-reference">Types Reference</a></h2>
<h3 id="core-types-6"><a class="header" href="#core-types-6">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TensorChain</code></td><td><code>lib.rs</code></td><td>Main API for chain operations, transaction management</td></tr>
<tr><td><code>Block</code></td><td><code>block.rs</code></td><td>Block structure with header, transactions, signatures</td></tr>
<tr><td><code>BlockHeader</code></td><td><code>block.rs</code></td><td>Height, prev_hash, delta_embedding, quantized_codes</td></tr>
<tr><td><code>Transaction</code></td><td><code>block.rs</code></td><td>Put, Delete, Update operations</td></tr>
<tr><td><code>ChainConfig</code></td><td><code>lib.rs</code></td><td>Node ID, max transactions, conflict threshold, auto-merge</td></tr>
<tr><td><code>ChainError</code></td><td><code>error.rs</code></td><td>Error types for all chain operations</td></tr>
<tr><td><code>ChainMetrics</code></td><td><code>lib.rs</code></td><td>Aggregated metrics from all components</td></tr>
</tbody></table>
</div>
<h3 id="consensus-types"><a class="header" href="#consensus-types">Consensus Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>RaftNode</code></td><td><code>raft.rs</code></td><td>Raft state machine with leader election, log replication</td></tr>
<tr><td><code>RaftState</code></td><td><code>raft.rs</code></td><td>Follower, Candidate, or Leader</td></tr>
<tr><td><code>RaftConfig</code></td><td><code>raft.rs</code></td><td>Election timeout, heartbeat interval, fast-path settings</td></tr>
<tr><td><code>RaftStats</code></td><td><code>raft.rs</code></td><td>Fast-path acceptance, heartbeat timing, quorum tracking</td></tr>
<tr><td><code>QuorumTracker</code></td><td><code>raft.rs</code></td><td>Tracks heartbeat responses to detect quorum loss</td></tr>
<tr><td><code>SnapshotMetadata</code></td><td><code>raft.rs</code></td><td>Log compaction point with hash and membership config</td></tr>
<tr><td><code>LogEntry</code></td><td><code>network.rs</code></td><td>Raft log entry with term, index, and data</td></tr>
<tr><td><code>ConsensusManager</code></td><td><code>consensus.rs</code></td><td>Semantic conflict detection and transaction merging</td></tr>
<tr><td><code>DeltaVector</code></td><td><code>consensus.rs</code></td><td>Sparse delta embedding with affected keys</td></tr>
<tr><td><code>ConflictClass</code></td><td><code>consensus.rs</code></td><td>Orthogonal, LowConflict, Ambiguous, Conflicting, Identical, Opposite</td></tr>
<tr><td><code>FastPathValidator</code></td><td><code>validation.rs</code></td><td>Block similarity validation for fast-path acceptance</td></tr>
<tr><td><code>FastPathState</code></td><td><code>raft.rs</code></td><td>Per-leader embedding history for fast-path</td></tr>
<tr><td><code>TransferState</code></td><td><code>raft.rs</code></td><td>Active leadership transfer tracking</td></tr>
<tr><td><code>HeartbeatStats</code></td><td><code>raft.rs</code></td><td>Heartbeat success/failure counters</td></tr>
</tbody></table>
</div>
<h3 id="distributed-transaction-types"><a class="header" href="#distributed-transaction-types">Distributed Transaction Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>DistributedTxCoordinator</code></td><td><code>distributed_tx.rs</code></td><td>2PC coordinator with timeout and retry</td></tr>
<tr><td><code>DistributedTransaction</code></td><td><code>distributed_tx.rs</code></td><td>Transaction spanning multiple shards</td></tr>
<tr><td><code>TxPhase</code></td><td><code>distributed_tx.rs</code></td><td>Preparing, Prepared, Committing, Committed, Aborting, Aborted</td></tr>
<tr><td><code>PrepareVote</code></td><td><code>distributed_tx.rs</code></td><td>Yes (with lock handle), No (with reason), Conflict</td></tr>
<tr><td><code>LockManager</code></td><td><code>distributed_tx.rs</code></td><td>Key-level locking for transaction isolation</td></tr>
<tr><td><code>KeyLock</code></td><td><code>distributed_tx.rs</code></td><td>Lock on a key with timeout and handle</td></tr>
<tr><td><code>TxWal</code></td><td><code>tx_wal.rs</code></td><td>Write-ahead log for crash recovery</td></tr>
<tr><td><code>TxWalEntry</code></td><td><code>tx_wal.rs</code></td><td>WAL entry types: TxBegin, PrepareVote, PhaseChange, TxComplete</td></tr>
<tr><td><code>TxRecoveryState</code></td><td><code>tx_wal.rs</code></td><td>Reconstructed state from WAL replay</td></tr>
<tr><td><code>PrepareRequest</code></td><td><code>distributed_tx.rs</code></td><td>Request to prepare a transaction on a shard</td></tr>
<tr><td><code>CommitRequest</code></td><td><code>distributed_tx.rs</code></td><td>Request to commit a prepared transaction</td></tr>
<tr><td><code>AbortRequest</code></td><td><code>distributed_tx.rs</code></td><td>Request to abort a transaction</td></tr>
<tr><td><code>CoordinatorState</code></td><td><code>distributed_tx.rs</code></td><td>Serializable coordinator state for persistence</td></tr>
<tr><td><code>ParticipantState</code></td><td><code>distributed_tx.rs</code></td><td>Serializable participant state for persistence</td></tr>
</tbody></table>
</div>
<h3 id="gossip-types"><a class="header" href="#gossip-types">Gossip Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>GossipMembershipManager</code></td><td><code>gossip.rs</code></td><td>SWIM-style gossip with signing support</td></tr>
<tr><td><code>GossipConfig</code></td><td><code>gossip.rs</code></td><td>Fanout, interval, suspicion timeout, signature requirements</td></tr>
<tr><td><code>GossipMessage</code></td><td><code>gossip.rs</code></td><td>Sync, Suspect, Alive, PingReq, PingAck</td></tr>
<tr><td><code>GossipNodeState</code></td><td><code>gossip.rs</code></td><td>Node health, Lamport timestamp, incarnation</td></tr>
<tr><td><code>LWWMembershipState</code></td><td><code>gossip.rs</code></td><td>CRDT for conflict-free state merging</td></tr>
<tr><td><code>PendingSuspicion</code></td><td><code>gossip.rs</code></td><td>Suspicion timer tracking</td></tr>
<tr><td><code>HealProgress</code></td><td><code>gossip.rs</code></td><td>Recovery tracking for partitioned nodes</td></tr>
<tr><td><code>SignedGossipMessage</code></td><td><code>signing.rs</code></td><td>Gossip message with Ed25519 signature</td></tr>
</tbody></table>
</div>
<h3 id="deadlock-detection-types"><a class="header" href="#deadlock-detection-types">Deadlock Detection Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>DeadlockDetector</code></td><td><code>deadlock.rs</code></td><td>Cycle detection with configurable victim selection</td></tr>
<tr><td><code>WaitForGraph</code></td><td><code>deadlock.rs</code></td><td>Directed graph of transaction dependencies</td></tr>
<tr><td><code>DeadlockInfo</code></td><td><code>deadlock.rs</code></td><td>Detected cycle with selected victim</td></tr>
<tr><td><code>VictimSelectionPolicy</code></td><td><code>deadlock.rs</code></td><td>Youngest, Oldest, LowestPriority, MostLocks</td></tr>
<tr><td><code>DeadlockStats</code></td><td><code>deadlock.rs</code></td><td>Detection timing and cycle length statistics</td></tr>
<tr><td><code>WaitInfo</code></td><td><code>deadlock.rs</code></td><td>Lock conflict information for wait-graph edges</td></tr>
</tbody></table>
</div>
<h3 id="identity-and-signing-types"><a class="header" href="#identity-and-signing-types">Identity and Signing Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Identity</code></td><td><code>signing.rs</code></td><td>Ed25519 private key (zeroized on drop)</td></tr>
<tr><td><code>PublicIdentity</code></td><td><code>signing.rs</code></td><td>Ed25519 public key for verification</td></tr>
<tr><td><code>SignedMessage</code></td><td><code>signing.rs</code></td><td>Message envelope with signature and replay protection</td></tr>
<tr><td><code>ValidatorRegistry</code></td><td><code>signing.rs</code></td><td>Registry of known validator public keys</td></tr>
<tr><td><code>SequenceTracker</code></td><td><code>signing.rs</code></td><td>Replay attack detection via sequence numbers</td></tr>
<tr><td><code>SequenceTrackerConfig</code></td><td><code>signing.rs</code></td><td>Max age, max entries, cleanup interval</td></tr>
</tbody></table>
</div>
<h3 id="message-validation-types"><a class="header" href="#message-validation-types">Message Validation Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Module</th><th>Description</th></tr></thead><tbody>
<tr><td><code>MessageValidationConfig</code></td><td><code>message_validation.rs</code></td><td>Bounds for DoS prevention</td></tr>
<tr><td><code>CompositeValidator</code></td><td><code>message_validation.rs</code></td><td>Validates all message types</td></tr>
<tr><td><code>EmbeddingValidator</code></td><td><code>message_validation.rs</code></td><td>Checks dimension, magnitude, NaN/Inf</td></tr>
<tr><td><code>MessageValidator</code></td><td><code>message_validation.rs</code></td><td>Trait for pluggable validation</td></tr>
</tbody></table>
</div>
<h2 id="architecture-diagram-3"><a class="header" href="#architecture-diagram-3">Architecture Diagram</a></h2>
<pre class="mermaid">flowchart TB
    subgraph Client[&quot;Client Layer&quot;]
        TensorChain[&quot;TensorChain API&quot;]
        TransactionWorkspace[&quot;Transaction Workspace&quot;]
    end

    subgraph Consensus[&quot;Consensus Layer&quot;]
        RaftNode[&quot;Raft Node&quot;]
        ConsensusManager[&quot;Consensus Manager&quot;]
        FastPath[&quot;Fast-Path Validator&quot;]
    end

    subgraph Network[&quot;Network Layer&quot;]
        Transport[&quot;Transport Trait&quot;]
        TcpTransport[&quot;TCP Transport&quot;]
        MemoryTransport[&quot;Memory Transport&quot;]
        MessageValidator[&quot;Message Validator&quot;]
    end

    subgraph Membership[&quot;Membership Layer&quot;]
        GossipManager[&quot;Gossip Manager&quot;]
        MembershipManager[&quot;Membership Manager&quot;]
        GeometricMembership[&quot;Geometric Membership&quot;]
    end

    subgraph DistTx[&quot;Distributed Transactions&quot;]
        Coordinator[&quot;2PC Coordinator&quot;]
        LockManager[&quot;Lock Manager&quot;]
        DeadlockDetector[&quot;Deadlock Detector&quot;]
        TxWal[&quot;Transaction WAL&quot;]
    end

    subgraph Storage[&quot;Storage Layer&quot;]
        Chain[&quot;Chain (Graph Engine)&quot;]
        Codebook[&quot;Codebook Manager&quot;]
        RaftWal[&quot;Raft WAL&quot;]
    end

    TensorChain --&gt; TransactionWorkspace
    TensorChain --&gt; ConsensusManager
    TensorChain --&gt; Codebook

    TransactionWorkspace --&gt; Chain

    RaftNode --&gt; Transport
    RaftNode --&gt; ConsensusManager
    RaftNode --&gt; FastPath
    RaftNode --&gt; RaftWal

    Transport --&gt; TcpTransport
    Transport --&gt; MemoryTransport
    TcpTransport --&gt; MessageValidator

    GossipManager --&gt; Transport
    GossipManager --&gt; MembershipManager
    MembershipManager --&gt; GeometricMembership

    Coordinator --&gt; LockManager
    Coordinator --&gt; DeadlockDetector
    Coordinator --&gt; Transport
    Coordinator --&gt; TxWal

    LockManager --&gt; DeadlockDetector

    Chain --&gt; Codebook
</pre>
<h2 id="subsystems"><a class="header" href="#subsystems">Subsystems</a></h2>
<h3 id="consensus-subsystem"><a class="header" href="#consensus-subsystem">Consensus Subsystem</a></h3>
<p>The Raft consensus implementation provides strong consistency guarantees:</p>
<p><strong>State Machine</strong>:</p>
<ul>
<li><code>Follower</code>: Receives AppendEntries from leader, grants votes</li>
<li><code>Candidate</code>: Requests votes after election timeout</li>
<li><code>Leader</code>: Proposes blocks, sends heartbeats, handles client requests</li>
</ul>
<p><strong>Log Replication</strong>:</p>
<pre><code class="language-sql">Leader:  propose(block) -&gt; AppendEntries to followers
                        -&gt; Wait for quorum acknowledgment
                        -&gt; Update commit_index
                        -&gt; Apply to state machine
</code></pre>
<p><strong>Fast-Path Validation</strong>:
When enabled and block embedding similarity exceeds threshold (default 0.95),
followers skip full validation. This optimization assumes semantically similar
blocks from the same leader are likely valid.</p>
<p><strong>Log Compaction</strong>:
After <code>snapshot_threshold</code> entries (default 10,000), a snapshot captures the
state machine at the commit point. Entries before the snapshot can be truncated,
keeping only <code>snapshot_trailing_logs</code> entries for followers catching up.</p>
<h3 id="distributed-transactions-subsystem"><a class="header" href="#distributed-transactions-subsystem">Distributed Transactions Subsystem</a></h3>
<p>Cross-shard coordination uses two-phase commit with tensor-native conflict
detection:</p>
<p><strong>Phase 1 - Prepare</strong>:</p>
<pre><code class="language-text">Coordinator                    Participant (per shard)
    |                                  |
    |--- TxPrepareMsg ---------------&gt;|
    |    (ops, delta_embedding)        |
    |                                  |-- acquire locks
    |                                  |-- compute local delta
    |                                  |-- check conflicts
    |&lt;--- TxPrepareResponse ----------|
    |     (Yes/No/Conflict)            |
</code></pre>
<p><strong>Phase 2 - Commit or Abort</strong>:</p>
<pre><code class="language-text">If all Yes AND deltas orthogonal:
    |--- TxCommitMsg ----------------&gt;| -- release locks, apply ops
    |&lt;--- TxAckMsg -------------------|

Otherwise:
    |--- TxAbortMsg -----------------&gt;| -- release locks, rollback
    |&lt;--- TxAckMsg -------------------|
</code></pre>
<p><strong>Conflict Detection</strong>:
Uses hybrid detection combining cosine similarity (angular conflict) and Jaccard
index (structural conflict):</p>
<div class="table-wrapper"><table><thead><tr><th>Cosine</th><th>Jaccard</th><th>Classification</th><th>Action</th></tr></thead><tbody>
<tr><td>&lt; 0.1</td><td>&lt; 0.5</td><td>Orthogonal</td><td>Auto-merge (vector add)</td></tr>
<tr><td>0.1-0.7</td><td>&lt; 0.5</td><td>LowConflict</td><td>Weighted merge</td></tr>
<tr><td>&gt;= 0.7</td><td>any</td><td>Conflicting</td><td>Reject</td></tr>
<tr><td>any</td><td>&gt;= 0.5</td><td>Conflicting</td><td>Reject (structural)</td></tr>
<tr><td>&gt;= 0.99</td><td>all keys</td><td>Identical</td><td>Deduplicate</td></tr>
<tr><td>&lt;= -0.95</td><td>all keys</td><td>Opposite</td><td>Cancel (no-op)</td></tr>
</tbody></table>
</div>
<h3 id="gossip-protocol-subsystem"><a class="header" href="#gossip-protocol-subsystem">Gossip Protocol Subsystem</a></h3>
<p>SWIM-style failure detection with LWW-CRDT state:</p>
<p><strong>Gossip Round</strong>:</p>
<pre><code class="language-sql">1. Select k peers (fanout=3) using geometric routing
2. Send Sync message with piggybacked node states
3. Merge received states (higher incarnation wins)
4. Update Lamport time
</code></pre>
<p><strong>Failure Detection</strong>:</p>
<pre><code class="language-text">Direct ping failed
    |
    v
Send PingReq to k intermediaries
    |
    v
All indirect pings failed?
    |-- No --&gt; Mark healthy
    |-- Yes --&gt; Start suspicion timer (5s)
                    |
                    v
                Timer expired without Alive?
                    |-- No --&gt; Mark healthy (refuted)
                    |-- Yes --&gt; Mark failed
</code></pre>
<p><strong>Incarnation Numbers</strong>:
When a node receives a Suspect about itself, it increments its incarnation and
broadcasts Alive to refute the suspicion.</p>
<h3 id="deadlock-detection-subsystem"><a class="header" href="#deadlock-detection-subsystem">Deadlock Detection Subsystem</a></h3>
<p>Wait-for graph analysis for cycle detection:</p>
<p><strong>Graph Structure</strong>:</p>
<pre><code class="language-text">Edge: waiter_tx -&gt; holder_tx
Meaning: waiter is blocked waiting for holder to release locks
</code></pre>
<p><strong>Detection Algorithm</strong> (Tarjan’s DFS):</p>
<pre><code class="language-sql">1. For each unvisited node, start DFS
2. Track recursion stack for back-edge detection
3. Back-edge to ancestor = cycle found
4. Extract cycle path for victim selection
</code></pre>
<p><strong>Victim Selection Policies</strong>:</p>
<ul>
<li><code>Youngest</code>: Abort most recent transaction (minimize wasted work)</li>
<li><code>Oldest</code>: Abort earliest transaction (prevent starvation)</li>
<li><code>LowestPriority</code>: Abort transaction with highest priority value</li>
<li><code>MostLocks</code>: Abort transaction holding most locks (minimize cascade)</li>
</ul>
<h2 id="configuration-options-3"><a class="header" href="#configuration-options-3">Configuration Options</a></h2>
<h3 id="raftconfig"><a class="header" href="#raftconfig">RaftConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>election_timeout</code></td><td>(150, 300)</td><td>Random timeout range in ms</td></tr>
<tr><td><code>heartbeat_interval</code></td><td>50</td><td>Heartbeat interval in ms</td></tr>
<tr><td><code>similarity_threshold</code></td><td>0.95</td><td>Fast-path similarity threshold</td></tr>
<tr><td><code>enable_fast_path</code></td><td>true</td><td>Enable fast-path validation</td></tr>
<tr><td><code>enable_pre_vote</code></td><td>true</td><td>Enable pre-vote phase</td></tr>
<tr><td><code>enable_geometric_tiebreak</code></td><td>true</td><td>Enable geometric tie-breaking</td></tr>
<tr><td><code>geometric_tiebreak_threshold</code></td><td>0.3</td><td>Minimum similarity for tiebreak</td></tr>
<tr><td><code>snapshot_threshold</code></td><td>10,000</td><td>Entries before compaction</td></tr>
<tr><td><code>snapshot_trailing_logs</code></td><td>100</td><td>Entries to keep after snapshot</td></tr>
<tr><td><code>snapshot_chunk_size</code></td><td>1MB</td><td>Chunk size for snapshot transfer</td></tr>
<tr><td><code>transfer_timeout_ms</code></td><td>1,000</td><td>Leadership transfer timeout</td></tr>
<tr><td><code>compaction_check_interval</code></td><td>10</td><td>Ticks between compaction checks</td></tr>
<tr><td><code>compaction_cooldown_ms</code></td><td>60,000</td><td>Minimum time between compactions</td></tr>
<tr><td><code>snapshot_max_memory</code></td><td>256MB</td><td>Max memory for snapshot buffering</td></tr>
<tr><td><code>auto_heartbeat</code></td><td>true</td><td>Spawn heartbeat task on leader election</td></tr>
<tr><td><code>max_heartbeat_failures</code></td><td>3</td><td>Failures before logging warning</td></tr>
</tbody></table>
</div>
<h3 id="distributedtxconfig"><a class="header" href="#distributedtxconfig">DistributedTxConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>max_concurrent</code></td><td>100</td><td>Maximum concurrent transactions</td></tr>
<tr><td><code>prepare_timeout_ms</code></td><td>5,000</td><td>Prepare phase timeout</td></tr>
<tr><td><code>commit_timeout_ms</code></td><td>10,000</td><td>Commit phase timeout</td></tr>
<tr><td><code>orthogonal_threshold</code></td><td>0.1</td><td>Cosine threshold for orthogonality</td></tr>
<tr><td><code>optimistic_locking</code></td><td>true</td><td>Enable semantic conflict detection</td></tr>
</tbody></table>
</div>
<h3 id="gossipconfig"><a class="header" href="#gossipconfig">GossipConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>fanout</code></td><td>3</td><td>Peers per gossip round</td></tr>
<tr><td><code>gossip_interval_ms</code></td><td>200</td><td>Interval between rounds</td></tr>
<tr><td><code>suspicion_timeout_ms</code></td><td>5,000</td><td>Time before failure declaration</td></tr>
<tr><td><code>max_states_per_message</code></td><td>20</td><td>State limit per message</td></tr>
<tr><td><code>geometric_routing</code></td><td>true</td><td>Use embedding-based peer selection</td></tr>
<tr><td><code>indirect_ping_count</code></td><td>3</td><td>Indirect pings on direct failure</td></tr>
<tr><td><code>indirect_ping_timeout_ms</code></td><td>500</td><td>Timeout for indirect pings</td></tr>
<tr><td><code>require_signatures</code></td><td>false</td><td>Require Ed25519 signatures</td></tr>
<tr><td><code>max_message_age_ms</code></td><td>300,000</td><td>Maximum signed message age</td></tr>
</tbody></table>
</div>
<h3 id="deadlockdetectorconfig"><a class="header" href="#deadlockdetectorconfig">DeadlockDetectorConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable deadlock detection</td></tr>
<tr><td><code>detection_interval_ms</code></td><td>100</td><td>Detection cycle interval</td></tr>
<tr><td><code>victim_policy</code></td><td>Youngest</td><td>Victim selection policy</td></tr>
<tr><td><code>max_cycle_length</code></td><td>100</td><td>Maximum detectable cycle length</td></tr>
<tr><td><code>auto_abort_victim</code></td><td>true</td><td>Automatically abort victim</td></tr>
</tbody></table>
</div>
<h3 id="messagevalidationconfig"><a class="header" href="#messagevalidationconfig">MessageValidationConfig</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable validation</td></tr>
<tr><td><code>max_term</code></td><td>u64::MAX - 1</td><td>Prevent overflow attacks</td></tr>
<tr><td><code>max_shard_id</code></td><td>65,536</td><td>Bound shard addressing</td></tr>
<tr><td><code>max_tx_timeout_ms</code></td><td>300,000</td><td>Maximum transaction timeout</td></tr>
<tr><td><code>max_node_id_len</code></td><td>256</td><td>Maximum node ID length</td></tr>
<tr><td><code>max_key_len</code></td><td>4,096</td><td>Maximum key length</td></tr>
<tr><td><code>max_embedding_dimension</code></td><td>65,536</td><td>Prevent huge allocations</td></tr>
<tr><td><code>max_embedding_magnitude</code></td><td>1,000,000</td><td>Detect invalid values</td></tr>
<tr><td><code>max_query_len</code></td><td>1MB</td><td>Maximum query string length</td></tr>
<tr><td><code>max_message_age_ms</code></td><td>300,000</td><td>Reject stale/replayed messages</td></tr>
<tr><td><code>max_blocks_per_request</code></td><td>1,000</td><td>Limit block range requests</td></tr>
<tr><td><code>max_snapshot_chunk_size</code></td><td>10MB</td><td>Limit snapshot chunk size</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas-9"><a class="header" href="#edge-cases-and-gotchas-9">Edge Cases and Gotchas</a></h2>
<h3 id="raft-edge-cases"><a class="header" href="#raft-edge-cases">Raft Edge Cases</a></h3>
<ol>
<li>
<p><strong>Split Vote</strong>: When multiple candidates split the vote evenly, election
timeout triggers new election. Randomized timeouts (150-300ms) reduce
collision probability.</p>
</li>
<li>
<p><strong>Network Partition</strong>: During partition, minority side cannot commit (lacks
quorum). Pre-vote prevents term inflation when partition heals.</p>
</li>
<li>
<p><strong>Stale Leader</strong>: A partitioned leader may not know it lost leadership.
Quorum tracker detects heartbeat failures and steps down.</p>
</li>
<li>
<p><strong>Log Divergence</strong>: Followers with divergent logs are overwritten by leader’s
log (consistency &gt; availability).</p>
</li>
<li>
<p><strong>Snapshot During Election</strong>: Snapshot transfer continues even if leadership
changes. New leader may need to resend snapshot.</p>
</li>
</ol>
<h3 id="2pc-edge-cases"><a class="header" href="#2pc-edge-cases">2PC Edge Cases</a></h3>
<ol>
<li>
<p><strong>Coordinator Failure After Prepare</strong>: Participants holding locks may
timeout. WAL recovery allows new coordinator to resume.</p>
</li>
<li>
<p><strong>Participant Failure</strong>: Coordinator times out waiting for vote. Transaction
aborts, participant recovers from WAL on restart.</p>
</li>
<li>
<p><strong>Network Partition Between Phases</strong>: Commit messages may not reach all
participants. Retry loop ensures eventual delivery.</p>
</li>
<li>
<p><strong>Lock Timeout vs Transaction Timeout</strong>: Lock timeout (30s) should exceed
transaction timeout (5s) to prevent premature lock release.</p>
</li>
<li>
<p><strong>Orphaned Locks</strong>: Locks from crashed transactions are cleaned up by
periodic <code>cleanup_expired()</code> or WAL recovery.</p>
</li>
</ol>
<h3 id="gossip-edge-cases"><a class="header" href="#gossip-edge-cases">Gossip Edge Cases</a></h3>
<ol>
<li>
<p><strong>Incarnation Overflow</strong>: Theoretically possible with u64, but requires 2^64
restarts. Practically impossible.</p>
</li>
<li>
<p><strong>Clock Skew</strong>: Lamport timestamps are logical, not wall-clock. Sync messages
update local Lamport time to <code>max(local, remote) + 1</code>.</p>
</li>
<li>
<p><strong>Signature Replay</strong>: Sequence numbers and timestamp freshness checks prevent
replaying old signed messages.</p>
</li>
<li>
<p><strong>Rapid Restart</strong>: Node restarting rapidly may have lower incarnation than
suspected state. New incarnation on restart resolves this.</p>
</li>
</ol>
<h3 id="conflict-detection-edge-cases"><a class="header" href="#conflict-detection-edge-cases">Conflict Detection Edge Cases</a></h3>
<ol>
<li>
<p><strong>Zero Vector</strong>: Empty deltas (no changes) have undefined cosine similarity.
Treated as orthogonal.</p>
</li>
<li>
<p><strong>Nearly Identical</strong>: Transactions with 0.99 &lt; similarity &lt; 1.0 may conflict.
Use structural overlap (Jaccard) as secondary check.</p>
</li>
<li>
<p><strong>Large Dimension Mismatch</strong>: Deltas with different dimensions cannot be
directly compared. Pad smaller to match larger.</p>
</li>
</ol>
<h2 id="recovery-procedures"><a class="header" href="#recovery-procedures">Recovery Procedures</a></h2>
<h3 id="raft-recovery-from-wal"><a class="header" href="#raft-recovery-from-wal">Raft Recovery from WAL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Open WAL and replay entries
let wal = RaftWal::open(wal_path)?;
let recovery = RaftRecoveryState::from_wal(&amp;wal)?;

// 2. Restore term and voted_for
node.current_term = recovery.current_term;
node.voted_for = recovery.voted_for;

// 3. Validate snapshot if present
if let Some((meta, data)) = load_snapshot() {
    let computed_hash = sha256(&amp;data);
    if computed_hash == meta.snapshot_hash {
        // Valid snapshot - restore state machine
        apply_snapshot(meta, data);
    } else {
        // Corrupted snapshot - ignore
        warn!("Snapshot hash mismatch, starting fresh");
    }
}

// 4. Start as follower
node.state = RaftState::Follower;
<span class="boring">}</span></code></pre></pre>
<h3 id="2pc-coordinator-recovery"><a class="header" href="#2pc-coordinator-recovery">2PC Coordinator Recovery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Replay WAL to reconstruct pending transactions
let recovery = TxRecoveryState::from_wal(&amp;wal)?;

// 2. Process each transaction based on phase
for tx in recovery.prepared_txs {
    // All YES votes - resume commit
    coordinator.pending.insert(tx.tx_id, restore_tx(tx, TxPhase::Prepared));
}

for tx in recovery.committing_txs {
    // Was committing - complete commit
    coordinator.complete_commit(tx.tx_id)?;
}

for tx in recovery.aborting_txs {
    // Was aborting - complete abort
    coordinator.complete_abort(tx.tx_id)?;
}

// 3. Timed out transactions default to abort (presumed abort)
for tx in recovery.timed_out_txs {
    coordinator.abort(tx.tx_id, "recovered - timeout")?;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="gossip-state-recovery"><a class="header" href="#gossip-state-recovery">Gossip State Recovery</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Gossip state is reconstructed via protocol, not WAL
// 1. Start with only local node in state
let mut state = LWWMembershipState::new();
state.update_local(local_node.clone(), NodeHealth::Healthy, 0);

// 2. Add known peers as Unknown
for peer in known_peers {
    state.merge(&amp;[GossipNodeState::new(peer, NodeHealth::Unknown, 0, 0)]);
}

// 3. Gossip protocol will converge to correct state
// - Healthy nodes will respond to Sync
// - Failed nodes will be suspected and eventually marked failed
<span class="boring">}</span></code></pre></pre>
<h2 id="operational-best-practices"><a class="header" href="#operational-best-practices">Operational Best Practices</a></h2>
<h3 id="cluster-sizing"><a class="header" href="#cluster-sizing">Cluster Sizing</a></h3>
<ul>
<li><strong>Minimum</strong>: 3 nodes (tolerates 1 failure)</li>
<li><strong>Recommended</strong>: 5 nodes (tolerates 2 failures)</li>
<li><strong>Large</strong>: 7 nodes (tolerates 3 failures)</li>
<li>Avoid even numbers (split-brain risk)</li>
</ul>
<h3 id="timeout-tuning"><a class="header" href="#timeout-tuning">Timeout Tuning</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Network latency &lt; 10ms (same datacenter)
RaftConfig {
    election_timeout: (150, 300),
    heartbeat_interval: 50,
}

// Network latency 10-50ms (cross-datacenter)
RaftConfig {
    election_timeout: (500, 1000),
    heartbeat_interval: 150,
}

// Network latency &gt; 50ms (geo-distributed)
RaftConfig {
    election_timeout: (2000, 4000),
    heartbeat_interval: 500,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<p>Key metrics to monitor:</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Warning Threshold</th><th>Critical Threshold</th></tr></thead><tbody>
<tr><td><code>heartbeat_success_rate</code></td><td>&lt; 0.95</td><td>&lt; 0.80</td></tr>
<tr><td><code>fast_path_rate</code></td><td>&lt; 0.50</td><td>&lt; 0.20</td></tr>
<tr><td><code>commit_rate</code></td><td>&lt; 0.80</td><td>&lt; 0.50</td></tr>
<tr><td><code>conflict_rate</code></td><td>&gt; 0.10</td><td>&gt; 0.30</td></tr>
<tr><td><code>deadlocks_detected</code></td><td>&gt; 0/min</td><td>&gt; 10/min</td></tr>
<tr><td><code>quorum_lost_events</code></td><td>&gt; 0/hour</td><td>&gt; 0/min</td></tr>
</tbody></table>
</div>
<h3 id="security-considerations-1"><a class="header" href="#security-considerations-1">Security Considerations</a></h3>
<ol>
<li><strong>Enable Message Signing</strong>: Set <code>require_signatures: true</code> in production</li>
<li><strong>Rotate Keys</strong>: Periodically generate new identities and update registry</li>
<li><strong>Network Isolation</strong>: Use TLS for transport, firewall cluster ports</li>
<li><strong>Audit Logging</strong>: Log all state transitions for forensic analysis</li>
</ol>
<h2 id="related-modules-10"><a class="header" href="#related-modules-10">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>tensor_store</code></td><td>Provides <code>TensorStore</code> for persistence, <code>SparseVector</code> for embeddings, <code>ArchetypeRegistry</code> for delta compression</td></tr>
<tr><td><code>graph_engine</code></td><td>Blocks linked via graph edges, chain structure built on graph</td></tr>
<tr><td><code>tensor_compress</code></td><td>Int8 quantization for delta embeddings (4x compression)</td></tr>
<tr><td><code>tensor_checkpoint</code></td><td>Snapshot persistence for crash recovery</td></tr>
</tbody></table>
</div>
<h2 id="performance-characteristics-5"><a class="header" href="#performance-characteristics-5">Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>Transaction commit</td><td>~50us</td><td>Single transaction block</td></tr>
<tr><td>Conflict detection</td><td>~1us</td><td>Cosine + Jaccard calculation</td></tr>
<tr><td>Deadlock detection</td><td>~350ns</td><td>DFS cycle detection</td></tr>
<tr><td>Gossip round</td><td>~200ms</td><td>Configurable interval</td></tr>
<tr><td>Heartbeat</td><td>~50ms</td><td>Leader to all followers</td></tr>
<tr><td>Fast-path validation</td><td>~2us</td><td>Similarity check only</td></tr>
<tr><td>Full validation</td><td>~50us</td><td>Complete block verification</td></tr>
<tr><td>Lock acquisition</td><td>~100ns</td><td>Uncontended case</td></tr>
<tr><td>Lock acquisition (contended)</td><td>~10us</td><td>With wait-graph update</td></tr>
<tr><td>Signature verification</td><td>~50us</td><td>Ed25519 verify</td></tr>
<tr><td>Message validation</td><td>~1us</td><td>Bounds checking</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="neumann-parser"><a class="header" href="#neumann-parser">Neumann Parser</a></h1>
<p>The <code>neumann_parser</code> crate provides a hand-written recursive descent parser for
the Neumann unified query language. It converts source text into an Abstract
Syntax Tree (AST) that can be executed by the query router.</p>
<p>The parser is designed with zero external dependencies, full span tracking for
error reporting, and support for SQL, graph, vector, and domain-specific
operations in a single unified syntax.</p>
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Concept</th><th>Description</th></tr></thead><tbody>
<tr><td>Recursive Descent</td><td>Top-down parsing where each grammar rule becomes a function</td></tr>
<tr><td>Pratt Parsing</td><td>Operator precedence parsing for expressions with correct associativity</td></tr>
<tr><td>Span Tracking</td><td>Every AST node carries source location for error messages</td></tr>
<tr><td>Case Insensitivity</td><td>Keywords are matched case-insensitively via uppercase conversion</td></tr>
<tr><td>Single Lookahead</td><td>Parser uses one-token lookahead with optional peek</td></tr>
<tr><td>Depth Limiting</td><td>Expression nesting is limited to 64 levels to prevent stack overflow</td></tr>
</tbody></table>
</div>
<h2 id="architecture-9"><a class="header" href="#architecture-9">Architecture</a></h2>
<pre class="mermaid">flowchart LR
    subgraph Input
        Source[&quot;Source String&quot;]
    end

    subgraph Lexer
        Chars[&quot;char iterator&quot;] --&gt; Tokenizer
        Tokenizer --&gt; Tokens[&quot;Token Stream&quot;]
    end

    subgraph Parser
        Tokens --&gt; StatementParser[&quot;Statement Parser&quot;]
        StatementParser --&gt; ExprParser[&quot;Expression Parser (Pratt)&quot;]
        ExprParser --&gt; AST[&quot;Abstract Syntax Tree&quot;]
    end

    Source --&gt; Chars
    AST --&gt; Output[&quot;Statement + Span&quot;]
</pre>
<h3 id="detailed-parsing-flow"><a class="header" href="#detailed-parsing-flow">Detailed Parsing Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant User
    participant parse()
    participant Parser
    participant Lexer
    participant ExprParser

    User-&gt;&gt;parse(): &quot;SELECT * FROM users&quot;
    parse()-&gt;&gt;Parser: new(source)
    Parser-&gt;&gt;Lexer: new(source)
    Lexer--&gt;&gt;Parser: first token

    Parser-&gt;&gt;Parser: parse_statement()
    Parser-&gt;&gt;Parser: match on token kind
    Parser-&gt;&gt;Parser: parse_select()
    Parser-&gt;&gt;Parser: parse_select_body()

    loop For each select item
        Parser-&gt;&gt;ExprParser: parse_expr()
        ExprParser-&gt;&gt;ExprParser: parse_expr_bp(0)
        ExprParser-&gt;&gt;ExprParser: parse_prefix_expr()
        ExprParser--&gt;&gt;Parser: Expr with span
    end

    Parser--&gt;&gt;parse(): Statement
    parse()--&gt;&gt;User: Result&lt;Statement&gt;
</pre>
<h2 id="source-files"><a class="header" href="#source-files">Source Files</a></h2>
<div class="table-wrapper"><table><thead><tr><th>File</th><th>Purpose</th><th>Key Functions</th></tr></thead><tbody>
<tr><td><code>lib.rs</code></td><td>Public API exports</td><td><code>parse()</code>, <code>parse_all()</code>, <code>parse_expr()</code>, <code>tokenize()</code></td></tr>
<tr><td><code>lexer.rs</code></td><td>Tokenization (source to tokens)</td><td><code>Lexer::next_token()</code>, <code>scan_ident()</code>, <code>scan_number()</code>, <code>scan_string()</code></td></tr>
<tr><td><code>token.rs</code></td><td>Token definitions and keyword lookup</td><td><code>TokenKind</code>, <code>keyword_from_str()</code></td></tr>
<tr><td><code>parser.rs</code></td><td>Statement parsing (recursive descent)</td><td><code>Parser::parse_statement()</code>, <code>parse_select()</code>, <code>parse_insert()</code></td></tr>
<tr><td><code>expr.rs</code></td><td>Expression parsing (Pratt algorithm)</td><td><code>ExprParser::parse_expr()</code>, <code>parse_expr_bp()</code>, <code>infix_binding_power()</code></td></tr>
<tr><td><code>ast.rs</code></td><td>AST node definitions</td><td><code>Statement</code>, <code>StatementKind</code>, <code>Expr</code>, <code>ExprKind</code></td></tr>
<tr><td><code>span.rs</code></td><td>Source location tracking</td><td><code>BytePos</code>, <code>Span</code>, <code>line_col()</code>, <code>get_line()</code></td></tr>
<tr><td><code>error.rs</code></td><td>Error types with source context</td><td><code>ParseError</code>, <code>ParseErrorKind</code>, <code>format_with_source()</code></td></tr>
</tbody></table>
</div>
<h2 id="core-types-7"><a class="header" href="#core-types-7">Core Types</a></h2>
<h3 id="token-system"><a class="header" href="#token-system">Token System</a></h3>
<pre class="mermaid">classDiagram
    class Token {
        +TokenKind kind
        +Span span
        +is_eof() bool
        +is_keyword() bool
    }

    class TokenKind {
        &lt;&lt;enumeration&gt;&gt;
        Ident(String)
        Integer(i64)
        Float(f64)
        String(String)
        Select
        From
        Where
        ...
        Error(String)
        Eof
    }

    class Span {
        +BytePos start
        +BytePos end
        +len() u32
        +merge(Span) Span
        +extract(str) str
    }

    Token --&gt; TokenKind
    Token --&gt; Span
</pre>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Token</code></td><td>A token with its kind and span</td></tr>
<tr><td><code>TokenKind</code></td><td>Enum of all token variants (130+ variants including keywords, literals, operators)</td></tr>
<tr><td><code>Lexer</code></td><td>Stateful tokenizer that produces tokens from source</td></tr>
</tbody></table>
</div>
<h3 id="ast-structure"><a class="header" href="#ast-structure">AST Structure</a></h3>
<pre class="mermaid">classDiagram
    class Statement {
        +StatementKind kind
        +Span span
    }

    class StatementKind {
        &lt;&lt;enumeration&gt;&gt;
        Select(SelectStmt)
        Insert(InsertStmt)
        Node(NodeStmt)
        Edge(EdgeStmt)
        Similar(SimilarStmt)
        Vault(VaultStmt)
        ...
    }

    class Expr {
        +ExprKind kind
        +Span span
        +boxed() Box~Expr~
    }

    class ExprKind {
        &lt;&lt;enumeration&gt;&gt;
        Literal(Literal)
        Ident(Ident)
        Binary(Box~Expr~, BinaryOp, Box~Expr~)
        Unary(UnaryOp, Box~Expr~)
        Call(FunctionCall)
        ...
    }

    Statement --&gt; StatementKind
    StatementKind --&gt; Expr
    Expr --&gt; ExprKind
</pre>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Statement</code></td><td>Top-level parsed statement with span</td></tr>
<tr><td><code>StatementKind</code></td><td>Enum of all statement variants (30+ variants)</td></tr>
<tr><td><code>Expr</code></td><td>Expression node with span</td></tr>
<tr><td><code>ExprKind</code></td><td>Enum of expression variants (20+ variants)</td></tr>
<tr><td><code>Literal</code></td><td>Literal values (Null, Boolean, Integer, Float, String)</td></tr>
<tr><td><code>Ident</code></td><td>Identifier with name and span</td></tr>
<tr><td><code>BinaryOp</code></td><td>Binary operators with precedence (18 operators)</td></tr>
<tr><td><code>UnaryOp</code></td><td>Unary operators (Not, Neg, BitNot)</td></tr>
</tbody></table>
</div>
<h3 id="span-types"><a class="header" href="#span-types">Span Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>BytePos</code></td><td>A byte offset into source text (u32)</td><td><code>BytePos(7)</code></td></tr>
<tr><td><code>Span</code></td><td>A range of bytes (start, end)</td><td><code>Span { start: 0, end: 6 }</code></td></tr>
<tr><td><code>Spanned&lt;T&gt;</code></td><td>A value paired with its source location</td><td><code>Spanned::new(42, span)</code></td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Span operations
let span1 = Span::from_offsets(0, 6);   // "SELECT"
let span2 = Span::from_offsets(7, 8);   // "*"
let merged = span1.merge(span2);         // "SELECT *"

// Extract source text
let source = "SELECT * FROM users";
let text = span1.extract(source);        // "SELECT"

// Line/column computation
let (line, col) = line_col(source, BytePos(7));  // (1, 8)
<span class="boring">}</span></code></pre></pre>
<h3 id="error-types-7"><a class="header" href="#error-types-7">Error Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>ParseError</code></td><td>Error with kind, span, and optional help message</td></tr>
<tr><td><code>ParseErrorKind</code></td><td>Enum of error variants (10 kinds)</td></tr>
<tr><td><code>ParseResult&lt;T&gt;</code></td><td><code>Result&lt;T, ParseError&gt;</code></td></tr>
<tr><td><code>Errors</code></td><td>Collection of parse errors with iteration support</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Error kinds
pub enum ParseErrorKind {
    UnexpectedToken { found: TokenKind, expected: String },
    UnexpectedEof { expected: String },
    InvalidSyntax(String),
    InvalidNumber(String),
    UnterminatedString,
    UnknownCommand(String),
    DuplicateColumn(String),
    InvalidEscape(char),
    TooDeep,           // Expression nesting &gt; 64 levels
    Custom(String),
}
<span class="boring">}</span></code></pre></pre>
<h2 id="lexer-implementation"><a class="header" href="#lexer-implementation">Lexer Implementation</a></h2>
<h3 id="state-machine-1"><a class="header" href="#state-machine-1">State Machine</a></h3>
<p>The lexer is implemented as an iterator-based state machine with
single-character lookahead:</p>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Initial
    Initial --&gt; Whitespace: is_whitespace
    Initial --&gt; LineComment: --
    Initial --&gt; BlockComment: /*
    Initial --&gt; Identifier: a-zA-Z_
    Initial --&gt; Number: 0-9
    Initial --&gt; String: ' or &quot;
    Initial --&gt; Operator: +-*/etc
    Initial --&gt; EOF: end

    Whitespace --&gt; Initial: skip
    LineComment --&gt; Initial: newline
    BlockComment --&gt; Initial: */

    Identifier --&gt; Token: non-alnum
    Number --&gt; Token: non-digit
    String --&gt; Token: closing quote
    Operator --&gt; Token: complete

    Token --&gt; Initial: emit token
    EOF --&gt; [*]
</pre>
<h3 id="internal-structure-2"><a class="header" href="#internal-structure-2">Internal Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Lexer&lt;'a&gt; {
    source: &amp;'a str,      // Original source text
    chars: Chars&lt;'a&gt;,     // Character iterator
    pos: u32,             // Current byte position
    peeked: Option&lt;char&gt;, // One-character lookahead
}
<span class="boring">}</span></code></pre></pre>
<h3 id="character-classification"><a class="header" href="#character-classification">Character Classification</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Characters</th><th>Handling</th></tr></thead><tbody>
<tr><td>Whitespace</td><td>space, tab, newline</td><td>Skipped</td></tr>
<tr><td>Line comment</td><td><code>--</code> to newline</td><td>Skipped</td></tr>
<tr><td>Block comment</td><td><code>/* */</code> (nestable)</td><td>Skipped, supports nesting</td></tr>
<tr><td>Identifier</td><td><code>[a-zA-Z_][a-zA-Z0-9_]*</code></td><td>Keyword lookup then Ident</td></tr>
<tr><td>Integer</td><td><code>[0-9]+</code></td><td>Parse as i64</td></tr>
<tr><td>Float</td><td><code>[0-9]+\.[0-9]+</code> or scientific</td><td>Parse as f64</td></tr>
<tr><td>String</td><td><code>'...'</code> or <code>"..."</code></td><td>Handle escapes</td></tr>
</tbody></table>
</div>
<h3 id="string-escape-sequences"><a class="header" href="#string-escape-sequences">String Escape Sequences</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Escape</th><th>Result</th></tr></thead><tbody>
<tr><td><code>\n</code></td><td>Newline</td></tr>
<tr><td><code>\r</code></td><td>Carriage return</td></tr>
<tr><td><code>\t</code></td><td>Tab</td></tr>
<tr><td><code>\\</code></td><td>Backslash</td></tr>
<tr><td><code>\'</code></td><td>Single quote</td></tr>
<tr><td><code>\"</code></td><td>Double quote</td></tr>
<tr><td><code>\0</code></td><td>Null character</td></tr>
<tr><td><code>''</code></td><td>Single quote (SQL-style doubled)</td></tr>
<tr><td><code>\x</code></td><td>Unknown: preserved as <code>\x</code></td></tr>
</tbody></table>
</div>
<h3 id="operator-recognition"><a class="header" href="#operator-recognition">Operator Recognition</a></h3>
<p>Multi-character operators are recognized with lookahead:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Lexer::next_token() operator matching
match c {
    '-' =&gt; if self.eat('&gt;') { Arrow }      // -&gt;
           else { Minus },                  // -
    '=' =&gt; if self.eat('&gt;') { FatArrow }   // =&gt;
           else { Eq },                     // =
    '&lt;' =&gt; if self.eat('=') { Le }         // &lt;=
           else if self.eat('&gt;') { Ne }    // &lt;&gt;
           else if self.eat('&lt;') { Shl }   // &lt;&lt;
           else { Lt },                     // &lt;
    '&gt;' =&gt; if self.eat('=') { Ge }         // &gt;=
           else if self.eat('&gt;') { Shr }   // &gt;&gt;
           else { Gt },                     // &gt;
    '|' =&gt; if self.eat('|') { Concat }     // ||
           else { Pipe },                   // |
    '&amp;' =&gt; if self.eat('&amp;') { AmpAmp }     // &amp;&amp;
           else { Amp },                    // &amp;
    ':' =&gt; if self.eat(':') { ColonColon } // ::
           else { Colon },                  // :
    // ...
}
<span class="boring">}</span></code></pre></pre>
<h2 id="pratt-parser-expression-parsing"><a class="header" href="#pratt-parser-expression-parsing">Pratt Parser (Expression Parsing)</a></h2>
<h3 id="algorithm-overview-2"><a class="header" href="#algorithm-overview-2">Algorithm Overview</a></h3>
<p>The Pratt parser handles operator precedence through “binding power” - each
operator has a left and right binding power that determines associativity and
precedence.</p>
<pre class="mermaid">flowchart TD
    A[parse_expr_bp\nmin_bp] --&gt; B[parse_prefix]
    B --&gt; C{More tokens?}
    C --&gt;|No| D[Return lhs]
    C --&gt;|Yes| E[parse_postfix]
    E --&gt; F{Infix op?}
    F --&gt;|No| D
    F --&gt;|Yes| G{l_bp &gt;= min_bp?}
    G --&gt;|No| D
    G --&gt;|Yes| H[Advance]
    H --&gt; I[parse_expr_bp\nr_bp]
    I --&gt; J[Build Binary node]
    J --&gt; C
</pre>
<h3 id="binding-power-table"><a class="header" href="#binding-power-table">Binding Power Table</a></h3>
<p>Each operator has left and right binding powers <code>(l_bp, r_bp)</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Precedence</th><th>Operators</th><th>Binding Power (l, r)</th><th>Associativity</th></tr></thead><tbody>
<tr><td>1 (lowest)</td><td>OR</td><td>(1, 2)</td><td>Left</td></tr>
<tr><td>2</td><td>AND</td><td>(3, 4)</td><td>Left</td></tr>
<tr><td>3</td><td>=, !=, &lt;, &lt;=, &gt;, &gt;=</td><td>(5, 6)</td><td>Left</td></tr>
<tr><td>4</td><td><code>|</code> (bitwise OR)</td><td>(7, 8)</td><td>Left</td></tr>
<tr><td>5</td><td>^ (bitwise XOR)</td><td>(9, 10)</td><td>Left</td></tr>
<tr><td>6</td><td>&amp; (bitwise AND)</td><td>(11, 12)</td><td>Left</td></tr>
<tr><td>7</td><td>&lt;&lt;, &gt;&gt;</td><td>(13, 14)</td><td>Left</td></tr>
<tr><td>8</td><td>+, -, <code>||</code> (concat)</td><td>(15, 16)</td><td>Left</td></tr>
<tr><td>9</td><td>*, /, %</td><td>(17, 18)</td><td>Left</td></tr>
<tr><td>10 (highest)</td><td>NOT, -, ~ (unary)</td><td>19 (prefix)</td><td>Right</td></tr>
</tbody></table>
</div>
<p>Left associativity is achieved by having <code>r_bp &gt; l_bp</code>.</p>
<h3 id="implementation-details-3"><a class="header" href="#implementation-details-3">Implementation Details</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const MAX_DEPTH: usize = 64;  // Prevent stack overflow

fn parse_expr_bp(&amp;mut self, min_bp: u8) -&gt; ParseResult&lt;Expr&gt; {
    self.depth += 1;
    if self.depth &gt; MAX_DEPTH {
        return Err(ParseError::new(ParseErrorKind::TooDeep, self.current.span));
    }

    let mut lhs = self.parse_prefix()?;

    loop {
        // Handle postfix operators (IS NULL, IN, BETWEEN, LIKE, DOT)
        lhs = self.parse_postfix(lhs)?;

        // Check for infix operator
        let op = match self.current_binary_op() {
            Some(op) =&gt; op,
            None =&gt; break,
        };

        let (l_bp, r_bp) = infix_binding_power(op);
        if l_bp &lt; min_bp {
            break;  // Operator binds less tightly than current context
        }

        self.advance();
        let rhs = self.parse_expr_bp(r_bp)?;

        let span = lhs.span.merge(rhs.span);
        lhs = Expr::new(ExprKind::Binary(Box::new(lhs), op, Box::new(rhs)), span);
    }

    self.depth -= 1;
    Ok(lhs)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="prefix-expression-handling"><a class="header" href="#prefix-expression-handling">Prefix Expression Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn parse_prefix(&amp;mut self) -&gt; ParseResult&lt;Expr&gt; {
    match &amp;self.current.kind {
        // Literals
        TokenKind::Integer(n) =&gt; { /* emit Literal(Integer) */ },
        TokenKind::Float(n) =&gt; { /* emit Literal(Float) */ },
        TokenKind::String(s) =&gt; { /* emit Literal(String) */ },
        TokenKind::True | TokenKind::False =&gt; { /* emit Literal(Boolean) */ },
        TokenKind::Null =&gt; { /* emit Literal(Null) */ },

        // Identifiers and function calls
        TokenKind::Ident(_) =&gt; self.parse_ident_or_call(),

        // Aggregate functions (COUNT, SUM, AVG, MIN, MAX)
        TokenKind::Count | TokenKind::Sum | ... =&gt; self.parse_aggregate_call(),

        // Wildcard
        TokenKind::Star =&gt; { /* emit Wildcard */ },

        // Parenthesized expression or tuple
        TokenKind::LParen =&gt; self.parse_paren_expr(),

        // Array literal
        TokenKind::LBracket =&gt; self.parse_array(),

        // Unary operators
        TokenKind::Minus =&gt; { /* parse operand with PREFIX_BP, emit Unary(Neg) */ },
        TokenKind::Not | TokenKind::Bang =&gt; { /* emit Unary(Not) */ },
        TokenKind::Tilde =&gt; { /* emit Unary(BitNot) */ },

        // Special expressions
        TokenKind::Case =&gt; self.parse_case(),
        TokenKind::Exists =&gt; self.parse_exists(),
        TokenKind::Cast =&gt; self.parse_cast(),

        // Contextual keywords as identifiers
        _ if token.kind.is_contextual_keyword() =&gt; self.parse_keyword_as_ident(),

        // Error
        _ =&gt; Err(ParseError::unexpected(...)),
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="postfix-expression-handling"><a class="header" href="#postfix-expression-handling">Postfix Expression Handling</a></h3>
<p>Postfix operators bind tighter than any infix operator:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn parse_postfix(&amp;mut self, mut expr: Expr) -&gt; ParseResult&lt;Expr&gt; {
    loop {
        // Handle NOT IN, NOT BETWEEN, NOT LIKE
        if self.check(&amp;TokenKind::Not) {
            let next = self.peek().kind.clone();
            if next == TokenKind::In { /* parse NOT IN */ }
            else if next == TokenKind::Between { /* parse NOT BETWEEN */ }
            else if next == TokenKind::Like { /* parse NOT LIKE */ }
        }

        match self.current.kind {
            TokenKind::Is =&gt; {
                // IS [NOT] NULL
                self.advance();
                let negated = self.eat(&amp;TokenKind::Not);
                self.expect(&amp;TokenKind::Null)?;
                expr = Expr::new(ExprKind::IsNull { expr, negated }, span);
            },
            TokenKind::In =&gt; { /* parse IN (values) or IN (subquery) */ },
            TokenKind::Between =&gt; { /* parse BETWEEN low AND high */ },
            TokenKind::Like =&gt; { /* parse LIKE pattern */ },
            TokenKind::Dot =&gt; {
                // Qualified name: table.column or table.*
                self.advance();
                if self.eat(&amp;TokenKind::Star) {
                    expr = Expr::new(ExprKind::QualifiedWildcard(ident), span);
                } else {
                    let field = self.expect_ident()?;
                    expr = Expr::new(ExprKind::Qualified(Box::new(expr), field), span);
                }
            },
            _ =&gt; return Ok(expr),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="statement-kinds"><a class="header" href="#statement-kinds">Statement Kinds</a></h2>
<h3 id="sql-statements"><a class="header" href="#sql-statements">SQL Statements</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Statement</th><th>Example</th><th>AST Type</th></tr></thead><tbody>
<tr><td><code>Select</code></td><td><code>SELECT * FROM users WHERE id = 1</code></td><td><code>SelectStmt</code></td></tr>
<tr><td><code>Insert</code></td><td><code>INSERT INTO users (name) VALUES ('Alice')</code></td><td><code>InsertStmt</code></td></tr>
<tr><td><code>Update</code></td><td><code>UPDATE users SET name = 'Bob' WHERE id = 1</code></td><td><code>UpdateStmt</code></td></tr>
<tr><td><code>Delete</code></td><td><code>DELETE FROM users WHERE id = 1</code></td><td><code>DeleteStmt</code></td></tr>
<tr><td><code>CreateTable</code></td><td><code>CREATE TABLE users (id INT PRIMARY KEY)</code></td><td><code>CreateTableStmt</code></td></tr>
<tr><td><code>DropTable</code></td><td><code>DROP TABLE IF EXISTS users CASCADE</code></td><td><code>DropTableStmt</code></td></tr>
<tr><td><code>CreateIndex</code></td><td><code>CREATE UNIQUE INDEX idx ON users(email)</code></td><td><code>CreateIndexStmt</code></td></tr>
<tr><td><code>DropIndex</code></td><td><code>DROP INDEX idx_name</code></td><td><code>DropIndexStmt</code></td></tr>
<tr><td><code>ShowTables</code></td><td><code>SHOW TABLES</code></td><td>unit</td></tr>
<tr><td><code>Describe</code></td><td><code>DESCRIBE TABLE users</code></td><td><code>DescribeStmt</code></td></tr>
</tbody></table>
</div>
<h3 id="graph-statements"><a class="header" href="#graph-statements">Graph Statements</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Statement</th><th>Example</th><th>AST Type</th></tr></thead><tbody>
<tr><td><code>Node</code></td><td><code>NODE CREATE person {name: 'Alice'}</code></td><td><code>NodeStmt</code></td></tr>
<tr><td><code>Edge</code></td><td><code>EDGE CREATE 1 -&gt; 2 : FOLLOWS {since: 2023}</code></td><td><code>EdgeStmt</code></td></tr>
<tr><td><code>Neighbors</code></td><td><code>NEIGHBORS 'entity' OUTGOING follows</code></td><td><code>NeighborsStmt</code></td></tr>
<tr><td><code>Path</code></td><td><code>PATH SHORTEST 1 TO 5</code></td><td><code>PathStmt</code></td></tr>
<tr><td><code>Find</code></td><td><code>FIND NODE person WHERE age &gt; 18</code></td><td><code>FindStmt</code></td></tr>
</tbody></table>
</div>
<h3 id="vector-statements"><a class="header" href="#vector-statements">Vector Statements</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Statement</th><th>Example</th><th>AST Type</th></tr></thead><tbody>
<tr><td><code>Embed</code></td><td><code>EMBED STORE 'key' [0.1, 0.2, 0.3]</code></td><td><code>EmbedStmt</code></td></tr>
<tr><td><code>Similar</code></td><td><code>SIMILAR 'query' LIMIT 10 COSINE</code></td><td><code>SimilarStmt</code></td></tr>
</tbody></table>
</div>
<h3 id="domain-statements"><a class="header" href="#domain-statements">Domain Statements</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Statement</th><th>Example</th><th>AST Type</th></tr></thead><tbody>
<tr><td><code>Vault</code></td><td><code>VAULT SET 'secret' 'value'</code></td><td><code>VaultStmt</code></td></tr>
<tr><td><code>Cache</code></td><td><code>CACHE STATS</code></td><td><code>CacheStmt</code></td></tr>
<tr><td><code>Blob</code></td><td><code>BLOB PUT 'file.txt' 'data'</code></td><td><code>BlobStmt</code></td></tr>
<tr><td><code>Blobs</code></td><td><code>BLOBS BY TAG 'important'</code></td><td><code>BlobsStmt</code></td></tr>
<tr><td><code>Chain</code></td><td><code>BEGIN CHAIN TRANSACTION</code></td><td><code>ChainStmt</code></td></tr>
<tr><td><code>Cluster</code></td><td><code>CLUSTER STATUS</code></td><td><code>ClusterStmt</code></td></tr>
<tr><td><code>Checkpoint</code></td><td><code>CHECKPOINT 'backup1'</code></td><td><code>CheckpointStmt</code></td></tr>
<tr><td><code>Entity</code></td><td><code>ENTITY CREATE 'key' {props} EMBEDDING [vec]</code></td><td><code>EntityStmt</code></td></tr>
</tbody></table>
</div>
<h2 id="expression-kinds"><a class="header" href="#expression-kinds">Expression Kinds</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Kind</th><th>Example</th><th>Notes</th></tr></thead><tbody>
<tr><td><code>Literal</code></td><td><code>42</code>, <code>3.14</code>, <code>'hello'</code>, <code>TRUE</code>, <code>NULL</code></td><td>Five literal types</td></tr>
<tr><td><code>Ident</code></td><td><code>column_name</code></td><td>Simple identifier</td></tr>
<tr><td><code>Qualified</code></td><td><code>table.column</code></td><td>Dot notation</td></tr>
<tr><td><code>Binary</code></td><td><code>a + b</code>, <code>x AND y</code></td><td>18 binary operators</td></tr>
<tr><td><code>Unary</code></td><td><code>NOT flag</code>, <code>-value</code>, <code>~bits</code></td><td>3 unary operators</td></tr>
<tr><td><code>Call</code></td><td><code>COUNT(*)</code>, <code>MAX(price)</code></td><td>Function with args</td></tr>
<tr><td><code>Case</code></td><td><code>CASE WHEN x THEN y ELSE z END</code></td><td>Simple and searched</td></tr>
<tr><td><code>Subquery</code></td><td><code>(SELECT ...)</code></td><td>Nested SELECT</td></tr>
<tr><td><code>Exists</code></td><td><code>EXISTS (SELECT 1 ...)</code></td><td>Existence test</td></tr>
<tr><td><code>In</code></td><td><code>x IN (1, 2, 3)</code> or <code>x IN (SELECT...)</code></td><td>Value list or subquery</td></tr>
<tr><td><code>Between</code></td><td><code>x BETWEEN 1 AND 10</code></td><td>Range check</td></tr>
<tr><td><code>Like</code></td><td><code>name LIKE '%smith'</code></td><td>Pattern matching</td></tr>
<tr><td><code>IsNull</code></td><td><code>x IS NULL</code>, <code>y IS NOT NULL</code></td><td>NULL check</td></tr>
<tr><td><code>Array</code></td><td><code>[1, 2, 3]</code></td><td>Array literal</td></tr>
<tr><td><code>Tuple</code></td><td><code>(1, 2, 3)</code></td><td>Tuple/row literal</td></tr>
<tr><td><code>Cast</code></td><td><code>CAST(x AS INT)</code></td><td>Type conversion</td></tr>
<tr><td><code>Wildcard</code></td><td><code>*</code></td><td>All columns</td></tr>
<tr><td><code>QualifiedWildcard</code></td><td><code>table.*</code></td><td>All columns from table</td></tr>
</tbody></table>
</div>
<h2 id="span-tracking-implementation"><a class="header" href="#span-tracking-implementation">Span Tracking Implementation</a></h2>
<h3 id="bytepos-and-span"><a class="header" href="#bytepos-and-span">BytePos and Span</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// A byte position in source code (u32 for memory efficiency).
pub struct BytePos(pub u32);

/// A span representing a range of source code.
pub struct Span {
    pub start: BytePos,  // Inclusive
    pub end: BytePos,    // Exclusive
}

impl Span {
    /// Combines two spans into one that covers both.
    pub const fn merge(self, other: Span) -&gt; Span {
        let start = if self.start.0 &lt; other.start.0 { self.start } else { other.start };
        let end = if self.end.0 &gt; other.end.0 { self.end } else { other.end };
        Span { start, end }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="linecolumn-calculation"><a class="header" href="#linecolumn-calculation">Line/Column Calculation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Computes line and column from a byte position.
pub fn line_col(source: &amp;str, pos: BytePos) -&gt; (usize, usize) {
    let offset = pos.as_usize().min(source.len());
    let mut line = 1;
    let mut col = 1;

    for (i, ch) in source.char_indices() {
        if i &gt;= offset { break; }
        if ch == '\n' {
            line += 1;
            col = 1;
        } else {
            col += 1;
        }
    }

    (line, col)
}

/// Returns the line containing a position.
pub fn get_line(source: &amp;str, pos: BytePos) -&gt; &amp;str {
    let offset = pos.as_usize().min(source.len());
    let line_start = source[..offset].rfind('\n').map(|i| i + 1).unwrap_or(0);
    let line_end = source[offset..].find('\n').map(|i| offset + i).unwrap_or(source.len());
    &amp;source[line_start..line_end]
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-recovery"><a class="header" href="#error-recovery">Error Recovery</a></h2>
<h3 id="error-creation-patterns"><a class="header" href="#error-creation-patterns">Error Creation Patterns</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Unexpected token
ParseError::unexpected(
    TokenKind::Comma,
    self.current.span,
    "column name"
)

// Unexpected EOF
ParseError::unexpected_eof(
    self.current.span,
    "expression"
)

// Invalid syntax
ParseError::invalid(
    "CASE requires at least one WHEN clause",
    self.current.span
)

// With help message
ParseError::invalid("unknown keyword SELCT", span)
    .with_help("did you mean SELECT?")
<span class="boring">}</span></code></pre></pre>
<h3 id="error-formatting"><a class="header" href="#error-formatting">Error Formatting</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn format_with_source(&amp;self, source: &amp;str) -&gt; String {
    let (line, col) = line_col(source, self.span.start);
    let line_text = get_line(source, self.span.start);

    // Build error message with source context
    let mut result = format!("error: {}\n", self.kind);
    result.push_str(&amp;format!("  --&gt; line {}:{}\n", line, col));
    result.push_str("   |\n");
    result.push_str(&amp;format!("{:3} | {}\n", line, line_text));
    result.push_str("   | ");

    // Add carets under the error location
    for _ in 0..(col - 1) { result.push(' '); }
    let len = self.span.len().max(1) as usize;
    for _ in 0..len.min(line_text.len() - col + 1).max(1) {
        result.push('^');
    }
    result.push('\n');

    if let Some(help) = &amp;self.help {
        result.push_str(&amp;format!("   = help: {}\n", help));
    }

    result
}
<span class="boring">}</span></code></pre></pre>
<h3 id="example-error-output"><a class="header" href="#example-error-output">Example Error Output</a></h3>
<pre><code class="language-sql">error: unexpected FROM, expected expression or '*' after SELECT
  --&gt; line 1:8
   |
  1 | SELECT FROM users
   |        ^^^^
</code></pre>
<h2 id="usage-examples-8"><a class="header" href="#usage-examples-8">Usage Examples</a></h2>
<h3 id="parse-a-statement"><a class="header" href="#parse-a-statement">Parse a Statement</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::parse;

let stmt = parse("SELECT * FROM users WHERE id = 1")?;

match &amp;stmt.kind {
    StatementKind::Select(select) =&gt; {
        println!("Distinct: {}", select.distinct);
        println!("Columns: {}", select.columns.len());
        if let Some(from) = &amp;select.from {
            println!("Table: {:?}", from.table.kind);
        }
        if let Some(where_clause) = &amp;select.where_clause {
            println!("Has WHERE clause");
        }
    }
    _ =&gt; {}
}
<span class="boring">}</span></code></pre></pre>
<h3 id="parse-multiple-statements"><a class="header" href="#parse-multiple-statements">Parse Multiple Statements</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::parse_all;

let stmts = parse_all("SELECT 1; SELECT 2; INSERT INTO t VALUES (1)")?;
assert_eq!(stmts.len(), 3);

for stmt in &amp;stmts {
    println!("Statement at {:?}", stmt.span);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="parse-an-expression"><a class="header" href="#parse-an-expression">Parse an Expression</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::parse_expr;

let expr = parse_expr("1 + 2 * 3")?;
// Parses as: 1 + (2 * 3) due to precedence

if let ExprKind::Binary(lhs, BinaryOp::Add, rhs) = expr.kind {
    // lhs = Literal(1)
    // rhs = Binary(Literal(2), Mul, Literal(3))
}
<span class="boring">}</span></code></pre></pre>
<h3 id="tokenize-source"><a class="header" href="#tokenize-source">Tokenize Source</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::tokenize;

let tokens = tokenize("SELECT * FROM users");
for token in tokens {
    println!("{:?} at {:?}", token.kind, token.span);
}

// Output:
// Select at 0..6
// Star at 7..8
// From at 9..13
// Ident("users") at 14..19
// Eof at 19..19
<span class="boring">}</span></code></pre></pre>
<h3 id="working-with-the-parser-directly"><a class="header" href="#working-with-the-parser-directly">Working with the Parser Directly</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::Parser;

let mut parser = Parser::new("SELECT 1; SELECT 2");

// Parse first statement
let stmt1 = parser.parse_statement()?;
assert!(matches!(stmt1.kind, StatementKind::Select(_)));

// Parse second statement
let stmt2 = parser.parse_statement()?;
assert!(matches!(stmt2.kind, StatementKind::Select(_)));

// Third call returns Empty (EOF)
let stmt3 = parser.parse_statement()?;
assert!(matches!(stmt3.kind, StatementKind::Empty));
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::parse;

let result = parse("SELECT FROM users");
if let Err(e) = result {
    // Format error with source context
    let formatted = e.format_with_source("SELECT FROM users");
    println!("{}", formatted);

    // Access error details
    println!("Error kind: {:?}", e.kind);
    println!("Span: {:?}", e.span);
    if let Some(help) = &amp;e.help {
        println!("Help: {}", help);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="grammar-overview"><a class="header" href="#grammar-overview">Grammar Overview</a></h2>
<h3 id="select-statement"><a class="header" href="#select-statement">SELECT Statement</a></h3>
<pre><code class="language-sql">SELECT [DISTINCT | ALL] columns
FROM table [alias]
[JOIN table ON condition | USING (cols)]...
[WHERE condition]
[GROUP BY exprs]
[HAVING condition]
[ORDER BY expr [ASC|DESC] [NULLS FIRST|LAST]]...
[LIMIT n]
[OFFSET n]
</code></pre>
<h3 id="create-table-statement"><a class="header" href="#create-table-statement">CREATE TABLE Statement</a></h3>
<pre><code class="language-sql">CREATE TABLE [IF NOT EXISTS] name (
    column type [NULL|NOT NULL] [PRIMARY KEY] [UNIQUE]
                [DEFAULT expr] [CHECK(expr)]
                [REFERENCES table(col) [ON DELETE action] [ON UPDATE action]]
    [, ...]
    [, PRIMARY KEY (cols)]
    [, UNIQUE (cols)]
    [, FOREIGN KEY (cols) REFERENCES table(cols)]
    [, CHECK (expr)]
)
</code></pre>
<h3 id="graph-operations"><a class="header" href="#graph-operations">Graph Operations</a></h3>
<pre><code class="language-sql">NODE CREATE label {properties}
NODE GET id
NODE DELETE id
NODE LIST [label]

EDGE CREATE from -&gt; to : type {properties}
EDGE GET id
EDGE DELETE id
EDGE LIST [type]

NEIGHBORS node [OUTGOING|INCOMING|BOTH] [edge_type]
          [BY SIMILAR [vector] LIMIT n]

PATH [SHORTEST|ALL] from TO to [MAX depth]
</code></pre>
<h3 id="vector-operations"><a class="header" href="#vector-operations">Vector Operations</a></h3>
<pre><code class="language-sql">EMBED STORE key [vector]
EMBED GET key
EMBED DELETE key
EMBED BUILD INDEX
EMBED BATCH [(key, [vector]), ...]

SIMILAR key|[vector] [LIMIT k] [COSINE|EUCLIDEAN|DOT_PRODUCT]
        [CONNECTED TO entity]
</code></pre>
<h3 id="chain-operations"><a class="header" href="#chain-operations">Chain Operations</a></h3>
<pre><code class="language-text">BEGIN CHAIN TRANSACTION
COMMIT CHAIN
ROLLBACK CHAIN TO height

CHAIN HEIGHT
CHAIN TIP
CHAIN BLOCK height
CHAIN VERIFY
CHAIN HISTORY key
CHAIN SIMILAR [embedding] LIMIT n
CHAIN DRIFT FROM height TO height

SHOW CODEBOOK GLOBAL
SHOW CODEBOOK LOCAL domain
ANALYZE CODEBOOK TRANSITIONS
</code></pre>
<h2 id="reserved-keywords"><a class="header" href="#reserved-keywords">Reserved Keywords</a></h2>
<p>Keywords are case-insensitive. The lexer converts to uppercase for matching.</p>
<p><strong>SQL (70+ keywords)</strong>: SELECT, DISTINCT, ALL, FROM, WHERE, INSERT, INTO,
VALUES, UPDATE, SET, DELETE, CREATE, DROP, TABLE, INDEX, AND, OR, NOT, NULL, IS,
IN, LIKE, BETWEEN, ORDER, BY, ASC, DESC, NULLS, FIRST, LAST, LIMIT, OFFSET,
GROUP, HAVING, JOIN, INNER, LEFT, RIGHT, FULL, OUTER, CROSS, NATURAL, ON, USING,
AS, PRIMARY, KEY, UNIQUE, REFERENCES, FOREIGN, CHECK, DEFAULT, CASCADE,
RESTRICT, IF, EXISTS, SHOW, TABLES, UNION, INTERSECT, EXCEPT, CASE, WHEN, THEN,
ELSE, END, CAST, ANY</p>
<p><strong>Types (16 keywords)</strong>: INT, INTEGER, BIGINT, SMALLINT, FLOAT, DOUBLE, REAL,
DECIMAL, NUMERIC, VARCHAR, CHAR, TEXT, BOOLEAN, DATE, TIME, TIMESTAMP</p>
<p><strong>Aggregates (5 keywords)</strong>: COUNT, SUM, AVG, MIN, MAX</p>
<p><strong>Graph (16 keywords)</strong>: NODE, EDGE, NEIGHBORS, PATH, GET, LIST, STORE,
OUTGOING, INCOMING, BOTH, SHORTEST, PROPERTIES, LABEL, VERTEX, VERTICES, EDGES</p>
<p><strong>Vector (10 keywords)</strong>: EMBED, SIMILAR, VECTOR, EMBEDDING, DIMENSION,
DISTANCE, COSINE, EUCLIDEAN, DOT_PRODUCT, BUILD</p>
<p><strong>Unified (6 keywords)</strong>: FIND, WITH, RETURN, MATCH, ENTITY, CONNECTED</p>
<p><strong>Domain (30+ keywords)</strong>: VAULT, GRANT, REVOKE, ROTATE, CACHE, INIT, STATS,
CLEAR, EVICT, PUT, SEMANTIC, THRESHOLD, CHECKPOINT, ROLLBACK, CHAIN, BEGIN,
COMMIT, TRANSACTION, HISTORY, DRIFT, CODEBOOK, GLOBAL, LOCAL, ANALYZE, HEIGHT,
TIP, BLOCK, CLUSTER, CONNECT, DISCONNECT, STATUS, NODES, LEADER, BLOB, BLOBS,
INFO, LINK, TAG, VERIFY, GC, REPAIR</p>
<h3 id="contextual-keywords"><a class="header" href="#contextual-keywords">Contextual Keywords</a></h3>
<p>These keywords can be used as identifiers in expression contexts (column names,
etc.):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn is_contextual_keyword(&amp;self) -&gt; bool {
    matches!(self,
        Status | Nodes | Leader | Connect | Disconnect | Cluster |
        Blobs | Info | Link | Unlink | Links | Tag | Untag | Verify | Gc | Repair |
        Height | Transitions | Tip | Block | Codebook | Global | Local | Drift |
        Begin | Commit | Transaction | ...
    )
}
<span class="boring">}</span></code></pre></pre>
<h2 id="edge-cases-and-gotchas-10"><a class="header" href="#edge-cases-and-gotchas-10">Edge Cases and Gotchas</a></h2>
<h3 id="ambiguous-token-sequences"><a class="header" href="#ambiguous-token-sequences">Ambiguous Token Sequences</a></h3>
<ol>
<li><strong>Minus vs Arrow</strong>: <code>-</code> vs <code>-&gt;</code> distinguished by lookahead</li>
<li><strong>Less-than variants</strong>: <code>&lt;</code> vs <code>&lt;=</code> vs <code>&lt;&gt;</code> vs <code>&lt;&lt;</code></li>
<li><strong>Pipe variants</strong>: <code>|</code> (bitwise) vs <code>||</code> (concat)</li>
<li><strong>Keyword as identifier</strong>: <code>SELECT status FROM orders</code> - <code>status</code> is
contextual keyword</li>
</ol>
<h3 id="number-parsing-edge-cases"><a class="header" href="#number-parsing-edge-cases">Number Parsing Edge Cases</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// "3." is integer 3 followed by dot
tokens("3. ") // [Integer(3), Dot, Eof]

// "3.0" is float
tokens("3.0") // [Float(3.0), Eof]

// "3.x" is integer 3, dot, identifier x
tokens("3.x") // [Integer(3), Dot, Ident("x"), Eof]

// Scientific notation
tokens("1e10")   // [Float(1e10), Eof]
tokens("2.5E-3") // [Float(0.0025), Eof]
<span class="boring">}</span></code></pre></pre>
<h3 id="string-literal-edge-cases"><a class="header" href="#string-literal-edge-cases">String Literal Edge Cases</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// SQL-style doubled quotes
tokens("'it''s'") // [String("it's"), Eof]

// Unterminated string
tokens("'unterminated") // [Error("unterminated string literal"), Eof]

// String with newline (error)
tokens("'line1\nline2'") // Error - strings cannot span lines
<span class="boring">}</span></code></pre></pre>
<h3 id="expression-depth-limit"><a class="header" href="#expression-depth-limit">Expression Depth Limit</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Deeply nested expressions hit the depth limit (64)
let mut expr = "x".to_string();
for _ in 0..70 {
    expr = format!("({})", expr);
}
parse_expr(&amp;expr) // Err(ParseErrorKind::TooDeep)
<span class="boring">}</span></code></pre></pre>
<h3 id="between-precedence"><a class="header" href="#between-precedence">BETWEEN Precedence</a></h3>
<p>The <code>AND</code> in <code>BETWEEN low AND high</code> is part of the BETWEEN syntax, not a logical
operator:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// "x BETWEEN 1 AND 10 AND y = 5" parses as:
// (x BETWEEN 1 AND 10) AND (y = 5)
// Not: x BETWEEN 1 AND (10 AND y = 5)
<span class="boring">}</span></code></pre></pre>
<h3 id="qualified-wildcard-restriction"><a class="header" href="#qualified-wildcard-restriction">Qualified Wildcard Restriction</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Valid: table.*
parse_expr("users.*") // Ok(QualifiedWildcard)

// Invalid: (expr).*
parse_expr("(1 + 2).*") // Err("qualified wildcard requires identifier")
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-4"><a class="header" href="#performance-4">Performance</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td>Tokenize</td><td>O(n)</td><td>Single pass, no backtracking</td></tr>
<tr><td>Parse</td><td>O(n)</td><td>Single pass, constant stack per token</td></tr>
<tr><td>Total</td><td>O(n)</td><td>Where n = input length</td></tr>
</tbody></table>
</div>
<h3 id="memory-usage"><a class="header" href="#memory-usage">Memory Usage</a></h3>
<ul>
<li>Lexer: O(1) - only stores position and one peeked character</li>
<li>Parser: O(1) - only stores current and peeked token</li>
<li>AST: O(n) - proportional to number of nodes</li>
<li>Span: 8 bytes per span (two u32 values)</li>
</ul>
<h3 id="optimizations"><a class="header" href="#optimizations">Optimizations</a></h3>
<ol>
<li><strong>Keyword lookup</strong>: O(1) via match statement on uppercase string</li>
<li><strong>Token comparison</strong>: Uses <code>std::mem::discriminant</code> for enum comparison</li>
<li><strong>Span tracking</strong>: Constant-time merge operation</li>
<li><strong>No allocations during parsing</strong>: Identifiers and strings owned in tokens</li>
</ol>
<h2 id="related-modules-11"><a class="header" href="#related-modules-11">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>query_router</code></td><td>Consumes AST and executes queries against engines</td></tr>
<tr><td><code>neumann_shell</code></td><td>Uses parser for interactive REPL commands</td></tr>
<tr><td><code>tensor_chain</code></td><td>Chain statements (BEGIN, COMMIT, HISTORY) parsed here</td></tr>
<tr><td><code>tensor_vault</code></td><td>Vault statements (SET, GET, GRANT) parsed here</td></tr>
<tr><td><code>tensor_cache</code></td><td>Cache statements (INIT, STATS, PUT) parsed here</td></tr>
<tr><td><code>tensor_blob</code></td><td>Blob statements (PUT, GET, TAG) parsed here</td></tr>
</tbody></table>
</div>
<h2 id="testing"><a class="header" href="#testing">Testing</a></h2>
<p>The parser has comprehensive test coverage including:</p>
<ul>
<li><strong>Unit tests in each module</strong>: Token, span, lexer, parser, expression tests</li>
<li><strong>Integration tests</strong>: Complex SQL queries, multi-statement parsing</li>
<li><strong>Edge case tests</strong>: Unterminated strings, deeply nested expressions,
ambiguous operators</li>
<li><strong>Fuzz targets</strong>: <code>parser_parse</code>, <code>parser_parse_all</code>, <code>parser_parse_expr</code>,
<code>parser_tokenize</code></li>
</ul>
<pre><code class="language-bash"># Run parser tests
cargo test -p neumann_parser

# Run parser fuzz targets
cargo +nightly fuzz run parser_parse -- -max_total_time=60
cargo +nightly fuzz run parser_tokenize -- -max_total_time=60
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="query-router"><a class="header" href="#query-router">Query Router</a></h1>
<p>Query Router is the unified query execution layer for Neumann. It parses shell
commands, routes them to appropriate engines, and combines results. All query
types (relational, graph, vector, unified) flow through the router, which
provides a single entry point for the entire system.</p>
<p>The router supports both synchronous and asynchronous execution, optional result
caching, and distributed query execution when cluster mode is enabled.</p>
<h2 id="key-types-10"><a class="header" href="#key-types-10">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>QueryRouter</code></td><td>Main router orchestrating queries across all engines</td></tr>
<tr><td><code>QueryResult</code></td><td>Unified result enum for all query types</td></tr>
<tr><td><code>RouterError</code></td><td>Error types for query routing failures</td></tr>
<tr><td><code>NodeResult</code></td><td>Graph node result with id, label, properties</td></tr>
<tr><td><code>EdgeResult</code></td><td>Graph edge result with id, from, to, label</td></tr>
<tr><td><code>SimilarResult</code></td><td>Vector similarity result with key and score</td></tr>
<tr><td><code>UnifiedResult</code></td><td>Cross-engine query result with description and items</td></tr>
<tr><td><code>ChainResult</code></td><td>Blockchain operation results</td></tr>
<tr><td><code>QueryPlanner</code></td><td>Plans distributed query execution across shards</td></tr>
<tr><td><code>ResultMerger</code></td><td>Merges results from multiple shards</td></tr>
<tr><td><code>ShardResult</code></td><td>Result from a single shard with timing and error info</td></tr>
<tr><td><code>DistributedQueryConfig</code></td><td>Configuration for distributed execution</td></tr>
<tr><td><code>DistributedQueryStats</code></td><td>Statistics tracking for distributed queries</td></tr>
<tr><td><code>FilterCondition</code></td><td>Re-exported from vector_engine for programmatic filter building</td></tr>
<tr><td><code>FilterValue</code></td><td>Re-exported from vector_engine for filter values</td></tr>
<tr><td><code>FilterStrategy</code></td><td>Re-exported from vector_engine for search strategy</td></tr>
<tr><td><code>FilteredSearchConfig</code></td><td>Re-exported from vector_engine for filtered search config</td></tr>
</tbody></table>
</div>
<h3 id="queryresult-variants"><a class="header" href="#queryresult-variants">QueryResult Variants</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Description</th><th>Typical Source</th></tr></thead><tbody>
<tr><td><code>Empty</code></td><td>No result (CREATE, INSERT)</td><td>DDL, writes</td></tr>
<tr><td><code>Value(String)</code></td><td>Single value result</td><td>Scalar queries, DESCRIBE</td></tr>
<tr><td><code>Count(usize)</code></td><td>Count of affected rows/nodes/edges</td><td>UPDATE, DELETE</td></tr>
<tr><td><code>Ids(Vec&lt;u64&gt;)</code></td><td>List of IDs</td><td>INSERT</td></tr>
<tr><td><code>Rows(Vec&lt;Row&gt;)</code></td><td>Relational query results</td><td>SELECT</td></tr>
<tr><td><code>Nodes(Vec&lt;NodeResult&gt;)</code></td><td>Graph node results</td><td>NODE queries</td></tr>
<tr><td><code>Edges(Vec&lt;EdgeResult&gt;)</code></td><td>Graph edge results</td><td>EDGE queries</td></tr>
<tr><td><code>Path(Vec&lt;u64&gt;)</code></td><td>Graph traversal path</td><td>PATH queries</td></tr>
<tr><td><code>Similar(Vec&lt;SimilarResult&gt;)</code></td><td>Vector similarity results</td><td>SIMILAR queries</td></tr>
<tr><td><code>Unified(UnifiedResult)</code></td><td>Cross-engine query results</td><td>FIND queries</td></tr>
<tr><td><code>TableList(Vec&lt;String&gt;)</code></td><td>List of table names</td><td>SHOW TABLES</td></tr>
<tr><td><code>Blob(Vec&lt;u8&gt;)</code></td><td>Blob data bytes</td><td>BLOB GET</td></tr>
<tr><td><code>ArtifactInfo(ArtifactInfoResult)</code></td><td>Blob artifact metadata</td><td>BLOB INFO</td></tr>
<tr><td><code>ArtifactList(Vec&lt;String&gt;)</code></td><td>List of artifact IDs</td><td>BLOBS LIST</td></tr>
<tr><td><code>BlobStats(BlobStatsResult)</code></td><td>Blob storage statistics</td><td>BLOB STATS</td></tr>
<tr><td><code>CheckpointList(Vec&lt;CheckpointInfo&gt;)</code></td><td>List of checkpoints</td><td>CHECKPOINTS</td></tr>
<tr><td><code>Chain(ChainResult)</code></td><td>Chain operation result</td><td>CHAIN queries</td></tr>
</tbody></table>
</div>
<h3 id="routererror-types"><a class="header" href="#routererror-types">RouterError Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th><th>Recovery</th></tr></thead><tbody>
<tr><td><code>ParseError</code></td><td>Invalid query syntax</td><td>Fix query syntax</td></tr>
<tr><td><code>UnknownCommand</code></td><td>Unknown command or keyword</td><td>Check command spelling</td></tr>
<tr><td><code>RelationalError</code></td><td>Error from relational engine</td><td>Check table/column names</td></tr>
<tr><td><code>GraphError</code></td><td>Error from graph engine</td><td>Verify node/edge IDs</td></tr>
<tr><td><code>VectorError</code></td><td>Error from vector engine</td><td>Check embedding dimensions</td></tr>
<tr><td><code>VaultError</code></td><td>Error from vault</td><td>Verify permissions</td></tr>
<tr><td><code>CacheError</code></td><td>Error from cache</td><td>Check cache configuration</td></tr>
<tr><td><code>BlobError</code></td><td>Error from blob storage</td><td>Verify artifact exists</td></tr>
<tr><td><code>CheckpointError</code></td><td>Error from checkpoint system</td><td>Check blob store initialized</td></tr>
<tr><td><code>ChainError</code></td><td>Error from chain system</td><td>Verify chain initialized</td></tr>
<tr><td><code>InvalidArgument</code></td><td>Invalid argument value</td><td>Check argument types</td></tr>
<tr><td><code>MissingArgument</code></td><td>Missing required argument</td><td>Provide required args</td></tr>
<tr><td><code>TypeMismatch</code></td><td>Type mismatch in query</td><td>Check value types</td></tr>
<tr><td><code>AuthenticationRequired</code></td><td>Vault operations require identity</td><td>Call <code>SET IDENTITY</code> first</td></tr>
</tbody></table>
</div>
<h3 id="error-propagation"><a class="header" href="#error-propagation">Error Propagation</a></h3>
<p>The router implements <code>From</code> traits to convert engine-specific errors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Errors from underlying engines are automatically converted
impl From&lt;RelationalError&gt; for RouterError {
    fn from(e: RelationalError) -&gt; Self {
        RouterError::RelationalError(e.to_string())
    }
}

impl From&lt;GraphError&gt; for RouterError { ... }
impl From&lt;VectorError&gt; for RouterError { ... }
impl From&lt;VaultError&gt; for RouterError { ... }
impl From&lt;CacheError&gt; for RouterError { ... }
impl From&lt;BlobError&gt; for RouterError { ... }
impl From&lt;CheckpointError&gt; for RouterError { ... }
impl From&lt;ChainError&gt; for RouterError { ... }
impl From&lt;UnifiedError&gt; for RouterError { ... }
<span class="boring">}</span></code></pre></pre>
<p>This allows using the <code>?</code> operator throughout execution methods:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn exec_select(&amp;self, select: &amp;SelectStmt) -&gt; Result&lt;QueryResult&gt; {
    // RelationalError automatically converts to RouterError
    let rows = self.relational.select_columnar(table_name, condition, options)?;
    Ok(QueryResult::Rows(rows))
}
<span class="boring">}</span></code></pre></pre>
<h2 id="architecture-10"><a class="header" href="#architecture-10">Architecture</a></h2>
<pre class="mermaid">graph TB
    subgraph QueryRouter
        Execute[execute_parsed]
        ExecuteAsync[execute_parsed_async]
        Distributed[try_execute_distributed]
        Cache[Query Cache]
        Statement[execute_statement]
        StatementAsync[execute_statement_async]
    end

    Execute --&gt; Distributed
    ExecuteAsync --&gt; StatementAsync
    Distributed --&gt;|cluster active| ScatterGather[Scatter-Gather]
    Distributed --&gt;|local| Cache
    Cache --&gt;|cache hit| Return[Return Result]
    Cache --&gt;|cache miss| Statement

    Statement --&gt; Relational[RelationalEngine]
    Statement --&gt; Graph[GraphEngine]
    Statement --&gt; Vector[VectorEngine]
    Statement --&gt; Vault[Vault]
    Statement --&gt; CacheOps[Cache Operations]
    Statement --&gt; Blob[BlobStore]
    Statement --&gt; Checkpoint[CheckpointManager]
    Statement --&gt; Chain[TensorChain]
    Statement --&gt; Cluster[ClusterOrchestrator]

    subgraph Engines
        Relational
        Graph
        Vector
    end

    subgraph Optional Services
        Vault
        CacheOps
        Blob
        Checkpoint
        Chain
        Cluster
    end

    Relational --&gt; Store[TensorStore]
    Graph --&gt; Store
    Vector --&gt; Store
</pre>
<h3 id="internal-router-structure"><a class="header" href="#internal-router-structure">Internal Router Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct QueryRouter {
    // Core engines (always initialized)
    relational: Arc&lt;RelationalEngine&gt;,
    graph: Arc&lt;GraphEngine&gt;,
    vector: Arc&lt;VectorEngine&gt;,

    // Unified engine for cross-engine queries (lazily initialized)
    unified: Option&lt;UnifiedEngine&gt;,

    // Optional services (require explicit initialization)
    vault: Option&lt;Arc&lt;Vault&gt;&gt;,
    cache: Option&lt;Arc&lt;Cache&gt;&gt;,
    blob: Option&lt;Arc&lt;tokio::sync::Mutex&lt;BlobStore&gt;&gt;&gt;,
    blob_runtime: Option&lt;Arc&lt;Runtime&gt;&gt;,
    checkpoint: Option&lt;Arc&lt;tokio::sync::Mutex&lt;CheckpointManager&gt;&gt;&gt;,
    chain: Option&lt;Arc&lt;TensorChain&gt;&gt;,

    // Cluster mode
    cluster: Option&lt;Arc&lt;ClusterOrchestrator&gt;&gt;,
    cluster_runtime: Option&lt;Arc&lt;Runtime&gt;&gt;,
    distributed_planner: Option&lt;Arc&lt;QueryPlanner&gt;&gt;,
    distributed_config: DistributedQueryConfig,
    local_shard_id: ShardId,

    // Authentication state
    current_identity: Option&lt;String&gt;,

    // Vector index for fast similarity search
    hnsw_index: Option&lt;(HNSWIndex, Vec&lt;String&gt;)&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="initialization-1"><a class="header" href="#initialization-1">Initialization</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use query_router::QueryRouter;
use tensor_store::TensorStore;

// Create with independent engines
let router = QueryRouter::new();

// Create with existing engines
let router = QueryRouter::with_engines(relational, graph, vector);

// Create with shared storage (enables unified entities)
let store = TensorStore::new();
let router = QueryRouter::with_shared_store(store);
<span class="boring">}</span></code></pre></pre>
<h3 id="constructor-comparison"><a class="header" href="#constructor-comparison">Constructor Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Constructor</th><th>UnifiedEngine</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>new()</code></td><td>No</td><td>Simple single-engine queries</td></tr>
<tr><td><code>with_engines(...)</code></td><td>No</td><td>Custom engine configuration</td></tr>
<tr><td><code>with_shared_store(...)</code></td><td>Yes</td><td>Cross-engine unified queries</td></tr>
</tbody></table>
</div>
<h3 id="shared-store-benefits"><a class="header" href="#shared-store-benefits">Shared Store Benefits</a></h3>
<p>When using <code>with_shared_store()</code>, all engines share the same underlying
<code>TensorStore</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn with_shared_store(store: TensorStore) -&gt; Self {
    let relational = Arc::new(RelationalEngine::with_store(store.clone()));
    let graph = Arc::new(GraphEngine::with_store(store.clone()));
    let vector = Arc::new(VectorEngine::with_store(store.clone()));
    let unified = UnifiedEngine::with_engines(
        store,
        Arc::clone(&amp;relational),
        Arc::clone(&amp;graph),
        Arc::clone(&amp;vector),
    );
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p>This enables:</p>
<ul>
<li>Cross-engine queries via <code>UnifiedEngine</code></li>
<li>Entity-level operations spanning all modalities</li>
<li>Consistent view of data across engines</li>
</ul>
<h2 id="query-execution"><a class="header" href="#query-execution">Query Execution</a></h2>
<h3 id="execution-methods"><a class="header" href="#execution-methods">Execution Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Parser</th><th>Async</th><th>Distributed</th><th>Cache</th></tr></thead><tbody>
<tr><td><code>execute(command)</code></td><td>Regex (legacy)</td><td>No</td><td>No</td><td>No</td></tr>
<tr><td><code>execute_parsed(command)</code></td><td>AST</td><td>No</td><td>Yes</td><td>Yes</td></tr>
<tr><td><code>execute_parsed_async(command)</code></td><td>AST</td><td>Yes</td><td>No</td><td>Yes</td></tr>
<tr><td><code>execute_statement(stmt)</code></td><td>Pre-parsed</td><td>No</td><td>No</td><td>No</td></tr>
<tr><td><code>execute_statement_async(stmt)</code></td><td>Pre-parsed</td><td>Yes</td><td>No</td><td>No</td></tr>
</tbody></table>
</div>
<h3 id="execution-flow"><a class="header" href="#execution-flow">Execution Flow</a></h3>
<pre class="mermaid">flowchart TD
    A[execute_parsed] --&gt; B{Cluster Active?}
    B --&gt;|Yes| C[try_execute_distributed]
    B --&gt;|No| D[Parse Command]

    C --&gt; E{Plan Type}
    E --&gt;|Local| D
    E --&gt;|Remote| F[execute_on_shard]
    E --&gt;|ScatterGather| G[execute_scatter_gather]

    D --&gt; H{Cacheable?}
    H --&gt;|Yes| I{Cache Hit?}
    H --&gt;|No| J[execute_statement]

    I --&gt;|Yes| K[Return Cached]
    I --&gt;|No| J

    J --&gt; L[Engine Dispatch]
    L --&gt; M{Write Op?}
    M --&gt;|Yes| N[Invalidate Cache]
    M --&gt;|No| O[Cache Result]

    O --&gt; P[Return Result]
    N --&gt; P
    K --&gt; P
    F --&gt; P
    G --&gt; P
</pre>
<h3 id="detailed-execution-steps"><a class="header" href="#detailed-execution-steps">Detailed Execution Steps</a></h3>
<ol>
<li><strong>Distributed Check</strong>: If cluster is active, <code>try_execute_distributed</code> plans
query execution</li>
<li><strong>Parse</strong>: Convert command string to AST via <code>neumann_parser</code></li>
<li><strong>Cache Check</strong>: For cacheable queries (<code>SELECT</code>, <code>SIMILAR</code>, <code>NEIGHBORS</code>,
<code>PATH</code>), check cache first</li>
<li><strong>Execute</strong>: Dispatch to appropriate engine based on <code>StatementKind</code></li>
<li><strong>Cache Update</strong>: Store result for cacheable queries (as JSON via serde)</li>
<li><strong>Invalidate</strong>: Clear entire cache on write operations (INSERT, UPDATE,
DELETE, DDL)</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Synchronous execution
let result = router.execute_parsed("SELECT * FROM users")?;

// Async execution
let result = router.execute_parsed_async("SELECT * FROM users").await?;

// Concurrent queries
let (users, posts, similar) = tokio::join!(
    router.execute_parsed_async("SELECT * FROM users"),
    router.execute_parsed_async("SELECT * FROM posts"),
    router.execute_parsed_async("SIMILAR 'doc:1' LIMIT 10"),
);
<span class="boring">}</span></code></pre></pre>
<h3 id="cache-key-generation"><a class="header" href="#cache-key-generation">Cache Key Generation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn cache_key_for_query(command: &amp;str) -&gt; String {
    format!("query:{}", command.trim().to_lowercase())
}
<span class="boring">}</span></code></pre></pre>
<p>This normalizes queries for cache lookup by trimming whitespace and lowercasing.</p>
<h2 id="statement-routing"><a class="header" href="#statement-routing">Statement Routing</a></h2>
<p>The router dispatches statements based on their <code>StatementKind</code>:</p>
<pre class="mermaid">flowchart LR
    subgraph StatementKind
        SQL[Select/Insert/Update/Delete]
        DDL[CreateTable/DropTable/CreateIndex/DropIndex]
        Graph[Node/Edge/Neighbors/Path]
        Vector[Embed/Similar]
        Unified[Find/Entity]
        Services[Vault/Cache/Blob/Checkpoint/Chain/Cluster]
    end

    SQL --&gt; RE[RelationalEngine]
    DDL --&gt; RE
    Graph --&gt; GE[GraphEngine]
    Vector --&gt; VE[VectorEngine]
    Unified --&gt; UE[UnifiedEngine]
    Services --&gt; Svc[Optional Services]
</pre>
<h3 id="complete-statement-routing-table"><a class="header" href="#complete-statement-routing-table">Complete Statement Routing Table</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Statement Type</th><th>Engine</th><th>Handler Method</th><th>Operations</th></tr></thead><tbody>
<tr><td><code>Select</code></td><td>Relational</td><td><code>exec_select</code></td><td>Table queries with WHERE, JOIN, GROUP BY, ORDER BY</td></tr>
<tr><td><code>Insert</code></td><td>Relational</td><td><code>exec_insert</code></td><td>Single/multi-row insert, INSERT…SELECT</td></tr>
<tr><td><code>Update</code></td><td>Relational</td><td><code>exec_update</code></td><td>Row updates with conditions</td></tr>
<tr><td><code>Delete</code></td><td>Relational</td><td><code>exec_delete</code></td><td>Row deletion with protection</td></tr>
<tr><td><code>CreateTable</code></td><td>Relational</td><td><code>exec_create_table</code></td><td>Table DDL</td></tr>
<tr><td><code>DropTable</code></td><td>Relational</td><td>inline</td><td>Table removal with protection</td></tr>
<tr><td><code>CreateIndex</code></td><td>Relational</td><td>inline</td><td>Index creation</td></tr>
<tr><td><code>DropIndex</code></td><td>Relational</td><td>inline</td><td>Index removal with protection</td></tr>
<tr><td><code>ShowTables</code></td><td>Relational</td><td>inline</td><td>List tables</td></tr>
<tr><td><code>Describe</code></td><td>Multiple</td><td><code>exec_describe</code></td><td>Schema/node/edge info</td></tr>
<tr><td><code>Node</code></td><td>Graph</td><td><code>exec_node</code></td><td>CREATE/GET/DELETE/LIST/UPDATE</td></tr>
<tr><td><code>Edge</code></td><td>Graph</td><td><code>exec_edge</code></td><td>CREATE/GET/DELETE/LIST/UPDATE</td></tr>
<tr><td><code>Neighbors</code></td><td>Graph</td><td><code>exec_neighbors</code></td><td>Neighbor traversal</td></tr>
<tr><td><code>Path</code></td><td>Graph</td><td><code>exec_path</code></td><td>Path finding</td></tr>
<tr><td><code>Embed</code></td><td>Vector</td><td><code>exec_embed</code></td><td>Embedding storage, batch, delete</td></tr>
<tr><td><code>Similar</code></td><td>Vector</td><td><code>exec_similar</code></td><td>k-NN search</td></tr>
<tr><td><code>ShowEmbeddings</code></td><td>Vector</td><td>inline</td><td>List embedding keys</td></tr>
<tr><td><code>CountEmbeddings</code></td><td>Vector</td><td>inline</td><td>Count embeddings</td></tr>
<tr><td><code>Find</code></td><td>Unified</td><td><code>exec_find</code></td><td>Cross-engine queries</td></tr>
<tr><td><code>Entity</code></td><td>Unified</td><td><code>exec_entity</code></td><td>Entity CRUD</td></tr>
<tr><td><code>Vault</code></td><td>Vault</td><td><code>exec_vault</code></td><td>Secret management</td></tr>
<tr><td><code>Cache</code></td><td>Cache</td><td><code>exec_cache</code></td><td>LLM response cache</td></tr>
<tr><td><code>Blob</code></td><td>BlobStore</td><td><code>exec_blob</code></td><td>Artifact operations</td></tr>
<tr><td><code>Blobs</code></td><td>BlobStore</td><td><code>exec_blobs</code></td><td>Artifact listing</td></tr>
<tr><td><code>Checkpoint</code></td><td>Checkpoint</td><td><code>exec_checkpoint</code></td><td>Create snapshot</td></tr>
<tr><td><code>Rollback</code></td><td>Checkpoint</td><td><code>exec_rollback</code></td><td>Restore snapshot</td></tr>
<tr><td><code>Checkpoints</code></td><td>Checkpoint</td><td><code>exec_checkpoints</code></td><td>List snapshots</td></tr>
<tr><td><code>Chain</code></td><td>TensorChain</td><td><code>exec_chain</code></td><td>Blockchain operations</td></tr>
<tr><td><code>Cluster</code></td><td>Orchestrator</td><td><code>exec_cluster</code></td><td>Cluster management</td></tr>
<tr><td><code>Empty</code></td><td>—</td><td>inline</td><td>No-op</td></tr>
</tbody></table>
</div>
<h3 id="statement-handler-pattern"><a class="header" href="#statement-handler-pattern">Statement Handler Pattern</a></h3>
<p>Each handler follows a consistent pattern:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn exec_&lt;statement&gt;(&amp;self, stmt: &amp;&lt;Statement&gt;Stmt) -&gt; Result&lt;QueryResult&gt; {
    // 1. Validate/extract parameters
    let param = self.eval_string_expr(&amp;stmt.field)?;

    // 2. Check service availability (for optional services)
    let service = self.service.as_ref()
        .ok_or_else(|| RouterError::ServiceError("Service not initialized".to_string()))?;

    // 3. For destructive ops, check protection
    if is_destructive {
        match self.protect_destructive_op(...)? {
            ProtectedOpResult::Cancelled =&gt; return Err(...),
            ProtectedOpResult::Proceed =&gt; {},
        }
    }

    // 4. Execute operation
    let result = service.operation(...)?;

    // 5. Convert to QueryResult
    Ok(QueryResult::Variant(result))
}
<span class="boring">}</span></code></pre></pre>
<h2 id="supported-queries"><a class="header" href="#supported-queries">Supported Queries</a></h2>
<h3 id="relational-operations"><a class="header" href="#relational-operations">Relational Operations</a></h3>
<pre><code class="language-sql">-- DDL
CREATE TABLE users (id INT, name VARCHAR(100), email VARCHAR(255))
DROP TABLE users

-- DML
INSERT INTO users (id, name, email) VALUES (1, 'Alice', 'alice@example.com')
INSERT INTO users SELECT * FROM temp_users
UPDATE users SET name = 'Bob' WHERE id = 1
DELETE FROM users WHERE id = 1

-- Queries
SELECT * FROM users WHERE id = 1
SELECT id, name FROM users ORDER BY name ASC LIMIT 10 OFFSET 5
SELECT COUNT(*), AVG(age) FROM users WHERE active = true GROUP BY dept HAVING COUNT(*) &gt; 5

-- JOINs
SELECT * FROM users u INNER JOIN orders o ON u.id = o.user_id
SELECT * FROM users u LEFT JOIN profiles p ON u.id = p.user_id
SELECT * FROM a CROSS JOIN b
SELECT * FROM a NATURAL JOIN b
</code></pre>
<h3 id="aggregate-functions-1"><a class="header" href="#aggregate-functions-1">Aggregate Functions</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th><th>Null Handling</th></tr></thead><tbody>
<tr><td><code>COUNT(*)</code></td><td>Count all rows</td><td>Counts nulls</td></tr>
<tr><td><code>COUNT(col)</code></td><td>Count non-null values</td><td>Excludes nulls</td></tr>
<tr><td><code>SUM(col)</code></td><td>Sum numeric values</td><td>Skips nulls</td></tr>
<tr><td><code>AVG(col)</code></td><td>Average numeric values</td><td>Skips nulls, returns NULL if no values</td></tr>
<tr><td><code>MIN(col)</code></td><td>Minimum value</td><td>Skips nulls</td></tr>
<tr><td><code>MAX(col)</code></td><td>Maximum value</td><td>Skips nulls</td></tr>
</tbody></table>
</div>
<h3 id="graph-operations-1"><a class="header" href="#graph-operations-1">Graph Operations</a></h3>
<pre><code class="language-sql">-- Node operations
NODE CREATE person {name: 'Alice', age: 30}
NODE GET 123
NODE DELETE 123
NODE LIST person LIMIT 100
NODE UPDATE 123 {name: 'Alice Smith'}

-- Edge operations
EDGE CREATE person:1 friend person:2 {since: 2020}
EDGE GET 456
EDGE DELETE 456
EDGE LIST friend LIMIT 50

-- Traversals
NEIGHBORS person:1 friend OUTGOING
NEIGHBORS 123 * BOTH
PATH person:1 TO person:5 VIA friend
</code></pre>
<h3 id="vector-operations-1"><a class="header" href="#vector-operations-1">Vector Operations</a></h3>
<pre><code class="language-sql">-- Single embedding
EMBED doc1 [0.1, 0.2, 0.3, 0.4]
EMBED DELETE doc1

-- Batch embedding
EMBED BATCH [('key1', [0.1, 0.2]), ('key2', [0.3, 0.4])]

-- Similarity search
SIMILAR 'doc1' LIMIT 5
SIMILAR 'doc1' LIMIT 5 EUCLIDEAN
SIMILAR [0.1, 0.2, 0.3] LIMIT 10 COSINE

-- Listing
SHOW EMBEDDINGS LIMIT 100
COUNT EMBEDDINGS
</code></pre>
<h3 id="distance-metrics-3"><a class="header" href="#distance-metrics-3">Distance Metrics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Description</th><th>Use Case</th><th>Formula</th></tr></thead><tbody>
<tr><td><code>COSINE</code></td><td>Cosine similarity (default)</td><td>Semantic similarity</td><td><code>1 - (a.b) / (‖a‖ * ‖b‖)</code></td></tr>
<tr><td><code>EUCLIDEAN</code></td><td>Euclidean distance (L2)</td><td>Spatial distance</td><td>sqrt(sum((a[i] - b[i])^2))</td></tr>
<tr><td><code>DOT_PRODUCT</code></td><td>Dot product</td><td>Magnitude-aware similarity</td><td>sum(a[i] * b[i])</td></tr>
</tbody></table>
</div>
<h3 id="unified-entity-operations"><a class="header" href="#unified-entity-operations">Unified Entity Operations</a></h3>
<pre><code class="language-sql">-- Create entity with all modalities
ENTITY CREATE 'user:1' {name: 'Alice'} EMBEDDING [0.1, 0.2, 0.3]

-- Connect entities
ENTITY CONNECT 'user:1' -&gt; 'doc:1' : authored

-- Combined similarity + graph search
SIMILAR 'query:key' CONNECTED TO 'hub:entity' LIMIT 10
</code></pre>
<h2 id="cross-engine-queries-1"><a class="header" href="#cross-engine-queries-1">Cross-Engine Queries</a></h2>
<p>Cross-engine queries combine graph relationships with vector similarity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let store = TensorStore::new();
let mut router = QueryRouter::with_shared_store(store);

// Set up entities with embeddings
router.vector().set_entity_embedding("user:1", vec![0.1, 0.2, 0.3])?;
router.vector().set_entity_embedding("user:2", vec![0.15, 0.25, 0.35])?;

// Connect via graph edges
router.connect_entities("user:1", "user:2", "follows")?;

// Build HNSW index for O(log n) similarity search
router.build_vector_index()?;

// Find neighbors sorted by similarity
let results = router.find_neighbors_by_similarity("user:1", &amp;query_vec, 10)?;

// Find similar AND connected entities
let results = router.find_similar_connected("user:1", "user:2", 5)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="cross-engine-methods"><a class="header" href="#cross-engine-methods">Cross-Engine Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th><th>Complexity</th></tr></thead><tbody>
<tr><td><code>build_vector_index()</code></td><td>Build HNSW index for O(log n) search</td><td>O(n log n)</td></tr>
<tr><td><code>connect_entities(from, to, type)</code></td><td>Add graph edge between entities</td><td>O(1)</td></tr>
<tr><td><code>find_neighbors_by_similarity(key, query, k)</code></td><td>Neighbors sorted by vector similarity</td><td>O(k * log n) with HNSW</td></tr>
<tr><td><code>find_similar_connected(query, connected_to, k)</code></td><td>Similar AND connected entities</td><td>O(k * log n) + O(neighbors)</td></tr>
<tr><td><code>create_unified_entity(key, fields, embedding)</code></td><td>Create entity with all modalities</td><td>O(1)</td></tr>
</tbody></table>
</div>
<h3 id="implementation-details-4"><a class="header" href="#implementation-details-4">Implementation Details</a></h3>
<p>The <code>find_similar_connected</code> method combines vector and graph operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn find_similar_connected(
    &amp;self,
    query_key: &amp;str,
    connected_to: &amp;str,
    top_k: usize,
) -&gt; Result&lt;Vec&lt;UnifiedItem&gt;&gt; {
    let query_embedding = self.vector.get_entity_embedding(query_key)?;

    // Use HNSW index if available, otherwise brute-force
    let similar = if let Some((ref index, ref keys)) = self.hnsw_index {
        self.vector.search_with_hnsw(index, keys, &amp;query_embedding, top_k * 2)?
    } else {
        self.vector.search_entities(&amp;query_embedding, top_k * 2)?
    };

    // Get graph neighbors of connected_to entity
    let connected_neighbors: HashSet&lt;String&gt; = self.graph
        .get_entity_neighbors(connected_to)
        .unwrap_or_default()
        .into_iter()
        .collect();

    // Filter to entities that are both similar AND connected
    let items: Vec&lt;UnifiedItem&gt; = similar
        .into_iter()
        .filter(|s| connected_neighbors.contains(&amp;s.key))
        .take(top_k)
        .map(|s| UnifiedItem::new("vector+graph", &amp;s.key).with_score(s.score))
        .collect();

    Ok(items)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="optional-services"><a class="header" href="#optional-services">Optional Services</a></h2>
<p>Services are lazily initialized and can be enabled as needed:</p>
<pre class="mermaid">flowchart TD
    subgraph Initialization Order
        A[QueryRouter::new] --&gt; B[Core Engines Ready]
        B --&gt; C{Need Vault?}
        C --&gt;|Yes| D[init_vault]
        B --&gt; E{Need Cache?}
        E --&gt;|Yes| F[init_cache]
        B --&gt; G{Need Blob?}
        G --&gt;|Yes| H[init_blob]
        H --&gt; I{Need Checkpoint?}
        I --&gt;|Yes| J[init_checkpoint]
        B --&gt; K{Need Chain?}
        K --&gt;|Yes| L[init_chain]
        B --&gt; M{Need Cluster?}
        M --&gt;|Yes| N[init_cluster]
    end

    style J fill:#ffcccc
    note[Checkpoint requires Blob]
</pre>
<h3 id="vault"><a class="header" href="#vault">Vault</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Initialize with master key
router.init_vault(master_key)?;

// Or auto-initialize from NEUMANN_VAULT_KEY env var
router.ensure_vault()?;

// Set identity for access control
router.set_identity("user:alice");
<span class="boring">}</span></code></pre></pre>
<p>Vault requires authentication for all operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn exec_vault(&amp;self, stmt: &amp;VaultStmt) -&gt; Result&lt;QueryResult&gt; {
    let vault = self.vault.as_ref()
        .ok_or_else(|| RouterError::VaultError("Vault not initialized".to_string()))?;

    // SECURITY: Require explicit authentication
    let identity = self.require_identity()?;

    match &amp;stmt.operation {
        VaultOp::Get { key } =&gt; {
            let value = vault.get(identity, &amp;key)?;
            Ok(QueryResult::Value(value))
        },
        // ...
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cache"><a class="header" href="#cache">Cache</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Default configuration
router.init_cache();

// Custom configuration
router.init_cache_with_config(CacheConfig::default())?;

// Auto-initialize
router.ensure_cache();
<span class="boring">}</span></code></pre></pre>
<p>Cache operations are available through queries:</p>
<pre><code class="language-sql">CACHE INIT
CACHE STATS
CACHE CLEAR
CACHE EVICT 100
CACHE GET 'key'
CACHE PUT 'key' 'value'
CACHE SEMANTIC GET 'query' THRESHOLD 0.9
CACHE SEMANTIC PUT 'query' 'response' [0.1, 0.2, 0.3]
</code></pre>
<h3 id="blob-storage"><a class="header" href="#blob-storage">Blob Storage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Initialize blob store
router.init_blob()?;
router.start_blob()?;  // Start GC

// Graceful shutdown
router.shutdown_blob()?;
<span class="boring">}</span></code></pre></pre>
<p>Blob operations use async execution internally:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn exec_blob(&amp;self, stmt: &amp;BlobStmt) -&gt; Result&lt;QueryResult&gt; {
    let blob = self.blob.as_ref()
        .ok_or_else(|| RouterError::BlobError("Blob store not initialized".to_string()))?;
    let runtime = self.blob_runtime.as_ref()
        .ok_or_else(|| RouterError::BlobError("Blob runtime not initialized".to_string()))?;

    match &amp;stmt.operation {
        BlobOp::Put { filename, data, ... } =&gt; {
            let artifact_id = runtime.block_on(async {
                let blob_guard = blob.lock().await;
                blob_guard.put(&amp;filename, &amp;data, options).await
            })?;
            Ok(QueryResult::Value(artifact_id))
        },
        // ...
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="checkpoint-1"><a class="header" href="#checkpoint-1">Checkpoint</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Requires blob storage
router.init_blob()?;
router.init_checkpoint()?;

// Set confirmation handler for destructive ops
router.set_confirmation_handler(handler)?;
<span class="boring">}</span></code></pre></pre>
<p>Checkpoint provides automatic protection for destructive operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn protect_destructive_op(
    &amp;self,
    command: &amp;str,
    op: DestructiveOp,
    sample_data: Vec&lt;String&gt;,
) -&gt; Result&lt;ProtectedOpResult&gt; {
    let Some(checkpoint) = self.checkpoint.as_ref() else {
        return Ok(ProtectedOpResult::Proceed);
    };

    runtime.block_on(async {
        let cp = checkpoint.lock().await;

        if !cp.auto_checkpoint_enabled() {
            return Ok(ProtectedOpResult::Proceed);
        }

        let preview = cp.generate_preview(&amp;op, sample_data);

        if !cp.request_confirmation(&amp;op, &amp;preview) {
            return Ok(ProtectedOpResult::Cancelled);
        }

        // Create auto-checkpoint before operation
        cp.create_auto(command, op, preview, store).await?;

        Ok(ProtectedOpResult::Proceed)
    })
}
<span class="boring">}</span></code></pre></pre>
<p>Protected operations include:</p>
<ul>
<li><code>DELETE</code> (relational rows)</li>
<li><code>DROP TABLE</code></li>
<li><code>DROP INDEX</code></li>
<li><code>NODE DELETE</code></li>
<li><code>EMBED DELETE</code></li>
<li><code>VAULT DELETE</code></li>
<li><code>BLOB DELETE</code></li>
<li><code>CACHE CLEAR</code></li>
</ul>
<h3 id="chain"><a class="header" href="#chain">Chain</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Initialize tensor chain
router.init_chain("node_1")?;

// Auto-initialize with default node ID
router.ensure_chain()?;
<span class="boring">}</span></code></pre></pre>
<p>Chain operations available through queries:</p>
<pre><code class="language-sql">CHAIN BEGIN
CHAIN COMMIT
CHAIN ROLLBACK 100
CHAIN HISTORY 'key'
CHAIN HEIGHT
CHAIN TIP
CHAIN BLOCK 42
CHAIN VERIFY
CHAIN SHOW CODEBOOK GLOBAL
CHAIN SHOW CODEBOOK LOCAL 'domain'
CHAIN ANALYZE TRANSITIONS
</code></pre>
<h3 id="cluster"><a class="header" href="#cluster">Cluster</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Initialize cluster mode
router.init_cluster("node_1", bind_addr, &amp;peers)?;

// Check cluster status
if router.is_cluster_active() {
    // Distributed queries enabled
}

// Graceful shutdown
router.shutdown_cluster()?;
<span class="boring">}</span></code></pre></pre>
<p>Cluster initialization creates:</p>
<ol>
<li><code>ClusterOrchestrator</code> for Raft consensus</li>
<li><code>ConsistentHashPartitioner</code> for key-based routing</li>
<li><code>QueryPlanner</code> for distributed execution</li>
</ol>
<h2 id="distributed-query-execution"><a class="header" href="#distributed-query-execution">Distributed Query Execution</a></h2>
<p>When cluster mode is active, queries are automatically distributed:</p>
<pre class="mermaid">flowchart TD
    A[Query] --&gt; B[QueryPlanner]
    B --&gt; C{classify_query}

    C --&gt;|GET key| D{partition key}
    D --&gt;|Local| E[QueryPlan::Local]
    D --&gt;|Remote| F[QueryPlan::Remote]

    C --&gt;|SIMILAR| G[QueryPlan::ScatterGather]
    C --&gt;|SELECT *| G
    C --&gt;|COUNT| H[QueryPlan::ScatterGather + Aggregate]
    C --&gt;|Unknown| E

    F --&gt; I[execute_on_shard]
    G --&gt; J[execute_scatter_gather]
    H --&gt; J

    J --&gt; K[ResultMerger::merge]
    K --&gt; L[QueryResult]
</pre>
<h3 id="query-classification"><a class="header" href="#query-classification">Query Classification</a></h3>
<p>The <code>QueryPlanner</code> classifies queries based on text pattern matching:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn classify_query(&amp;self, query: &amp;str) -&gt; QueryType {
    let query_upper = query.to_uppercase();

    // Point lookups
    if query_upper.starts_with("GET ")
       || query_upper.starts_with("NODE GET ")
       || query_upper.starts_with("ENTITY GET ") {
        if let Some(key) = self.extract_key(query) {
            return QueryType::PointLookup { key };
        }
    }

    // Similarity search
    if query_upper.starts_with("SIMILAR ") {
        let k = self.extract_top_k(query).unwrap_or(10);
        return QueryType::SimilaritySearch { k };
    }

    // Table scans with aggregates
    if query_upper.starts_with("SELECT ") {
        if query_upper.contains("COUNT(") {
            return QueryType::Aggregate { func: AggregateFunction::Count };
        }
        if query_upper.contains("SUM(") {
            return QueryType::Aggregate { func: AggregateFunction::Sum };
        }
        return QueryType::TableScan;
    }

    QueryType::Unknown
}
<span class="boring">}</span></code></pre></pre>
<h3 id="query-plans"><a class="header" href="#query-plans">Query Plans</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Plan</th><th>When Used</th><th>Example</th><th>Shards Contacted</th></tr></thead><tbody>
<tr><td><code>Local</code></td><td>Point lookups on local shard</td><td><code>GET user:1</code> (local key)</td><td>1</td></tr>
<tr><td><code>Remote</code></td><td>Point lookups on remote shard</td><td><code>GET user:2</code> (remote key)</td><td>1</td></tr>
<tr><td><code>ScatterGather</code></td><td>Full scans, aggregates, similarity</td><td><code>SELECT *</code>, <code>SIMILAR</code>, <code>COUNT</code></td><td>All</td></tr>
</tbody></table>
</div>
<h3 id="merge-strategies"><a class="header" href="#merge-strategies">Merge Strategies</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>Description</th><th>Use Case</th><th>Algorithm</th></tr></thead><tbody>
<tr><td><code>Union</code></td><td>Combine all results</td><td>SELECT, NODE queries</td><td>Concatenate rows/nodes/edges</td></tr>
<tr><td><code>TopK(k)</code></td><td>Keep top K by score</td><td>SIMILAR queries</td><td>Sort by score desc, truncate</td></tr>
<tr><td><code>Aggregate(func)</code></td><td>SUM, COUNT, AVG, MAX, MIN</td><td>Aggregate queries</td><td>Combine partial aggregates</td></tr>
<tr><td><code>FirstNonEmpty</code></td><td>First result found</td><td>Point lookups</td><td>Short-circuit on first result</td></tr>
<tr><td><code>Concat</code></td><td>Concatenate in order</td><td>Ordered results</td><td>Same as Union</td></tr>
</tbody></table>
</div>
<h3 id="result-merger-implementation"><a class="header" href="#result-merger-implementation">Result Merger Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl ResultMerger {
    pub fn merge(results: Vec&lt;ShardResult&gt;, strategy: &amp;MergeStrategy) -&gt; Result&lt;QueryResult&gt; {
        // Filter out errors if not fail-fast
        let successful: Vec&lt;_&gt; = results.into_iter()
            .filter(|r| r.error.is_none())
            .collect();

        if successful.is_empty() {
            return Ok(QueryResult::Empty);
        }

        match strategy {
            MergeStrategy::Union =&gt; Self::merge_union(successful),
            MergeStrategy::TopK(k) =&gt; Self::merge_top_k(successful, *k),
            MergeStrategy::Aggregate(func) =&gt; Self::merge_aggregate(successful, *func),
            MergeStrategy::FirstNonEmpty =&gt; Self::merge_first_non_empty(successful),
            MergeStrategy::Concat =&gt; Self::merge_concat(successful),
        }
    }

    fn merge_top_k(results: Vec&lt;ShardResult&gt;, k: usize) -&gt; Result&lt;QueryResult&gt; {
        let mut all_similar: Vec&lt;SimilarResult&gt; = Vec::new();

        for shard_result in results {
            if let QueryResult::Similar(similar) = shard_result.result {
                all_similar.extend(similar);
            }
        }

        // Sort by score descending
        all_similar.sort_by(|a, b|
            b.score.partial_cmp(&amp;a.score).unwrap_or(std::cmp::Ordering::Equal)
        );

        // Take top K
        all_similar.truncate(k);

        Ok(QueryResult::Similar(all_similar))
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="distributed-query-configuration"><a class="header" href="#distributed-query-configuration">Distributed Query Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DistributedQueryConfig {
    /// Maximum concurrent shard queries (default: 10)
    pub max_concurrent: usize,
    /// Query timeout per shard in milliseconds (default: 5000)
    pub shard_timeout_ms: u64,
    /// Retry count for failed shards (default: 2)
    pub retry_count: usize,
    /// Whether to fail fast on first shard error (default: false)
    pub fail_fast: bool,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="semantic-routing"><a class="header" href="#semantic-routing">Semantic Routing</a></h3>
<p>For embedding-aware routing, use <code>plan_with_embedding</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn plan_with_embedding(&amp;self, query: &amp;str, embedding: &amp;[f32]) -&gt; QueryPlan {
    // Get semantically relevant shards
    let relevant_shards = self.shards_for_embedding(embedding);

    if relevant_shards.is_empty() {
        return self.plan(query);  // Fallback to all shards
    }

    // Route similarity search to relevant shards only
    match self.classify_query(query) {
        QueryType::SimilaritySearch { k } =&gt; QueryPlan::ScatterGather {
            shards: relevant_shards,
            query: query.to_string(),
            merge: MergeStrategy::TopK(k),
        },
        _ =&gt; self.plan(query),
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-characteristics-6"><a class="header" href="#performance-characteristics-6">Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td>Parse</td><td>O(n)</td><td>n = query length</td></tr>
<tr><td>SELECT</td><td>O(m)</td><td>m = rows in table</td></tr>
<tr><td>SELECT with index</td><td>O(log m + k)</td><td>k = matching rows</td></tr>
<tr><td>INSERT</td><td>O(1)</td><td>Single row insert</td></tr>
<tr><td>NODE</td><td>O(1)</td><td>Single node create</td></tr>
<tr><td>EDGE</td><td>O(1)</td><td>Single edge create</td></tr>
<tr><td>PATH</td><td>O(V+E)</td><td>BFS traversal</td></tr>
<tr><td>SIMILAR (brute-force)</td><td>O(n*d)</td><td>n = embeddings, d = dimensions</td></tr>
<tr><td>SIMILAR (HNSW)</td><td>O(log n * d)</td><td>After <code>build_vector_index()</code></td></tr>
<tr><td><code>find_similar_connected</code></td><td>O(log n) or O(n)</td><td>Uses HNSW if index built</td></tr>
<tr><td>Distributed query</td><td>O(query) / shards</td><td>Parallelized across shards</td></tr>
<tr><td>Result merge (Union)</td><td>O(total results)</td><td>Linear in combined size</td></tr>
<tr><td>Result merge (TopK)</td><td>O(n log k)</td><td>Sort + truncate</td></tr>
</tbody></table>
</div>
<h3 id="hnsw-index-performance"><a class="header" href="#hnsw-index-performance">HNSW Index Performance</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Entities</th><th>Brute-force</th><th>With HNSW</th><th>Speedup</th></tr></thead><tbody>
<tr><td>200</td><td>4.17s</td><td>9.3us</td><td>448,000x</td></tr>
</tbody></table>
</div>
<h3 id="distributed-query-overhead"><a class="header" href="#distributed-query-overhead">Distributed Query Overhead</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Overhead</th></tr></thead><tbody>
<tr><td>Query planning</td><td>~1-5 us</td></tr>
<tr><td>Network round-trip</td><td>~1-10 ms (depends on network)</td></tr>
<tr><td>Result serialization</td><td>~10-100 us (depends on result size)</td></tr>
<tr><td>Result merging</td><td>~1-10 us (TopK), O(n) for Union</td></tr>
</tbody></table>
</div>
<h2 id="query-caching"><a class="header" href="#query-caching">Query Caching</a></h2>
<p>Cacheable statements are automatically cached when a cache is configured:</p>
<ul>
<li><strong>Cacheable</strong>: <code>SELECT</code>, <code>SIMILAR</code>, <code>NEIGHBORS</code>, <code>PATH</code></li>
<li><strong>Write operations</strong>: <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>, DDL invalidate cache</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn is_cacheable_statement(stmt: &amp;Statement) -&gt; bool {
    matches!(&amp;stmt.kind,
        StatementKind::Select(_)
        | StatementKind::Similar(_)
        | StatementKind::Neighbors(_)
        | StatementKind::Path(_)
    )
}

fn is_write_statement(stmt: &amp;Statement) -&gt; bool {
    matches!(&amp;stmt.kind,
        StatementKind::Insert(_)
        | StatementKind::Update(_)
        | StatementKind::Delete(_)
        | StatementKind::CreateTable(_)
        | StatementKind::DropTable(_)
        | StatementKind::CreateIndex(_)
        | StatementKind::DropIndex(_)
    )
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cache-usage-example"><a class="header" href="#cache-usage-example">Cache Usage Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Enable caching
router.init_cache();

// First call executes and caches (JSON serialization)
let result1 = router.execute_parsed("SELECT * FROM users")?;

// Second call returns cached result (JSON deserialization)
let result2 = router.execute_parsed("SELECT * FROM users")?;

// Write operations invalidate entire cache
router.execute_parsed("INSERT INTO users VALUES (2, 'Bob')")?;
// Cache is now empty
<span class="boring">}</span></code></pre></pre>
<h3 id="cache-gotchas"><a class="header" href="#cache-gotchas">Cache Gotchas</a></h3>
<ol>
<li><strong>Full cache invalidation</strong>: Any write operation clears the entire cache. No
table-level tracking.</li>
<li><strong>Case sensitivity</strong>: Cache keys are lowercased, so <code>SELECT</code> and <code>select</code> hit
the same entry.</li>
<li><strong>Whitespace normalization</strong>: Queries are trimmed but not fully normalized.</li>
<li><strong>No TTL</strong>: Cached entries persist until invalidated by writes or explicit
<code>CACHE CLEAR</code>.</li>
</ol>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<h3 id="service-initialization-order"><a class="header" href="#service-initialization-order">Service Initialization Order</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Initialize in dependency order
let mut router = QueryRouter::with_shared_store(store);

// Optional services (no dependencies)
router.init_vault(key)?;
router.init_cache();

// Blob first (required for checkpoint)
router.init_blob()?;
router.start_blob()?;

// Checkpoint depends on blob
router.init_checkpoint()?;
router.set_confirmation_handler(handler)?;

// Chain is independent
router.init_chain("node_1")?;

// Cluster is independent but typically last
router.init_cluster("node_1", addr, &amp;peers)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="identity-management"><a class="header" href="#identity-management">Identity Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Always set identity before vault operations
router.set_identity("user:alice");

// Check authentication status
if !router.is_authenticated() {
    return Err("Authentication required");
}

// Identity persists across queries
router.execute_parsed("VAULT GET 'secret'")?;  // Uses alice's identity
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match router.execute_parsed(query) {
    Ok(result) =&gt; handle_result(result),
    Err(RouterError::ParseError(msg)) =&gt; println!("Invalid query: {}", msg),
    Err(RouterError::AuthenticationRequired) =&gt; println!("Please run SET IDENTITY first"),
    Err(RouterError::RelationalError(msg)) if msg.contains("not found") =&gt; {
        println!("Table not found");
    },
    Err(e) =&gt; println!("Error: {}", e),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="async-vs-sync"><a class="header" href="#async-vs-sync">Async vs Sync</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use sync for simple scripts
let result = router.execute_parsed("SELECT * FROM users")?;

// Use async for concurrent operations
async fn parallel_queries(router: &amp;QueryRouter) -&gt; Result&lt;()&gt; {
    let (users, orders) = tokio::join!(
        router.execute_parsed_async("SELECT * FROM users"),
        router.execute_parsed_async("SELECT * FROM orders"),
    );
    // Both queries execute concurrently
    Ok(())
}

// Note: async execution doesn't support distributed routing yet
<span class="boring">}</span></code></pre></pre>
<h3 id="building-vector-index"><a class="header" href="#building-vector-index">Building Vector Index</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Build index after loading embeddings
for (key, embedding) in embeddings {
    router.vector().set_entity_embedding(&amp;key, embedding)?;
}

// Build HNSW index for fast similarity search
router.build_vector_index()?;

// Now SIMILAR queries use O(log n) search
let results = router.execute_parsed("SIMILAR 'query' LIMIT 10")?;
<span class="boring">}</span></code></pre></pre>
<h2 id="related-modules-12"><a class="header" href="#related-modules-12">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><a href="architecture/tensor-store.html">Tensor Store</a></td><td>Underlying storage layer</td></tr>
<tr><td><a href="architecture/relational-engine.html">Relational Engine</a></td><td>Table operations</td></tr>
<tr><td><a href="architecture/graph-engine.html">Graph Engine</a></td><td>Node/edge operations</td></tr>
<tr><td><a href="architecture/vector-engine.html">Vector Engine</a></td><td>Embedding operations</td></tr>
<tr><td><a href="architecture/tensor-unified.html">Tensor Unified</a></td><td>Cross-engine queries</td></tr>
<tr><td><a href="architecture/neumann-parser.html">Neumann Parser</a></td><td>Query parsing</td></tr>
<tr><td><a href="architecture/tensor-vault.html">Tensor Vault</a></td><td>Secret storage</td></tr>
<tr><td><a href="architecture/tensor-cache.html">Tensor Cache</a></td><td>LLM response caching</td></tr>
<tr><td><a href="architecture/tensor-blob.html">Tensor Blob</a></td><td>Artifact storage</td></tr>
<tr><td><a href="architecture/tensor-checkpoint.html">Tensor Checkpoint</a></td><td>Snapshots</td></tr>
<tr><td><a href="architecture/tensor-chain.html">Tensor Chain</a></td><td>Blockchain</td></tr>
<tr><td><a href="architecture/neumann-shell.html">Neumann Shell</a></td><td>CLI interface</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="neumann-shell-architecture"><a class="header" href="#neumann-shell-architecture">Neumann Shell Architecture</a></h1>
<p>The Neumann Shell (<code>neumann_shell</code>) provides an interactive CLI interface for
the Neumann database. It is a thin layer that delegates query execution to the
Query Router while providing readline-based input handling, command history,
output formatting, and crash recovery via write-ahead logging.</p>
<p>The shell follows four design principles: human-first interface (readable
prompts, formatted output, command history), thin layer (minimal logic,
delegates to Query Router), graceful handling (Ctrl+C does not exit, errors
displayed cleanly), and zero configuration (works out of the box with sensible
defaults).</p>
<h2 id="key-types-11"><a class="header" href="#key-types-11">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Shell</code></td><td>Main shell struct holding router, config, and WAL state</td></tr>
<tr><td><code>ShellConfig</code></td><td>Configuration for history file, history size, and prompt</td></tr>
<tr><td><code>CommandResult</code></td><td>Result enum: <code>Output</code>, <code>Exit</code>, <code>Help</code>, <code>Empty</code>, <code>Error</code></td></tr>
<tr><td><code>LoopAction</code></td><td>Action after command: <code>Continue</code> or <code>Exit</code></td></tr>
<tr><td><code>ShellError</code></td><td>Error type for initialization failures</td></tr>
<tr><td><code>Wal</code></td><td>Internal write-ahead log for crash recovery</td></tr>
<tr><td><code>RouterExecutor</code></td><td>Wrapper implementing <code>QueryExecutor</code> trait for cluster operations</td></tr>
<tr><td><code>ShellConfirmationHandler</code></td><td>Interactive confirmation handler for destructive operations</td></tr>
</tbody></table>
</div>
<h2 id="shell-configuration"><a class="header" href="#shell-configuration">Shell Configuration</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>history_file</code></td><td><code>Option&lt;PathBuf&gt;</code></td><td><code>~/.neumann_history</code></td><td>Path for persistent history</td></tr>
<tr><td><code>history_size</code></td><td><code>usize</code></td><td><code>1000</code></td><td>Maximum history entries</td></tr>
<tr><td><code>prompt</code></td><td><code>String</code></td><td><code>"&gt; "</code></td><td>Input prompt string</td></tr>
</tbody></table>
</div>
<p>The default history file location is determined by reading the <code>HOME</code>
environment variable:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn dirs_home() -&gt; Option&lt;PathBuf&gt; {
    std::env::var_os("HOME").map(PathBuf::from)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="command-result-types"><a class="header" href="#command-result-types">Command Result Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Description</th><th>REPL Behavior</th></tr></thead><tbody>
<tr><td><code>Output(String)</code></td><td>Query executed successfully with output</td><td>Print to stdout, continue loop</td></tr>
<tr><td><code>Exit</code></td><td>Shell should exit</td><td>Print “Goodbye!”, break loop</td></tr>
<tr><td><code>Help(String)</code></td><td>Help text to display</td><td>Print to stdout, continue loop</td></tr>
<tr><td><code>Empty</code></td><td>Empty input (no-op)</td><td>Continue loop silently</td></tr>
<tr><td><code>Error(String)</code></td><td>Error occurred</td><td>Print to stderr, continue loop</td></tr>
</tbody></table>
</div>
<h2 id="repl-loop-implementation"><a class="header" href="#repl-loop-implementation">REPL Loop Implementation</a></h2>
<p>The shell implements a Read-Eval-Print Loop (REPL) using the <code>rustyline</code> crate
for readline functionality. Here is the complete control flow:</p>
<pre class="mermaid">flowchart TD
    A[Start run] --&gt; B[Create Editor]
    B --&gt; C[Load history file]
    C --&gt; D[Set max history size]
    D --&gt; E[Set confirmation handler if checkpoint available]
    E --&gt; F[Print version banner]
    F --&gt; G[readline with prompt]
    G --&gt; H{Input result?}
    H --&gt;|Ok line| I{Line empty?}
    I --&gt;|No| J[Add to history]
    I --&gt;|Yes| G
    J --&gt; K[execute command]
    K --&gt; L[process_result]
    L --&gt; M{LoopAction?}
    M --&gt;|Continue| G
    M --&gt;|Exit| N[Save history]
    H --&gt;|Ctrl+C| O[Print ^C]
    O --&gt; G
    H --&gt;|Ctrl+D EOF| P[Print Goodbye!]
    P --&gt; N
    H --&gt;|Error| Q[Print error]
    Q --&gt; N
    N --&gt; R[End]
</pre>
<h3 id="initialization-sequence"><a class="header" href="#initialization-sequence">Initialization Sequence</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn run(&amp;mut self) -&gt; Result&lt;(), ShellError&gt; {
    // 1. Create rustyline editor
    let editor: Editor&lt;(), DefaultHistory&gt; =
        DefaultEditor::new().map_err(|e| ShellError::Init(e.to_string()))?;
    let editor = Arc::new(Mutex::new(editor));

    // 2. Load existing history
    {
        let mut ed = editor.lock();
        if let Some(ref path) = self.config.history_file {
            let _ = ed.load_history(path);
        }
        ed.history_mut()
            .set_max_len(self.config.history_size)
            .map_err(|e| ShellError::Init(e.to_string()))?;
    }

    // 3. Set up confirmation handler for destructive operations
    {
        let router = self.router.read();
        if router.has_checkpoint() {
            let handler = Arc::new(ShellConfirmationHandler::new(Arc::clone(&amp;editor)));
            drop(router);
            let router = self.router.write();
            if let Err(e) = router.set_confirmation_handler(handler) {
                eprintln!("Warning: Failed to set confirmation handler: {e}");
            }
        }
    }

    println!("Neumann Database Shell v{}", Self::version());
    println!("Type 'help' for available commands.\n");

    // 4. Main REPL loop
    loop {
        let readline_result = {
            let mut ed = editor.lock();
            ed.readline(&amp;self.config.prompt)
        };

        match readline_result {
            Ok(line) =&gt; {
                if !line.trim().is_empty() {
                    let mut ed = editor.lock();
                    let _ = ed.add_history_entry(line.trim());
                }
                if Self::process_result(&amp;self.execute(&amp;line)) == LoopAction::Exit {
                    break;
                }
            },
            Err(ReadlineError::Interrupted) =&gt; println!("^C"),
            Err(ReadlineError::Eof) =&gt; {
                println!("Goodbye!");
                break;
            },
            Err(err) =&gt; {
                eprintln!("Error: {err}");
                break;
            },
        }
    }

    // 5. Save history on exit
    if let Some(ref path) = self.config.history_file {
        let mut ed = editor.lock();
        let _ = ed.save_history(path);
    }
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="command-execution-flow"><a class="header" href="#command-execution-flow">Command Execution Flow</a></h3>
<pre class="mermaid">flowchart TD
    A[execute input] --&gt; B{Trim empty?}
    B --&gt;|Yes| C[Return Empty]
    B --&gt;|No| D[Convert to lowercase]
    D --&gt; E{Built-in command?}
    E --&gt;|exit/quit/\q| F[Return Exit]
    E --&gt;|help/\h/\?| G[Return Help]
    E --&gt;|tables/\dt| H[list_tables]
    E --&gt;|clear/\c| I[Return ANSI clear]
    E --&gt;|wal status| J[handle_wal_status]
    E --&gt;|wal truncate| K[handle_wal_truncate]
    E --&gt;|No match| L{Prefix match?}
    L --&gt;|save compressed| M[handle_save_compressed]
    L --&gt;|save| N[handle_save]
    L --&gt;|load| O[handle_load]
    L --&gt;|vault init| P[handle_vault_init]
    L --&gt;|vault identity| Q[handle_vault_identity]
    L --&gt;|cache init| R[handle_cache_init]
    L --&gt;|cluster connect| S[handle_cluster_connect]
    L --&gt;|cluster disconnect| T[handle_cluster_disconnect]
    L --&gt;|None| U[router.execute_parsed]
    U --&gt; V{Result?}
    V --&gt;|Ok| W{is_write_command?}
    W --&gt;|Yes| X{WAL active?}
    X --&gt;|Yes| Y[wal.append]
    Y --&gt; Z[Return Output]
    X --&gt;|No| Z
    W --&gt;|No| Z
    V --&gt;|Err| AA[Return Error]
</pre>
<h2 id="usage-examples-9"><a class="header" href="#usage-examples-9">Usage Examples</a></h2>
<h3 id="shell-creation"><a class="header" href="#shell-creation">Shell Creation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_shell::{Shell, ShellConfig};

// Default configuration
let shell = Shell::new();

// Custom configuration
let config = ShellConfig {
    history_file: Some("/custom/path/.neumann_history".into()),
    history_size: 500,
    prompt: "neumann&gt; ".to_string(),
};
let shell = Shell::with_config(config);
<span class="boring">}</span></code></pre></pre>
<h3 id="running-the-repl"><a class="header" href="#running-the-repl">Running the REPL</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>shell.run()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="programmatic-execution"><a class="header" href="#programmatic-execution">Programmatic Execution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_shell::CommandResult;

match shell.execute("SELECT * FROM users") {
    CommandResult::Output(text) =&gt; println!("{}", text),
    CommandResult::Error(err) =&gt; eprintln!("Error: {}", err),
    CommandResult::Exit =&gt; println!("Goodbye!"),
    CommandResult::Help(text) =&gt; println!("{}", text),
    CommandResult::Empty =&gt; {},
}
<span class="boring">}</span></code></pre></pre>
<h3 id="direct-router-access"><a class="header" href="#direct-router-access">Direct Router Access</a></h3>
<p>The shell provides thread-safe access to the underlying Query Router:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Read-only access
let router_guard = shell.router();
let tables = router_guard.list_tables();

// Mutable access
let mut router_guard = shell.router_mut();
router_guard.init_vault(&amp;key)?;

// Get Arc clone for shared ownership
let router_arc = shell.router_arc();
<span class="boring">}</span></code></pre></pre>
<h2 id="built-in-commands"><a class="header" href="#built-in-commands">Built-in Commands</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Command</th><th>Aliases</th><th>Description</th></tr></thead><tbody>
<tr><td><code>help</code></td><td><code>\h</code>, <code>\?</code></td><td>Show help message</td></tr>
<tr><td><code>exit</code></td><td><code>quit</code>, <code>\q</code></td><td>Exit the shell</td></tr>
<tr><td><code>tables</code></td><td><code>\dt</code></td><td>List all tables</td></tr>
<tr><td><code>clear</code></td><td><code>\c</code></td><td>Clear the screen (ANSI escape: <code>\x1B[2J\x1B[H</code>)</td></tr>
<tr><td><code>save 'path'</code></td><td>—</td><td>Save database snapshot to file</td></tr>
<tr><td><code>save compressed 'path'</code></td><td>—</td><td>Save compressed snapshot (int8 quantization)</td></tr>
<tr><td><code>load 'path'</code></td><td>—</td><td>Load database snapshot from file (auto-detects format)</td></tr>
<tr><td><code>wal status</code></td><td>—</td><td>Show write-ahead log status</td></tr>
<tr><td><code>wal truncate</code></td><td>—</td><td>Clear the write-ahead log</td></tr>
<tr><td><code>vault init</code></td><td>—</td><td>Initialize vault from <code>NEUMANN_VAULT_KEY</code> environment variable</td></tr>
<tr><td><code>vault identity 'name'</code></td><td>—</td><td>Set current identity for vault access control</td></tr>
<tr><td><code>cache init</code></td><td>—</td><td>Initialize semantic cache with default configuration</td></tr>
<tr><td><code>cluster connect</code></td><td>—</td><td>Connect to cluster with specified node addresses</td></tr>
<tr><td><code>cluster disconnect</code></td><td>—</td><td>Disconnect from cluster</td></tr>
</tbody></table>
</div>
<h3 id="command-parsing-details"><a class="header" href="#command-parsing-details">Command Parsing Details</a></h3>
<p>All built-in commands are case-insensitive. The shell first converts input to
lowercase before matching:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let lower = trimmed.to_lowercase();
match lower.as_str() {
    "exit" | "quit" | "\\q" =&gt; return CommandResult::Exit,
    "help" | "\\h" | "\\?" =&gt; return CommandResult::Help(Self::help_text()),
    "tables" | "\\dt" =&gt; return self.list_tables(),
    "clear" | "\\c" =&gt; return CommandResult::Output("\x1B[2J\x1B[H".to_string()),
    "wal status" =&gt; return self.handle_wal_status(),
    "wal truncate" =&gt; return self.handle_wal_truncate(),
    _ =&gt; {},
}
<span class="boring">}</span></code></pre></pre>
<h3 id="path-extraction"><a class="header" href="#path-extraction">Path Extraction</a></h3>
<p>The <code>extract_path</code> function handles both quoted and unquoted paths:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn extract_path(input: &amp;str, command: &amp;str) -&gt; Option&lt;String&gt; {
    let rest = input[command.len()..].trim();
    if rest.is_empty() {
        return None;
    }

    // Handle quoted path (single or double quotes)
    if (rest.starts_with('\'') &amp;&amp; rest.ends_with('\''))
        || (rest.starts_with('"') &amp;&amp; rest.ends_with('"'))
    {
        if rest.len() &gt; 2 {
            return Some(rest[1..rest.len() - 1].to_string());
        }
        return None;
    }

    // Handle unquoted path
    Some(rest.to_string())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Examples:</strong></p>
<ul>
<li><code>save 'foo.bin'</code> -&gt; <code>Some("foo.bin")</code></li>
<li><code>LOAD "bar.bin"</code> -&gt; <code>Some("bar.bin")</code></li>
<li><code>save /path/to/file.bin</code> -&gt; <code>Some("/path/to/file.bin")</code></li>
<li><code>save ''</code> -&gt; <code>None</code></li>
<li><code>save</code> -&gt; <code>None</code></li>
</ul>
<h2 id="query-support"><a class="header" href="#query-support">Query Support</a></h2>
<p>The shell supports all query types from the Query Router:</p>
<h3 id="relational-sql"><a class="header" href="#relational-sql">Relational (SQL)</a></h3>
<pre><code class="language-sql">CREATE TABLE users (id INT, name TEXT, email TEXT)
INSERT INTO users VALUES (1, 'Alice', 'alice@example.com')
SELECT * FROM users WHERE id = 1
UPDATE users SET name = 'Bob' WHERE id = 1
DELETE FROM users WHERE id = 1
DROP TABLE users
</code></pre>
<h3 id="graph"><a class="header" href="#graph">Graph</a></h3>
<pre><code class="language-sql">NODE CREATE person {name: 'Alice', age: 30}
NODE LIST [label]
NODE GET id
EDGE CREATE node1 -&gt; node2 : label [{props}]
EDGE LIST [type]
EDGE GET id
NEIGHBORS node_id OUTGOING|INCOMING|BOTH [: label]
PATH node1 -&gt; node2 [LIMIT n]
</code></pre>
<h3 id="vector"><a class="header" href="#vector">Vector</a></h3>
<pre><code class="language-sql">EMBED STORE 'key' [vector values]
EMBED GET 'key'
EMBED DELETE 'key'
SIMILAR 'key' [COSINE|EUCLIDEAN|DOT_PRODUCT] LIMIT n
</code></pre>
<h3 id="unified-cross-engine"><a class="header" href="#unified-cross-engine">Unified (Cross-Engine)</a></h3>
<pre><code class="language-sql">FIND NODE [label] [WHERE condition] [LIMIT n]
FIND EDGE [type] [WHERE condition] [LIMIT n]
</code></pre>
<h3 id="blob-storage-1"><a class="header" href="#blob-storage-1">Blob Storage</a></h3>
<pre><code class="language-sql">BLOB PUT 'path' [CHUNK size] [TAGS 'a','b'] [FOR 'entity']
BLOB GET 'id' TO 'path'
BLOB DELETE 'id'
BLOB INFO 'id'
BLOB LINK 'id' TO 'entity'
BLOB UNLINK 'id' FROM 'entity'
BLOBS
BLOBS FOR 'entity'
BLOBS BY TAG 'tag'
</code></pre>
<h3 id="vault-secrets"><a class="header" href="#vault-secrets">Vault (Secrets)</a></h3>
<pre><code class="language-sql">VAULT INIT
VAULT IDENTITY 'node:name'
VAULT SET 'key' 'value'
VAULT GET 'key'
VAULT DELETE 'key'
VAULT LIST 'pattern'
VAULT ROTATE 'key' 'new'
VAULT GRANT 'entity' ON 'key'
VAULT REVOKE 'entity' ON 'key'
</code></pre>
<h3 id="cache-llm-responses"><a class="header" href="#cache-llm-responses">Cache (LLM Responses)</a></h3>
<pre><code class="language-sql">CACHE INIT
CACHE STATS
CACHE CLEAR
CACHE EVICT [n]
CACHE GET 'key'
CACHE PUT 'key' 'value'
</code></pre>
<h3 id="checkpoints-rollback"><a class="header" href="#checkpoints-rollback">Checkpoints (Rollback)</a></h3>
<pre><code class="language-sql">CHECKPOINT
CHECKPOINT 'name'
CHECKPOINTS
CHECKPOINTS LIMIT n
ROLLBACK TO 'name-or-id'
</code></pre>
<h2 id="write-ahead-log-wal"><a class="header" href="#write-ahead-log-wal">Write-Ahead Log (WAL)</a></h2>
<p>The shell includes a write-ahead log for crash recovery. When enabled, all write
commands are logged to a file that can be replayed after loading a snapshot.</p>
<h3 id="wal-data-structure"><a class="header" href="#wal-data-structure">WAL Data Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Wal {
    file: File,    // Open file handle for appending
    path: PathBuf, // Path to WAL file (derived from snapshot: data.bin -&gt; data.log)
}

impl Wal {
    fn open_append(path: &amp;Path) -&gt; std::io::Result&lt;Self&gt;;
    fn append(&amp;mut self, cmd: &amp;str) -&gt; std::io::Result&lt;()&gt;;  // Writes line + flush
    fn truncate(&amp;mut self) -&gt; std::io::Result&lt;()&gt;;           // Recreates empty file
    fn path(&amp;self) -&gt; &amp;Path;
    fn size(&amp;self) -&gt; std::io::Result&lt;u64&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="wal-file-format"><a class="header" href="#wal-file-format">WAL File Format</a></h3>
<p>The WAL is a simple text file with one command per line. Each command is written
verbatim followed by a newline and an immediate flush:</p>
<pre><code class="language-sql">INSERT INTO users VALUES (1, 'Alice')
NODE CREATE person {name: 'Bob'}
EMBED STORE 'doc1' [0.1, 0.2, 0.3]
</code></pre>
<p><strong>Format details:</strong></p>
<ul>
<li>Line-delimited plain text</li>
<li>UTF-8 encoded</li>
<li>Each line is the exact command string</li>
<li>Flushed immediately after each write for durability</li>
<li>Empty lines are skipped during replay</li>
</ul>
<h3 id="wal-lifecycle"><a class="header" href="#wal-lifecycle">WAL Lifecycle</a></h3>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Inactive: Shell created
    Inactive --&gt; Active: LOAD 'snapshot.bin'
    Active --&gt; Active: Write command logged
    Active --&gt; Active: Read command (no log)
    Active --&gt; Empty: SAVE 'snapshot.bin'
    Empty --&gt; Active: Write command
    Active --&gt; Empty: WAL TRUNCATE
    Active --&gt; [*]: Shell exits
</pre>
<h3 id="write-command-detection"><a class="header" href="#write-command-detection">Write Command Detection</a></h3>
<p>The <code>is_write_command</code> function determines which commands should be logged to
the WAL:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn is_write_command(cmd: &amp;str) -&gt; bool {
    let upper = cmd.to_uppercase();
    let first_word = upper.split_whitespace().next().unwrap_or("");

    match first_word {
        "INSERT" | "UPDATE" | "DELETE" | "CREATE" | "DROP" =&gt; true,
        "NODE" =&gt; !upper.contains("NODE GET"),
        "EDGE" =&gt; !upper.contains("EDGE GET"),
        "EMBED" =&gt; upper.contains("EMBED STORE") || upper.contains("EMBED DELETE"),
        "VAULT" =&gt; {
            upper.contains("VAULT SET")
                || upper.contains("VAULT DELETE")
                || upper.contains("VAULT ROTATE")
                || upper.contains("VAULT GRANT")
                || upper.contains("VAULT REVOKE")
        },
        "CACHE" =&gt; upper.contains("CACHE CLEAR"),
        "BLOB" =&gt; {
            upper.contains("BLOB PUT")
                || upper.contains("BLOB DELETE")
                || upper.contains("BLOB LINK")
                || upper.contains("BLOB UNLINK")
                || upper.contains("BLOB TAG")
                || upper.contains("BLOB UNTAG")
                || upper.contains("BLOB GC")
                || upper.contains("BLOB REPAIR")
                || upper.contains("BLOB META SET")
        },
        _ =&gt; false,
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Write commands logged to WAL:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Commands</th></tr></thead><tbody>
<tr><td>Relational</td><td><code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>, <code>CREATE</code>, <code>DROP</code></td></tr>
<tr><td>Graph</td><td><code>NODE CREATE</code>, <code>NODE DELETE</code>, <code>EDGE CREATE</code>, <code>EDGE DELETE</code></td></tr>
<tr><td>Vector</td><td><code>EMBED STORE</code>, <code>EMBED DELETE</code></td></tr>
<tr><td>Vault</td><td><code>VAULT SET</code>, <code>VAULT DELETE</code>, <code>VAULT ROTATE</code>, <code>VAULT GRANT</code>, <code>VAULT REVOKE</code></td></tr>
<tr><td>Cache</td><td><code>CACHE CLEAR</code></td></tr>
<tr><td>Blob</td><td><code>BLOB PUT</code>, <code>BLOB DELETE</code>, <code>BLOB LINK</code>, <code>BLOB UNLINK</code>, <code>BLOB TAG</code>, <code>BLOB UNTAG</code>, <code>BLOB GC</code>, <code>BLOB REPAIR</code>, <code>BLOB META SET</code></td></tr>
</tbody></table>
</div>
<h3 id="wal-replay-algorithm"><a class="header" href="#wal-replay-algorithm">WAL Replay Algorithm</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn replay_wal(&amp;self, wal_path: &amp;Path) -&gt; Result&lt;usize, String&gt; {
    let file = File::open(wal_path).map_err(|e| format!("Failed to open WAL: {e}"))?;
    let reader = BufReader::new(file);

    let mut count = 0;
    for (line_num, line) in reader.lines().enumerate() {
        let cmd = line.map_err(|e| format!("Failed to read WAL line {}: {e}", line_num + 1))?;
        let cmd = cmd.trim();

        if cmd.is_empty() {
            continue;  // Skip empty lines
        }

        let result = self.router.read().execute_parsed(cmd);
        if let Err(e) = result {
            return Err(format!("WAL replay failed at line {}: {e}", line_num + 1));
        }
        count += 1;
    }

    Ok(count)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="example-session"><a class="header" href="#example-session">Example Session</a></h3>
<pre><code class="language-sql">&gt; LOAD 'data.bin'
Loaded snapshot from: data.bin

&gt; INSERT INTO users VALUES (1, 'Alice')
1 row affected

&gt; -- If the shell crashes here, the INSERT is saved in data.log

&gt; -- On next load, the WAL is automatically replayed:
&gt; LOAD 'data.bin'
Loaded snapshot from: data.bin
Replayed 1 commands from WAL

&gt; WAL STATUS
WAL enabled
  Path: data.log
  Size: 42 bytes

&gt; SAVE 'data.bin'
Saved snapshot to: data.bin

&gt; WAL STATUS
WAL enabled
  Path: data.log
  Size: 0 bytes
</code></pre>
<p><strong>WAL Behavior Summary:</strong></p>
<ul>
<li>WAL is activated after <code>LOAD</code> (stored as <code>&lt;snapshot&gt;.log</code>)</li>
<li>All write commands (INSERT, UPDATE, DELETE, NODE CREATE, etc.) are logged</li>
<li>On subsequent <code>LOAD</code>, the snapshot is loaded first, then WAL is replayed</li>
<li><code>SAVE</code> truncates the WAL (snapshot now contains all data)</li>
<li><code>WAL TRUNCATE</code> manually clears the log without saving</li>
</ul>
<h2 id="persistence-commands"><a class="header" href="#persistence-commands">Persistence Commands</a></h2>
<h3 id="save-and-load"><a class="header" href="#save-and-load">Save and Load</a></h3>
<pre><code class="language-sql">&gt; CREATE TABLE users (id INT, name TEXT)
OK

&gt; INSERT INTO users VALUES (1, 'Alice')
1 row affected

&gt; SAVE 'backup.bin'
Saved snapshot to: backup.bin

&gt; SAVE COMPRESSED 'backup_compressed.bin'
Saved compressed snapshot to: backup_compressed.bin

&gt; LOAD 'backup.bin'
Loaded snapshot from: backup.bin
</code></pre>
<h3 id="auto-detection-of-embedding-dimension"><a class="header" href="#auto-detection-of-embedding-dimension">Auto-Detection of Embedding Dimension</a></h3>
<p>For compressed snapshots, the shell auto-detects the embedding dimension by
sampling stored vectors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn detect_embedding_dimension(store: &amp;TensorStore) -&gt; usize {
    // Sample vectors to find dimension
    let keys = store.scan("");
    for key in keys.iter().take(100) {
        if let Ok(tensor) = store.get(key) {
            for field in tensor.keys() {
                match tensor.get(field) {
                    Some(TensorValue::Vector(v)) =&gt; return v.len(),
                    Some(TensorValue::Sparse(s)) =&gt; return s.dimension(),
                    _ =&gt; {},
                }
            }
        }
    }

    // Default to standard BERT dimension if no vectors found
    tensor_compress::CompressionDefaults::STANDARD  // 768
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Compression Options:</strong></p>
<ul>
<li><code>SAVE</code>: Uncompressed bincode format</li>
<li><code>SAVE COMPRESSED</code>: Uses int8 quantization (4x smaller), delta encoding, and
RLE</li>
<li><code>LOAD</code>: Auto-detects format (works with both compressed and uncompressed)</li>
</ul>
<h2 id="output-formatting"><a class="header" href="#output-formatting">Output Formatting</a></h2>
<p>The shell converts <code>QueryResult</code> variants into human-readable strings through
the <code>format_result</code> function:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_result(result: &amp;QueryResult) -&gt; String {
    match result {
        QueryResult::Empty =&gt; "OK".to_string(),
        QueryResult::Value(s) =&gt; s.clone(),
        QueryResult::Count(n) =&gt; format_count(*n),
        QueryResult::Ids(ids) =&gt; format_ids(ids),
        QueryResult::Rows(rows) =&gt; format_rows(rows),
        QueryResult::Nodes(nodes) =&gt; format_nodes(nodes),
        QueryResult::Edges(edges) =&gt; format_edges(edges),
        QueryResult::Path(path) =&gt; format_path(path),
        QueryResult::Similar(results) =&gt; format_similar(results),
        QueryResult::Unified(unified) =&gt; unified.description.clone(),
        QueryResult::TableList(tables) =&gt; format_table_list(tables),
        QueryResult::Blob(data) =&gt; format_blob(data),
        QueryResult::ArtifactInfo(info) =&gt; format_artifact_info(info),
        QueryResult::ArtifactList(ids) =&gt; format_artifact_list(ids),
        QueryResult::BlobStats(stats) =&gt; format_blob_stats(stats),
        QueryResult::CheckpointList(checkpoints) =&gt; format_checkpoint_list(checkpoints),
        QueryResult::Chain(chain) =&gt; format_chain_result(chain),
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="table-formatting-algorithm-ascii-tables"><a class="header" href="#table-formatting-algorithm-ascii-tables">Table Formatting Algorithm (ASCII Tables)</a></h3>
<p>The <code>format_rows</code> function implements dynamic column width calculation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_rows(rows: &amp;[Row]) -&gt; String {
    if rows.is_empty() {
        return "(0 rows)".to_string();
    }

    // Get column names from first row
    let columns: Vec&lt;&amp;String&gt; = rows[0].values.iter().map(|(k, _)| k).collect();
    if columns.is_empty() {
        return "(0 rows)".to_string();
    }

    // Convert rows to string values
    let string_rows: Vec&lt;Vec&lt;String&gt;&gt; = rows
        .iter()
        .map(|row| {
            columns
                .iter()
                .map(|col| row.get(col).map(|v| format!("{v:?}")).unwrap_or_default())
                .collect()
        })
        .collect();

    // Calculate column widths (max of header and all cell widths)
    let mut widths: Vec&lt;usize&gt; = columns.iter().map(|c| c.len()).collect();
    for row in &amp;string_rows {
        for (i, cell) in row.iter().enumerate() {
            if i &lt; widths.len() {
                widths[i] = widths[i].max(cell.len());
            }
        }
    }

    // Build output with header, separator, and data rows
    let mut output = String::new();

    // Header
    let header: Vec&lt;String&gt; = columns
        .iter()
        .zip(&amp;widths)
        .map(|(col, &amp;w)| format!("{col:w$}"))
        .collect();
    output.push_str(&amp;header.join(" | "));
    output.push('\n');

    // Separator
    let sep: Vec&lt;String&gt; = widths.iter().map(|&amp;w| "-".repeat(w)).collect();
    output.push_str(&amp;sep.join("-+-"));
    output.push('\n');

    // Data rows
    for row in &amp;string_rows {
        let formatted: Vec&lt;String&gt; = row
            .iter()
            .zip(&amp;widths)
            .map(|(cell, &amp;w)| format!("{cell:w$}"))
            .collect();
        output.push_str(&amp;formatted.join(" | "));
        output.push('\n');
    }

    let _ = write!(output, "({} rows)", rows.len());
    output
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Output example:</strong></p>
<pre><code class="language-text">name  | age | email
------+-----+------------------
Alice | 30  | alice@example.com
Bob   | 25  | bob@example.com
(2 rows)
</code></pre>
<h3 id="node-formatting"><a class="header" href="#node-formatting">Node Formatting</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_nodes(nodes: &amp;[NodeResult]) -&gt; String {
    if nodes.is_empty() {
        "(0 nodes)".to_string()
    } else {
        let lines: Vec&lt;String&gt; = nodes
            .iter()
            .map(|n| {
                let props: Vec&lt;String&gt; = n
                    .properties
                    .iter()
                    .map(|(k, v)| format!("{k}: {v}"))
                    .collect();
                if props.is_empty() {
                    format!("  [{}] {} {{}}", n.id, n.label)
                } else {
                    format!("  [{}] {} {{{}}}", n.id, n.label, props.join(", "))
                }
            })
            .collect();
        format!("Nodes:\n{}\n({} nodes)", lines.join("\n"), nodes.len())
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Output example:</strong></p>
<pre><code class="language-text">Nodes:
  [1] person {name: Alice, age: 30}
  [2] person {name: Bob, age: 25}
(2 nodes)
</code></pre>
<h3 id="edge-formatting"><a class="header" href="#edge-formatting">Edge Formatting</a></h3>
<pre><code class="language-text">Edges:
  [1] 1 -&gt; 2 : knows
(1 edges)
</code></pre>
<h3 id="path-formatting"><a class="header" href="#path-formatting">Path Formatting</a></h3>
<pre><code class="language-text">Path: 1 -&gt; 3 -&gt; 5 -&gt; 7
</code></pre>
<h3 id="similar-embeddings-formatting"><a class="header" href="#similar-embeddings-formatting">Similar Embeddings Formatting</a></h3>
<pre><code class="language-text">Similar:
  1. doc1 (similarity: 0.9800)
  2. doc2 (similarity: 0.9500)
</code></pre>
<h3 id="blob-formatting"><a class="header" href="#blob-formatting">Blob Formatting</a></h3>
<p>Binary data handling with size threshold:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_blob(data: &amp;[u8]) -&gt; String {
    let size = data.len();
    if size &lt;= 256 {
        // Try to display as UTF-8 if valid
        if let Ok(s) = std::str::from_utf8(data) {
            if s.chars().all(|c| !c.is_control() || c == '\n' || c == '\t') {
                return s.to_string();
            }
        }
    }
    // Show summary for binary/large data
    format!("&lt;binary data: {size} bytes&gt;")
}
<span class="boring">}</span></code></pre></pre>
<h3 id="timestamp-formatting"><a class="header" href="#timestamp-formatting">Timestamp Formatting</a></h3>
<p>Relative time formatting for better readability:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_timestamp(unix_secs: u64) -&gt; String {
    let now = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map(|d| d.as_secs())
        .unwrap_or(0);

    if unix_secs == 0 {
        return "unknown".to_string();
    }

    let diff = now.saturating_sub(unix_secs);

    if diff &lt; 60 {
        format!("{diff}s ago")
    } else if diff &lt; 3600 {
        let mins = diff / 60;
        format!("{mins}m ago")
    } else if diff &lt; 86400 {
        let hours = diff / 3600;
        format!("{hours}h ago")
    } else {
        let days = diff / 86400;
        format!("{days}d ago")
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="destructive-operation-confirmation"><a class="header" href="#destructive-operation-confirmation">Destructive Operation Confirmation</a></h2>
<p>The shell integrates with the checkpoint system to provide interactive
confirmation for destructive operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct ShellConfirmationHandler {
    editor: Arc&lt;Mutex&lt;Editor&lt;(), DefaultHistory&gt;&gt;&gt;,
}

impl ConfirmationHandler for ShellConfirmationHandler {
    fn confirm(&amp;self, op: &amp;DestructiveOp, preview: &amp;OperationPreview) -&gt; bool {
        let prompt = format_confirmation_prompt(op, preview);

        // Print the warning with sample data
        println!("\n{prompt}");

        // Ask for confirmation using readline
        let mut editor = self.editor.lock();
        editor
            .readline("Type 'yes' to proceed: ")
            .is_ok_and(|input| input.trim().eq_ignore_ascii_case("yes"))
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Supported destructive operations:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Warning Message</th></tr></thead><tbody>
<tr><td><code>Delete</code></td><td><code>WARNING: About to delete N row(s) from table 'name'</code></td></tr>
<tr><td><code>DropTable</code></td><td><code>WARNING: About to drop table 'name' with N row(s)</code></td></tr>
<tr><td><code>DropIndex</code></td><td><code>WARNING: About to drop index on 'column' in table 'name'</code></td></tr>
<tr><td><code>NodeDelete</code></td><td><code>WARNING: About to delete node N and M connected edge(s)</code></td></tr>
<tr><td><code>EmbedDelete</code></td><td><code>WARNING: About to delete embedding 'key'</code></td></tr>
<tr><td><code>VaultDelete</code></td><td><code>WARNING: About to delete vault secret 'key'</code></td></tr>
<tr><td><code>BlobDelete</code></td><td><code>WARNING: About to delete blob 'id' (size)</code></td></tr>
<tr><td><code>CacheClear</code></td><td><code>WARNING: About to clear cache with N entries</code></td></tr>
</tbody></table>
</div>
<h2 id="keyboard-shortcuts"><a class="header" href="#keyboard-shortcuts">Keyboard Shortcuts</a></h2>
<p>Provided by rustyline:</p>
<div class="table-wrapper"><table><thead><tr><th>Shortcut</th><th>Action</th></tr></thead><tbody>
<tr><td>Up/Down</td><td>Navigate history</td></tr>
<tr><td>Ctrl+C</td><td>Cancel current input (prints <code>^C</code>, continues loop)</td></tr>
<tr><td>Ctrl+D</td><td>Exit shell (EOF)</td></tr>
<tr><td>Ctrl+L</td><td>Clear screen</td></tr>
<tr><td>Ctrl+A</td><td>Move to start of line</td></tr>
<tr><td>Ctrl+E</td><td>Move to end of line</td></tr>
<tr><td>Ctrl+W</td><td>Delete word backward</td></tr>
<tr><td>Ctrl+U</td><td>Delete to start of line</td></tr>
</tbody></table>
</div>
<h2 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Error Type</th><th>Example</th><th>Output Stream</th></tr></thead><tbody>
<tr><td>Parse error</td><td><code>Error: unexpected token 'FORM' at position 12</code></td><td>stderr</td></tr>
<tr><td>Table not found</td><td><code>Error: table 'users' not found</code></td><td>stderr</td></tr>
<tr><td>Invalid query</td><td><code>Error: unsupported operation</code></td><td>stderr</td></tr>
<tr><td>WAL write failure</td><td><code>Command succeeded but WAL write failed: ...</code></td><td>Returned as Error</td></tr>
<tr><td>WAL replay failure</td><td><code>WAL replay failed at line N: ...</code></td><td>Returned as Error</td></tr>
</tbody></table>
</div>
<p>Errors are printed to stderr and do not exit the shell. The <code>process_result</code>
function routes output appropriately:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn process_result(result: &amp;CommandResult) -&gt; LoopAction {
    match result {
        CommandResult::Output(text) | CommandResult::Help(text) =&gt; {
            println!("{text}");
            LoopAction::Continue
        },
        CommandResult::Error(text) =&gt; {
            eprintln!("{text}");
            LoopAction::Continue
        },
        CommandResult::Exit =&gt; {
            println!("Goodbye!");
            LoopAction::Exit
        },
        CommandResult::Empty =&gt; LoopAction::Continue,
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cluster-connectivity"><a class="header" href="#cluster-connectivity">Cluster Connectivity</a></h2>
<h3 id="connect-command-syntax"><a class="header" href="#connect-command-syntax">Connect Command Syntax</a></h3>
<pre><code class="language-text">CLUSTER CONNECT 'node_id@bind_addr' ['peer_id@peer_addr', ...]
</code></pre>
<p><strong>Example:</strong></p>
<pre><code class="language-sql">&gt; CLUSTER CONNECT 'node1@127.0.0.1:8001' 'node2@127.0.0.1:8002'
Cluster initialized: node1 @ 127.0.0.1:8001 with 1 peer(s)
</code></pre>
<h3 id="address-parsing"><a class="header" href="#address-parsing">Address Parsing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn parse_node_address(s: &amp;str) -&gt; Result&lt;(String, SocketAddr), String&gt; {
    let parts: Vec&lt;&amp;str&gt; = s.splitn(2, '@').collect();
    if parts.len() != 2 {
        return Err("Expected format 'node_id@host:port'".to_string());
    }

    let node_id = parts[0].to_string();
    let addr: SocketAddr = parts[1]
        .parse()
        .map_err(|e| format!("Invalid address '{}': {}", parts[1], e))?;

    Ok((node_id, addr))
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cluster-query-execution"><a class="header" href="#cluster-query-execution">Cluster Query Execution</a></h3>
<p>The shell wraps the router for distributed query execution:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct RouterExecutor(Arc&lt;RwLock&lt;QueryRouter&gt;&gt;);

impl QueryExecutor for RouterExecutor {
    fn execute(&amp;self, query: &amp;str) -&gt; Result&lt;Vec&lt;u8&gt;, String&gt; {
        let router = self.0.read();
        router.execute_for_cluster(query)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-characteristics-7"><a class="header" href="#performance-characteristics-7">Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>Empty input</td><td>2.3 ns</td></tr>
<tr><td>Help command</td><td>43 ns</td></tr>
<tr><td>SELECT (100 rows)</td><td>17.8 us</td></tr>
<tr><td>Format 1000 rows</td><td>267 us</td></tr>
</tbody></table>
</div>
<p>The shell adds negligible overhead to query execution.</p>
<h2 id="edge-cases-and-gotchas-11"><a class="header" href="#edge-cases-and-gotchas-11">Edge Cases and Gotchas</a></h2>
<ol>
<li>
<p><strong>Empty quoted paths</strong>: <code>save ''</code> returns an error, not an empty path.</p>
</li>
<li>
<p><strong>WAL not active by default</strong>: The WAL only becomes active after <code>LOAD</code>. New
shells have no WAL.</p>
</li>
<li>
<p><strong>Case sensitivity</strong>: Built-in commands are case-insensitive, but query
strings preserve case for data.</p>
</li>
<li>
<p><strong>History persistence</strong>: History is only saved when the shell exits normally
(not on crash).</p>
</li>
<li>
<p><strong>ANSI codes</strong>: The <code>clear</code> command outputs ANSI escape sequences
(<code>\x1B[2J\x1B[H</code>), which may not work on all terminals.</p>
</li>
<li>
<p><strong>Confirmation handler</strong>: Only active if checkpoint module is available when
shell starts.</p>
</li>
<li>
<p><strong>WAL replay stops on first error</strong>: If any command fails during replay, the
entire replay stops.</p>
</li>
<li>
<p><strong>Missing columns</strong>: When formatting rows with inconsistent columns, missing
values show as empty strings.</p>
</li>
<li>
<p><strong>Binary blob display</strong>: Blobs over 256 bytes or with control characters show
as <code>&lt;binary data: N bytes&gt;</code>.</p>
</li>
<li>
<p><strong>Timestamp overflow</strong>: Very old timestamps (before 1970) or 0 display as
“unknown”.</p>
</li>
</ol>
<h2 id="user-experience-tips"><a class="header" href="#user-experience-tips">User Experience Tips</a></h2>
<ol>
<li>
<p><strong>Use compressed snapshots for large datasets</strong>: <code>SAVE COMPRESSED</code> reduces
file size by ~4x with minimal precision loss.</p>
</li>
<li>
<p><strong>Check WAL status before critical operations</strong>: Run <code>WAL STATUS</code> to verify
recovery capability.</p>
</li>
<li>
<p><strong>Use tab completion</strong>: Rustyline provides filename completion in some
contexts.</p>
</li>
<li>
<p><strong>Ctrl+C is safe</strong>: It only cancels the current line, not the entire session.</p>
</li>
<li>
<p><strong>History survives sessions</strong>: Previous commands are available across shell
restarts.</p>
</li>
<li>
<p><strong>For scripts, use programmatic API</strong>: <code>shell.execute()</code> returns structured
results for automation.</p>
</li>
<li>
<p><strong>Cluster connect before distributed operations</strong>: Ensure <code>CLUSTER CONNECT</code>
succeeds before running distributed transactions.</p>
</li>
</ol>
<h2 id="dependencies-8"><a class="header" href="#dependencies-8">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>query_router</code></td><td>Query execution</td></tr>
<tr><td><code>relational_engine</code></td><td>Row type for formatting</td></tr>
<tr><td><code>tensor_store</code></td><td>Snapshot persistence (save/load)</td></tr>
<tr><td><code>tensor_compress</code></td><td>Compressed snapshot support</td></tr>
<tr><td><code>tensor_checkpoint</code></td><td>Checkpoint confirmation handling</td></tr>
<tr><td><code>tensor_chain</code></td><td>Cluster query executor trait</td></tr>
<tr><td><code>rustyline</code></td><td>Readline functionality (history, shortcuts, Ctrl+C)</td></tr>
<tr><td><code>parking_lot</code></td><td>Mutex and RwLock for thread-safe router access</td></tr>
<tr><td><code>base64</code></td><td>Vault key decoding</td></tr>
</tbody></table>
</div>
<h2 id="related-modules-13"><a class="header" href="#related-modules-13">Related Modules</a></h2>
<ul>
<li><strong>query_router</strong>: The Query Router executes all queries. The shell delegates
all query parsing and execution to this module.</li>
<li><strong>tensor_store</strong>: Provides the underlying storage layer and snapshot
functionality.</li>
<li><strong>tensor_compress</strong>: Handles compressed snapshot format with int8
quantization.</li>
<li><strong>tensor_checkpoint</strong>: Provides checkpoint/rollback functionality with
confirmation prompts.</li>
<li><strong>tensor_chain</strong>: Provides cluster connectivity and distributed transaction
support.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="neumann-server-architecture"><a class="header" href="#neumann-server-architecture">Neumann Server Architecture</a></h1>
<p>The Neumann Server (<code>neumann_server</code>) provides a gRPC server that exposes the
Neumann database over the network. It serves as the network gateway for remote
clients, wrapping the Query Router with authentication, TLS encryption, and
streaming support for large result sets and blob storage.</p>
<p>The server follows four design principles: zero-configuration startup (works
out of the box with sensible defaults), security-first (API key authentication
with constant-time comparison, TLS support), streaming-native (all large
operations use gRPC streaming), and health monitoring (automatic failure
tracking with configurable thresholds).</p>
<h2 id="architecture-overview-2"><a class="header" href="#architecture-overview-2">Architecture Overview</a></h2>
<pre class="mermaid">flowchart TD
    subgraph Clients
        CLI[neumann_client]
        gRPC[gRPC Clients]
        Web[gRPC-Web Browsers]
    end

    subgraph NeumannServer
        QS[QueryService]
        BS[BlobService]
        HS[HealthService]
        RS[ReflectionService]
        Auth[Auth Middleware]
        TLS[TLS Layer]
    end

    subgraph Backend
        QR[QueryRouter]
        Blob[BlobStore]
    end

    CLI --&gt; TLS
    gRPC --&gt; TLS
    Web --&gt; TLS
    TLS --&gt; Auth
    Auth --&gt; QS
    Auth --&gt; BS
    Auth --&gt; HS
    QS --&gt; QR
    BS --&gt; Blob
    RS --&gt; |Service Discovery| gRPC
</pre>
<h2 id="key-types-12"><a class="header" href="#key-types-12">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>NeumannServer</code></td><td>Main server struct with router, blob store, and configuration</td></tr>
<tr><td><code>ServerConfig</code></td><td>Configuration for bind address, TLS, auth, and limits</td></tr>
<tr><td><code>TlsConfig</code></td><td>TLS certificate paths and client certificate settings</td></tr>
<tr><td><code>AuthConfig</code></td><td>API key list, header name, and anonymous access control</td></tr>
<tr><td><code>ApiKey</code></td><td>Individual API key with identity and optional description</td></tr>
<tr><td><code>QueryServiceImpl</code></td><td>gRPC service for query execution with streaming</td></tr>
<tr><td><code>BlobServiceImpl</code></td><td>gRPC service for artifact storage with streaming</td></tr>
<tr><td><code>HealthServiceImpl</code></td><td>gRPC service for health checks</td></tr>
<tr><td><code>HealthState</code></td><td>Shared health state across services</td></tr>
<tr><td><code>ServerError</code></td><td>Error type for server operations</td></tr>
</tbody></table>
</div>
<h2 id="server-configuration"><a class="header" href="#server-configuration">Server Configuration</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>bind_addr</code></td><td><code>SocketAddr</code></td><td><code>127.0.0.1:9200</code></td><td>Server bind address</td></tr>
<tr><td><code>tls</code></td><td><code>Option&lt;TlsConfig&gt;</code></td><td><code>None</code></td><td>TLS configuration</td></tr>
<tr><td><code>auth</code></td><td><code>Option&lt;AuthConfig&gt;</code></td><td><code>None</code></td><td>Authentication configuration</td></tr>
<tr><td><code>max_message_size</code></td><td><code>usize</code></td><td>64 MB</td><td>Maximum gRPC message size</td></tr>
<tr><td><code>max_upload_size</code></td><td><code>usize</code></td><td>512 MB</td><td>Maximum blob upload size</td></tr>
<tr><td><code>enable_grpc_web</code></td><td><code>bool</code></td><td><code>true</code></td><td>Enable gRPC-web for browsers</td></tr>
<tr><td><code>enable_reflection</code></td><td><code>bool</code></td><td><code>true</code></td><td>Enable service reflection</td></tr>
<tr><td><code>blob_chunk_size</code></td><td><code>usize</code></td><td>64 KB</td><td>Chunk size for blob streaming</td></tr>
<tr><td><code>stream_channel_capacity</code></td><td><code>usize</code></td><td>32</td><td>Bounded channel capacity for backpressure</td></tr>
</tbody></table>
</div>
<h3 id="configuration-builder"><a class="header" href="#configuration-builder">Configuration Builder</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_server::{ServerConfig, TlsConfig, AuthConfig, ApiKey};
use std::path::PathBuf;

let config = ServerConfig::new()
    .with_bind_addr("0.0.0.0:9443".parse()?)
    .with_tls(TlsConfig::new(
        PathBuf::from("server.crt"),
        PathBuf::from("server.key"),
    ))
    .with_auth(
        AuthConfig::new()
            .with_api_key(ApiKey::new(
                "sk-prod-key-12345678".to_string(),
                "service:backend".to_string(),
            ))
            .with_anonymous(false)
    )
    .with_max_message_size(128 * 1024 * 1024)
    .with_grpc_web(true)
    .with_reflection(true);
<span class="boring">}</span></code></pre></pre>
<h2 id="tls-configuration"><a class="header" href="#tls-configuration">TLS Configuration</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>cert_path</code></td><td><code>PathBuf</code></td><td>Required</td><td>Path to certificate file (PEM)</td></tr>
<tr><td><code>key_path</code></td><td><code>PathBuf</code></td><td>Required</td><td>Path to private key file (PEM)</td></tr>
<tr><td><code>ca_cert_path</code></td><td><code>Option&lt;PathBuf&gt;</code></td><td><code>None</code></td><td>CA certificate for client auth</td></tr>
<tr><td><code>require_client_cert</code></td><td><code>bool</code></td><td><code>false</code></td><td>Require client certificates</td></tr>
</tbody></table>
</div>
<h3 id="tls-setup-example"><a class="header" href="#tls-setup-example">TLS Setup Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_server::TlsConfig;
use std::path::PathBuf;

// Basic TLS
let tls = TlsConfig::new(
    PathBuf::from("/etc/neumann/server.crt"),
    PathBuf::from("/etc/neumann/server.key"),
);

// Mutual TLS (mTLS)
let tls = TlsConfig::new(
    PathBuf::from("/etc/neumann/server.crt"),
    PathBuf::from("/etc/neumann/server.key"),
)
.with_ca_cert(PathBuf::from("/etc/neumann/ca.crt"))
.with_required_client_cert(true);
<span class="boring">}</span></code></pre></pre>
<h2 id="authentication"><a class="header" href="#authentication">Authentication</a></h2>
<h3 id="authconfig-options"><a class="header" href="#authconfig-options">AuthConfig Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>api_keys</code></td><td><code>Vec&lt;ApiKey&gt;</code></td><td>Empty</td><td>List of valid API keys</td></tr>
<tr><td><code>api_key_header</code></td><td><code>String</code></td><td><code>x-api-key</code></td><td>Header name for API key</td></tr>
<tr><td><code>allow_anonymous</code></td><td><code>bool</code></td><td><code>false</code></td><td>Allow unauthenticated access</td></tr>
</tbody></table>
</div>
<h3 id="api-key-validation"><a class="header" href="#api-key-validation">API Key Validation</a></h3>
<p>The server uses constant-time comparison to prevent timing attacks. All keys are
checked regardless of match status to avoid leaking information about valid
prefixes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Internal validation logic
fn validate_key(&amp;self, key: &amp;str) -&gt; Option&lt;&amp;str&gt; {
    let key_bytes = key.as_bytes();
    let mut found_identity: Option&lt;&amp;str&gt; = None;

    for api_key in &amp;self.api_keys {
        let stored_bytes = api_key.key.as_bytes();
        let max_len = stored_bytes.len().max(key_bytes.len());

        let mut matches: u8 = 1;
        for i in 0..max_len {
            let stored_byte = stored_bytes.get(i).copied().unwrap_or(0);
            let key_byte = key_bytes.get(i).copied().unwrap_or(0);
            matches &amp;= u8::from(stored_byte == key_byte);
        }

        let lengths_match = u8::from(stored_bytes.len() == key_bytes.len());
        matches &amp;= lengths_match;

        if matches == 1 {
            found_identity = Some(api_key.identity.as_str());
        }
    }

    found_identity
}
<span class="boring">}</span></code></pre></pre>
<h3 id="authentication-flow"><a class="header" href="#authentication-flow">Authentication Flow</a></h3>
<pre class="mermaid">flowchart TD
    A[Request arrives] --&gt; B{Auth configured?}
    B --&gt;|No| C[Allow with no identity]
    B --&gt;|Yes| D{API key header present?}
    D --&gt;|No| E{Anonymous allowed?}
    E --&gt;|Yes| C
    E --&gt;|No| F[Return UNAUTHENTICATED]
    D --&gt;|Yes| G{Key valid?}
    G --&gt;|Yes| H[Allow with identity from key]
    G --&gt;|No| F
</pre>
<h2 id="grpc-services"><a class="header" href="#grpc-services">gRPC Services</a></h2>
<h3 id="queryservice"><a class="header" href="#queryservice">QueryService</a></h3>
<p>The QueryService provides query execution with three RPC methods:</p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Execute</code></td><td>Unary</td><td>Execute single query, return full result</td></tr>
<tr><td><code>ExecuteStream</code></td><td>Server streaming</td><td>Execute query, stream results chunk by chunk</td></tr>
<tr><td><code>ExecuteBatch</code></td><td>Unary</td><td>Execute multiple queries, return all results</td></tr>
</tbody></table>
</div>
<h4 id="execute-rpc"><a class="header" href="#execute-rpc">Execute RPC</a></h4>
<pre><code class="language-protobuf">rpc Execute(QueryRequest) returns (QueryResponse);

message QueryRequest {
    string query = 1;
    optional string identity = 2;
}

message QueryResponse {
    oneof result {
        EmptyResult empty = 1;
        CountResult count = 2;
        RowsResult rows = 3;
        NodesResult nodes = 4;
        EdgesResult edges = 5;
        PathResult path = 6;
        SimilarResult similar = 7;
        TableListResult table_list = 8;
        BlobResult blob = 9;
        IdsResult ids = 10;
    }
    optional ErrorInfo error = 15;
}
</code></pre>
<h4 id="executestream-rpc"><a class="header" href="#executestream-rpc">ExecuteStream RPC</a></h4>
<p>For large result sets (rows, nodes, edges, similar items, blobs), the streaming
RPC sends results one item at a time:</p>
<pre><code class="language-protobuf">rpc ExecuteStream(QueryRequest) returns (stream QueryResponseChunk);

message QueryResponseChunk {
    oneof chunk {
        RowChunk row = 1;
        NodeChunk node = 2;
        EdgeChunk edge = 3;
        SimilarChunk similar_item = 4;
        bytes blob_data = 5;
        ErrorInfo error = 15;
    }
    bool is_final = 16;
}
</code></pre>
<h4 id="executebatch-rpc"><a class="header" href="#executebatch-rpc">ExecuteBatch RPC</a></h4>
<pre><code class="language-protobuf">rpc ExecuteBatch(BatchQueryRequest) returns (BatchQueryResponse);

message BatchQueryRequest {
    repeated QueryRequest queries = 1;
}

message BatchQueryResponse {
    repeated QueryResponse results = 1;
}
</code></pre>
<p><strong>Security Note</strong>: In batch execution, the authenticated request identity is
always used. Per-query identity fields are ignored to prevent privilege
escalation attacks.</p>
<h3 id="blobservice"><a class="header" href="#blobservice">BlobService</a></h3>
<p>The BlobService provides artifact storage with streaming upload/download:</p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Upload</code></td><td>Client streaming</td><td>Upload artifact with metadata</td></tr>
<tr><td><code>Download</code></td><td>Server streaming</td><td>Download artifact in chunks</td></tr>
<tr><td><code>Delete</code></td><td>Unary</td><td>Delete artifact</td></tr>
<tr><td><code>GetMetadata</code></td><td>Unary</td><td>Get artifact metadata</td></tr>
</tbody></table>
</div>
<h4 id="upload-protocol"><a class="header" href="#upload-protocol">Upload Protocol</a></h4>
<pre class="mermaid">sequenceDiagram
    participant C as Client
    participant S as BlobService

    C-&gt;&gt;S: UploadMetadata (filename, content_type, tags)
    C-&gt;&gt;S: Chunk 1
    C-&gt;&gt;S: Chunk 2
    C-&gt;&gt;S: ...
    C-&gt;&gt;S: Chunk N (end stream)
    S-&gt;&gt;C: UploadResponse (artifact_id, size, checksum)
</pre>
<p>The first message must be metadata, followed by data chunks:</p>
<pre><code class="language-protobuf">rpc Upload(stream BlobUploadRequest) returns (BlobUploadResponse);

message BlobUploadRequest {
    oneof request {
        UploadMetadata metadata = 1;
        bytes chunk = 2;
    }
}

message UploadMetadata {
    string filename = 1;
    optional string content_type = 2;
    repeated string tags = 3;
}

message BlobUploadResponse {
    string artifact_id = 1;
    uint64 size = 2;
    string checksum = 3;
}
</code></pre>
<h4 id="download-protocol"><a class="header" href="#download-protocol">Download Protocol</a></h4>
<pre><code class="language-protobuf">rpc Download(BlobDownloadRequest) returns (stream BlobDownloadChunk);

message BlobDownloadRequest {
    string artifact_id = 1;
}

message BlobDownloadChunk {
    bytes data = 1;
    bool is_final = 2;
}
</code></pre>
<h3 id="healthservice"><a class="header" href="#healthservice">HealthService</a></h3>
<p>The HealthService follows the gRPC health checking protocol:</p>
<pre><code class="language-protobuf">rpc Check(HealthCheckRequest) returns (HealthCheckResponse);

message HealthCheckRequest {
    optional string service = 1;
}

message HealthCheckResponse {
    ServingStatus status = 1;
}

enum ServingStatus {
    UNSPECIFIED = 0;
    SERVING = 1;
    NOT_SERVING = 2;
}
</code></pre>
<h4 id="health-check-targets"><a class="header" href="#health-check-targets">Health Check Targets</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Service Name</th><th>Checks</th></tr></thead><tbody>
<tr><td>Empty or <code>""</code></td><td>Overall server health (all services)</td></tr>
<tr><td><code>neumann.v1.QueryService</code></td><td>Query service health</td></tr>
<tr><td><code>neumann.v1.BlobService</code></td><td>Blob service health</td></tr>
<tr><td>Unknown service</td><td>Returns <code>UNSPECIFIED</code></td></tr>
</tbody></table>
</div>
<h4 id="automatic-health-tracking"><a class="header" href="#automatic-health-tracking">Automatic Health Tracking</a></h4>
<p>The QueryService tracks consecutive failures and marks itself unhealthy after
reaching the threshold (default: 5 failures):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const FAILURE_THRESHOLD: u32 = 5;

fn record_failure(&amp;self) {
    let failures = self.consecutive_failures.fetch_add(1, Ordering::SeqCst) + 1;
    if failures &gt;= FAILURE_THRESHOLD {
        if let Some(ref health) = self.health_state {
            health.set_query_service_healthy(false);
        }
    }
}

fn record_success(&amp;self) {
    self.consecutive_failures.store(0, Ordering::SeqCst);
    if let Some(ref health) = self.health_state {
        health.set_query_service_healthy(true);
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="server-lifecycle"><a class="header" href="#server-lifecycle">Server Lifecycle</a></h2>
<h3 id="startup-sequence"><a class="header" href="#startup-sequence">Startup Sequence</a></h3>
<pre class="mermaid">flowchart TD
    A[Create NeumannServer] --&gt; B[Validate configuration]
    B --&gt; C{TLS configured?}
    C --&gt;|Yes| D[Load certificates]
    C --&gt;|No| E[Plain TCP]
    D --&gt; F[Build TLS config]
    F --&gt; G[Create services]
    E --&gt; G
    G --&gt; H{gRPC-web enabled?}
    H --&gt;|Yes| I[Add gRPC-web layer]
    H --&gt;|No| J[Standard gRPC]
    I --&gt; K{Reflection enabled?}
    J --&gt; K
    K --&gt;|Yes| L[Add reflection service]
    K --&gt;|No| M[Start serving]
    L --&gt; M
    M --&gt; N[Accept connections]
</pre>
<h3 id="basic-server-setup"><a class="header" href="#basic-server-setup">Basic Server Setup</a></h3>
<pre><pre class="playground"><code class="language-rust">use neumann_server::{NeumannServer, ServerConfig};
use query_router::QueryRouter;
use std::sync::Arc;
use parking_lot::RwLock;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Create router
    let router = Arc::new(RwLock::new(QueryRouter::new()));

    // Create server with default config
    let server = NeumannServer::new(router, ServerConfig::default());

    // Start serving (blocks until shutdown)
    server.serve().await?;

    Ok(())
}</code></pre></pre>
<h3 id="server-with-shared-storage"><a class="header" href="#server-with-shared-storage">Server with Shared Storage</a></h3>
<p>For applications that need both query and blob services sharing the same
storage:</p>
<pre><pre class="playground"><code class="language-rust">use neumann_server::{NeumannServer, ServerConfig};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let config = ServerConfig::default();

    // Creates QueryRouter and BlobStore sharing the same TensorStore
    let server = NeumannServer::with_shared_storage(config).await?;

    server.serve().await?;

    Ok(())
}</code></pre></pre>
<h3 id="graceful-shutdown"><a class="header" href="#graceful-shutdown">Graceful Shutdown</a></h3>
<pre><pre class="playground"><code class="language-rust">use tokio::signal;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let server = NeumannServer::with_shared_storage(ServerConfig::default()).await?;

    // Shutdown on Ctrl+C
    server.serve_with_shutdown(signal::ctrl_c().map(|_| ())).await?;

    Ok(())
}</code></pre></pre>
<h2 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h2>
<h3 id="server-errors"><a class="header" href="#server-errors">Server Errors</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th><th>gRPC Status</th></tr></thead><tbody>
<tr><td><code>Config</code></td><td>Invalid configuration</td><td><code>INVALID_ARGUMENT</code></td></tr>
<tr><td><code>Transport</code></td><td>Network/TLS failure</td><td><code>UNAVAILABLE</code></td></tr>
<tr><td><code>Query</code></td><td>Query execution failed</td><td><code>INVALID_ARGUMENT</code></td></tr>
<tr><td><code>Auth</code></td><td>Authentication failed</td><td><code>UNAUTHENTICATED</code></td></tr>
<tr><td><code>Blob</code></td><td>Blob operation failed</td><td><code>INTERNAL</code></td></tr>
<tr><td><code>Internal</code></td><td>Unexpected server error</td><td><code>INTERNAL</code></td></tr>
<tr><td><code>InvalidArgument</code></td><td>Bad request data</td><td><code>INVALID_ARGUMENT</code></td></tr>
<tr><td><code>NotFound</code></td><td>Resource not found</td><td><code>NOT_FOUND</code></td></tr>
<tr><td><code>PermissionDenied</code></td><td>Access denied</td><td><code>PERMISSION_DENIED</code></td></tr>
<tr><td><code>Io</code></td><td>I/O error</td><td><code>INTERNAL</code></td></tr>
</tbody></table>
</div>
<h3 id="error-conversion-1"><a class="header" href="#error-conversion-1">Error Conversion</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl From&lt;ServerError&gt; for Status {
    fn from(err: ServerError) -&gt; Self {
        match &amp;err {
            ServerError::Config(msg) =&gt; Status::invalid_argument(msg),
            ServerError::Transport(e) =&gt; Status::unavailable(e.to_string()),
            ServerError::Query(msg) =&gt; Status::invalid_argument(msg),
            ServerError::Auth(msg) =&gt; Status::unauthenticated(msg),
            ServerError::Blob(msg) =&gt; Status::internal(msg),
            ServerError::Internal(msg) =&gt; Status::internal(msg),
            ServerError::InvalidArgument(msg) =&gt; Status::invalid_argument(msg),
            ServerError::NotFound(msg) =&gt; Status::not_found(msg),
            ServerError::PermissionDenied(msg) =&gt; Status::permission_denied(msg),
            ServerError::Io(e) =&gt; Status::internal(e.to_string()),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="backpressure-and-flow-control"><a class="header" href="#backpressure-and-flow-control">Backpressure and Flow Control</a></h2>
<h3 id="streaming-backpressure"><a class="header" href="#streaming-backpressure">Streaming Backpressure</a></h3>
<p>The server uses bounded channels for streaming responses to prevent memory
exhaustion:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Default: 32 items buffered
let (tx, rx) = mpsc::channel(self.stream_channel_capacity);

tokio::spawn(async move {
    for item in results {
        // This will block if channel is full, providing backpressure
        if tx.send(Ok(item)).await.is_err() {
            // Receiver dropped, stop sending
            return;
        }
    }
});
<span class="boring">}</span></code></pre></pre>
<h3 id="upload-size-limits"><a class="header" href="#upload-size-limits">Upload Size Limits</a></h3>
<p>The BlobService enforces upload size limits:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if data.len().saturating_add(chunk.len()) &gt; max_size {
    return Err(Status::resource_exhausted(format!(
        "upload exceeds maximum size of {max_size} bytes"
    )));
}
<span class="boring">}</span></code></pre></pre>
<h2 id="production-deployment"><a class="header" href="#production-deployment">Production Deployment</a></h2>
<h3 id="recommended-configuration"><a class="header" href="#recommended-configuration">Recommended Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = ServerConfig::new()
    .with_bind_addr("0.0.0.0:9443".parse()?)
    .with_tls(TlsConfig::new(
        PathBuf::from("/etc/neumann/tls/server.crt"),
        PathBuf::from("/etc/neumann/tls/server.key"),
    ))
    .with_auth(
        AuthConfig::new()
            .with_api_key(ApiKey::new(
                std::env::var("NEUMANN_API_KEY")?,
                "service:default".to_string(),
            ))
            .with_anonymous(false)
    )
    .with_max_message_size(64 * 1024 * 1024)
    .with_max_upload_size(1024 * 1024 * 1024)  // 1GB
    .with_stream_channel_capacity(64)
    .with_grpc_web(true)
    .with_reflection(false);  // Disable in production
<span class="boring">}</span></code></pre></pre>
<h3 id="health-check-integration"><a class="header" href="#health-check-integration">Health Check Integration</a></h3>
<p>Use health checks with load balancers:</p>
<pre><code class="language-bash"># grpcurl health check
grpcurl -plaintext localhost:9200 neumann.v1.Health/Check

# With service name
grpcurl -plaintext -d '{"service":"neumann.v1.QueryService"}' \
    localhost:9200 neumann.v1.Health/Check
</code></pre>
<h3 id="logging"><a class="header" href="#logging">Logging</a></h3>
<p>The server uses the <code>tracing</code> crate for structured logging:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing_subscriber::FmtSubscriber;

let subscriber = FmtSubscriber::builder()
    .with_max_level(tracing::Level::INFO)
    .finish();
tracing::subscriber::set_global_default(subscriber)?;

// Server logs connection info and errors
// INFO: Starting Neumann gRPC server with TLS on 0.0.0.0:9443
// ERROR: Query execution error: table 'users' not found
<span class="boring">}</span></code></pre></pre>
<h2 id="dependencies-9"><a class="header" href="#dependencies-9">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>query_router</code></td><td>Query execution backend</td></tr>
<tr><td><code>tensor_blob</code></td><td>Blob storage backend</td></tr>
<tr><td><code>tensor_store</code></td><td>Shared storage for both query and blob</td></tr>
<tr><td><code>tonic</code></td><td>gRPC server framework</td></tr>
<tr><td><code>tonic-web</code></td><td>gRPC-web layer for browser support</td></tr>
<tr><td><code>tonic-reflection</code></td><td>Service reflection for debugging</td></tr>
<tr><td><code>tokio</code></td><td>Async runtime</td></tr>
<tr><td><code>parking_lot</code></td><td>Thread-safe router access</td></tr>
<tr><td><code>tracing</code></td><td>Structured logging</td></tr>
<tr><td><code>thiserror</code></td><td>Error type derivation</td></tr>
</tbody></table>
</div>
<h2 id="related-modules-14"><a class="header" href="#related-modules-14">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>neumann_client</code></td><td>Client SDK for connecting to this server</td></tr>
<tr><td><code>query_router</code></td><td>Query execution backend</td></tr>
<tr><td><code>tensor_blob</code></td><td>Blob storage backend</td></tr>
<tr><td><code>neumann_shell</code></td><td>Interactive CLI (alternative interface)</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="neumann-client-architecture"><a class="header" href="#neumann-client-architecture">Neumann Client Architecture</a></h1>
<p>The Neumann Client (<code>neumann_client</code>) provides a Rust SDK for interacting with
the Neumann database. It supports two modes: embedded mode for in-process
database access via the Query Router, and remote mode for network access via
gRPC to a Neumann Server.</p>
<p>The client follows four design principles: dual-mode flexibility (same API for
embedded and remote), security-first (API keys are zeroized on drop),
async-native (built on tokio for remote operations), and zero-copy where
possible (streaming results for large datasets).</p>
<h2 id="architecture-overview-3"><a class="header" href="#architecture-overview-3">Architecture Overview</a></h2>
<pre class="mermaid">flowchart TD
    subgraph Application
        App[User Application]
    end

    subgraph NeumannClient
        Client[NeumannClient]
        Builder[ClientBuilder]
        Config[ClientConfig]
    end

    subgraph EmbeddedMode
        Router[QueryRouter]
        Store[TensorStore]
    end

    subgraph RemoteMode
        gRPC[gRPC Channel]
        TLS[TLS Layer]
    end

    subgraph NeumannServer
        Server[NeumannServer]
    end

    App --&gt; Builder
    Builder --&gt; Client
    Client --&gt;|embedded| Router
    Router --&gt; Store
    Client --&gt;|remote| gRPC
    gRPC --&gt; TLS
    TLS --&gt; Server
</pre>
<h2 id="key-types-13"><a class="header" href="#key-types-13">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>NeumannClient</code></td><td>Main client struct supporting both embedded and remote modes</td></tr>
<tr><td><code>ClientBuilder</code></td><td>Fluent builder for remote client connections</td></tr>
<tr><td><code>ClientConfig</code></td><td>Configuration for remote connections (address, API key, TLS)</td></tr>
<tr><td><code>ClientMode</code></td><td>Enum: <code>Embedded</code> or <code>Remote</code></td></tr>
<tr><td><code>ClientError</code></td><td>Error type for client operations</td></tr>
<tr><td><code>RemoteQueryResult</code></td><td>Wrapper for proto query response with typed accessors</td></tr>
<tr><td><code>QueryResult</code></td><td>Re-export of query_router result type (embedded mode)</td></tr>
</tbody></table>
</div>
<h2 id="client-modes"><a class="header" href="#client-modes">Client Modes</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Mode</th><th>Feature Flag</th><th>Use Case</th></tr></thead><tbody>
<tr><td>Embedded</td><td><code>embedded</code></td><td>In-process database, unit testing, CLI tools</td></tr>
<tr><td>Remote</td><td><code>remote</code> (default)</td><td>Production gRPC connections to server</td></tr>
<tr><td>Full</td><td><code>full</code></td><td>Both modes available</td></tr>
</tbody></table>
</div>
<h3 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h3>
<pre><code class="language-toml">[dependencies]
# Remote only (default)
neumann_client = "0.1"

# Embedded only
neumann_client = { version = "0.1", default-features = false, features = ["embedded"] }

# Both modes
neumann_client = { version = "0.1", features = ["full"] }
</code></pre>
<h2 id="client-configuration"><a class="header" href="#client-configuration">Client Configuration</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>address</code></td><td><code>String</code></td><td><code>localhost:9200</code></td><td>Server address (host:port)</td></tr>
<tr><td><code>api_key</code></td><td><code>Option&lt;String&gt;</code></td><td><code>None</code></td><td>API key for authentication</td></tr>
<tr><td><code>tls</code></td><td><code>bool</code></td><td><code>false</code></td><td>Enable TLS encryption</td></tr>
<tr><td><code>timeout_ms</code></td><td><code>u64</code></td><td><code>30000</code></td><td>Request timeout in milliseconds</td></tr>
</tbody></table>
</div>
<h3 id="security-api-key-zeroization"><a class="header" href="#security-api-key-zeroization">Security: API Key Zeroization</a></h3>
<p>API keys are automatically zeroed from memory when the configuration is dropped
to prevent credential leakage:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Drop for ClientConfig {
    fn drop(&amp;mut self) {
        if let Some(ref mut key) = self.api_key {
            key.zeroize();  // Overwrites memory with zeros
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="remote-mode"><a class="header" href="#remote-mode">Remote Mode</a></h2>
<h3 id="connection-builder"><a class="header" href="#connection-builder">Connection Builder</a></h3>
<p>The <code>ClientBuilder</code> provides a fluent API for configuring remote connections:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_client::NeumannClient;
use std::time::Duration;

// Minimal connection
let client = NeumannClient::connect("localhost:9200")
    .build()
    .await?;

// Full configuration
let client = NeumannClient::connect("db.example.com:9443")
    .api_key("sk-production-key")
    .with_tls()
    .timeout_ms(60_000)
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-flow"><a class="header" href="#connection-flow">Connection Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant App as Application
    participant Builder as ClientBuilder
    participant Client as NeumannClient
    participant Channel as gRPC Channel
    participant Server as NeumannServer

    App-&gt;&gt;Builder: connect(&quot;address&quot;)
    App-&gt;&gt;Builder: api_key(&quot;key&quot;)
    App-&gt;&gt;Builder: with_tls()
    App-&gt;&gt;Builder: build().await
    Builder-&gt;&gt;Channel: Create endpoint
    Channel-&gt;&gt;Server: TCP/TLS handshake
    Server--&gt;&gt;Channel: Connection established
    Channel--&gt;&gt;Builder: Channel ready
    Builder--&gt;&gt;Client: NeumannClient created
    Client--&gt;&gt;App: Ready for queries
</pre>
<h3 id="query-execution-1"><a class="header" href="#query-execution-1">Query Execution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Single query
let result = client.execute("SELECT * FROM users").await?;

// With identity (for vault access)
let result = client
    .execute_with_identity("VAULT GET 'secret'", Some("service:backend"))
    .await?;

// Batch queries
let results = client
    .execute_batch(&amp;[
        "CREATE TABLE orders (id:int, total:float)",
        "INSERT orders id=1, total=99.99",
        "SELECT orders",
    ])
    .await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="remotequeryresult-accessors"><a class="header" href="#remotequeryresult-accessors">RemoteQueryResult Accessors</a></h3>
<p>The <code>RemoteQueryResult</code> wrapper provides typed access to query results:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let result = client.execute("SELECT * FROM users").await?;

// Check for errors
if result.has_error() {
    eprintln!("Error: {}", result.error_message().unwrap());
    return Err(...);
}

// Check result type
if result.is_empty() {
    println!("No results");
}

// Access typed data
if let Some(count) = result.count() {
    println!("Count: {}", count);
}

if let Some(rows) = result.rows() {
    for row in rows {
        println!("Row ID: {}", row.id);
    }
}

if let Some(nodes) = result.nodes() {
    for node in nodes {
        println!("Node: {} ({})", node.id, node.label);
    }
}

if let Some(edges) = result.edges() {
    for edge in edges {
        println!("Edge: {} -&gt; {}", edge.from, edge.to);
    }
}

if let Some(similar) = result.similar() {
    for item in similar {
        println!("{}: {:.4}", item.key, item.score);
    }
}

// Access raw proto response
let proto = result.into_inner();
<span class="boring">}</span></code></pre></pre>
<h3 id="blocking-connection"><a class="header" href="#blocking-connection">Blocking Connection</a></h3>
<p>For synchronous contexts, use the blocking builder:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let client = NeumannClient::connect("localhost:9200")
    .api_key("test-key")
    .build_blocking()?;  // Creates temporary tokio runtime
<span class="boring">}</span></code></pre></pre>
<h2 id="embedded-mode"><a class="header" href="#embedded-mode">Embedded Mode</a></h2>
<h3 id="creating-an-embedded-client"><a class="header" href="#creating-an-embedded-client">Creating an Embedded Client</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_client::NeumannClient;

// New embedded database
let client = NeumannClient::embedded()?;

// With custom router (for shared state)
use query_router::QueryRouter;
use std::sync::Arc;
use parking_lot::RwLock;

let router = Arc::new(RwLock::new(QueryRouter::new()));
let client = NeumannClient::with_router(router);
<span class="boring">}</span></code></pre></pre>
<h3 id="synchronous-query-execution"><a class="header" href="#synchronous-query-execution">Synchronous Query Execution</a></h3>
<p>Embedded mode provides synchronous execution for simpler code flow:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_client::QueryResult;

// Create table
let result = client.execute_sync("CREATE TABLE users (name:string, age:int)")?;
assert!(matches!(result, QueryResult::Empty));

// Insert data
let result = client.execute_sync("INSERT users name=\"Alice\", age=30")?;

// Query data
let result = client.execute_sync("SELECT users")?;
match result {
    QueryResult::Rows(rows) =&gt; {
        for row in rows {
            println!("{:?}", row);
        }
    }
    _ =&gt; {}
}
<span class="boring">}</span></code></pre></pre>
<h3 id="with-identity"><a class="header" href="#with-identity">With Identity</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Set identity for vault access control
let result = client.execute_sync_with_identity(
    "VAULT GET 'api_secret'",
    Some("service:backend"),
)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-5"><a class="header" href="#error-handling-5">Error Handling</a></h2>
<h3 id="error-types-8"><a class="header" href="#error-types-8">Error Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Code</th><th>Retryable</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Connection</code></td><td>6</td><td>Yes</td><td>Failed to connect to server</td></tr>
<tr><td><code>Query</code></td><td>9</td><td>No</td><td>Query execution failed</td></tr>
<tr><td><code>Authentication</code></td><td>5</td><td>No</td><td>Invalid API key</td></tr>
<tr><td><code>PermissionDenied</code></td><td>3</td><td>No</td><td>Access denied</td></tr>
<tr><td><code>NotFound</code></td><td>2</td><td>No</td><td>Resource not found</td></tr>
<tr><td><code>InvalidArgument</code></td><td>1</td><td>No</td><td>Bad request data</td></tr>
<tr><td><code>Parse</code></td><td>8</td><td>No</td><td>Query parse error</td></tr>
<tr><td><code>Internal</code></td><td>7</td><td>No</td><td>Server internal error</td></tr>
<tr><td><code>Timeout</code></td><td>6</td><td>Yes</td><td>Request timed out</td></tr>
<tr><td><code>Unavailable</code></td><td>6</td><td>Yes</td><td>Server unavailable</td></tr>
</tbody></table>
</div>
<h3 id="error-methods"><a class="header" href="#error-methods">Error Methods</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let err = ClientError::Connection("connection refused".to_string());

// Get error code
let code = err.code();  // 6

// Check if retryable
if err.is_retryable() {
    // Retry with exponential backoff
}

// Display error
eprintln!("Error: {}", err);  // "connection error: connection refused"
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-pattern"><a class="header" href="#error-handling-pattern">Error Handling Pattern</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_client::ClientError;

match client.execute("SELECT * FROM users").await {
    Ok(result) =&gt; {
        if result.has_error() {
            // Query-level error (e.g., table not found)
            eprintln!("Query error: {}", result.error_message().unwrap());
        } else {
            // Process results
        }
    }
    Err(ClientError::Connection(msg)) =&gt; {
        // Network error - maybe retry
        eprintln!("Connection failed: {}", msg);
    }
    Err(ClientError::Authentication(msg)) =&gt; {
        // Bad credentials - check API key
        eprintln!("Auth failed: {}", msg);
    }
    Err(ClientError::Timeout(msg)) =&gt; {
        // Request too slow - maybe retry with longer timeout
        eprintln!("Timeout: {}", msg);
    }
    Err(e) =&gt; {
        eprintln!("Unexpected error: {}", e);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="conversion-from-grpc-status"><a class="header" href="#conversion-from-grpc-status">Conversion from gRPC Status</a></h3>
<p>Remote errors are automatically converted from tonic Status:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl From&lt;tonic::Status&gt; for ClientError {
    fn from(status: tonic::Status) -&gt; Self {
        match status.code() {
            Code::InvalidArgument =&gt; Self::InvalidArgument(status.message().to_string()),
            Code::NotFound =&gt; Self::NotFound(status.message().to_string()),
            Code::PermissionDenied =&gt; Self::PermissionDenied(status.message().to_string()),
            Code::Unauthenticated =&gt; Self::Authentication(status.message().to_string()),
            Code::Unavailable =&gt; Self::Unavailable(status.message().to_string()),
            Code::DeadlineExceeded =&gt; Self::Timeout(status.message().to_string()),
            _ =&gt; Self::Internal(status.message().to_string()),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="connection-management"><a class="header" href="#connection-management">Connection Management</a></h2>
<h3 id="connection-state"><a class="header" href="#connection-state">Connection State</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let client = NeumannClient::connect("localhost:9200")
    .build()
    .await?;

// Check mode
match client.mode() {
    ClientMode::Embedded =&gt; println!("In-process"),
    ClientMode::Remote =&gt; println!("Connected to server"),
}

// Check connection status
if client.is_connected() {
    // Ready for queries
}
<span class="boring">}</span></code></pre></pre>
<h3 id="closing-connections"><a class="header" href="#closing-connections">Closing Connections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut client = NeumannClient::connect("localhost:9200")
    .build()
    .await?;

// Explicit close
client.close();

// Or automatic on drop
drop(client);  // Connection closed, API key zeroized
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-examples-10"><a class="header" href="#usage-examples-10">Usage Examples</a></h2>
<h3 id="complete-remote-example"><a class="header" href="#complete-remote-example">Complete Remote Example</a></h3>
<pre><pre class="playground"><code class="language-rust">use neumann_client::{NeumannClient, ClientError};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Connect to server
    let client = NeumannClient::connect("localhost:9200")
        .api_key(std::env::var("NEUMANN_API_KEY")?)
        .with_tls()
        .timeout_ms(30_000)
        .build()
        .await?;

    // Create schema
    client.execute("CREATE TABLE products (name:string, price:float)").await?;

    // Insert data
    client.execute("INSERT products name=\"Widget\", price=9.99").await?;
    client.execute("INSERT products name=\"Gadget\", price=19.99").await?;

    // Query data
    let result = client.execute("SELECT products WHERE price &gt; 10").await?;

    if let Some(rows) = result.rows() {
        for row in rows {
            println!("Product: {:?}", row);
        }
    }

    Ok(())
}</code></pre></pre>
<h3 id="complete-embedded-example"><a class="header" href="#complete-embedded-example">Complete Embedded Example</a></h3>
<pre><pre class="playground"><code class="language-rust">use neumann_client::{NeumannClient, QueryResult};

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    // Create embedded client
    let client = NeumannClient::embedded()?;

    // Create schema
    client.execute_sync("CREATE TABLE events (name:string, timestamp:int)")?;

    // Insert data
    client.execute_sync("INSERT events name=\"login\", timestamp=1700000000")?;

    // Query data
    match client.execute_sync("SELECT events")? {
        QueryResult::Rows(rows) =&gt; {
            println!("Found {} events", rows.len());
            for row in rows {
                println!("  {:?}", row);
            }
        }
        _ =&gt; println!("Unexpected result type"),
    }

    Ok(())
}</code></pre></pre>
<h3 id="testing-with-embedded-mode"><a class="header" href="#testing-with-embedded-mode">Testing with Embedded Mode</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use neumann_client::{NeumannClient, QueryResult};

    #[test]
    fn test_user_creation() {
        let client = NeumannClient::embedded().unwrap();

        // Setup
        client
            .execute_sync("CREATE TABLE users (email:string, active:bool)")
            .unwrap();

        // Test
        client
            .execute_sync("INSERT users email=\"test@example.com\", active=true")
            .unwrap();

        // Verify
        let result = client.execute_sync("SELECT users").unwrap();
        match result {
            QueryResult::Rows(rows) =&gt; {
                assert_eq!(rows.len(), 1);
            }
            _ =&gt; panic!("Expected rows"),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="shared-router-between-clients"><a class="header" href="#shared-router-between-clients">Shared Router Between Clients</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_client::NeumannClient;
use query_router::QueryRouter;
use std::sync::Arc;
use parking_lot::RwLock;

// Create shared router
let router = Arc::new(RwLock::new(QueryRouter::new()));

// Create multiple clients sharing same state
let client1 = NeumannClient::with_router(Arc::clone(&amp;router));
let client2 = NeumannClient::with_router(Arc::clone(&amp;router));

// Changes from client1 visible to client2
client1.execute_sync("CREATE TABLE shared (x:int)")?;
let result = client2.execute_sync("SELECT shared")?;  // Works!
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<h3 id="connection-reuse"><a class="header" href="#connection-reuse">Connection Reuse</a></h3>
<p>Create one client and reuse it for multiple queries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Reuse client
let client = NeumannClient::connect("localhost:9200").build().await?;
for query in queries {
    client.execute(&amp;query).await?;
}

// Bad: New connection per query
for query in queries {
    let client = NeumannClient::connect("localhost:9200").build().await?;
    client.execute(&amp;query).await?;
}  // Connection overhead for each query
<span class="boring">}</span></code></pre></pre>
<h3 id="timeout-configuration"><a class="header" href="#timeout-configuration">Timeout Configuration</a></h3>
<p>Set appropriate timeouts based on query complexity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Quick queries
let client = NeumannClient::connect("localhost:9200")
    .timeout_ms(5_000)  // 5 seconds
    .build()
    .await?;

// Complex analytics
let client = NeumannClient::connect("localhost:9200")
    .timeout_ms(300_000)  // 5 minutes
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="api-key-security"><a class="header" href="#api-key-security">API Key Security</a></h3>
<p>Never hardcode API keys:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: Environment variable
let api_key = std::env::var("NEUMANN_API_KEY")?;
let client = NeumannClient::connect("localhost:9200")
    .api_key(api_key)
    .build()
    .await?;

// Bad: Hardcoded key
let client = NeumannClient::connect("localhost:9200")
    .api_key("sk-secret-key-12345")  // Will be in binary!
    .build()
    .await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="dependencies-10"><a class="header" href="#dependencies-10">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Crate</th><th>Purpose</th><th>Feature</th></tr></thead><tbody>
<tr><td><code>query_router</code></td><td>Embedded mode query execution</td><td><code>embedded</code></td></tr>
<tr><td><code>tonic</code></td><td>gRPC client</td><td><code>remote</code></td></tr>
<tr><td><code>tokio</code></td><td>Async runtime</td><td><code>remote</code></td></tr>
<tr><td><code>parking_lot</code></td><td>Thread-safe router access</td><td><code>embedded</code></td></tr>
<tr><td><code>zeroize</code></td><td>Secure memory clearing</td><td>Always</td></tr>
<tr><td><code>thiserror</code></td><td>Error type derivation</td><td>Always</td></tr>
<tr><td><code>tracing</code></td><td>Structured logging</td><td>Always</td></tr>
</tbody></table>
</div>
<h2 id="related-modules-15"><a class="header" href="#related-modules-15">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>neumann_server</code></td><td>Server counterpart for remote mode</td></tr>
<tr><td><code>query_router</code></td><td>Query execution backend for embedded mode</td></tr>
<tr><td><code>neumann_shell</code></td><td>Alternative interactive interface</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="typescript-sdk-architecture"><a class="header" href="#typescript-sdk-architecture">TypeScript SDK Architecture</a></h1>
<p>The TypeScript SDK (<code>@neumann/client</code>) provides a TypeScript/JavaScript client
for the Neumann database with support for both Node.js (gRPC) and browser
(gRPC-Web) environments.</p>
<p>The SDK follows four design principles: environment agnostic (same API for
Node.js and browsers via dynamic imports), type-safe (full TypeScript support
with discriminated unions for results), streaming-first (async iterators for
large result sets), and zero dependencies in core types (proto converters are
separate from type definitions).</p>
<h2 id="architecture-overview-4"><a class="header" href="#architecture-overview-4">Architecture Overview</a></h2>
<pre class="mermaid">flowchart TD
    subgraph Application
        App[TypeScript Application]
    end

    subgraph SDK[&quot;@neumann/client&quot;]
        Client[NeumannClient]
        Types[Type Definitions]
        Errors[Error Classes]
        Converters[Proto Converters]
    end

    subgraph NodeJS[Node.js Environment]
        gRPC[&quot;@grpc/grpc-js&quot;]
    end

    subgraph Browser[Browser Environment]
        gRPCWeb[grpc-web]
    end

    App --&gt; Client
    Client --&gt; Types
    Client --&gt; Errors
    Client --&gt; Converters
    Client --&gt;|connect| gRPC
    Client --&gt;|connectWeb| gRPCWeb
    gRPC --&gt; Server[NeumannServer]
    gRPCWeb --&gt; Server
</pre>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<pre><code class="language-bash"># npm
npm install @neumann/client

# yarn
yarn add @neumann/client

# pnpm
pnpm add @neumann/client
</code></pre>
<p>For Node.js, also install the gRPC package:</p>
<pre><code class="language-bash">npm install @grpc/grpc-js
</code></pre>
<p>For browsers, install gRPC-Web:</p>
<pre><code class="language-bash">npm install grpc-web
</code></pre>
<h2 id="key-types-14"><a class="header" href="#key-types-14">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>NeumannClient</code></td><td>Main client class for database operations</td></tr>
<tr><td><code>ConnectOptions</code></td><td>Options for server connection (API key, TLS, metadata)</td></tr>
<tr><td><code>QueryOptions</code></td><td>Options for query execution (identity)</td></tr>
<tr><td><code>ClientMode</code></td><td>Client mode: <code>'remote'</code> or <code>'embedded'</code></td></tr>
<tr><td><code>QueryResult</code></td><td>Discriminated union of all result types</td></tr>
<tr><td><code>Value</code></td><td>Typed scalar value with type tag</td></tr>
<tr><td><code>Row</code></td><td>Relational row with column values</td></tr>
<tr><td><code>Node</code></td><td>Graph node with label and properties</td></tr>
<tr><td><code>Edge</code></td><td>Graph edge with type, source, target, properties</td></tr>
<tr><td><code>Path</code></td><td>Graph path as list of segments</td></tr>
<tr><td><code>SimilarItem</code></td><td>Vector similarity search result</td></tr>
<tr><td><code>ArtifactInfo</code></td><td>Blob artifact metadata</td></tr>
<tr><td><code>NeumannError</code></td><td>Base error class with error code</td></tr>
</tbody></table>
</div>
<h2 id="connection-options"><a class="header" href="#connection-options">Connection Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>apiKey</code></td><td><code>string?</code></td><td><code>undefined</code></td><td>API key for authentication</td></tr>
<tr><td><code>tls</code></td><td><code>boolean?</code></td><td><code>false</code></td><td>Enable TLS encryption</td></tr>
<tr><td><code>metadata</code></td><td><code>Record&lt;string, string&gt;?</code></td><td><code>undefined</code></td><td>Custom metadata headers</td></tr>
</tbody></table>
</div>
<h2 id="query-options"><a class="header" href="#query-options">Query Options</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>identity</code></td><td><code>string?</code></td><td><code>undefined</code></td><td>Identity for vault access control</td></tr>
</tbody></table>
</div>
<h2 id="connection-methods"><a class="header" href="#connection-methods">Connection Methods</a></h2>
<h3 id="nodejs-connection"><a class="header" href="#nodejs-connection">Node.js Connection</a></h3>
<pre><code class="language-typescript">import { NeumannClient } from '@neumann/client';

// Basic connection
const client = await NeumannClient.connect('localhost:9200');

// With authentication and TLS
const client = await NeumannClient.connect('db.example.com:9443', {
  apiKey: process.env.NEUMANN_API_KEY,
  tls: true,
  metadata: { 'x-request-id': 'abc123' },
});
</code></pre>
<h3 id="browser-connection-grpc-web"><a class="header" href="#browser-connection-grpc-web">Browser Connection (gRPC-Web)</a></h3>
<pre><code class="language-typescript">import { NeumannClient } from '@neumann/client';

// Connect via gRPC-Web
const client = await NeumannClient.connectWeb('https://api.example.com', {
  apiKey: 'your-api-key',
});
</code></pre>
<h2 id="query-execution-2"><a class="header" href="#query-execution-2">Query Execution</a></h2>
<h3 id="single-query"><a class="header" href="#single-query">Single Query</a></h3>
<pre><code class="language-typescript">const result = await client.execute('SELECT users');

// With identity for vault access
const result = await client.execute('VAULT GET "secret"', {
  identity: 'service:backend',
});
</code></pre>
<h3 id="streaming-query"><a class="header" href="#streaming-query">Streaming Query</a></h3>
<p>For large result sets, use streaming to receive results incrementally:</p>
<pre><code class="language-typescript">for await (const chunk of client.executeStream('SELECT large_table')) {
  if (chunk.type === 'rows') {
    for (const row of chunk.rows) {
      console.log(rowToObject(row));
    }
  }
}
</code></pre>
<h3 id="batch-query"><a class="header" href="#batch-query">Batch Query</a></h3>
<p>Execute multiple queries in a single request:</p>
<pre><code class="language-typescript">const results = await client.executeBatch([
  'CREATE TABLE orders (id:int, total:float)',
  'INSERT orders id=1, total=99.99',
  'SELECT orders',
]);

for (const result of results) {
  console.log(result.type);
}
</code></pre>
<h2 id="query-result-types"><a class="header" href="#query-result-types">Query Result Types</a></h2>
<p>The <code>QueryResult</code> type is a discriminated union. Use the <code>type</code> field to
determine which result type you have:</p>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Fields</th><th>Description</th></tr></thead><tbody>
<tr><td><code>'empty'</code></td><td>-</td><td>No result (DDL operations)</td></tr>
<tr><td><code>'value'</code></td><td><code>value: string</code></td><td>Single value result</td></tr>
<tr><td><code>'count'</code></td><td><code>count: number</code></td><td>Row count</td></tr>
<tr><td><code>'rows'</code></td><td><code>rows: Row[]</code></td><td>Relational query rows</td></tr>
<tr><td><code>'nodes'</code></td><td><code>nodes: Node[]</code></td><td>Graph nodes</td></tr>
<tr><td><code>'edges'</code></td><td><code>edges: Edge[]</code></td><td>Graph edges</td></tr>
<tr><td><code>'paths'</code></td><td><code>paths: Path[]</code></td><td>Graph paths</td></tr>
<tr><td><code>'similar'</code></td><td><code>items: SimilarItem[]</code></td><td>Vector similarity results</td></tr>
<tr><td><code>'ids'</code></td><td><code>ids: string[]</code></td><td>List of IDs</td></tr>
<tr><td><code>'tableList'</code></td><td><code>names: string[]</code></td><td>Table names</td></tr>
<tr><td><code>'blob'</code></td><td><code>data: Uint8Array</code></td><td>Binary blob data</td></tr>
<tr><td><code>'blobInfo'</code></td><td><code>info: ArtifactInfo</code></td><td>Blob metadata</td></tr>
<tr><td><code>'error'</code></td><td><code>code: number, message: string</code></td><td>Error response</td></tr>
</tbody></table>
</div>
<h3 id="type-guards"><a class="header" href="#type-guards">Type Guards</a></h3>
<p>Use the provided type guards for type-safe result handling:</p>
<pre><code class="language-typescript">import {
  isRowsResult,
  isNodesResult,
  isErrorResult,
  rowToObject,
} from '@neumann/client';

const result = await client.execute('SELECT users');

if (isErrorResult(result)) {
  console.error(`Error ${result.code}: ${result.message}`);
} else if (isRowsResult(result)) {
  for (const row of result.rows) {
    console.log(rowToObject(row));
  }
}
</code></pre>
<h3 id="result-pattern-matching"><a class="header" href="#result-pattern-matching">Result Pattern Matching</a></h3>
<pre><code class="language-typescript">const result = await client.execute(query);

switch (result.type) {
  case 'empty':
    console.log('OK');
    break;
  case 'count':
    console.log(`${result.count} rows affected`);
    break;
  case 'rows':
    console.table(result.rows.map(rowToObject));
    break;
  case 'nodes':
    result.nodes.forEach((n) =&gt; console.log(`[${n.id}] ${n.label}`));
    break;
  case 'similar':
    result.items.forEach((s) =&gt; console.log(`${s.key}: ${s.score.toFixed(4)}`));
    break;
  case 'error':
    throw new Error(result.message);
}
</code></pre>
<h2 id="value-types"><a class="header" href="#value-types">Value Types</a></h2>
<p>Values use a tagged union pattern for type safety:</p>
<pre><code class="language-typescript">import {
  Value,
  nullValue,
  intValue,
  floatValue,
  stringValue,
  boolValue,
  bytesValue,
  valueToNative,
  valueFromNative,
} from '@neumann/client';

// Create typed values
const v1: Value = nullValue();
const v2: Value = intValue(42);
const v3: Value = floatValue(3.14);
const v4: Value = stringValue('hello');
const v5: Value = boolValue(true);
const v6: Value = bytesValue(new Uint8Array([1, 2, 3]));

// Convert to native JavaScript types
const native = valueToNative(v2); // 42

// Create from native values (auto-detects type)
const auto = valueFromNative(42); // { type: 'int', data: 42 }
</code></pre>
<h2 id="conversion-utilities"><a class="header" href="#conversion-utilities">Conversion Utilities</a></h2>
<h3 id="row-conversion"><a class="header" href="#row-conversion">Row Conversion</a></h3>
<pre><code class="language-typescript">import { rowToObject } from '@neumann/client';

const result = await client.execute('SELECT users');
if (result.type === 'rows') {
  const objects = result.rows.map(rowToObject);
  // [{ name: 'Alice', age: 30 }, { name: 'Bob', age: 25 }]
}
</code></pre>
<h3 id="node-conversion"><a class="header" href="#node-conversion">Node Conversion</a></h3>
<pre><code class="language-typescript">import { nodeToObject } from '@neumann/client';

const result = await client.execute('NODE LIST');
if (result.type === 'nodes') {
  const objects = result.nodes.map(nodeToObject);
  // [{ id: '1', label: 'person', properties: { name: 'Alice' } }]
}
</code></pre>
<h3 id="edge-conversion"><a class="header" href="#edge-conversion">Edge Conversion</a></h3>
<pre><code class="language-typescript">import { edgeToObject } from '@neumann/client';

const result = await client.execute('EDGE LIST');
if (result.type === 'edges') {
  const objects = result.edges.map(edgeToObject);
  // [{ id: '1', type: 'knows', source: '1', target: '2', properties: {} }]
}
</code></pre>
<h2 id="error-handling-6"><a class="header" href="#error-handling-6">Error Handling</a></h2>
<h3 id="error-codes"><a class="header" href="#error-codes">Error Codes</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td><code>UNKNOWN</code></td><td>Unknown error</td></tr>
<tr><td>1</td><td><code>INVALID_ARGUMENT</code></td><td>Bad request data</td></tr>
<tr><td>2</td><td><code>NOT_FOUND</code></td><td>Resource not found</td></tr>
<tr><td>3</td><td><code>PERMISSION_DENIED</code></td><td>Access denied</td></tr>
<tr><td>4</td><td><code>ALREADY_EXISTS</code></td><td>Resource already exists</td></tr>
<tr><td>5</td><td><code>UNAUTHENTICATED</code></td><td>Authentication failed</td></tr>
<tr><td>6</td><td><code>UNAVAILABLE</code></td><td>Server unavailable</td></tr>
<tr><td>7</td><td><code>INTERNAL</code></td><td>Internal server error</td></tr>
<tr><td>8</td><td><code>PARSE_ERROR</code></td><td>Query parse error</td></tr>
<tr><td>9</td><td><code>QUERY_ERROR</code></td><td>Query execution error</td></tr>
</tbody></table>
</div>
<h3 id="error-classes"><a class="header" href="#error-classes">Error Classes</a></h3>
<pre><code class="language-typescript">import {
  NeumannError,
  ConnectionError,
  AuthenticationError,
  PermissionDeniedError,
  NotFoundError,
  InvalidArgumentError,
  ParseError,
  QueryError,
  InternalError,
  errorFromCode,
} from '@neumann/client';

try {
  await client.execute('SELECT nonexistent');
} catch (e) {
  if (e instanceof ConnectionError) {
    console.error('Connection failed:', e.message);
  } else if (e instanceof AuthenticationError) {
    console.error('Auth failed - check API key');
  } else if (e instanceof ParseError) {
    console.error('Query syntax error:', e.message);
  } else if (e instanceof NeumannError) {
    console.error(`[${e.code}] ${e.message}`);
  }
}
</code></pre>
<h3 id="error-factory"><a class="header" href="#error-factory">Error Factory</a></h3>
<p>Create errors from numeric codes:</p>
<pre><code class="language-typescript">import { errorFromCode, ErrorCode } from '@neumann/client';

const error = errorFromCode(ErrorCode.NOT_FOUND, 'Table not found');
// Returns NotFoundError instance
</code></pre>
<h2 id="client-lifecycle"><a class="header" href="#client-lifecycle">Client Lifecycle</a></h2>
<pre><code class="language-typescript">// Create client
const client = await NeumannClient.connect('localhost:9200');

// Check connection status
console.log(client.isConnected); // true
console.log(client.clientMode); // 'remote'

// Execute queries
const result = await client.execute('SELECT users');

// Close connection when done
client.close();
console.log(client.isConnected); // false
</code></pre>
<h2 id="usage-examples-11"><a class="header" href="#usage-examples-11">Usage Examples</a></h2>
<h3 id="complete-crud-example"><a class="header" href="#complete-crud-example">Complete CRUD Example</a></h3>
<pre><code class="language-typescript">import { NeumannClient, isRowsResult, rowToObject } from '@neumann/client';

async function main() {
  const client = await NeumannClient.connect('localhost:9200', {
    apiKey: process.env.NEUMANN_API_KEY,
  });

  try {
    // Create table
    await client.execute('CREATE TABLE products (name:string, price:float)');

    // Insert data
    await client.execute('INSERT products name="Widget", price=9.99');
    await client.execute('INSERT products name="Gadget", price=19.99');

    // Query data
    const result = await client.execute('SELECT products WHERE price &gt; 10');

    if (isRowsResult(result)) {
      const products = result.rows.map(rowToObject);
      console.log('Products over $10:', products);
    }

    // Update data
    await client.execute('UPDATE products SET price=24.99 WHERE name="Gadget"');

    // Delete data
    await client.execute('DELETE products WHERE price &lt; 15');

    // Drop table
    await client.execute('DROP TABLE products');
  } finally {
    client.close();
  }
}
</code></pre>
<h3 id="graph-operations-2"><a class="header" href="#graph-operations-2">Graph Operations</a></h3>
<pre><code class="language-typescript">const client = await NeumannClient.connect('localhost:9200');

// Create nodes
await client.execute('NODE CREATE person {name: "Alice", age: 30}');
await client.execute('NODE CREATE person {name: "Bob", age: 25}');

// Create edge
await client.execute('EDGE CREATE 1 -&gt; 2 : knows {since: 2020}');

// Query nodes
const nodes = await client.execute('NODE LIST person');
if (nodes.type === 'nodes') {
  nodes.nodes.forEach((n) =&gt; {
    console.log(`[${n.id}] ${n.label}:`, nodeToObject(n).properties);
  });
}

// Find path
const path = await client.execute('PATH 1 -&gt; 2');
if (path.type === 'paths' &amp;&amp; path.paths.length &gt; 0) {
  const nodeIds = path.paths[0].segments.map((s) =&gt; s.node.id);
  console.log('Path:', nodeIds.join(' -&gt; '));
}
</code></pre>
<h3 id="vector-similarity-search"><a class="header" href="#vector-similarity-search">Vector Similarity Search</a></h3>
<pre><code class="language-typescript">const client = await NeumannClient.connect('localhost:9200');

// Store embeddings
await client.execute('EMBED STORE "doc1" [0.1, 0.2, 0.3, 0.4]');
await client.execute('EMBED STORE "doc2" [0.15, 0.25, 0.35, 0.45]');
await client.execute('EMBED STORE "doc3" [0.9, 0.8, 0.7, 0.6]');

// Find similar
const result = await client.execute('SIMILAR "doc1" COSINE LIMIT 2');
if (result.type === 'similar') {
  result.items.forEach((item) =&gt; {
    console.log(`${item.key}: ${item.score.toFixed(4)}`);
  });
}
</code></pre>
<h3 id="browser-usage-with-react"><a class="header" href="#browser-usage-with-react">Browser Usage with React</a></h3>
<pre><code class="language-typescript">import { useState, useEffect } from 'react';
import { NeumannClient, QueryResult } from '@neumann/client';

function useNeumannQuery(query: string) {
  const [result, setResult] = useState&lt;QueryResult | null&gt;(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState&lt;Error | null&gt;(null);

  useEffect(() =&gt; {
    let cancelled = false;

    async function fetchData() {
      try {
        const client = await NeumannClient.connectWeb('/api/neumann');
        const data = await client.execute(query);
        if (!cancelled) {
          setResult(data);
          setLoading(false);
        }
        client.close();
      } catch (e) {
        if (!cancelled) {
          setError(e as Error);
          setLoading(false);
        }
      }
    }

    fetchData();
    return () =&gt; {
      cancelled = true;
    };
  }, [query]);

  return { result, loading, error };
}
</code></pre>
<h2 id="proto-conversion"><a class="header" href="#proto-conversion">Proto Conversion</a></h2>
<p>The SDK includes utilities for converting protobuf messages to typed objects:</p>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody>
<tr><td><code>convertProtoValue</code></td><td>Convert proto Value to typed Value</td></tr>
<tr><td><code>convertProtoRow</code></td><td>Convert proto Row to Row</td></tr>
<tr><td><code>convertProtoNode</code></td><td>Convert proto Node to Node</td></tr>
<tr><td><code>convertProtoEdge</code></td><td>Convert proto Edge to Edge</td></tr>
<tr><td><code>convertProtoPath</code></td><td>Convert proto Path to Path</td></tr>
<tr><td><code>convertProtoSimilarItem</code></td><td>Convert proto SimilarItem to SimilarItem</td></tr>
<tr><td><code>convertProtoArtifactInfo</code></td><td>Convert proto ArtifactInfo to ArtifactInfo</td></tr>
</tbody></table>
</div>
<p>These are used internally but exported for custom integrations.</p>
<h2 id="dependencies-11"><a class="header" href="#dependencies-11">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Package</th><th>Purpose</th><th>Environment</th></tr></thead><tbody>
<tr><td><code>@grpc/grpc-js</code></td><td>gRPC client</td><td>Node.js</td></tr>
<tr><td><code>grpc-web</code></td><td>gRPC-Web client</td><td>Browser</td></tr>
</tbody></table>
</div>
<p>The SDK uses dynamic imports to load the appropriate gRPC library based on the
connection method used.</p>
<h2 id="related-modules-16"><a class="header" href="#related-modules-16">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>neumann_server</code></td><td>Server that this SDK connects to</td></tr>
<tr><td><code>neumann_client</code></td><td>Rust SDK with same capabilities</td></tr>
<tr><td><code>neumann-py</code></td><td>Python SDK with same API design</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="python-sdk-architecture"><a class="header" href="#python-sdk-architecture">Python SDK Architecture</a></h1>
<p>The Python SDK (<code>neumann-db</code>) provides a Python client for the Neumann database
with support for both embedded mode (via PyO3 bindings) and remote mode (via
gRPC). It includes async support and integrations for pandas and numpy.</p>
<p>The SDK follows four design principles: Pythonic API (context managers, type
hints, dataclasses), dual-mode (same API for embedded and remote), async-first
(native asyncio support), and ecosystem integration (pandas DataFrame and numpy
array support).</p>
<h2 id="architecture-overview-5"><a class="header" href="#architecture-overview-5">Architecture Overview</a></h2>
<pre class="mermaid">flowchart TD
    subgraph Application
        App[Python Application]
    end

    subgraph SDK[neumann-db]
        Client[NeumannClient]
        AsyncClient[AsyncNeumannClient]
        Tx[Transaction]
        Types[Data Types]
        Errors[Error Classes]
    end

    subgraph Integrations
        Pandas[pandas Integration]
        Numpy[numpy Integration]
    end

    subgraph EmbeddedMode[Embedded Mode]
        PyO3[_native PyO3 Module]
        Router[QueryRouter]
    end

    subgraph RemoteMode[Remote Mode]
        gRPC[grpcio]
        Proto[Proto Stubs]
    end

    App --&gt; Client
    App --&gt; AsyncClient
    Client --&gt; Tx
    Client --&gt; Types
    Client --&gt; Errors
    Client --&gt; Pandas
    Client --&gt; Numpy
    Client --&gt;|embedded| PyO3
    PyO3 --&gt; Router
    Client --&gt;|remote| gRPC
    AsyncClient --&gt; gRPC
    gRPC --&gt; Proto
    Proto --&gt; Server[NeumannServer]
</pre>
<h2 id="installation-2"><a class="header" href="#installation-2">Installation</a></h2>
<pre><code class="language-bash"># Basic installation (remote mode only)
pip install neumann-db

# With native module for embedded mode
pip install neumann-db[native]

# With pandas integration
pip install neumann-db[pandas]

# With numpy integration
pip install neumann-db[numpy]

# Full installation
pip install neumann-db[full]
</code></pre>
<h2 id="key-types-15"><a class="header" href="#key-types-15">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>NeumannClient</code></td><td>Synchronous client supporting both modes</td></tr>
<tr><td><code>AsyncNeumannClient</code></td><td>Async client for remote mode</td></tr>
<tr><td><code>Transaction</code></td><td>Transaction context manager</td></tr>
<tr><td><code>QueryResult</code></td><td>Query result with typed accessors</td></tr>
<tr><td><code>QueryResultType</code></td><td>Enum of result types</td></tr>
<tr><td><code>Value</code></td><td>Typed scalar value</td></tr>
<tr><td><code>ScalarType</code></td><td>Enum of scalar types</td></tr>
<tr><td><code>Row</code></td><td>Relational row with typed column accessors</td></tr>
<tr><td><code>Node</code></td><td>Graph node with properties</td></tr>
<tr><td><code>Edge</code></td><td>Graph edge with properties</td></tr>
<tr><td><code>Path</code></td><td>Graph path as list of segments</td></tr>
<tr><td><code>PathSegment</code></td><td>Path segment (node + optional edge)</td></tr>
<tr><td><code>SimilarItem</code></td><td>Vector similarity result</td></tr>
<tr><td><code>ArtifactInfo</code></td><td>Blob artifact metadata</td></tr>
<tr><td><code>NeumannError</code></td><td>Base exception class</td></tr>
</tbody></table>
</div>
<h2 id="client-modes-1"><a class="header" href="#client-modes-1">Client Modes</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Mode</th><th>Class Method</th><th>Requirements</th><th>Use Case</th></tr></thead><tbody>
<tr><td>Embedded</td><td><code>NeumannClient.embedded()</code></td><td><code>neumann-db[native]</code></td><td>Testing, CLI tools</td></tr>
<tr><td>Remote</td><td><code>NeumannClient.connect()</code></td><td><code>grpcio</code></td><td>Production</td></tr>
<tr><td>Async Remote</td><td><code>AsyncNeumannClient.connect()</code></td><td><code>grpcio</code></td><td>Async applications</td></tr>
</tbody></table>
</div>
<h2 id="synchronous-client"><a class="header" href="#synchronous-client">Synchronous Client</a></h2>
<h3 id="embedded-mode-1"><a class="header" href="#embedded-mode-1">Embedded Mode</a></h3>
<pre><code class="language-python">from neumann import NeumannClient

# In-memory database
client = NeumannClient.embedded()

# Persistent storage
client = NeumannClient.embedded(path="/path/to/data")

# Use as context manager
with NeumannClient.embedded() as client:
    client.execute("CREATE TABLE users (name:string)")
</code></pre>
<h3 id="remote-mode-1"><a class="header" href="#remote-mode-1">Remote Mode</a></h3>
<pre><code class="language-python">from neumann import NeumannClient

# Basic connection
client = NeumannClient.connect("localhost:9200")

# With authentication and TLS
client = NeumannClient.connect(
    "db.example.com:9443",
    api_key="your-api-key",
    tls=True,
)

# Context manager
with NeumannClient.connect("localhost:9200") as client:
    result = client.execute("SELECT users")
</code></pre>
<h3 id="query-execution-3"><a class="header" href="#query-execution-3">Query Execution</a></h3>
<pre><code class="language-python"># Single query
result = client.execute("SELECT users")

# With identity for vault access
result = client.execute(
    "VAULT GET 'secret'",
    identity="service:backend",
)

# Streaming query
for chunk in client.execute_stream("SELECT large_table"):
    for row in chunk.rows:
        print(row.to_dict())

# Batch execution
results = client.execute_batch([
    "CREATE TABLE orders (id:int, total:float)",
    "INSERT orders id=1, total=99.99",
    "SELECT orders",
])
</code></pre>
<h2 id="async-client"><a class="header" href="#async-client">Async Client</a></h2>
<p>The async client supports remote mode only (PyO3 has threading limitations):</p>
<pre><code class="language-python">from neumann.aio import AsyncNeumannClient

# Connect
client = await AsyncNeumannClient.connect(
    "localhost:9200",
    api_key="your-api-key",
)

# Execute query
result = await client.execute("SELECT users")

# Streaming
async for chunk in client.execute_stream("SELECT large_table"):
    for row in chunk.rows:
        print(row.to_dict())

# Batch
results = await client.execute_batch(queries)

# Close
await client.close()
</code></pre>
<h3 id="async-context-manager"><a class="header" href="#async-context-manager">Async Context Manager</a></h3>
<pre><code class="language-python">async with await AsyncNeumannClient.connect("localhost:9200") as client:
    result = await client.execute("SELECT users")
    for row in result.rows:
        print(row.to_dict())
</code></pre>
<h3 id="run-embedded-in-async-context"><a class="header" href="#run-embedded-in-async-context">Run Embedded in Async Context</a></h3>
<p>Use <code>run_in_executor</code> to use embedded mode from async code:</p>
<pre><code class="language-python">async def query_embedded():
    client = await AsyncNeumannClient.connect("localhost:9200")
    # This runs the embedded client in a thread pool
    result = await client.run_in_executor("SELECT users")
    return result
</code></pre>
<h2 id="transaction-support"><a class="header" href="#transaction-support">Transaction Support</a></h2>
<p>Transactions provide automatic commit/rollback with context managers:</p>
<pre><code class="language-python">from neumann import NeumannClient, Transaction

client = NeumannClient.connect("localhost:9200")

# Using Transaction directly
tx = Transaction(client)
tx.begin()
try:
    tx.execute("INSERT users name='Alice'")
    tx.execute("INSERT users name='Bob'")
    tx.commit()
except Exception:
    tx.rollback()
    raise

# Using context manager (preferred)
with Transaction(client) as tx:
    tx.execute("INSERT users name='Alice'")
    tx.execute("INSERT users name='Bob'")
    # Auto-commits on success, auto-rollbacks on exception
</code></pre>
<h3 id="transaction-properties"><a class="header" href="#transaction-properties">Transaction Properties</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Property</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>is_active</code></td><td><code>bool</code></td><td>True if transaction is active</td></tr>
</tbody></table>
</div>
<h3 id="transaction-methods"><a class="header" href="#transaction-methods">Transaction Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>begin()</code></td><td>Start the transaction</td></tr>
<tr><td><code>commit()</code></td><td>Commit the transaction</td></tr>
<tr><td><code>rollback()</code></td><td>Rollback the transaction</td></tr>
<tr><td><code>execute(query)</code></td><td>Execute query within transaction</td></tr>
</tbody></table>
</div>
<h2 id="query-result-types-1"><a class="header" href="#query-result-types-1">Query Result Types</a></h2>
<p>The <code>QueryResult</code> class provides typed access to query results:</p>
<div class="table-wrapper"><table><thead><tr><th>Property</th><th>Return Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>type</code></td><td><code>QueryResultType</code></td><td>Result type enum</td></tr>
<tr><td><code>is_empty</code></td><td><code>bool</code></td><td>True if empty result</td></tr>
<tr><td><code>is_error</code></td><td><code>bool</code></td><td>True if error result</td></tr>
<tr><td><code>value</code></td><td><code>str</code> or <code>None</code></td><td>Single value result</td></tr>
<tr><td><code>count</code></td><td><code>int</code> or <code>None</code></td><td>Row count</td></tr>
<tr><td><code>rows</code></td><td><code>list[Row]</code></td><td>Relational rows</td></tr>
<tr><td><code>nodes</code></td><td><code>list[Node]</code></td><td>Graph nodes</td></tr>
<tr><td><code>edges</code></td><td><code>list[Edge]</code></td><td>Graph edges</td></tr>
<tr><td><code>paths</code></td><td><code>list[Path]</code></td><td>Graph paths</td></tr>
<tr><td><code>similar_items</code></td><td><code>list[SimilarItem]</code></td><td>Similarity results</td></tr>
<tr><td><code>ids</code></td><td><code>list[str]</code></td><td>ID list</td></tr>
<tr><td><code>table_names</code></td><td><code>list[str]</code></td><td>Table names</td></tr>
<tr><td><code>blob_data</code></td><td><code>bytes</code> or <code>None</code></td><td>Binary data</td></tr>
<tr><td><code>blob_info</code></td><td><code>ArtifactInfo</code> or <code>None</code></td><td>Blob metadata</td></tr>
<tr><td><code>error_message</code></td><td><code>str</code> or <code>None</code></td><td>Error message</td></tr>
</tbody></table>
</div>
<h3 id="result-type-enum"><a class="header" href="#result-type-enum">Result Type Enum</a></h3>
<pre><code class="language-python">from neumann import QueryResultType

result = client.execute(query)

match result.type:
    case QueryResultType.EMPTY:
        print("OK")
    case QueryResultType.COUNT:
        print(f"{result.count} rows affected")
    case QueryResultType.ROWS:
        for row in result.rows:
            print(row.to_dict())
    case QueryResultType.NODES:
        for node in result.nodes:
            print(f"[{node.id}] {node.label}")
    case QueryResultType.SIMILAR:
        for item in result.similar_items:
            print(f"{item.key}: {item.score:.4f}")
    case QueryResultType.ERROR:
        raise Exception(result.error_message)
</code></pre>
<h2 id="data-types"><a class="header" href="#data-types">Data Types</a></h2>
<h3 id="value"><a class="header" href="#value">Value</a></h3>
<p>Immutable typed scalar value:</p>
<pre><code class="language-python">from neumann import Value, ScalarType

# Create values
v1 = Value.null()
v2 = Value.int_(42)
v3 = Value.float_(3.14)
v4 = Value.string("hello")
v5 = Value.bool_(True)
v6 = Value.bytes_(b"data")

# Access type and data
print(v2.type)  # ScalarType.INT
print(v2.data)  # 42

# Convert to Python native type
native = v2.as_python()  # 42
</code></pre>
<h3 id="row"><a class="header" href="#row">Row</a></h3>
<p>Relational row with typed accessors:</p>
<pre><code class="language-python">from neumann import Row

row = result.rows[0]

# Get raw Value
val = row.get("name")

# Get typed values
name: str | None = row.get_string("name")
age: int | None = row.get_int("age")
score: float | None = row.get_float("score")
active: bool | None = row.get_bool("active")

# Convert to dict
data = row.to_dict()  # {"name": "Alice", "age": 30}
</code></pre>
<h3 id="node"><a class="header" href="#node">Node</a></h3>
<p>Graph node with properties:</p>
<pre><code class="language-python">from neumann import Node

node = result.nodes[0]

print(node.id)      # "1"
print(node.label)   # "person"

# Get property
name = node.get_property("name")

# Convert to dict
data = node.to_dict()
# {"id": "1", "label": "person", "properties": {"name": "Alice"}}
</code></pre>
<h3 id="edge"><a class="header" href="#edge">Edge</a></h3>
<p>Graph edge with properties:</p>
<pre><code class="language-python">from neumann import Edge

edge = result.edges[0]

print(edge.id)         # "1"
print(edge.edge_type)  # "knows"
print(edge.source)     # "1"
print(edge.target)     # "2"

# Get property
since = edge.get_property("since")

# Convert to dict
data = edge.to_dict()
# {"id": "1", "type": "knows", "source": "1", "target": "2", "properties": {}}
</code></pre>
<h3 id="path"><a class="header" href="#path">Path</a></h3>
<p>Graph path as segments:</p>
<pre><code class="language-python">from neumann import Path

path = result.paths[0]

# Get all nodes in path
nodes = path.nodes  # [Node, Node, ...]

# Get all edges in path
edges = path.edges  # [Edge, Edge, ...]

# Path length
length = len(path)

# Iterate segments
for segment in path.segments:
    print(f"Node: {segment.node.id}")
    if segment.edge:
        print(f"  -&gt; via edge {segment.edge.id}")
</code></pre>
<h3 id="similaritem"><a class="header" href="#similaritem">SimilarItem</a></h3>
<p>Vector similarity result:</p>
<pre><code class="language-python">from neumann import SimilarItem

for item in result.similar_items:
    print(f"Key: {item.key}")
    print(f"Score: {item.score:.4f}")
    if item.metadata:
        print(f"Metadata: {item.metadata}")
</code></pre>
<h3 id="artifactinfo"><a class="header" href="#artifactinfo">ArtifactInfo</a></h3>
<p>Blob artifact metadata:</p>
<pre><code class="language-python">from neumann import ArtifactInfo

info = result.blob_info
print(f"ID: {info.artifact_id}")
print(f"Filename: {info.filename}")
print(f"Size: {info.size} bytes")
print(f"Checksum: {info.checksum}")
print(f"Content-Type: {info.content_type}")
print(f"Created: {info.created_at}")
print(f"Tags: {info.tags}")
</code></pre>
<h2 id="error-handling-7"><a class="header" href="#error-handling-7">Error Handling</a></h2>
<h3 id="error-codes-1"><a class="header" href="#error-codes-1">Error Codes</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Code</th><th>Name</th><th>Description</th></tr></thead><tbody>
<tr><td>0</td><td><code>UNKNOWN</code></td><td>Unknown error</td></tr>
<tr><td>1</td><td><code>INVALID_ARGUMENT</code></td><td>Bad request data</td></tr>
<tr><td>2</td><td><code>NOT_FOUND</code></td><td>Resource not found</td></tr>
<tr><td>3</td><td><code>PERMISSION_DENIED</code></td><td>Access denied</td></tr>
<tr><td>4</td><td><code>ALREADY_EXISTS</code></td><td>Resource exists</td></tr>
<tr><td>5</td><td><code>UNAUTHENTICATED</code></td><td>Auth failed</td></tr>
<tr><td>6</td><td><code>UNAVAILABLE</code></td><td>Server unavailable</td></tr>
<tr><td>7</td><td><code>INTERNAL</code></td><td>Internal error</td></tr>
<tr><td>8</td><td><code>PARSE_ERROR</code></td><td>Query parse error</td></tr>
<tr><td>9</td><td><code>QUERY_ERROR</code></td><td>Query execution error</td></tr>
</tbody></table>
</div>
<h3 id="error-classes-1"><a class="header" href="#error-classes-1">Error Classes</a></h3>
<pre><code class="language-python">from neumann import (
    NeumannError,
    ConnectionError,
    AuthenticationError,
    PermissionError,
    NotFoundError,
    InvalidArgumentError,
    ParseError,
    QueryError,
    InternalError,
    ErrorCode,
)

try:
    result = client.execute("SELECT nonexistent")
except ConnectionError as e:
    print(f"Connection failed: {e.message}")
except AuthenticationError:
    print("Check your API key")
except ParseError as e:
    print(f"Query syntax error: {e.message}")
except NeumannError as e:
    print(f"[{e.code.name}] {e.message}")
</code></pre>
<h3 id="error-factory-1"><a class="header" href="#error-factory-1">Error Factory</a></h3>
<pre><code class="language-python">from neumann.errors import error_from_code, ErrorCode

# Create error from code
error = error_from_code(ErrorCode.NOT_FOUND, "Table 'users' not found")
# Returns NotFoundError instance
</code></pre>
<h2 id="pandas-integration"><a class="header" href="#pandas-integration">Pandas Integration</a></h2>
<p>Convert query results to pandas DataFrames:</p>
<pre><code class="language-python">from neumann.integrations.pandas import (
    result_to_dataframe,
    rows_to_dataframe,
    dataframe_to_inserts,
)

# Result to DataFrame
result = client.execute("SELECT users")
df = result_to_dataframe(result)

# Rows to DataFrame
df = rows_to_dataframe(result.rows)

# DataFrame to INSERT statements
inserts = dataframe_to_inserts(
    df,
    table="users",
    column_mapping={"user_name": "name"},  # Optional column rename
)

# Execute inserts
for query in inserts:
    client.execute(query)
</code></pre>
<h2 id="numpy-integration"><a class="header" href="#numpy-integration">NumPy Integration</a></h2>
<p>Work with vectors using numpy arrays:</p>
<pre><code class="language-python">from neumann.integrations.numpy import (
    vector_to_insert,
    vectors_to_inserts,
    parse_embedding,
    cosine_similarity,
    euclidean_distance,
    normalize_vectors,
)
import numpy as np

# Single vector to INSERT
query = vector_to_insert("doc1", np.array([0.1, 0.2, 0.3]))
client.execute(query)

# Multiple vectors
vectors = {
    "doc1": np.array([0.1, 0.2, 0.3]),
    "doc2": np.array([0.4, 0.5, 0.6]),
}
queries = vectors_to_inserts(vectors, normalize=True)
for q in queries:
    client.execute(q)

# Parse embedding from result
embedding = parse_embedding("[0.1, 0.2, 0.3]")

# Distance calculations
sim = cosine_similarity(vec1, vec2)
dist = euclidean_distance(vec1, vec2)

# Batch normalization
normalized = normalize_vectors(np.array([vec1, vec2, vec3]))
</code></pre>
<h2 id="usage-examples-12"><a class="header" href="#usage-examples-12">Usage Examples</a></h2>
<h3 id="complete-crud-example-1"><a class="header" href="#complete-crud-example-1">Complete CRUD Example</a></h3>
<pre><code class="language-python">from neumann import NeumannClient

with NeumannClient.connect("localhost:9200") as client:
    # Create table
    client.execute("CREATE TABLE products (name:string, price:float)")

    # Insert data
    client.execute('INSERT products name="Widget", price=9.99')
    client.execute('INSERT products name="Gadget", price=19.99')

    # Query data
    result = client.execute("SELECT products WHERE price &gt; 10")
    for row in result.rows:
        print(row.to_dict())

    # Update
    client.execute('UPDATE products SET price=24.99 WHERE name="Gadget"')

    # Delete
    client.execute("DELETE products WHERE price &lt; 15")

    # Drop table
    client.execute("DROP TABLE products")
</code></pre>
<h3 id="graph-operations-3"><a class="header" href="#graph-operations-3">Graph Operations</a></h3>
<pre><code class="language-python">from neumann import NeumannClient

with NeumannClient.connect("localhost:9200") as client:
    # Create nodes
    client.execute('NODE CREATE person {name: "Alice", age: 30}')
    client.execute('NODE CREATE person {name: "Bob", age: 25}')

    # Create edge
    client.execute("EDGE CREATE 1 -&gt; 2 : knows {since: 2020}")

    # List nodes
    result = client.execute("NODE LIST person")
    for node in result.nodes:
        print(f"[{node.id}] {node.label}: {node.to_dict()['properties']}")

    # Find neighbors
    result = client.execute("NEIGHBORS 1 OUTGOING")

    # Find path
    result = client.execute("PATH 1 -&gt; 2")
    if result.paths:
        path = result.paths[0]
        print(" -&gt; ".join(n.id for n in path.nodes))
</code></pre>
<h3 id="vector-search-with-numpy"><a class="header" href="#vector-search-with-numpy">Vector Search with NumPy</a></h3>
<pre><code class="language-python">from neumann import NeumannClient
from neumann.integrations.numpy import vector_to_insert, normalize_vectors
import numpy as np

with NeumannClient.connect("localhost:9200") as client:
    # Generate and store embeddings
    embeddings = np.random.randn(100, 768).astype(np.float32)
    embeddings = normalize_vectors(embeddings)

    for i, emb in enumerate(embeddings):
        query = vector_to_insert(f"doc{i}", emb)
        client.execute(query)

    # Query vector
    query_vec = np.random.randn(768).astype(np.float32)
    query_str = vector_to_insert("query", query_vec)
    client.execute(query_str)

    # Find similar
    result = client.execute('SIMILAR "query" COSINE LIMIT 10')
    for item in result.similar_items:
        print(f"{item.key}: {item.score:.4f}")
</code></pre>
<h3 id="async-web-application"><a class="header" href="#async-web-application">Async Web Application</a></h3>
<pre><code class="language-python">from fastapi import FastAPI
from neumann.aio import AsyncNeumannClient

app = FastAPI()
client: AsyncNeumannClient | None = None

@app.on_event("startup")
async def startup():
    global client
    client = await AsyncNeumannClient.connect(
        "localhost:9200",
        api_key="your-api-key",
    )

@app.on_event("shutdown")
async def shutdown():
    if client:
        await client.close()

@app.get("/users")
async def get_users():
    result = await client.execute("SELECT users")
    return [row.to_dict() for row in result.rows]

@app.get("/users/{user_id}")
async def get_user(user_id: int):
    result = await client.execute(f"SELECT users WHERE id = {user_id}")
    if result.rows:
        return result.rows[0].to_dict()
    return {"error": "Not found"}
</code></pre>
<h2 id="dependencies-12"><a class="header" href="#dependencies-12">Dependencies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Package</th><th>Purpose</th><th>Extra</th></tr></thead><tbody>
<tr><td><code>grpcio</code></td><td>gRPC client</td><td>Default</td></tr>
<tr><td><code>protobuf</code></td><td>Protocol buffers</td><td>Default</td></tr>
<tr><td><code>neumann-native</code></td><td>PyO3 bindings</td><td><code>[native]</code></td></tr>
<tr><td><code>pandas</code></td><td>DataFrame support</td><td><code>[pandas]</code></td></tr>
<tr><td><code>numpy</code></td><td>Array support</td><td><code>[numpy]</code></td></tr>
</tbody></table>
</div>
<h2 id="related-modules-17"><a class="header" href="#related-modules-17">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><code>neumann_server</code></td><td>Server that this SDK connects to</td></tr>
<tr><td><code>neumann_client</code></td><td>Rust SDK with same capabilities</td></tr>
<tr><td><code>@neumann/client</code></td><td>TypeScript SDK with same API design</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="tcp-transport"><a class="header" href="#tcp-transport">TCP Transport</a></h1>
<p>The TCP transport layer provides reliable, secure node-to-node communication
for the tensor_chain distributed system. It implements connection pooling,
TLS security, rate limiting, compression, and automatic reconnection.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>The <code>TcpTransport</code> implements the <code>Transport</code> trait, providing:</p>
<ul>
<li><strong>Connection pooling</strong> for efficient peer communication</li>
<li><strong>TLS encryption</strong> with mutual authentication support</li>
<li><strong>Rate limiting</strong> using token bucket algorithm</li>
<li><strong>LZ4 compression</strong> for bandwidth efficiency</li>
<li><strong>Automatic reconnection</strong> with exponential backoff</li>
</ul>
<pre class="mermaid">flowchart TD
    A[Application] --&gt; B[TcpTransport]
    B --&gt; C[ConnectionManager]
    C --&gt; D1[ConnectionPool Node A]
    C --&gt; D2[ConnectionPool Node B]
    C --&gt; D3[ConnectionPool Node C]
    D1 --&gt; E1[TLS Stream]
    D2 --&gt; E2[TLS Stream]
    D3 --&gt; E3[TLS Stream]
</pre>
<h2 id="connection-architecture"><a class="header" href="#connection-architecture">Connection Architecture</a></h2>
<h3 id="connection-manager"><a class="header" href="#connection-manager">Connection Manager</a></h3>
<p>The <code>ConnectionManager</code> maintains connection pools for each peer. Each pool
can hold multiple connections for load distribution.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = TcpTransportConfig::new("node1", "0.0.0.0:9100".parse()?);
let transport = TcpTransport::new(config);
transport.start().await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="connection-lifecycle"><a class="header" href="#connection-lifecycle">Connection Lifecycle</a></h3>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Connecting
    Connecting --&gt; Handshaking: TCP Connected
    Handshaking --&gt; Active: Handshake Success
    Handshaking --&gt; Failed: Handshake Failed
    Active --&gt; Reading: Message Available
    Active --&gt; Writing: Send Request
    Reading --&gt; Active: Message Processed
    Writing --&gt; Active: Message Sent
    Active --&gt; Reconnecting: Connection Lost
    Reconnecting --&gt; Connecting: Backoff Complete
    Reconnecting --&gt; Failed: Max Retries
    Failed --&gt; [*]
</pre>
<h3 id="configuration-8"><a class="header" href="#configuration-8">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>pool_size</code></td><td>2</td><td>Connections per peer</td></tr>
<tr><td><code>connect_timeout_ms</code></td><td>5000</td><td>Connection timeout in milliseconds</td></tr>
<tr><td><code>io_timeout_ms</code></td><td>30000</td><td>Read/write timeout in milliseconds</td></tr>
<tr><td><code>max_message_size</code></td><td>16 MB</td><td>Maximum message size in bytes</td></tr>
<tr><td><code>keepalive</code></td><td>true</td><td>Enable TCP keepalive</td></tr>
<tr><td><code>keepalive_interval_secs</code></td><td>30</td><td>Keepalive probe interval</td></tr>
<tr><td><code>max_pending_messages</code></td><td>1000</td><td>Outbound queue size per peer</td></tr>
<tr><td><code>recv_buffer_size</code></td><td>1000</td><td>Incoming message channel size</td></tr>
</tbody></table>
</div>
<h2 id="tls-security"><a class="header" href="#tls-security">TLS Security</a></h2>
<p>The transport supports four security modes to accommodate different deployment
scenarios.</p>
<h3 id="security-modes"><a class="header" href="#security-modes">Security Modes</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Mode</th><th>TLS</th><th>mTLS</th><th>NodeId Verify</th><th>Use Case</th></tr></thead><tbody>
<tr><td>Strict</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Production deployments</td></tr>
<tr><td>Permissive</td><td>Yes</td><td>No</td><td>No</td><td>Gradual TLS rollout</td></tr>
<tr><td>Development</td><td>No</td><td>No</td><td>No</td><td>Local testing only</td></tr>
<tr><td>Legacy</td><td>No</td><td>No</td><td>No</td><td>Migration from older versions</td></tr>
</tbody></table>
</div>
<h3 id="nodeid-verification"><a class="header" href="#nodeid-verification">NodeId Verification</a></h3>
<p>NodeId verification ensures the peer’s identity matches their TLS certificate:</p>
<div class="table-wrapper"><table><thead><tr><th>Mode</th><th>Description</th></tr></thead><tbody>
<tr><td>None</td><td>Trust NodeId from handshake (testing only)</td></tr>
<tr><td>CommonName</td><td>NodeId must match certificate CN</td></tr>
<tr><td>SubjectAltName</td><td>NodeId must match a SAN DNS entry</td></tr>
</tbody></table>
</div>
<h3 id="tls-configuration-1"><a class="header" href="#tls-configuration-1">TLS Configuration</a></h3>
<pre><code class="language-toml">[tls]
cert_path = "/etc/neumann/node.crt"
key_path = "/etc/neumann/node.key"
ca_cert_path = "/etc/neumann/ca.crt"
require_client_auth = true
node_id_verification = "CommonName"
</code></pre>
<h3 id="mtls-handshake"><a class="header" href="#mtls-handshake">mTLS Handshake</a></h3>
<pre class="mermaid">sequenceDiagram
    participant C as Client Node
    participant S as Server Node

    C-&gt;&gt;S: TCP Connect
    C-&gt;&gt;S: TLS ClientHello
    S-&gt;&gt;C: TLS ServerHello + Certificate
    S-&gt;&gt;C: CertificateRequest
    C-&gt;&gt;S: Client Certificate
    C-&gt;&gt;S: CertificateVerify
    C-&gt;&gt;S: Finished
    S-&gt;&gt;C: Finished
    Note over C,S: TLS Established
    C-&gt;&gt;S: Handshake(node_id, capabilities)
    S-&gt;&gt;C: Handshake(node_id, capabilities)
    Note over C,S: Connection Ready
</pre>
<h2 id="rate-limiting-1"><a class="header" href="#rate-limiting-1">Rate Limiting</a></h2>
<p>Per-peer rate limiting uses the token bucket algorithm to prevent any single
peer from overwhelming the system.</p>
<h3 id="token-bucket-algorithm"><a class="header" href="#token-bucket-algorithm">Token Bucket Algorithm</a></h3>
<pre class="mermaid">flowchart LR
    A[Refill Timer] --&gt;|tokens/sec| B[Token Bucket]
    B --&gt;|check| C{Tokens &gt; 0?}
    C --&gt;|Yes| D[Allow Message]
    C --&gt;|No| E[Reject Message]
    D --&gt; F[Consume Token]
</pre>
<h3 id="configuration-presets-4"><a class="header" href="#configuration-presets-4">Configuration Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>Bucket Size</th><th>Refill Rate</th><th>Description</th></tr></thead><tbody>
<tr><td>Default</td><td>100</td><td>50/sec</td><td>Balanced throughput</td></tr>
<tr><td>Aggressive</td><td>50</td><td>25/sec</td><td>Lower burst, tighter limit</td></tr>
<tr><td>Permissive</td><td>200</td><td>100/sec</td><td>Higher throughput allowed</td></tr>
<tr><td>Disabled</td><td>—</td><td>—</td><td>No rate limiting</td></tr>
</tbody></table>
</div>
<h3 id="configuration-example"><a class="header" href="#configuration-example">Configuration Example</a></h3>
<pre><code class="language-toml">[rate_limit]
enabled = true
bucket_size = 100
refill_rate = 50.0
</code></pre>
<h2 id="compression"><a class="header" href="#compression">Compression</a></h2>
<p>Frame-level LZ4 compression reduces bandwidth usage for larger messages.
Compression is negotiated during the handshake.</p>
<h3 id="frame-format"><a class="header" href="#frame-format">Frame Format</a></h3>
<pre><code class="language-text">+--------+--------+------------+
| Length | Flags  | Payload    |
| 4 bytes| 1 byte | N bytes    |
+--------+--------+------------+

Flags byte:
  bit 0: 1 = LZ4 compressed, 0 = uncompressed
  bits 1-7: reserved (must be 0)
</code></pre>
<h3 id="configuration-9"><a class="header" href="#configuration-9">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable compression</td></tr>
<tr><td><code>method</code></td><td>Lz4</td><td>Compression algorithm</td></tr>
<tr><td><code>min_size</code></td><td>256</td><td>Minimum payload size to compress</td></tr>
</tbody></table>
</div>
<p>Messages smaller than <code>min_size</code> are sent uncompressed to avoid overhead.</p>
<pre><code class="language-toml">[compression]
enabled = true
method = "Lz4"
min_size = 256
</code></pre>
<h2 id="reconnection"><a class="header" href="#reconnection">Reconnection</a></h2>
<p>Automatic reconnection uses exponential backoff with jitter to recover from
transient failures without overwhelming the network.</p>
<h3 id="backoff-calculation"><a class="header" href="#backoff-calculation">Backoff Calculation</a></h3>
<pre><code class="language-text">backoff = min(initial * multiplier^attempt, max_backoff)
jitter = backoff * random(-jitter_factor, +jitter_factor)
final_delay = backoff + jitter
</code></pre>
<h3 id="configuration-10"><a class="header" href="#configuration-10">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable auto-reconnection</td></tr>
<tr><td><code>initial_backoff_ms</code></td><td>100</td><td>Initial backoff delay</td></tr>
<tr><td><code>max_backoff_ms</code></td><td>30000</td><td>Maximum backoff delay</td></tr>
<tr><td><code>multiplier</code></td><td>2.0</td><td>Exponential multiplier</td></tr>
<tr><td><code>max_attempts</code></td><td>None</td><td>Max retries (None = infinite)</td></tr>
<tr><td><code>jitter</code></td><td>0.1</td><td>Jitter factor (0.0 to 1.0)</td></tr>
</tbody></table>
</div>
<h3 id="backoff-example"><a class="header" href="#backoff-example">Backoff Example</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Attempt</th><th>Base Delay</th><th>With 10% Jitter</th></tr></thead><tbody>
<tr><td>0</td><td>100ms</td><td>90-110ms</td></tr>
<tr><td>1</td><td>200ms</td><td>180-220ms</td></tr>
<tr><td>2</td><td>400ms</td><td>360-440ms</td></tr>
<tr><td>3</td><td>800ms</td><td>720-880ms</td></tr>
<tr><td>…</td><td>…</td><td>…</td></tr>
<tr><td>8+</td><td>30000ms</td><td>27000-33000ms</td></tr>
</tbody></table>
</div>
<h2 id="metrics"><a class="header" href="#metrics">Metrics</a></h2>
<p>The transport exposes statistics through <code>TransportStats</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Description</th></tr></thead><tbody>
<tr><td><code>messages_sent</code></td><td>Total messages sent</td></tr>
<tr><td><code>messages_received</code></td><td>Total messages received</td></tr>
<tr><td><code>bytes_sent</code></td><td>Total bytes sent</td></tr>
<tr><td><code>bytes_received</code></td><td>Total bytes received</td></tr>
<tr><td><code>peer_count</code></td><td>Number of connected peers</td></tr>
<tr><td><code>connection_count</code></td><td>Total active connections</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let stats = transport.stats();
println!("Messages sent: {}", stats.messages_sent);
println!("Connected peers: {}", stats.peer_count);
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-8"><a class="header" href="#error-handling-8">Error Handling</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th><th>Recovery</th></tr></thead><tbody>
<tr><td><code>Timeout</code></td><td>Operation exceeded timeout</td><td>Retry with backoff</td></tr>
<tr><td><code>PeerNotFound</code></td><td>No pool for peer</td><td>Establish connection first</td></tr>
<tr><td><code>HandshakeFailed</code></td><td>Protocol mismatch or bad cert</td><td>Check configuration</td></tr>
<tr><td><code>TlsRequired</code></td><td>TLS needed but not configured</td><td>Configure TLS</td></tr>
<tr><td><code>MtlsRequired</code></td><td>mTLS needed but not enabled</td><td>Enable client auth</td></tr>
<tr><td><code>RateLimited</code></td><td>Token bucket exhausted</td><td>Wait for refill</td></tr>
<tr><td><code>Compression</code></td><td>Decompression failed</td><td>Check for data corruption</td></tr>
</tbody></table>
</div>
<h2 id="usage-example"><a class="header" href="#usage-example">Usage Example</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::tcp::{
    TcpTransport, TcpTransportConfig, TlsConfig, SecurityMode,
    RateLimitConfig, CompressionConfig,
};

// Create secure production configuration
let tls = TlsConfig::new_secure(
    "/etc/neumann/node.crt",
    "/etc/neumann/node.key",
    "/etc/neumann/ca.crt",
);

let config = TcpTransportConfig::new("node1", "0.0.0.0:9100".parse()?)
    .with_tls(tls)
    .with_security_mode(SecurityMode::Strict)
    .with_rate_limit(RateLimitConfig::default())
    .with_compression(CompressionConfig::default())
    .with_pool_size(4);

// Validate security before starting
config.validate_security()?;

// Start transport
let transport = TcpTransport::new(config);
transport.start().await?;

// Connect to peer
transport.connect(&amp;PeerConfig {
    node_id: "node2".to_string(),
    address: "10.0.1.2:9100".to_string(),
}).await?;

// Send message
transport.send(&amp;"node2".to_string(), Message::Ping { term: 1 }).await?;

// Receive messages
let (from, msg) = transport.recv().await?;
<span class="boring">}</span></code></pre></pre>
<h2 id="source-reference"><a class="header" href="#source-reference">Source Reference</a></h2>
<ul>
<li><code>tensor_chain/src/tcp/config.rs</code> - Configuration types</li>
<li><code>tensor_chain/src/tcp/transport.rs</code> - Transport implementation</li>
<li><code>tensor_chain/src/tcp/tls.rs</code> - TLS wrapper</li>
<li><code>tensor_chain/src/tcp/rate_limit.rs</code> - Token bucket rate limiter</li>
<li><code>tensor_chain/src/tcp/compression.rs</code> - LZ4 compression</li>
<li><code>tensor_chain/src/tcp/framing.rs</code> - Wire protocol codec</li>
<li><code>tensor_chain/src/tcp/connection.rs</code> - Connection pool</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="snapshot-streaming"><a class="header" href="#snapshot-streaming">Snapshot Streaming</a></h1>
<p>The snapshot streaming system provides memory-efficient serialization and
transfer of Raft log snapshots. It enables handling of large snapshots
containing millions of log entries without exhausting heap memory.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>Key features:</p>
<ul>
<li><strong>Incremental writing</strong>: Entries serialized one at a time via <code>SnapshotWriter</code></li>
<li><strong>Lazy reading</strong>: Entries deserialized on-demand via <code>SnapshotReader</code> iterator</li>
<li><strong>Memory bounded</strong>: Automatic disk spill via <code>SnapshotBuffer</code></li>
<li><strong>Backwards compatible</strong>: Falls back to legacy format for old snapshots</li>
</ul>
<pre class="mermaid">flowchart TD
    A[Raft State Machine] --&gt;|write_entry| B[SnapshotWriter]
    B --&gt;|finish| C[SnapshotBuffer]
    C --&gt;|memory/file| D{Size Check}
    D --&gt;|&lt; threshold| E[Memory Mode]
    D --&gt;|&gt; threshold| F[File Mode + mmap]
    E --&gt; G[Chunk Transfer]
    F --&gt; G
    G --&gt;|network| H[SnapshotReader]
    H --&gt;|iterator| I[Follower Node]
</pre>
<h2 id="wire-format"><a class="header" href="#wire-format">Wire Format</a></h2>
<p>The streaming format uses length-prefixed entries for efficient parsing.</p>
<h3 id="header-structure"><a class="header" href="#header-structure">Header Structure</a></h3>
<pre><code class="language-text">+--------+--------+------------------+
| Magic | Version | Entry Count |
| 4 bytes | 4 bytes | 8 bytes |
+--------+--------+------------------+
| "SNAP" | 1 | u64 LE |
+--------+--------+------------------+
Total: 16 bytes
</code></pre>
<h3 id="entry-structure"><a class="header" href="#entry-structure">Entry Structure</a></h3>
<pre><code class="language-text">+--------+------------------------+
| Length | Bincode-serialized |
| 4 bytes | LogEntry |
+--------+------------------------+
| u32 LE | variable |
+--------+------------------------+
</code></pre>
<h3 id="complete-snapshot-layout"><a class="header" href="#complete-snapshot-layout">Complete Snapshot Layout</a></h3>
<pre><code class="language-text">+--------+--------+--------+--------+--------+--------+
| SNAP   | Ver(1) | Count  | Len1   | Entry1 | Len2   | ...
| 4B     | 4B     | 8B     | 4B     | N bytes| 4B     | ...
+--------+--------+--------+--------+--------+--------+
</code></pre>
<h2 id="architecture-11"><a class="header" href="#architecture-11">Architecture</a></h2>
<h3 id="leader-to-follower-flow"><a class="header" href="#leader-to-follower-flow">Leader-to-Follower Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant L as Leader
    participant W as SnapshotWriter
    participant B as SnapshotBuffer
    participant N as Network
    participant R as SnapshotReader
    participant F as Follower

    L-&gt;&gt;W: write_entry(entry)
    W-&gt;&gt;B: serialize + write
    Note over B: Memory or File mode
    L-&gt;&gt;W: finish()
    W-&gt;&gt;B: finalize()
    B-&gt;&gt;N: chunk transfer
    N-&gt;&gt;R: received chunks
    R-&gt;&gt;F: iterator.next()
    F-&gt;&gt;F: apply(entry)
</pre>
<h3 id="snapshotbuffer-state-transitions"><a class="header" href="#snapshotbuffer-state-transitions">SnapshotBuffer State Transitions</a></h3>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Memory: new()
    Memory --&gt; Memory: write() [size &lt; threshold]
    Memory --&gt; File: write() [size &gt;= threshold]
    File --&gt; File: write() [grow if needed]
    Memory --&gt; Finalized: finalize()
    File --&gt; Finalized: finalize() + fsync
    Finalized --&gt; [*]: drop (cleanup)
</pre>
<h2 id="snapshotbuffer"><a class="header" href="#snapshotbuffer">SnapshotBuffer</a></h2>
<p>The <code>SnapshotBuffer</code> provides adaptive memory/disk storage with bounded
memory usage.</p>
<h3 id="configuration-11"><a class="header" href="#configuration-11">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>max_memory_bytes</code></td><td>256 MB</td><td>Threshold before disk spill</td></tr>
<tr><td><code>temp_dir</code></td><td>System</td><td>Directory for temp files</td></tr>
<tr><td><code>initial_file_capacity</code></td><td>64 MB</td><td>Initial file size when spilling</td></tr>
</tbody></table>
</div>
<h3 id="configuration-example-1"><a class="header" href="#configuration-example-1">Configuration Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::snapshot_buffer::SnapshotBufferConfig;

let config = SnapshotBufferConfig::default()
    .with_max_memory(512 * 1024 * 1024)  // 512 MB
    .with_temp_dir("/var/lib/neumann/snapshots");
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-characteristics-8"><a class="header" href="#performance-characteristics-8">Performance Characteristics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Memory Mode</th><th>File Mode</th></tr></thead><tbody>
<tr><td><code>write()</code></td><td>O(1) amortized</td><td>O(1) + possible mmap resize</td></tr>
<tr><td><code>as_slice()</code></td><td>O(1)</td><td>O(1) zero-copy via mmap</td></tr>
<tr><td><code>read_chunk()</code></td><td>O(n) copy</td><td>O(n) copy</td></tr>
<tr><td><code>finalize()</code></td><td>O(1)</td><td>O(1) + fsync</td></tr>
</tbody></table>
</div>
<h2 id="snapshotwriter"><a class="header" href="#snapshotwriter">SnapshotWriter</a></h2>
<p>The <code>SnapshotWriter</code> serializes log entries incrementally using the length-
prefixed format.</p>
<h3 id="usage-3"><a class="header" href="#usage-3">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::snapshot_streaming::SnapshotWriter;
use tensor_chain::snapshot_buffer::SnapshotBufferConfig;

let config = SnapshotBufferConfig::default();
let mut writer = SnapshotWriter::new(config)?;

// Write entries incrementally
for entry in log_entries {
    writer.write_entry(&amp;entry)?;
}

// Check progress
println!("Entries: {}", writer.entry_count());
println!("Bytes: {}", writer.bytes_written());
println!("Last index: {}", writer.last_index());

// Finalize and get buffer
let buffer = writer.finish()?;
<span class="boring">}</span></code></pre></pre>
<h3 id="progress-tracking"><a class="header" href="#progress-tracking">Progress Tracking</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>entry_count()</code></td><td>Number of entries written</td></tr>
<tr><td><code>bytes_written()</code></td><td>Total bytes including header</td></tr>
<tr><td><code>last_index()</code></td><td>Index of last entry written</td></tr>
<tr><td><code>last_term()</code></td><td>Term of last entry written</td></tr>
</tbody></table>
</div>
<h2 id="snapshotreader"><a class="header" href="#snapshotreader">SnapshotReader</a></h2>
<p>The <code>SnapshotReader</code> deserializes entries on-demand using an iterator
interface.</p>
<h3 id="usage-4"><a class="header" href="#usage-4">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::snapshot_streaming::SnapshotReader;

// Create reader (validates header)
let reader = SnapshotReader::new(&amp;buffer)?;

println!("Entry count: {}", reader.entry_count());

// Read via iterator
for result in reader {
    let entry = result?;
    state_machine.apply(entry);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="iterator-protocol"><a class="header" href="#iterator-protocol">Iterator Protocol</a></h3>
<pre class="mermaid">sequenceDiagram
    participant A as Application
    participant R as SnapshotReader
    participant B as Buffer

    loop For each entry
        A-&gt;&gt;R: next()
        R-&gt;&gt;B: read 4 bytes (length)
        R-&gt;&gt;B: read N bytes (entry)
        R-&gt;&gt;A: Some(Ok(LogEntry))
    end
    A-&gt;&gt;R: next()
    R-&gt;&gt;A: None (end)
</pre>
<h3 id="progress-tracking-1"><a class="header" href="#progress-tracking-1">Progress Tracking</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>entry_count()</code></td><td>Total entries in snapshot</td></tr>
<tr><td><code>entries_read()</code></td><td>Entries read so far</td></tr>
<tr><td><code>remaining()</code></td><td>Entries not yet read</td></tr>
</tbody></table>
</div>
<h2 id="chunk-transfer"><a class="header" href="#chunk-transfer">Chunk Transfer</a></h2>
<p>For network transfer, the buffer supports chunked reading with resume
capability.</p>
<h3 id="resume-protocol"><a class="header" href="#resume-protocol">Resume Protocol</a></h3>
<pre class="mermaid">sequenceDiagram
    participant L as Leader
    participant F as Follower

    L-&gt;&gt;F: Chunk 0 (offset=0, len=64KB)
    F-&gt;&gt;F: Store chunk
    Note over F: Network interruption
    F-&gt;&gt;L: Resume (offset=64KB)
    L-&gt;&gt;F: Chunk 1 (offset=64KB, len=64KB)
    F-&gt;&gt;F: Append chunk
    L-&gt;&gt;F: Chunk 2 (offset=128KB, len=32KB)
    F-&gt;&gt;F: Complete snapshot
</pre>
<h3 id="bandwidth-configuration"><a class="header" href="#bandwidth-configuration">Bandwidth Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Chunk Size</th><th>Use Case</th></tr></thead><tbody>
<tr><td>16 KB</td><td>High-latency networks</td></tr>
<tr><td>64 KB</td><td>Default, balanced</td></tr>
<tr><td>256 KB</td><td>Low-latency, high-bandwidth</td></tr>
<tr><td>1 MB</td><td>Local/datacenter transfers</td></tr>
</tbody></table>
</div>
<h2 id="error-handling-9"><a class="header" href="#error-handling-9">Error Handling</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Error Type</th><th>Cause</th><th>Recovery</th></tr></thead><tbody>
<tr><td><code>Io</code></td><td>File/mmap operation failed</td><td>Check disk space/perms</td></tr>
<tr><td><code>Buffer</code></td><td>Out of bounds read</td><td>Verify offset/length</td></tr>
<tr><td><code>Serialization</code></td><td>Bincode encode/decode failed</td><td>Check data integrity</td></tr>
<tr><td><code>InvalidFormat</code></td><td>Wrong magic, version, or size</td><td>Verify snapshot source</td></tr>
<tr><td><code>UnexpectedEof</code></td><td>Truncated data or count error</td><td>Re-transfer snapshot</td></tr>
</tbody></table>
</div>
<h3 id="security-limits"><a class="header" href="#security-limits">Security Limits</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Limit</th><th>Value</th><th>Purpose</th></tr></thead><tbody>
<tr><td>Max entry size</td><td>100 MB</td><td>Prevent memory exhaustion</td></tr>
<tr><td>Max header version</td><td>1</td><td>Reject unknown formats</td></tr>
</tbody></table>
</div>
<h2 id="legacy-compatibility"><a class="header" href="#legacy-compatibility">Legacy Compatibility</a></h2>
<p>The system automatically handles legacy (non-streaming) snapshots.</p>
<h3 id="format-detection"><a class="header" href="#format-detection">Format Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::snapshot_streaming::deserialize_entries;

// Automatically detects format
let entries = deserialize_entries(snapshot_bytes)?;

// Works with:
// - Streaming format (magic = "SNAP")
// - Legacy bincode Vec&lt;LogEntry&gt;
<span class="boring">}</span></code></pre></pre>
<h2 id="usage-example-1"><a class="header" href="#usage-example-1">Usage Example</a></h2>
<h3 id="complete-leader-workflow"><a class="header" href="#complete-leader-workflow">Complete Leader Workflow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::snapshot_streaming::{SnapshotWriter, serialize_entries};
use tensor_chain::snapshot_buffer::SnapshotBufferConfig;

// Create optimized config for large snapshots
let config = SnapshotBufferConfig::default()
    .with_max_memory(256 * 1024 * 1024);

// Serialize incrementally
let mut writer = SnapshotWriter::new(config)?;
for entry in state_machine.log_entries() {
    writer.write_entry(&amp;entry)?;
}
let buffer = writer.finish()?;

// Serve chunks to followers
let total_len = buffer.total_len();
let chunk_size = 64 * 1024;
let mut offset = 0;

while offset &lt; total_len {
    let len = (total_len - offset).min(chunk_size as u64) as usize;
    let chunk = buffer.as_slice(offset, len)?;
    send_chunk_to_follower(offset, chunk)?;
    offset += len as u64;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="complete-follower-workflow"><a class="header" href="#complete-follower-workflow">Complete Follower Workflow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::snapshot_streaming::SnapshotReader;
use tensor_chain::snapshot_buffer::SnapshotBuffer;

// Receive and assemble chunks
let mut buffer = SnapshotBuffer::with_defaults()?;
while let Some(chunk) = receive_chunk() {
    buffer.write(&amp;chunk)?;
}
buffer.finalize()?;

// Verify integrity
let expected_hash = received_hash;
let actual_hash = buffer.hash();
assert_eq!(expected_hash, actual_hash);

// Apply entries
let reader = SnapshotReader::new(&amp;buffer)?;
for result in reader {
    let entry = result?;
    state_machine.apply(entry)?;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="source-reference-1"><a class="header" href="#source-reference-1">Source Reference</a></h2>
<ul>
<li><code>tensor_chain/src/snapshot_streaming.rs</code> - Streaming protocol</li>
<li><code>tensor_chain/src/snapshot_buffer.rs</code> - Adaptive buffer implementation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transaction-workspace"><a class="header" href="#transaction-workspace">Transaction Workspace</a></h1>
<p>The transaction workspace system provides ACID transaction semantics for
tensor_chain operations. It enables isolated execution with snapshot-based
reads and atomic commits via delta tracking.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>Key features:</p>
<ul>
<li><strong>Snapshot isolation</strong>: Reads see consistent state from transaction start</li>
<li><strong>Delta tracking</strong>: Changes tracked as semantic embeddings for conflict
detection</li>
<li><strong>Atomic commit</strong>: All-or-nothing via block append</li>
<li><strong>Cross-shard coordination</strong>: Two-phase commit (2PC) for distributed
transactions</li>
</ul>
<pre class="mermaid">flowchart TD
    A[Client] --&gt;|begin| B[TransactionWorkspace]
    B --&gt;|snapshot| C[Checkpoint]
    B --&gt;|add_operation| D[Operations]
    B --&gt;|compute_delta| E[EmbeddingState]
    E --&gt; F{Conflict Check}
    F --&gt;|orthogonal| G[Commit]
    F --&gt;|conflicting| H[Rollback]
    H --&gt;|restore| C
</pre>
<h2 id="workspace-lifecycle"><a class="header" href="#workspace-lifecycle">Workspace Lifecycle</a></h2>
<h3 id="state-machine-2"><a class="header" href="#state-machine-2">State Machine</a></h3>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Active: begin()
    Active --&gt; Active: add_operation()
    Active --&gt; Committing: mark_committing()
    Committing --&gt; Committed: mark_committed()
    Committing --&gt; Failed: error
    Active --&gt; RolledBack: rollback()
    Failed --&gt; [*]
    Committed --&gt; [*]
    RolledBack --&gt; [*]
</pre>
<h3 id="state-descriptions"><a class="header" href="#state-descriptions">State Descriptions</a></h3>
<div class="table-wrapper"><table><thead><tr><th>State</th><th>Description</th></tr></thead><tbody>
<tr><td>Active</td><td>Operations can be added</td></tr>
<tr><td>Committing</td><td>Commit in progress, no more operations</td></tr>
<tr><td>Committed</td><td>Successfully committed to the chain</td></tr>
<tr><td>RolledBack</td><td>Rolled back, state restored from checkpoint</td></tr>
<tr><td>Failed</td><td>Error during commit, requires manual resolution</td></tr>
</tbody></table>
</div>
<h2 id="transaction-operations"><a class="header" href="#transaction-operations">Transaction Operations</a></h2>
<h3 id="basic-usage-3"><a class="header" href="#basic-usage-3">Basic Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::{TensorStore, TransactionWorkspace};
use tensor_chain::block::Transaction;

let store = TensorStore::new();

// Begin transaction
let workspace = TransactionWorkspace::begin(&amp;store)?;

// Add operations
workspace.add_operation(Transaction::Put {
    key: "user:1".to_string(),
    data: vec![1, 2, 3],
})?;

workspace.add_operation(Transaction::Put {
    key: "user:2".to_string(),
    data: vec![4, 5, 6],
})?;

// Check affected keys
let keys = workspace.affected_keys();
assert!(keys.contains("user:1"));

// Commit or rollback
workspace.mark_committing()?;
workspace.mark_committed();
<span class="boring">}</span></code></pre></pre>
<h3 id="operation-types"><a class="header" href="#operation-types">Operation Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Description</th><th>Affected Key</th></tr></thead><tbody>
<tr><td><code>Put</code></td><td>Insert or update key</td><td>The key itself</td></tr>
<tr><td><code>Delete</code></td><td>Remove key</td><td>The key itself</td></tr>
<tr><td><code>Update</code></td><td>Modify existing key</td><td>The key itself</td></tr>
</tbody></table>
</div>
<h2 id="delta-tracking"><a class="header" href="#delta-tracking">Delta Tracking</a></h2>
<p>The workspace tracks changes as semantic embeddings using the <code>EmbeddingState</code>
machine. This enables conflict detection based on vector similarity.</p>
<h3 id="beforeafter-embedding-flow"><a class="header" href="#beforeafter-embedding-flow">Before/After Embedding Flow</a></h3>
<pre class="mermaid">flowchart LR
    A[begin] --&gt;|capture| B[before embedding]
    B --&gt; C[operations]
    C --&gt;|compute| D[after embedding]
    D --&gt; E[delta = after - before]
    E --&gt; F[DeltaVector]
</pre>
<h3 id="computing-deltas"><a class="header" href="#computing-deltas">Computing Deltas</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Set the before-state embedding at transaction start
workspace.set_before_embedding(before_embedding);

// ... execute operations ...

// Compute delta at commit time
workspace.compute_delta(after_embedding);

// Get delta for conflict detection
let delta_vector = workspace.to_delta_vector();
<span class="boring">}</span></code></pre></pre>
<h3 id="delta-vector-structure"><a class="header" href="#delta-vector-structure">Delta Vector Structure</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>embedding</code></td><td><code>Vec&lt;f32&gt;</code></td><td>Semantic change vector</td></tr>
<tr><td><code>affected_keys</code></td><td><code>HashSet&lt;String&gt;</code></td><td>Keys modified by transaction</td></tr>
<tr><td><code>tx_id</code></td><td><code>u64</code></td><td>Transaction identifier</td></tr>
</tbody></table>
</div>
<h2 id="isolation-levels"><a class="header" href="#isolation-levels">Isolation Levels</a></h2>
<p>The workspace provides snapshot isolation by default. All reads within a
transaction see the state captured at <code>begin()</code>.</p>
<div class="table-wrapper"><table><thead><tr><th>Level</th><th>Dirty Reads</th><th>Non-Repeatable</th><th>Phantom Reads</th></tr></thead><tbody>
<tr><td>Snapshot (default)</td><td>No</td><td>No</td><td>No</td></tr>
</tbody></table>
</div>
<h3 id="snapshot-mechanism"><a class="header" href="#snapshot-mechanism">Snapshot Mechanism</a></h3>
<ol>
<li><code>begin()</code> captures the store state as a binary checkpoint</li>
<li>All reads within the transaction see this snapshot</li>
<li><code>rollback()</code> restores the snapshot if needed</li>
<li>Checkpoint is discarded after commit/rollback</li>
</ol>
<h2 id="lock-management"><a class="header" href="#lock-management">Lock Management</a></h2>
<p>For distributed transactions, the <code>LockManager</code> provides key-level locking
with deadlock prevention.</p>
<h3 id="lock-ordering"><a class="header" href="#lock-ordering">Lock Ordering</a></h3>
<p>To prevent deadlocks, always acquire locks in this order:</p>
<ol>
<li><code>pending</code> - Transaction state map</li>
<li><code>lock_manager.locks</code> - Key-level locks</li>
<li><code>lock_manager.tx_locks</code> - Per-transaction lock sets</li>
<li><code>pending_aborts</code> - Abort queue</li>
</ol>
<h3 id="lock-configuration"><a class="header" href="#lock-configuration">Lock Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>default_timeout</code></td><td>30s</td><td>Lock expiration time</td></tr>
<tr><td><code>timeout_ms</code></td><td>5000</td><td>Transaction timeout</td></tr>
</tbody></table>
</div>
<h3 id="lock-acquisition-1"><a class="header" href="#lock-acquisition-1">Lock Acquisition</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Try to acquire locks for multiple keys
match lock_manager.try_lock(tx_id, &amp;keys) {
    Ok(lock_handle) =&gt; {
        // Locks acquired successfully
    }
    Err(conflicting_tx) =&gt; {
        // Another transaction holds a lock
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="cross-shard-coordination"><a class="header" href="#cross-shard-coordination">Cross-Shard Coordination</a></h2>
<p>Distributed transactions use two-phase commit (2PC) for cross-shard
coordination.</p>
<h3 id="2pc-protocol"><a class="header" href="#2pc-protocol">2PC Protocol</a></h3>
<pre class="mermaid">sequenceDiagram
    participant C as Coordinator
    participant S1 as Shard 1
    participant S2 as Shard 2

    Note over C: Phase 1: Prepare
    C-&gt;&gt;S1: TxPrepare(ops, delta)
    C-&gt;&gt;S2: TxPrepare(ops, delta)
    S1-&gt;&gt;S1: acquire locks
    S2-&gt;&gt;S2: acquire locks
    S1-&gt;&gt;S1: check conflicts
    S2-&gt;&gt;S2: check conflicts
    S1-&gt;&gt;C: Vote(Yes, delta)
    S2-&gt;&gt;C: Vote(Yes, delta)

    Note over C: Phase 2: Commit
    C-&gt;&gt;S1: TxCommit
    C-&gt;&gt;S2: TxCommit
    S1-&gt;&gt;C: Ack
    S2-&gt;&gt;C: Ack
</pre>
<h3 id="transaction-phases"><a class="header" href="#transaction-phases">Transaction Phases</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>Description</th></tr></thead><tbody>
<tr><td>Preparing</td><td>Acquiring locks, computing deltas</td></tr>
<tr><td>Prepared</td><td>All participants voted YES</td></tr>
<tr><td>Committing</td><td>Finalizing the commit</td></tr>
<tr><td>Committed</td><td>Successfully committed</td></tr>
<tr><td>Aborting</td><td>Rolling back due to NO vote or timeout</td></tr>
<tr><td>Aborted</td><td>Successfully aborted</td></tr>
</tbody></table>
</div>
<h3 id="prepare-vote-types"><a class="header" href="#prepare-vote-types">Prepare Vote Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Vote</th><th>Description</th><th>Action</th></tr></thead><tbody>
<tr><td>Yes</td><td>Ready to commit, locks acquired</td><td>Proceed to Phase 2</td></tr>
<tr><td>No</td><td>Cannot commit (validation failed)</td><td>Abort</td></tr>
<tr><td>Conflict</td><td>Detected semantic conflict</td><td>Abort</td></tr>
</tbody></table>
</div>
<h2 id="conflict-detection"><a class="header" href="#conflict-detection">Conflict Detection</a></h2>
<p>The workspace uses delta embeddings to detect conflicts based on vector
similarity.</p>
<h3 id="orthogonality-check"><a class="header" href="#orthogonality-check">Orthogonality Check</a></h3>
<p>Two transactions are considered <strong>orthogonal</strong> (non-conflicting) if their
delta vectors have low cosine similarity:</p>
<pre><code class="language-text">similarity = cos(delta_A, delta_B)
orthogonal = abs(similarity) &lt; threshold
</code></pre>
<h3 id="configuration-12"><a class="header" href="#configuration-12">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>orthogonal_threshold</code></td><td>0.1</td><td>Max similarity for orthogonal</td></tr>
<tr><td><code>merge_window_ms</code></td><td>60000</td><td>Window for merge candidates</td></tr>
</tbody></table>
</div>
<h3 id="merge-candidates"><a class="header" href="#merge-candidates">Merge Candidates</a></h3>
<p>The <code>TransactionManager</code> can find transactions eligible for parallel commit:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find orthogonal transactions that can be merged
let candidates = manager.find_merge_candidates(
    &amp;workspace,
    0.1,      // orthogonal threshold
    60_000,   // merge window (60s)
);

// Candidates are sorted by similarity (most orthogonal first)
for candidate in candidates {
    println!("Tx {} similarity: {}", candidate.workspace.id(), candidate.similarity);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-10"><a class="header" href="#error-handling-10">Error Handling</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th><th>Recovery</th></tr></thead><tbody>
<tr><td><code>TransactionFailed</code></td><td>Operation on non-active workspace</td><td>Check state first</td></tr>
<tr><td><code>WorkspaceError</code></td><td>Snapshot/restore failed</td><td>Check store health</td></tr>
<tr><td><code>LockConflict</code></td><td>Another tx holds the lock</td><td>Retry with backoff</td></tr>
<tr><td><code>Timeout</code></td><td>Transaction exceeded timeout</td><td>Increase timeout</td></tr>
</tbody></table>
</div>
<h2 id="usage-example-2"><a class="header" href="#usage-example-2">Usage Example</a></h2>
<h3 id="complete-transaction-flow"><a class="header" href="#complete-transaction-flow">Complete Transaction Flow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::{TensorStore, TransactionManager};
use tensor_chain::block::Transaction;

// Create manager
let store = TensorStore::new();
let manager = TransactionManager::new();

// Begin transaction
let workspace = manager.begin(&amp;store)?;

// Add operations
workspace.add_operation(Transaction::Put {
    key: "account:1".to_string(),
    data: serialize(&amp;Account { balance: 100 }),
})?;

workspace.add_operation(Transaction::Put {
    key: "account:2".to_string(),
    data: serialize(&amp;Account { balance: 200 }),
})?;

// Set embeddings for conflict detection
workspace.set_before_embedding(vec![0.0; 128]);
workspace.compute_delta(compute_state_embedding(&amp;store));

// Check for conflicts with other active transactions
let candidates = manager.find_merge_candidates(&amp;workspace, 0.1, 60_000);
if candidates.is_empty() {
    // No orthogonal transactions, commit alone
    workspace.mark_committing()?;
    workspace.mark_committed();
} else {
    // Can merge with orthogonal transactions
    // ... merge logic ...
}

// Remove from manager
manager.remove(workspace.id());
<span class="boring">}</span></code></pre></pre>
<h2 id="source-reference-2"><a class="header" href="#source-reference-2">Source Reference</a></h2>
<ul>
<li><code>tensor_chain/src/transaction.rs</code> - TransactionWorkspace, TransactionManager</li>
<li><code>tensor_chain/src/distributed_tx.rs</code> - 2PC coordinator, LockManager</li>
<li><code>tensor_chain/src/embedding.rs</code> - EmbeddingState machine</li>
<li><code>tensor_chain/src/consensus.rs</code> - DeltaVector, conflict detection</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor-data-model"><a class="header" href="#tensor-data-model">Tensor Data Model</a></h1>
<p>Neumann uses a unified tensor-based data model that represents all data types as
mathematical tensors.</p>
<h2 id="core-types-8"><a class="header" href="#core-types-8">Core Types</a></h2>
<h3 id="tensorvalue-1"><a class="header" href="#tensorvalue-1">TensorValue</a></h3>
<p>The fundamental value type:</p>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>Scalar(ScalarValue)</code></td><td>Single value</td><td><code>42</code>, <code>"hello"</code>, <code>true</code></td></tr>
<tr><td><code>Vector(Vec&lt;f32&gt;)</code></td><td>Dense embedding</td><td><code>[0.1, 0.2, 0.3]</code></td></tr>
<tr><td><code>Pointer(String)</code></td><td>Reference to entity</td><td><code>"user_123"</code></td></tr>
<tr><td><code>Pointers(Vec&lt;String&gt;)</code></td><td>Multiple references</td><td><code>["a", "b", "c"]</code></td></tr>
</tbody></table>
</div>
<h3 id="scalarvalue-1"><a class="header" href="#scalarvalue-1">ScalarValue</a></h3>
<p>Primitive values:</p>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>Rust Type</th><th>Example</th></tr></thead><tbody>
<tr><td><code>Int(i64)</code></td><td>64-bit integer</td><td><code>42</code></td></tr>
<tr><td><code>Float(f64)</code></td><td>64-bit float</td><td><code>3.14</code></td></tr>
<tr><td><code>String(String)</code></td><td>UTF-8 string</td><td><code>"hello"</code></td></tr>
<tr><td><code>Bool(bool)</code></td><td>Boolean</td><td><code>true</code></td></tr>
<tr><td><code>Bytes(Vec&lt;u8&gt;)</code></td><td>Binary data</td><td><code>[0x01, 0x02]</code></td></tr>
<tr><td><code>Null</code></td><td>Null value</td><td><code>NULL</code></td></tr>
</tbody></table>
</div>
<h3 id="tensordata-1"><a class="header" href="#tensordata-1">TensorData</a></h3>
<p>A map of field names to TensorValues:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Conceptually: HashMap&lt;String, TensorValue&gt;
let user = TensorData::new()
    .with("id", TensorValue::Scalar(ScalarValue::Int(1)))
    .with("name", TensorValue::Scalar(ScalarValue::String("Alice".into())))
    .with("embedding", TensorValue::Vector(vec![0.1, 0.2, 0.3]));
<span class="boring">}</span></code></pre></pre>
<h2 id="sparse-vectors"><a class="header" href="#sparse-vectors">Sparse Vectors</a></h2>
<p>For high-dimensional sparse data:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Only stores non-zero values
let sparse = SparseVector::new(1000)  // 1000 dimensions
    .with_value(42, 0.5)
    .with_value(100, 0.3)
    .with_value(500, 0.8);
<span class="boring">}</span></code></pre></pre>
<h3 id="operations"><a class="header" href="#operations">Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Description</th></tr></thead><tbody>
<tr><td><code>cosine_similarity</code></td><td>Cosine distance between vectors</td></tr>
<tr><td><code>euclidean_distance</code></td><td>L2 distance</td></tr>
<tr><td><code>dot_product</code></td><td>Inner product</td></tr>
<tr><td><code>weighted_average</code></td><td>Blend multiple vectors</td></tr>
<tr><td><code>project_orthogonal</code></td><td>Remove component</td></tr>
</tbody></table>
</div>
<h2 id="type-mapping"><a class="header" href="#type-mapping">Type Mapping</a></h2>
<h3 id="relational-engine-1"><a class="header" href="#relational-engine-1">Relational Engine</a></h3>
<div class="table-wrapper"><table><thead><tr><th>SQL Type</th><th>TensorValue</th></tr></thead><tbody>
<tr><td><code>INT</code></td><td><code>Scalar(Int)</code></td></tr>
<tr><td><code>FLOAT</code></td><td><code>Scalar(Float)</code></td></tr>
<tr><td><code>STRING</code></td><td><code>Scalar(String)</code></td></tr>
<tr><td><code>BOOL</code></td><td><code>Scalar(Bool)</code></td></tr>
<tr><td><code>VECTOR(n)</code></td><td><code>Vector</code></td></tr>
</tbody></table>
</div>
<h3 id="graph-engine-1"><a class="header" href="#graph-engine-1">Graph Engine</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Graph Element</th><th>TensorValue</th></tr></thead><tbody>
<tr><td>Node ID</td><td><code>Scalar(String)</code></td></tr>
<tr><td>Edge target</td><td><code>Pointer</code></td></tr>
<tr><td>Properties</td><td><code>TensorData</code></td></tr>
</tbody></table>
</div>
<h3 id="vector-engine-1"><a class="header" href="#vector-engine-1">Vector Engine</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Vector Type</th><th>TensorValue</th></tr></thead><tbody>
<tr><td>Dense</td><td><code>Vector</code></td></tr>
<tr><td>Sparse</td><td><code>SparseVector</code> (internal)</td></tr>
</tbody></table>
</div>
<h2 id="storage-layout"><a class="header" href="#storage-layout">Storage Layout</a></h2>
<p>Data is stored in TensorStore as key-value pairs:</p>
<pre><code class="language-text">Key: "users/1"
Value: TensorData {
    "id": Scalar(Int(1)),
    "name": Scalar(String("Alice")),
    "embedding": Vector([0.1, 0.2, ...])
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sparse-vectors-1"><a class="header" href="#sparse-vectors-1">Sparse Vectors</a></h1>
<p>Sparse vectors are a memory-efficient representation for high-dimensional data
where most values are zero.</p>
<h2 id="when-to-use-sparse-vectors"><a class="header" href="#when-to-use-sparse-vectors">When to Use Sparse Vectors</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Use Case</th><th>Dense</th><th>Sparse</th></tr></thead><tbody>
<tr><td>Low dimensions (&lt;100)</td><td>Preferred</td><td>Overhead</td></tr>
<tr><td>High dimensions (&gt;1000)</td><td>Memory intensive</td><td>Preferred</td></tr>
<tr><td>Most values non-zero</td><td>Preferred</td><td>Overhead</td></tr>
<tr><td>&lt;10% values non-zero</td><td>Wasteful</td><td>Preferred</td></tr>
</tbody></table>
</div>
<h2 id="sparsevector-type"><a class="header" href="#sparsevector-type">SparseVector Type</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SparseVector {
    dimension: usize,
    indices: Vec&lt;usize&gt;,
    values: Vec&lt;f32&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-comparison"><a class="header" href="#memory-comparison">Memory Comparison</a></h3>
<p>For a 10,000-dimensional vector with 100 non-zero values:</p>
<div class="table-wrapper"><table><thead><tr><th>Representation</th><th>Memory</th></tr></thead><tbody>
<tr><td>Dense <code>Vec&lt;f32&gt;</code></td><td>40,000 bytes</td></tr>
<tr><td>Sparse</td><td>~800 bytes</td></tr>
<tr><td>Savings</td><td>98%</td></tr>
</tbody></table>
</div>
<h2 id="operations-1"><a class="header" href="#operations-1">Operations</a></h2>
<h3 id="creation"><a class="header" href="#creation">Creation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From dense
let sparse = SparseVector::from_dense(&amp;[0.0, 0.5, 0.0, 0.3, 0.0]);

// Incremental
let mut sparse = SparseVector::new(1000);
sparse.set(42, 0.5);
sparse.set(100, 0.3);
<span class="boring">}</span></code></pre></pre>
<h3 id="arithmetic"><a class="header" href="#arithmetic">Arithmetic</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Subtraction (for deltas)
let delta = new_state.sub(&amp;old_state);

// Weighted average
let blended = SparseVector::weighted_average(&amp;[
    (&amp;vec_a, 0.7),
    (&amp;vec_b, 0.3),
]);

// Orthogonal projection
let residual = vec.project_orthogonal(&amp;basis);
<span class="boring">}</span></code></pre></pre>
<h3 id="similarity-metrics"><a class="header" href="#similarity-metrics">Similarity Metrics</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Formula</th><th>Range</th></tr></thead><tbody>
<tr><td>Cosine</td><td><code>a.b / (‖a‖ * ‖b‖)</code></td><td>[-1, 1]</td></tr>
<tr><td>Euclidean</td><td><code>sqrt(sum((a-b)^2))</code></td><td>[0, inf)</td></tr>
<tr><td>Jaccard</td><td><code>‖A ∩ B‖ / ‖A ∪ B‖</code></td><td>[0, 1]</td></tr>
<tr><td>Angular</td><td><code>acos(cosine) / pi</code></td><td>[0, 1]</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let sim = vec_a.cosine_similarity(&amp;vec_b);
let dist = vec_a.euclidean_distance(&amp;vec_b);
let jacc = vec_a.jaccard_index(&amp;vec_b);
<span class="boring">}</span></code></pre></pre>
<h2 id="hnsw-index-3"><a class="header" href="#hnsw-index-3">HNSW Index</a></h2>
<p>Hierarchical Navigable Small World for approximate nearest neighbor search:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut index = HNSWIndex::new(HNSWConfig::default());

// Insert
index.insert("doc_1", sparse_vec_1);
index.insert("doc_2", sparse_vec_2);

// Search
let results = index.search(&amp;query_vec, 10); // top 10
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-13"><a class="header" href="#configuration-13">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>m</code></td><td>16</td><td>Max connections per layer</td></tr>
<tr><td><code>ef_construction</code></td><td>200</td><td>Build-time search width</td></tr>
<tr><td><code>ef_search</code></td><td>50</td><td>Query-time search width</td></tr>
</tbody></table>
</div>
<h2 id="delta-encoding"><a class="header" href="#delta-encoding">Delta Encoding</a></h2>
<p>For tracking state changes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Compute delta between states
let delta = DeltaVector::from_diff(&amp;old_embedding, &amp;new_embedding);

// Apply delta
let new_state = old_state.add(&amp;delta.to_sparse());

// Check if orthogonal (non-conflicting)
if delta_a.is_orthogonal(&amp;delta_b) {
    // Can merge automatically
}
<span class="boring">}</span></code></pre></pre>
<h2 id="compression-1"><a class="header" href="#compression-1">Compression</a></h2>
<p>Sparse vectors compress well:</p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Ratio</th><th>Speed</th></tr></thead><tbody>
<tr><td>Varint indices</td><td>2-4x</td><td>Fast</td></tr>
<tr><td>Quantization (int8)</td><td>4x</td><td>Fast</td></tr>
<tr><td>Binary quantization</td><td>32x</td><td>Very fast</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="semantic-operations"><a class="header" href="#semantic-operations">Semantic Operations</a></h1>
<p>Semantic operations in Neumann leverage vector embeddings to perform
meaning-aware computations.</p>
<h2 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h2>
<h3 id="embeddings"><a class="header" href="#embeddings">Embeddings</a></h3>
<p>Embeddings map data to vector space where similar items are close:</p>
<pre><code class="language-text">"cat" -&gt; [0.2, 0.8, 0.1, ...]
"dog" -&gt; [0.3, 0.7, 0.2, ...]  (close to cat)
"car" -&gt; [0.9, 0.1, 0.5, ...]  (far from cat)
</code></pre>
<h3 id="similarity-search-1"><a class="header" href="#similarity-search-1">Similarity Search</a></h3>
<p>Find items similar to a query:</p>
<pre><code class="language-sql">SELECT * FROM documents
WHERE SIMILAR(embedding, query_vec, 0.8)
LIMIT 10;
</code></pre>
<h2 id="operations-2"><a class="header" href="#operations-2">Operations</a></h2>
<h3 id="conflict-detection-1"><a class="header" href="#conflict-detection-1">Conflict Detection</a></h3>
<p>In tensor_chain, semantic operations detect conflicts:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Two changes conflict if their deltas overlap
let conflict = delta_a.cosine_similarity(&amp;delta_b) &gt; threshold;

// Orthogonal changes can be merged
if delta_a.is_orthogonal(&amp;delta_b) {
    let merged = delta_a.add(&amp;delta_b);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="auto-merge"><a class="header" href="#auto-merge">Auto-Merge</a></h3>
<p>Non-conflicting changes merge automatically:</p>
<pre class="mermaid">flowchart LR
    A[State S0] --&gt; B[Change A: fields 1-10]
    A --&gt; C[Change B: fields 11-20]
    B --&gt; D[Merged: fields 1-20]
    C --&gt; D
</pre>
<h3 id="semantic-conflict-resolution"><a class="header" href="#semantic-conflict-resolution">Semantic Conflict Resolution</a></h3>
<p>When changes overlap:</p>
<div class="table-wrapper"><table><thead><tr><th>Scenario</th><th>Detection</th><th>Resolution</th></tr></thead><tbody>
<tr><td>Orthogonal</td><td><code>similarity &lt; 0.1</code></td><td>Auto-merge</td></tr>
<tr><td>Partial overlap</td><td><code>0.1 &lt;= similarity &lt; 0.5</code></td><td>Manual review</td></tr>
<tr><td>Direct conflict</td><td><code>similarity &gt;= 0.5</code></td><td>Reject newer</td></tr>
</tbody></table>
</div>
<h2 id="codebook-quantization"><a class="header" href="#codebook-quantization">Codebook Quantization</a></h2>
<p>For efficient similarity comparisons:</p>
<h3 id="global-codebook"><a class="header" href="#global-codebook">Global Codebook</a></h3>
<p>Static centroids for consensus validation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let codebook = GlobalCodebook::new(1024, 128); // 1024 centroids, 128 dims
let quantized = codebook.quantize(&amp;embedding);
<span class="boring">}</span></code></pre></pre>
<h3 id="local-codebook"><a class="header" href="#local-codebook">Local Codebook</a></h3>
<p>Adaptive centroids per domain:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut codebook = LocalCodebook::new(256, 128);
codebook.update(&amp;new_embeddings, 0.1); // EMA update
<span class="boring">}</span></code></pre></pre>
<h2 id="distance-metrics-4"><a class="header" href="#distance-metrics-4">Distance Metrics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Use Case</th><th>Properties</th></tr></thead><tbody>
<tr><td>Cosine</td><td>Text similarity</td><td>Scale-invariant</td></tr>
<tr><td>Euclidean</td><td>Spatial data</td><td>Absolute distance</td></tr>
<tr><td>Angular</td><td>Normalized comparison</td><td>[0, 1] range</td></tr>
<tr><td>Geodesic</td><td>Manifold data</td><td>Curvature-aware</td></tr>
</tbody></table>
</div>
<h2 id="cache-semantic-search"><a class="header" href="#cache-semantic-search">Cache Semantic Search</a></h2>
<p>tensor_cache uses semantic similarity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Exact match first
if let Some(hit) = cache.get_exact(&amp;prompt_hash) {
    return hit;
}

// Then semantic search
if let Some(hit) = cache.search_similar(&amp;prompt_embedding, 0.95) {
    return hit;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="embedding-state-machine"><a class="header" href="#embedding-state-machine">Embedding State Machine</a></h2>
<p>tensor_chain tracks embedding lifecycle:</p>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Initial: new transaction
    Initial --&gt; Computed: compute_embedding()
    Computed --&gt; Validated: validate()
    Validated --&gt; Committed: commit()
</pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum EmbeddingState {
    Initial,                    // No embedding yet
    Computed(SparseVector),     // Computed, not validated
    Validated(SparseVector),    // Passed validation
}
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="distributed-transactions"><a class="header" href="#distributed-transactions">Distributed Transactions</a></h1>
<p>tensor_chain implements distributed transactions using Two-Phase Commit (2PC)
with semantic conflict detection.</p>
<h2 id="transaction-lifecycle-1"><a class="header" href="#transaction-lifecycle-1">Transaction Lifecycle</a></h2>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Pending: begin()
    Pending --&gt; Preparing: prepare()
    Preparing --&gt; Prepared: all votes received
    Prepared --&gt; Committing: commit decision
    Prepared --&gt; Aborting: abort decision
    Committing --&gt; Committed: all acks
    Aborting --&gt; Aborted: all acks
    Committed --&gt; [*]
    Aborted --&gt; [*]
</pre>
<h2 id="two-phase-commit"><a class="header" href="#two-phase-commit">Two-Phase Commit</a></h2>
<h3 id="phase-1-prepare"><a class="header" href="#phase-1-prepare">Phase 1: Prepare</a></h3>
<ol>
<li>Coordinator sends <code>Prepare</code> to all participants</li>
<li>Each participant:
<ul>
<li>Acquires locks</li>
<li>Validates constraints</li>
<li>Writes to WAL</li>
<li>Votes <code>Yes</code> or <code>No</code></li>
</ul>
</li>
</ol>
<h3 id="phase-2-commitabort"><a class="header" href="#phase-2-commitabort">Phase 2: Commit/Abort</a></h3>
<ol>
<li>If all vote <code>Yes</code>: Coordinator sends <code>Commit</code></li>
<li>If any vote <code>No</code>: Coordinator sends <code>Abort</code></li>
<li>Participants apply or rollback</li>
</ol>
<h2 id="message-types"><a class="header" href="#message-types">Message Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Message</th><th>Direction</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>TxPrepareMsg</code></td><td>Coordinator -&gt; Participant</td><td>Start prepare phase</td></tr>
<tr><td><code>TxVote</code></td><td>Participant -&gt; Coordinator</td><td>Vote yes/no</td></tr>
<tr><td><code>TxCommitMsg</code></td><td>Coordinator -&gt; Participant</td><td>Commit decision</td></tr>
<tr><td><code>TxAbortMsg</code></td><td>Coordinator -&gt; Participant</td><td>Abort decision</td></tr>
<tr><td><code>TxAck</code></td><td>Participant -&gt; Coordinator</td><td>Acknowledge commit/abort</td></tr>
</tbody></table>
</div>
<h2 id="lock-management-1"><a class="header" href="#lock-management-1">Lock Management</a></h2>
<h3 id="lock-types"><a class="header" href="#lock-types">Lock Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Lock</th><th>Compatibility</th><th>Use</th></tr></thead><tbody>
<tr><td>Shared (S)</td><td>S-S compatible</td><td>Read operations</td></tr>
<tr><td>Exclusive (X)</td><td>Incompatible with all</td><td>Write operations</td></tr>
</tbody></table>
</div>
<h3 id="lock-acquisition-2"><a class="header" href="#lock-acquisition-2">Lock Acquisition</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Acquire lock with timeout
let lock = lock_manager.acquire(
    tx_id,
    key,
    LockMode::Exclusive,
    Duration::from_secs(5),
)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="deadlock-detection-1"><a class="header" href="#deadlock-detection-1">Deadlock Detection</a></h2>
<p>Wait-for graph analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check for cycles before waiting
if wait_graph.would_create_cycle(my_tx, blocking_tx) {
    // Abort to prevent deadlock
    return Err(DeadlockDetected);
}

// Register wait
wait_graph.add_wait(my_tx, blocking_tx);
<span class="boring">}</span></code></pre></pre>
<h3 id="victim-selection"><a class="header" href="#victim-selection">Victim Selection</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Policy</th><th>Behavior</th></tr></thead><tbody>
<tr><td>Youngest</td><td>Abort most recent transaction</td></tr>
<tr><td>Oldest</td><td>Abort longest-running</td></tr>
<tr><td>LowestPriority</td><td>Abort lowest priority</td></tr>
<tr><td>MostLocks</td><td>Abort holding most locks</td></tr>
</tbody></table>
</div>
<h2 id="semantic-conflict-detection-1"><a class="header" href="#semantic-conflict-detection-1">Semantic Conflict Detection</a></h2>
<p>Beyond lock-based conflicts, tensor_chain detects semantic conflicts:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Compute embedding deltas
let delta_a = tx_a.compute_delta();
let delta_b = tx_b.compute_delta();

// Check for semantic overlap
if delta_a.cosine_similarity(&amp;delta_b) &gt; CONFLICT_THRESHOLD {
    // Semantic conflict - need manual resolution
    return PrepareVote::Conflict { ... };
}
<span class="boring">}</span></code></pre></pre>
<h2 id="recovery"><a class="header" href="#recovery">Recovery</a></h2>
<h3 id="coordinator-failure"><a class="header" href="#coordinator-failure">Coordinator Failure</a></h3>
<ol>
<li>New coordinator queries participants for tx state</li>
<li>If any committed: complete commit</li>
<li>If all prepared: re-run commit decision</li>
<li>Otherwise: abort</li>
</ol>
<h3 id="participant-failure"><a class="header" href="#participant-failure">Participant Failure</a></h3>
<ol>
<li>Participant replays WAL on restart</li>
<li>For prepared transactions: query coordinator</li>
<li>Apply commit or abort based on coordinator state</li>
</ol>
<h2 id="configuration-14"><a class="header" href="#configuration-14">Configuration</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DistributedTxConfig {
    /// Prepare phase timeout
    pub prepare_timeout_ms: u64,
    /// Commit phase timeout
    pub commit_timeout_ms: u64,
    /// Maximum concurrent transactions
    pub max_concurrent_tx: usize,
    /// Lock wait timeout
    pub lock_timeout_ms: u64,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-7"><a class="header" href="#best-practices-7">Best Practices</a></h2>
<ol>
<li><strong>Keep transactions short</strong>: Long transactions increase conflict probability</li>
<li><strong>Order lock acquisition</strong>: Acquire locks in consistent order to prevent
deadlocks</li>
<li><strong>Use appropriate isolation</strong>: Not all operations need serializable isolation</li>
<li><strong>Monitor deadlock rate</strong>: High rates indicate contention issues</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="consensus-protocols"><a class="header" href="#consensus-protocols">Consensus Protocols</a></h1>
<p>tensor_chain uses Raft consensus with SWIM gossip for membership management.</p>
<h2 id="raft-consensus-1"><a class="header" href="#raft-consensus-1">Raft Consensus</a></h2>
<h3 id="overview-3"><a class="header" href="#overview-3">Overview</a></h3>
<p>Raft provides:</p>
<ul>
<li>Leader election</li>
<li>Log replication</li>
<li>Safety (never returns incorrect results)</li>
<li>Availability (operational if majority alive)</li>
</ul>
<h3 id="node-states"><a class="header" href="#node-states">Node States</a></h3>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Follower
    Follower --&gt; Candidate: election timeout
    Candidate --&gt; Leader: wins election
    Candidate --&gt; Follower: discovers leader
    Leader --&gt; Follower: discovers higher term
    Candidate --&gt; Candidate: split vote
</pre>
<h3 id="terms"><a class="header" href="#terms">Terms</a></h3>
<p>Time divided into terms with at most one leader:</p>
<pre><code class="language-text">Term 1: [Leader A] -----&gt; [Follower timeout]
Term 2: [Election] -&gt; [Leader B] -----&gt; ...
</code></pre>
<h3 id="log-replication"><a class="header" href="#log-replication">Log Replication</a></h3>
<pre class="mermaid">sequenceDiagram
    participant C as Client
    participant L as Leader
    participant F1 as Follower 1
    participant F2 as Follower 2

    C-&gt;&gt;L: Write request
    L-&gt;&gt;L: Append to log
    par Replicate
        L-&gt;&gt;F1: AppendEntries
        L-&gt;&gt;F2: AppendEntries
    end
    F1-&gt;&gt;L: Success
    F2-&gt;&gt;L: Success
    L-&gt;&gt;L: Commit (majority)
    L-&gt;&gt;C: Success
</pre>
<h3 id="configuration-15"><a class="header" href="#configuration-15">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>election_timeout_min</code></td><td>150ms</td><td>Min election timeout</td></tr>
<tr><td><code>election_timeout_max</code></td><td>300ms</td><td>Max election timeout</td></tr>
<tr><td><code>heartbeat_interval</code></td><td>50ms</td><td>Leader heartbeat frequency</td></tr>
<tr><td><code>max_entries_per_append</code></td><td>100</td><td>Batch size for replication</td></tr>
</tbody></table>
</div>
<h2 id="swim-gossip"><a class="header" href="#swim-gossip">SWIM Gossip</a></h2>
<h3 id="overview-4"><a class="header" href="#overview-4">Overview</a></h3>
<p>Scalable Weakly-consistent Infection-style Membership:</p>
<ul>
<li>O(log N) failure detection</li>
<li>Distributed membership view</li>
<li>No single point of failure</li>
</ul>
<h3 id="protocol"><a class="header" href="#protocol">Protocol</a></h3>
<pre class="mermaid">sequenceDiagram
    participant A as Node A
    participant B as Node B (target)
    participant C as Node C

    A-&gt;&gt;B: Ping
    Note over B: No response
    A-&gt;&gt;C: PingReq(B)
    C-&gt;&gt;B: Ping
    alt B responds
        B-&gt;&gt;C: Ack
        C-&gt;&gt;A: Ack (indirect)
    else B down
        C-&gt;&gt;A: Nack
        A-&gt;&gt;A: Mark B suspect
    end
</pre>
<h3 id="node-states-1"><a class="header" href="#node-states-1">Node States</a></h3>
<div class="table-wrapper"><table><thead><tr><th>State</th><th>Description</th><th>Transition</th></tr></thead><tbody>
<tr><td>Healthy</td><td>Responding normally</td><td>—</td></tr>
<tr><td>Suspect</td><td>Failed direct ping</td><td>After timeout</td></tr>
<tr><td>Failed</td><td>Confirmed down</td><td>After indirect ping failure</td></tr>
</tbody></table>
</div>
<h3 id="lww-crdt-membership"><a class="header" href="#lww-crdt-membership">LWW-CRDT Membership</a></h3>
<p>Last-Writer-Wins with incarnation numbers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// State comparison
fn supersedes(&amp;self, other: &amp;Self) -&gt; bool {
    (self.incarnation, self.timestamp) &gt; (other.incarnation, other.timestamp)
}

// Merge takes winner per node
fn merge(&amp;mut self, other: &amp;Self) {
    for (node_id, state) in &amp;other.states {
        if state.supersedes(&amp;self.states[node_id]) {
            self.states.insert(node_id.clone(), state.clone());
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-16"><a class="header" href="#configuration-16">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>ping_interval</code></td><td>1s</td><td>Direct ping frequency</td></tr>
<tr><td><code>ping_timeout</code></td><td>500ms</td><td>Time to wait for response</td></tr>
<tr><td><code>suspect_timeout</code></td><td>3s</td><td>Time before marking failed</td></tr>
<tr><td><code>indirect_ping_count</code></td><td>3</td><td>Number of indirect pings</td></tr>
</tbody></table>
</div>
<h2 id="hybrid-logical-clocks"><a class="header" href="#hybrid-logical-clocks">Hybrid Logical Clocks</a></h2>
<p>Combine physical time with logical counters:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HybridTimestamp {
    wall_ms: u64,    // Physical time (milliseconds)
    logical: u16,    // Logical counter
}
<span class="boring">}</span></code></pre></pre>
<h3 id="properties"><a class="header" href="#properties">Properties</a></h3>
<ul>
<li>Monotonic: Always increases</li>
<li>Bounded drift: Stays close to wall clock</li>
<li>Causality: If A happens-before B, then ts(A) &lt; ts(B)</li>
</ul>
<h3 id="usage-5"><a class="header" href="#usage-5">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let hlc = HybridLogicalClock::new(node_id);

// Local event
let ts = hlc.now();

// Receive message with timestamp
let ts = hlc.receive(message_ts);
<span class="boring">}</span></code></pre></pre>
<h2 id="integration"><a class="header" href="#integration">Integration</a></h2>
<p>Raft and SWIM work together:</p>
<ol>
<li><strong>SWIM</strong> detects node failures quickly</li>
<li><strong>Raft</strong> handles leader election and log consistency</li>
<li><strong>HLC</strong> provides ordering across the cluster</li>
</ol>
<pre class="mermaid">flowchart TB
    subgraph Membership Layer
        SWIM[SWIM Gossip]
    end

    subgraph Consensus Layer
        Raft[Raft Consensus]
    end

    subgraph Time Layer
        HLC[Hybrid Logical Clock]
    end

    SWIM --&gt;|failure notifications| Raft
    HLC --&gt;|timestamps| SWIM
    HLC --&gt;|timestamps| Raft
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="embedding-state-machine-1"><a class="header" href="#embedding-state-machine-1">Embedding State Machine</a></h1>
<p>The <code>EmbeddingState</code> provides type-safe state transitions for transaction
embedding lifecycle. It eliminates Option ceremony and ensures correct API
usage at compile time.</p>
<h2 id="overview-5"><a class="header" href="#overview-5">Overview</a></h2>
<p>Transaction embeddings track the semantic change from before-state to
after-state. The state machine ensures:</p>
<ul>
<li>Before embedding is always available</li>
<li>Delta is only accessible after computation</li>
<li>Dimension mismatches are caught early</li>
<li>Double-computation is prevented</li>
</ul>
<h2 id="state-diagram"><a class="header" href="#state-diagram">State Diagram</a></h2>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Initial: new(before)
    Initial --&gt; Computed: compute(after)
    Computed --&gt; Computed: access only
    Initial --&gt; Initial: access only
</pre>
<div class="table-wrapper"><table><thead><tr><th>State</th><th>Description</th><th>Available Data</th></tr></thead><tbody>
<tr><td>Initial</td><td>Transaction started, before captured</td><td>before</td></tr>
<tr><td>Computed</td><td>Delta computed, ready for conflict check</td><td>before, after, delta</td></tr>
</tbody></table>
</div>
<h2 id="api-reference-6"><a class="header" href="#api-reference-6">API Reference</a></h2>
<h3 id="construction-methods"><a class="header" href="#construction-methods">Construction Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th><th>Result State</th></tr></thead><tbody>
<tr><td><code>new(before)</code></td><td>Create from sparse vector</td><td>Initial</td></tr>
<tr><td><code>from_dense(&amp;[f32])</code></td><td>Create from dense slice</td><td>Initial</td></tr>
<tr><td><code>empty(dim)</code></td><td>Create zero vector of given dimension</td><td>Initial</td></tr>
<tr><td><code>default()</code></td><td>Create empty (dimension 0)</td><td>Initial</td></tr>
</tbody></table>
</div>
<h3 id="state-query-methods"><a class="header" href="#state-query-methods">State Query Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Initial</th><th>Computed</th></tr></thead><tbody>
<tr><td><code>before()</code></td><td><code>&amp;SparseVector</code></td><td><code>&amp;SparseVector</code></td></tr>
<tr><td><code>after()</code></td><td><code>None</code></td><td><code>Some(&amp;SparseVector)</code></td></tr>
<tr><td><code>delta()</code></td><td><code>None</code></td><td><code>Some(&amp;SparseVector)</code></td></tr>
<tr><td><code>is_computed()</code></td><td><code>false</code></td><td><code>true</code></td></tr>
<tr><td><code>dimension()</code></td><td>dimension</td><td>dimension</td></tr>
</tbody></table>
</div>
<h3 id="transition-methods"><a class="header" href="#transition-methods">Transition Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>From</th><th>To</th><th>Error Conditions</th></tr></thead><tbody>
<tr><td><code>compute(after)</code></td><td>Initial</td><td>Computed</td><td>AlreadyComputed, DimensionMismatch</td></tr>
<tr><td><code>compute_from_dense(&amp;[f32])</code></td><td>Initial</td><td>Computed</td><td>AlreadyComputed, DimensionMismatch</td></tr>
<tr><td><code>compute_with_threshold(after, threshold)</code></td><td>Initial</td><td>Computed</td><td>AlreadyComputed, DimensionMismatch</td></tr>
</tbody></table>
</div>
<h2 id="threshold-configuration"><a class="header" href="#threshold-configuration">Threshold Configuration</a></h2>
<p>The <code>compute_with_threshold</code> method creates sparse deltas by ignoring small
changes. This reduces memory usage for high-dimensional embeddings.</p>
<h3 id="threshold-effects"><a class="header" href="#threshold-effects">Threshold Effects</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Threshold</th><th>Effect</th><th>Use Case</th></tr></thead><tbody>
<tr><td>0.0</td><td>All differences captured</td><td>Exact tracking</td></tr>
<tr><td>0.001</td><td>Ignore floating-point noise</td><td>General use</td></tr>
<tr><td>0.01</td><td>Ignore minor changes</td><td>Dimensionality reduction</td></tr>
<tr><td>0.1</td><td>Only major changes</td><td>Coarse conflict detection</td></tr>
</tbody></table>
</div>
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let state = EmbeddingState::from_dense(&amp;before);

// Only capture differences &gt; 0.01
let computed = state.compute_with_threshold(&amp;after, 0.01)?;

// Sparse delta - fewer non-zero entries
let delta = computed.delta().unwrap();
println!("Non-zero entries: {}", delta.nnz());
<span class="boring">}</span></code></pre></pre>
<h2 id="error-handling-11"><a class="header" href="#error-handling-11">Error Handling</a></h2>
<h3 id="error-types-9"><a class="header" href="#error-types-9">Error Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Cause</th><th>Prevention</th></tr></thead><tbody>
<tr><td><code>NotComputed</code></td><td>Accessing delta before compute</td><td>Check <code>is_computed()</code></td></tr>
<tr><td><code>AlreadyComputed</code></td><td>Calling compute twice</td><td>Check <code>is_computed()</code></td></tr>
<tr><td><code>DimensionMismatch</code></td><td>Before and after have different dims</td><td>Validate dimensions</td></tr>
</tbody></table>
</div>
<h3 id="error-display"><a class="header" href="#error-display">Error Display</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// NotComputed
"delta not yet computed"

// AlreadyComputed
"delta already computed"

// DimensionMismatch
"dimension mismatch: before=128, after=64"
<span class="boring">}</span></code></pre></pre>
<h2 id="example-usage"><a class="header" href="#example-usage">Example Usage</a></h2>
<h3 id="basic-workflow"><a class="header" href="#basic-workflow">Basic Workflow</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::embedding::EmbeddingState;
use tensor_store::SparseVector;

// 1. Capture before-state at transaction start
let before = SparseVector::from_dense(&amp;[1.0, 0.0, 0.0, 0.0]);
let state = EmbeddingState::new(before);

// 2. State is Initial - delta not available
assert!(!state.is_computed());
assert!(state.delta().is_none());

// 3. Compute delta at commit time
let after = SparseVector::from_dense(&amp;[1.0, 0.5, 0.0, 0.0]);
let computed = state.compute(after)?;

// 4. State is Computed - delta available
assert!(computed.is_computed());
let delta = computed.delta().unwrap();

// Delta is [0.0, 0.5, 0.0, 0.0]
assert_eq!(delta.nnz(), 1);  // Only one non-zero
<span class="boring">}</span></code></pre></pre>
<h3 id="using-delta_or_zero"><a class="header" href="#using-delta_or_zero">Using delta_or_zero</a></h3>
<p>For code that needs a dense vector regardless of state:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Safe to call in any state
let dense_delta = state.delta_or_zero();

// Returns zeros if Initial
// Returns actual delta if Computed
<span class="boring">}</span></code></pre></pre>
<h3 id="delta-magnitude"><a class="header" href="#delta-magnitude">Delta Magnitude</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check if transaction made significant changes
let magnitude = state.delta_magnitude();

if magnitude &lt; 0.001 {
    println!("No meaningful changes");
} else {
    println!("Change magnitude: {}", magnitude);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-with-consensus"><a class="header" href="#integration-with-consensus">Integration with Consensus</a></h2>
<p>The embedding state integrates with the consensus layer for conflict detection.</p>
<h3 id="delta-to-deltavector"><a class="header" href="#delta-to-deltavector">Delta to DeltaVector</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::consensus::DeltaVector;

let state = EmbeddingState::from_dense(&amp;before);
let computed = state.compute_from_dense(&amp;after)?;

// Create DeltaVector for conflict detection
let delta_vec = DeltaVector::new(
    computed.delta_or_zero(),
    affected_keys,
    tx_id,
);

// Check orthogonality with another transaction
let similarity = delta_vec.cosine_similarity(&amp;other_delta);
if similarity.abs() &lt; 0.1 {
    println!("Transactions are orthogonal - can merge");
}
<span class="boring">}</span></code></pre></pre>
<h3 id="conflict-classification"><a class="header" href="#conflict-classification">Conflict Classification</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Similarity</th><th>Classification</th><th>Action</th></tr></thead><tbody>
<tr><td>&lt; 0.1</td><td>Orthogonal</td><td>Can merge</td></tr>
<tr><td>0.1 - 0.5</td><td>Low conflict</td><td>Merge possible</td></tr>
<tr><td>0.5 - 0.9</td><td>Conflicting</td><td>Needs resolution</td></tr>
<tr><td>&gt; 0.9</td><td>Parallel</td><td>Must serialize</td></tr>
</tbody></table>
</div>
<h2 id="serialization"><a class="header" href="#serialization">Serialization</a></h2>
<p>The state machine supports bincode serialization for persistence:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Serialize
let bytes = bincode::serialize(&amp;state)?;

// Deserialize
let restored: EmbeddingState = bincode::deserialize(&amp;bytes)?;

// State is preserved
assert_eq!(state.is_computed(), restored.is_computed());
<span class="boring">}</span></code></pre></pre>
<h2 id="source-reference-3"><a class="header" href="#source-reference-3">Source Reference</a></h2>
<ul>
<li><code>tensor_chain/src/embedding.rs</code> - EmbeddingState implementation</li>
<li><code>tensor_store/src/lib.rs</code> - SparseVector type</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="codebook-manager"><a class="header" href="#codebook-manager">Codebook Manager</a></h1>
<p>The codebook system provides vector quantization for mapping continuous tensor
states to a finite vocabulary of valid states. It enables state validation and
efficient consensus through hierarchical quantization.</p>
<h2 id="overview-6"><a class="header" href="#overview-6">Overview</a></h2>
<p>The system consists of two levels:</p>
<ul>
<li><strong>GlobalCodebook</strong>: Static codebook shared across all nodes for consensus</li>
<li><strong>LocalCodebook</strong>: Adaptive codebook per domain that captures residuals</li>
</ul>
<pre class="mermaid">flowchart TD
    A[Input Vector] --&gt; B[Global Codebook]
    B --&gt; C{Residual &gt; threshold?}
    C --&gt;|No| D[Global code only]
    C --&gt;|Yes| E[Local Codebook]
    E --&gt; F[Global + Local codes]
    D --&gt; G[Final Quantization]
    F --&gt; G
</pre>
<h2 id="global-codebook-1"><a class="header" href="#global-codebook-1">Global Codebook</a></h2>
<p>The global codebook provides consensus-safe quantization using static
centroids shared by all nodes.</p>
<h3 id="initialization-methods"><a class="header" href="#initialization-methods">Initialization Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>new(dimension)</code></td><td>Empty codebook</td></tr>
<tr><td><code>from_centroids(Vec&lt;Vec&lt;f32&gt;&gt;)</code></td><td>From pre-computed centroids</td></tr>
<tr><td><code>from_centroids_with_labels</code></td><td>Centroids with semantic labels</td></tr>
<tr><td><code>from_kmeans(vectors, k, iters)</code></td><td>Initialize via k-means clustering</td></tr>
</tbody></table>
</div>
<h3 id="quantization"><a class="header" href="#quantization">Quantization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::codebook::GlobalCodebook;

// Initialize from training data
let codebook = GlobalCodebook::from_kmeans(&amp;training_vectors, 256, 100);

// Quantize a vector
if let Some((entry_id, similarity)) = codebook.quantize(&amp;vector) {
    println!("Nearest entry: {}, similarity: {}", entry_id, similarity);
}

// Compute residual for hierarchical quantization
if let Some((id, residual)) = codebook.compute_residual(&amp;vector) {
    // residual = vector - centroid[id]
}
<span class="boring">}</span></code></pre></pre>
<h2 id="local-codebook-1"><a class="header" href="#local-codebook-1">Local Codebook</a></h2>
<p>Local codebooks adapt to domain-specific patterns using exponential moving
average (EMA) updates. They capture residuals that the global codebook
misses.</p>
<h3 id="ema-update-formula"><a class="header" href="#ema-update-formula">EMA Update Formula</a></h3>
<p>When an observation matches an existing entry:</p>
<pre><code class="language-text">centroid_new = alpha * observation + (1 - alpha) * centroid_old
</code></pre>
<p>where <code>alpha</code> controls the learning rate (default: 0.1).</p>
<h3 id="configuration-17"><a class="header" href="#configuration-17">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>max_entries</code></td><td>256</td><td>Maximum entries in the codebook</td></tr>
<tr><td><code>ema_alpha</code></td><td>0.1</td><td>EMA learning rate</td></tr>
<tr><td><code>min_usage_for_prune</code></td><td>2</td><td>Minimum accesses before pruning</td></tr>
<tr><td><code>pruning_strategy</code></td><td>Hybrid</td><td>How to select entries for removal</td></tr>
</tbody></table>
</div>
<h3 id="pruning-strategies"><a class="header" href="#pruning-strategies">Pruning Strategies</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>Description</th><th>Score Formula</th></tr></thead><tbody>
<tr><td>LRU</td><td>Least Recently Used</td><td><code>last_access</code></td></tr>
<tr><td>LFU</td><td>Least Frequently Used</td><td><code>access_count</code></td></tr>
<tr><td>Hybrid</td><td>Weighted combination</td><td><code>w1*recency + w2*frequency</code></td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::codebook::{LocalCodebook, PruningStrategy};

let mut local = LocalCodebook::new("transactions", 128, 256, 0.1);

// Use LRU pruning
local.set_pruning_strategy(PruningStrategy::LRU);

// Or hybrid with custom weights
local.set_pruning_strategy(PruningStrategy::Hybrid {
    recency_weight: 0.7,
    frequency_weight: 0.3,
});
<span class="boring">}</span></code></pre></pre>
<h2 id="codebookmanager"><a class="header" href="#codebookmanager">CodebookManager</a></h2>
<p>The <code>CodebookManager</code> coordinates hierarchical quantization across global
and local codebooks.</p>
<h3 id="configuration-18"><a class="header" href="#configuration-18">Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::codebook::{CodebookManager, CodebookConfig, GlobalCodebook};

let config = CodebookConfig {
    local_capacity: 256,        // Max entries per local codebook
    ema_alpha: 0.1,             // EMA learning rate
    similarity_threshold: 0.9,   // Match threshold for local updates
    residual_threshold: 0.05,    // Min residual for local quantization
    validity_threshold: 0.8,     // State validity threshold
};

let global = GlobalCodebook::from_kmeans(&amp;training_data, 512, 100);
let manager = CodebookManager::new(global, config);
<span class="boring">}</span></code></pre></pre>
<h3 id="hierarchical-quantization"><a class="header" href="#hierarchical-quantization">Hierarchical Quantization</a></h3>
<pre class="mermaid">sequenceDiagram
    participant V as Input Vector
    participant G as Global Codebook
    participant L as Local Codebook
    participant R as Result

    V-&gt;&gt;G: quantize()
    G-&gt;&gt;G: Find nearest centroid
    G-&gt;&gt;V: (entry_id, similarity)
    V-&gt;&gt;V: residual = vector - centroid
    alt residual &gt; threshold
        V-&gt;&gt;L: quantize_and_update(residual)
        L-&gt;&gt;L: EMA update or insert
        L-&gt;&gt;R: codes = [global_id, local_id]
    else residual &lt;= threshold
        V-&gt;&gt;R: codes = [global_id]
    end
</pre>
<h3 id="usage-6"><a class="header" href="#usage-6">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Quantize a transaction embedding
let result = manager.quantize("transactions", &amp;embedding)?;

println!("Global entry: {}", result.global_entry_id);
println!("Global similarity: {}", result.global_similarity);

if let Some(local_id) = result.local_entry_id {
    println!("Local entry: {}", local_id);
    println!("Local similarity: {}", result.local_similarity.unwrap());
}

// Final codes for storage/transmission
println!("Codes: {:?}", result.codes);
<span class="boring">}</span></code></pre></pre>
<h2 id="state-validation"><a class="header" href="#state-validation">State Validation</a></h2>
<p>The codebook system validates states against known-good patterns.</p>
<h3 id="validation-methods"><a class="header" href="#validation-methods">Validation Methods</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check if a state is valid (matches any codebook entry)
let is_valid = manager.is_valid_state("transactions", &amp;state);

// Check if a transition is valid
let is_valid_transition = manager.is_valid_transition(
    "transactions",
    &amp;from_state,
    &amp;to_state,
    0.5,  // max allowed distance
);
<span class="boring">}</span></code></pre></pre>
<h3 id="validation-flow"><a class="header" href="#validation-flow">Validation Flow</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Check</th><th>Threshold</th><th>Outcome</th></tr></thead><tbody>
<tr><td>Global match</td><td><code>validity_threshold</code></td><td>Valid if similarity &gt;= threshold</td></tr>
<tr><td>Local match</td><td><code>validity_threshold</code></td><td>Valid if similarity &gt;= threshold</td></tr>
<tr><td>Transition distance</td><td><code>max_distance</code></td><td>Valid if euclidean &lt;= max</td></tr>
</tbody></table>
</div>
<h2 id="worked-example"><a class="header" href="#worked-example">Worked Example</a></h2>
<h3 id="training-and-runtime-quantization"><a class="header" href="#training-and-runtime-quantization">Training and Runtime Quantization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::codebook::{CodebookManager, CodebookConfig, GlobalCodebook};

// Phase 1: Training - build global codebook
let training_embeddings: Vec&lt;Vec&lt;f32&gt;&gt; = collect_training_data();
let global = GlobalCodebook::from_kmeans(&amp;training_embeddings, 512, 100);

// Phase 2: Runtime - create manager
let config = CodebookConfig::default();
let manager = CodebookManager::new(global, config);

// Phase 3: Quantize incoming transactions
for tx in transactions {
    let embedding = compute_embedding(&amp;tx);

    // Hierarchical quantization
    let quant = manager.quantize("transactions", &amp;embedding)?;

    // Validate the state
    if !manager.is_valid_state("transactions", &amp;embedding) {
        warn!("Unusual transaction state: {:?}", tx);
    }

    // Store codes for consensus
    tx.set_quantization_codes(quant.codes);
}

// Local codebook learns domain-specific patterns over time
manager.with_local("transactions", |local| {
    let stats = local.stats();
    println!("Local entries: {}", stats.entry_count);
    println!("Total updates: {}", stats.total_updates);
});
<span class="boring">}</span></code></pre></pre>
<h2 id="k-means-initialization"><a class="header" href="#k-means-initialization">k-Means Initialization</a></h2>
<p>The global codebook uses k-means++ initialization for optimal centroid
placement.</p>
<pre class="mermaid">flowchart TD
    A[Training Vectors] --&gt; B[Random First Centroid]
    B --&gt; C[Compute Distances]
    C --&gt; D[Weighted Probability Selection]
    D --&gt; E{k centroids?}
    E --&gt;|No| C
    E --&gt;|Yes| F[Lloyd's Iteration]
    F --&gt; G{Converged?}
    G --&gt;|No| F
    G --&gt;|Yes| H[Final Centroids]
</pre>
<h3 id="configuration-19"><a class="header" href="#configuration-19">Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::{KMeans, KMeansConfig};

let config = KMeansConfig {
    max_iterations: 100,
    tolerance: 1e-4,
    init_method: InitMethod::KMeansPlusPlus,
};

let kmeans = KMeans::new(config);
let centroids = kmeans.fit(&amp;vectors, 512);
<span class="boring">}</span></code></pre></pre>
<h2 id="statistics-and-monitoring-1"><a class="header" href="#statistics-and-monitoring-1">Statistics and Monitoring</a></h2>
<h3 id="local-codebook-stats"><a class="header" href="#local-codebook-stats">Local Codebook Stats</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Description</th></tr></thead><tbody>
<tr><td><code>entry_count</code></td><td>Current number of entries</td></tr>
<tr><td><code>total_updates</code></td><td>EMA updates performed</td></tr>
<tr><td><code>total_lookups</code></td><td>Quantization queries</td></tr>
<tr><td><code>total_prunes</code></td><td>Entries removed due to capacity</td></tr>
<tr><td><code>total_insertions</code></td><td>New entries added</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>manager.with_local("transactions", |local| {
    let stats = local.stats();
    let hit_rate = 1.0 - (stats.total_insertions as f64 / stats.total_lookups as f64);
    println!("Cache hit rate: {:.2}%", hit_rate * 100.0);
});
<span class="boring">}</span></code></pre></pre>
<h2 id="source-reference-4"><a class="header" href="#source-reference-4">Source Reference</a></h2>
<ul>
<li><code>tensor_chain/src/codebook.rs</code> - Codebook implementations</li>
<li><code>tensor_store/src/lib.rs</code> - KMeans clustering</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="worked-examples"><a class="header" href="#worked-examples">Worked Examples</a></h1>
<p>This tutorial demonstrates tensor_chain’s conflict detection, deadlock
resolution, and orthogonal transaction merging through detailed scenarios.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li>Understanding of transaction workspaces</li>
<li>Familiarity with delta embeddings</li>
<li>Basic knowledge of distributed transactions</li>
</ul>
<h2 id="scenario-1-semantic-conflict-detection"><a class="header" href="#scenario-1-semantic-conflict-detection">Scenario 1: Semantic Conflict Detection</a></h2>
<p>Two transactions modify overlapping data. The system detects the conflict
using delta embedding similarity.</p>
<h3 id="setup"><a class="header" href="#setup">Setup</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::{TensorStore, TransactionManager};
use tensor_chain::block::Transaction;

let store = TensorStore::new();
let manager = TransactionManager::new();

// Initialize account data
store.put("account:1", serialize(&amp;Account { balance: 1000 }))?;
store.put("account:2", serialize(&amp;Account { balance: 2000 }))?;
<span class="boring">}</span></code></pre></pre>
<h3 id="transaction-execution"><a class="header" href="#transaction-execution">Transaction Execution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Transaction A: Transfer from account:1 to account:2
let tx_a = manager.begin(&amp;store)?;
tx_a.add_operation(Transaction::Put {
    key: "account:1".to_string(),
    data: serialize(&amp;Account { balance: 900 }),  // -100
})?;
tx_a.add_operation(Transaction::Put {
    key: "account:2".to_string(),
    data: serialize(&amp;Account { balance: 2100 }), // +100
})?;

// Transaction B: Transfer from account:1 to account:3 (conflicts on account:1)
let tx_b = manager.begin(&amp;store)?;
tx_b.add_operation(Transaction::Put {
    key: "account:1".to_string(),
    data: serialize(&amp;Account { balance: 800 }),  // -200
})?;
tx_b.add_operation(Transaction::Put {
    key: "account:3".to_string(),
    data: serialize(&amp;Account { balance: 200 }),  // +200
})?;
<span class="boring">}</span></code></pre></pre>
<h3 id="conflict-detection-flow"><a class="header" href="#conflict-detection-flow">Conflict Detection Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant A as Transaction A
    participant B as Transaction B
    participant CM as ConsensusManager

    A-&gt;&gt;A: compute_delta()
    Note over A: delta_a = [0.8, 0.2, 0.0, 0.0]
    B-&gt;&gt;B: compute_delta()
    Note over B: delta_b = [0.9, 0.0, 0.1, 0.0]

    A-&gt;&gt;CM: prepare(delta_a)
    B-&gt;&gt;CM: prepare(delta_b)

    CM-&gt;&gt;CM: cosine_similarity(delta_a, delta_b)
    Note over CM: similarity = 0.72 (HIGH)

    CM-&gt;&gt;A: Vote::Yes
    CM-&gt;&gt;B: Vote::Conflict(similarity=0.72, tx=A)

    A-&gt;&gt;A: commit()
    B-&gt;&gt;B: abort() + retry
</pre>
<h3 id="classification-table"><a class="header" href="#classification-table">Classification Table</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Similarity Range</th><th>Classification</th><th>Action</th></tr></thead><tbody>
<tr><td>0.0 - 0.1</td><td>Orthogonal</td><td>Parallel commit OK</td></tr>
<tr><td>0.1 - 0.5</td><td>Low overlap</td><td>Merge possible</td></tr>
<tr><td>0.5 - 0.9</td><td>Conflicting</td><td>Serialize execution</td></tr>
<tr><td>0.9 - 1.0</td><td>Parallel</td><td>Abort one</td></tr>
</tbody></table>
</div>
<h3 id="application-retry-logic"><a class="header" href="#application-retry-logic">Application Retry Logic</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Retry with exponential backoff
let mut attempt = 0;
let max_attempts = 5;

loop {
    let workspace = manager.begin(&amp;store)?;

    // Re-read current state
    let account = store.get("account:1")?;

    // Apply changes
    workspace.add_operation(Transaction::Put {
        key: "account:1".to_string(),
        data: serialize(&amp;Account {
            balance: account.balance - 200,
        }),
    })?;

    // Try to commit
    match commit_with_conflict_check(&amp;workspace, &amp;manager) {
        Ok(()) =&gt; break,
        Err(ConflictError { similarity, .. }) =&gt; {
            attempt += 1;
            if attempt &gt;= max_attempts {
                return Err("max retries exceeded");
            }

            // Exponential backoff with jitter
            let backoff = (100 * 2u64.pow(attempt)) + rand::random::&lt;u64&gt;() % 50;
            std::thread::sleep(Duration::from_millis(backoff));
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="scenario-2-deadlock-detection-and-resolution"><a class="header" href="#scenario-2-deadlock-detection-and-resolution">Scenario 2: Deadlock Detection and Resolution</a></h2>
<p>Two transactions wait on each other’s locks, creating a cycle in the
wait-for graph.</p>
<h3 id="setup-1"><a class="header" href="#setup-1">Setup</a></h3>
<pre><code class="language-text">Transaction T1: needs locks on [key_A, key_B]
Transaction T2: needs locks on [key_B, key_A]

Timeline:
  T1 acquires key_A
  T2 acquires key_B
  T1 waits for key_B (held by T2)
  T2 waits for key_A (held by T1)
  -&gt; DEADLOCK
</code></pre>
<h3 id="wait-for-graph"><a class="header" href="#wait-for-graph">Wait-For Graph</a></h3>
<pre class="mermaid">flowchart LR
    T1((T1)) --&gt;|waits for key_B| T2((T2))
    T2 --&gt;|waits for key_A| T1
</pre>
<h3 id="detection-flow"><a class="header" href="#detection-flow">Detection Flow</a></h3>
<pre class="mermaid">sequenceDiagram
    participant T1 as Transaction 1
    participant T2 as Transaction 2
    participant LM as LockManager
    participant WG as WaitForGraph
    participant DD as DeadlockDetector

    T1-&gt;&gt;LM: try_lock(key_A)
    LM-&gt;&gt;T1: Ok(handle_1)

    T2-&gt;&gt;LM: try_lock(key_B)
    LM-&gt;&gt;T2: Ok(handle_2)

    T1-&gt;&gt;LM: try_lock(key_B)
    LM-&gt;&gt;WG: add_wait(T1, T2)
    LM-&gt;&gt;T1: Err(blocked by T2)

    T2-&gt;&gt;LM: try_lock(key_A)
    LM-&gt;&gt;WG: add_wait(T2, T1)
    LM-&gt;&gt;T2: Err(blocked by T1)

    DD-&gt;&gt;WG: detect_cycle()
    WG-&gt;&gt;DD: Some([T1, T2])

    DD-&gt;&gt;DD: select_victim(T2)
    DD-&gt;&gt;T2: abort()
    DD-&gt;&gt;LM: release(T2)
    DD-&gt;&gt;WG: remove(T2)

    T1-&gt;&gt;LM: try_lock(key_B)
    LM-&gt;&gt;T1: Ok(handle_3)
</pre>
<h3 id="victim-selection-1"><a class="header" href="#victim-selection-1">Victim Selection</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Weight</th><th>Description</th></tr></thead><tbody>
<tr><td>Lock count</td><td>0.3</td><td>Fewer locks = preferred victim</td></tr>
<tr><td>Transaction age</td><td>0.3</td><td>Younger = preferred victim</td></tr>
<tr><td>Priority</td><td>0.4</td><td>Lower priority = preferred victim</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn select_victim(cycle: &amp;[u64], priorities: &amp;HashMap&lt;u64, u32&gt;) -&gt; u64 {
    cycle
        .iter()
        .min_by_key(|&amp;&amp;tx_id| {
            let priority = priorities.get(&amp;tx_id).copied().unwrap_or(0);
            let lock_count = lock_manager.lock_count_for_transaction(tx_id);
            (priority, lock_count)
        })
        .copied()
        .unwrap()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-20"><a class="header" href="#configuration-20">Configuration</a></h3>
<pre><code class="language-toml">[deadlock]
detection_interval_ms = 100
max_cycle_length = 10
victim_selection = "youngest"  # or "lowest_priority", "fewest_locks"
</code></pre>
<h2 id="scenario-3-orthogonal-transaction-merging"><a class="header" href="#scenario-3-orthogonal-transaction-merging">Scenario 3: Orthogonal Transaction Merging</a></h2>
<p>Two transactions modify non-overlapping data with orthogonal delta
embeddings. They can be committed in parallel.</p>
<h3 id="setup-2"><a class="header" href="#setup-2">Setup</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Transaction A: Update user preferences
let tx_a = manager.begin(&amp;store)?;
tx_a.add_operation(Transaction::Put {
    key: "user:1:prefs".to_string(),
    data: serialize(&amp;Preferences { theme: "dark" }),
})?;
tx_a.set_before_embedding(vec![0.0; 128]);
tx_a.compute_delta(vec![1.0, 0.0, 0.0, 0.0]);  // Direction: X

// Transaction B: Update product inventory
let tx_b = manager.begin(&amp;store)?;
tx_b.add_operation(Transaction::Put {
    key: "product:42:stock".to_string(),
    data: serialize(&amp;Stock { quantity: 100 }),
})?;
tx_b.set_before_embedding(vec![0.0; 128]);
tx_b.compute_delta(vec![0.0, 1.0, 0.0, 0.0]);  // Direction: Y
<span class="boring">}</span></code></pre></pre>
<h3 id="parallel-commit"><a class="header" href="#parallel-commit">Parallel Commit</a></h3>
<pre class="mermaid">sequenceDiagram
    participant A as Transaction A
    participant B as Transaction B
    participant CM as ConsensusManager
    participant C as Chain

    par Prepare Phase
        A-&gt;&gt;CM: prepare(delta_a)
        B-&gt;&gt;CM: prepare(delta_b)
    end

    CM-&gt;&gt;CM: similarity = 0.0 (ORTHOGONAL)

    par Commit Phase
        CM-&gt;&gt;A: Vote::Yes
        CM-&gt;&gt;B: Vote::Yes
        A-&gt;&gt;C: append(block_a)
        B-&gt;&gt;C: append(block_b)
    end

    Note over C: Both blocks committed
</pre>
<h3 id="orthogonality-analysis"><a class="header" href="#orthogonality-analysis">Orthogonality Analysis</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Transaction A</th><th>Transaction B</th><th>Overlap</th><th>Similarity</th><th>Can Merge?</th></tr></thead><tbody>
<tr><td>user:1:prefs</td><td>product:42:stock</td><td>None</td><td>0.00</td><td>Yes</td></tr>
<tr><td>user:1:balance</td><td>user:2:balance</td><td>None</td><td>0.15</td><td>Yes</td></tr>
<tr><td>user:1:balance</td><td>user:1:prefs</td><td>user:1</td><td>0.30</td><td>Maybe</td></tr>
<tr><td>account:1</td><td>account:1</td><td>Full</td><td>0.95</td><td>No</td></tr>
</tbody></table>
</div>
<h3 id="merge-implementation"><a class="header" href="#merge-implementation">Merge Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Find merge candidates
let candidates = manager.find_merge_candidates(
    &amp;tx_a,
    0.1,      // orthogonal threshold
    60_000,   // merge window (60s)
);

if !candidates.is_empty() {
    // Create merged block with multiple transactions
    let mut merged_ops = tx_a.operations();
    for candidate in &amp;candidates {
        merged_ops.extend(candidate.workspace.operations());
    }

    // Compute merged delta
    let merged_delta = tx_a.to_delta_vector();
    for candidate in &amp;candidates {
        merged_delta = merged_delta.add(&amp;candidate.delta);
    }

    // Single block contains both transactions
    let block = Block::new(header, merged_ops);
    chain.append(block)?;

    // Mark all as committed
    tx_a.mark_committed();
    for candidate in candidates {
        candidate.workspace.mark_committed();
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Scenario</th><th>Detection Method</th><th>Resolution</th></tr></thead><tbody>
<tr><td>Conflict</td><td>Delta similarity &gt; 0.5</td><td>Serialize, retry loser</td></tr>
<tr><td>Deadlock</td><td>Wait-for graph cycle</td><td>Abort victim, retry</td></tr>
<tr><td>Orthogonal</td><td>Delta similarity &lt; 0.1</td><td>Parallel commit/merge</td></tr>
</tbody></table>
</div>
<h2 id="further-reading"><a class="header" href="#further-reading">Further Reading</a></h2>
<ul>
<li><a href="tutorials/../concepts/embedding-state.html">Embedding State Machine</a></li>
<li><a href="tutorials/../architecture/transaction-workspace.html">Transaction Workspace</a></li>
<li><a href="tutorials/../concepts/distributed-transactions.html">Distributed Transactions</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deployment"><a class="header" href="#deployment">Deployment</a></h1>
<h2 id="single-node"><a class="header" href="#single-node">Single Node</a></h2>
<p>For development and testing:</p>
<pre><code class="language-bash">neumann --data-dir ./data
</code></pre>
<h2 id="cluster-deployment"><a class="header" href="#cluster-deployment">Cluster Deployment</a></h2>
<h3 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h3>
<ul>
<li>3, 5, or 7 nodes (odd number for quorum)</li>
<li>Network connectivity between nodes</li>
<li>Synchronized clocks (NTP)</li>
</ul>
<h3 id="configuration-21"><a class="header" href="#configuration-21">Configuration</a></h3>
<p>Each node needs a config file:</p>
<pre><code class="language-toml"># /etc/neumann/config.toml

[node]
id = "node1"
data_dir = "/var/lib/neumann"
bind_address = "0.0.0.0:7878"

[cluster]
peers = [
    "node2:7878",
    "node3:7878",
]

[raft]
election_timeout_min_ms = 150
election_timeout_max_ms = 300
heartbeat_interval_ms = 50

[gossip]
bind_address = "0.0.0.0:7879"
ping_interval_ms = 1000
</code></pre>
<h3 id="starting-the-cluster"><a class="header" href="#starting-the-cluster">Starting the Cluster</a></h3>
<pre><code class="language-bash"># Start first node (will become leader)
neumann --config /etc/neumann/config.toml --bootstrap

# Start remaining nodes
neumann --config /etc/neumann/config.toml
</code></pre>
<h3 id="verify-cluster-health"><a class="header" href="#verify-cluster-health">Verify Cluster Health</a></h3>
<pre><code class="language-bash"># Check cluster status
curl http://node1:9090/health

# View membership
neumann-admin cluster-status
</code></pre>
<h2 id="docker-compose-1"><a class="header" href="#docker-compose-1">Docker Compose</a></h2>
<pre><code class="language-yaml">version: '3.8'
services:
  node1:
    image: neumann/neumann:latest
    environment:
      - NEUMANN_NODE_ID=node1
      - NEUMANN_PEERS=node2:7878,node3:7878
    ports:
      - "7878:7878"
      - "9090:9090"
    volumes:
      - node1-data:/var/lib/neumann

  node2:
    image: neumann/neumann:latest
    environment:
      - NEUMANN_NODE_ID=node2
      - NEUMANN_PEERS=node1:7878,node3:7878
    volumes:
      - node2-data:/var/lib/neumann

  node3:
    image: neumann/neumann:latest
    environment:
      - NEUMANN_NODE_ID=node3
      - NEUMANN_PEERS=node1:7878,node2:7878
    volumes:
      - node3-data:/var/lib/neumann

volumes:
  node1-data:
  node2-data:
  node3-data:
</code></pre>
<h2 id="kubernetes"><a class="header" href="#kubernetes">Kubernetes</a></h2>
<p>See the Helm chart in <code>deploy/helm/neumann/</code>.</p>
<pre><code class="language-bash">helm install neumann ./deploy/helm/neumann \
  --set replicas=3 \
  --set persistence.size=100Gi
</code></pre>
<h2 id="production-checklist"><a class="header" href="#production-checklist">Production Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Odd number of nodes (3, 5, or 7)</li>
<li><input disabled="" type="checkbox"/>
Nodes in separate availability zones</li>
<li><input disabled="" type="checkbox"/>
NTP configured and synchronized</li>
<li><input disabled="" type="checkbox"/>
Firewall rules for ports 7878, 7879, 9090</li>
<li><input disabled="" type="checkbox"/>
Monitoring and alerting configured</li>
<li><input disabled="" type="checkbox"/>
Backup strategy in place</li>
<li><input disabled="" type="checkbox"/>
Resource limits set appropriately</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-22"><a class="header" href="#configuration-22">Configuration</a></h1>
<h2 id="configuration-sources"><a class="header" href="#configuration-sources">Configuration Sources</a></h2>
<p>Configuration is loaded in order (later overrides earlier):</p>
<ol>
<li>Default values</li>
<li>Config file (<code>/etc/neumann/config.toml</code>)</li>
<li>Environment variables (<code>NEUMANN_*</code>)</li>
<li>Command-line flags</li>
</ol>
<h2 id="config-file-format"><a class="header" href="#config-file-format">Config File Format</a></h2>
<pre><code class="language-toml">[node]
id = "node1"
data_dir = "/var/lib/neumann"
bind_address = "0.0.0.0:7878"

[cluster]
peers = ["node2:7878", "node3:7878"]

[raft]
election_timeout_min_ms = 150
election_timeout_max_ms = 300
heartbeat_interval_ms = 50
max_entries_per_append = 100
snapshot_interval = 10000

[gossip]
bind_address = "0.0.0.0:7879"
ping_interval_ms = 1000
ping_timeout_ms = 500
suspect_timeout_ms = 3000
indirect_ping_count = 3

[transaction]
prepare_timeout_ms = 5000
commit_timeout_ms = 5000
lock_timeout_ms = 5000
max_concurrent_tx = 1000

[deadlock]
enabled = true
detection_interval_ms = 100
victim_policy = "youngest"
auto_abort_victim = true

[storage]
max_memory_mb = 1024
wal_sync_mode = "fsync"
compression = "lz4"

[metrics]
enabled = true
bind_address = "0.0.0.0:9090"
</code></pre>
<h2 id="environment-variables-2"><a class="header" href="#environment-variables-2">Environment Variables</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Config Path</th><th>Example</th></tr></thead><tbody>
<tr><td><code>NEUMANN_NODE_ID</code></td><td><code>node.id</code></td><td><code>node1</code></td></tr>
<tr><td><code>NEUMANN_DATA_DIR</code></td><td><code>node.data_dir</code></td><td><code>/var/lib/neumann</code></td></tr>
<tr><td><code>NEUMANN_PEERS</code></td><td><code>cluster.peers</code></td><td><code>node2:7878,node3:7878</code></td></tr>
<tr><td><code>NEUMANN_LOG_LEVEL</code></td><td>—</td><td><code>info</code></td></tr>
</tbody></table>
</div>
<h2 id="command-line-flags"><a class="header" href="#command-line-flags">Command-Line Flags</a></h2>
<pre><code class="language-bash">neumann \
  --config /etc/neumann/config.toml \
  --node-id node1 \
  --data-dir /var/lib/neumann \
  --bind 0.0.0.0:7878 \
  --bootstrap \
  --log-level debug
</code></pre>
<h2 id="key-parameters"><a class="header" href="#key-parameters">Key Parameters</a></h2>
<h3 id="raft-tuning"><a class="header" href="#raft-tuning">Raft Tuning</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Tuning</th></tr></thead><tbody>
<tr><td><code>election_timeout_min_ms</code></td><td>150</td><td>Increase for high-latency networks</td></tr>
<tr><td><code>election_timeout_max_ms</code></td><td>300</td><td>Should be 2x min</td></tr>
<tr><td><code>heartbeat_interval_ms</code></td><td>50</td><td>Lower for faster failure detection</td></tr>
<tr><td><code>snapshot_interval</code></td><td>10000</td><td>Higher for less I/O, slower recovery</td></tr>
</tbody></table>
</div>
<h3 id="transaction-tuning"><a class="header" href="#transaction-tuning">Transaction Tuning</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Tuning</th></tr></thead><tbody>
<tr><td><code>prepare_timeout_ms</code></td><td>5000</td><td>Increase for slow networks</td></tr>
<tr><td><code>lock_timeout_ms</code></td><td>5000</td><td>Lower to fail fast on contention</td></tr>
<tr><td><code>max_concurrent_tx</code></td><td>1000</td><td>Based on memory and CPU</td></tr>
</tbody></table>
</div>
<h3 id="storage-tuning"><a class="header" href="#storage-tuning">Storage Tuning</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Tuning</th></tr></thead><tbody>
<tr><td><code>max_memory_mb</code></td><td>1024</td><td>Based on available RAM</td></tr>
<tr><td><code>wal_sync_mode</code></td><td><code>fsync</code></td><td><code>none</code> for speed (data loss risk)</td></tr>
<tr><td><code>compression</code></td><td><code>lz4</code></td><td><code>none</code> for speed, <code>zstd</code> for ratio</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="monitoring-1"><a class="header" href="#monitoring-1">Monitoring</a></h1>
<h2 id="metrics-endpoint"><a class="header" href="#metrics-endpoint">Metrics Endpoint</a></h2>
<p>Prometheus metrics are exposed at <code>http://node:9090/metrics</code>.</p>
<h2 id="key-metrics"><a class="header" href="#key-metrics">Key Metrics</a></h2>
<h3 id="raft-consensus-2"><a class="header" href="#raft-consensus-2">Raft Consensus</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tensor_chain_raft_state</code></td><td>Gauge</td><td>Current state (follower=0, candidate=1, leader=2)</td></tr>
<tr><td><code>tensor_chain_term</code></td><td>Gauge</td><td>Current Raft term</td></tr>
<tr><td><code>tensor_chain_commit_index</code></td><td>Gauge</td><td>Highest committed log index</td></tr>
<tr><td><code>tensor_chain_applied_index</code></td><td>Gauge</td><td>Highest applied log index</td></tr>
<tr><td><code>tensor_chain_elections_total</code></td><td>Counter</td><td>Total elections started</td></tr>
<tr><td><code>tensor_chain_append_entries_total</code></td><td>Counter</td><td>Total AppendEntries RPCs</td></tr>
</tbody></table>
</div>
<h3 id="transactions"><a class="header" href="#transactions">Transactions</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tensor_chain_tx_active</code></td><td>Gauge</td><td>Currently active transactions</td></tr>
<tr><td><code>tensor_chain_tx_commits_total</code></td><td>Counter</td><td>Total committed transactions</td></tr>
<tr><td><code>tensor_chain_tx_aborts_total</code></td><td>Counter</td><td>Total aborted transactions</td></tr>
<tr><td><code>tensor_chain_tx_latency_seconds</code></td><td>Histogram</td><td>Transaction latency</td></tr>
</tbody></table>
</div>
<h3 id="deadlock-detection-2"><a class="header" href="#deadlock-detection-2">Deadlock Detection</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tensor_chain_deadlocks_total</code></td><td>Counter</td><td>Total deadlocks detected</td></tr>
<tr><td><code>tensor_chain_deadlock_victims_total</code></td><td>Counter</td><td>Transactions aborted as victims</td></tr>
<tr><td><code>tensor_chain_wait_graph_size</code></td><td>Gauge</td><td>Current wait-for graph size</td></tr>
</tbody></table>
</div>
<h3 id="gossip"><a class="header" href="#gossip">Gossip</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tensor_chain_gossip_members</code></td><td>Gauge</td><td>Known cluster members</td></tr>
<tr><td><code>tensor_chain_gossip_healthy</code></td><td>Gauge</td><td>Healthy members</td></tr>
<tr><td><code>tensor_chain_gossip_suspect</code></td><td>Gauge</td><td>Suspect members</td></tr>
<tr><td><code>tensor_chain_gossip_failed</code></td><td>Gauge</td><td>Failed members</td></tr>
</tbody></table>
</div>
<h3 id="storage"><a class="header" href="#storage">Storage</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>tensor_chain_entries_total</code></td><td>Gauge</td><td>Total stored entries</td></tr>
<tr><td><code>tensor_chain_memory_bytes</code></td><td>Gauge</td><td>Memory usage</td></tr>
<tr><td><code>tensor_chain_disk_bytes</code></td><td>Gauge</td><td>Disk usage</td></tr>
<tr><td><code>tensor_chain_wal_size_bytes</code></td><td>Gauge</td><td>WAL file size</td></tr>
</tbody></table>
</div>
<h2 id="prometheus-configuration"><a class="header" href="#prometheus-configuration">Prometheus Configuration</a></h2>
<pre><code class="language-yaml">scrape_configs:
  - job_name: 'neumann'
    static_configs:
      - targets:
        - 'node1:9090'
        - 'node2:9090'
        - 'node3:9090'
</code></pre>
<h2 id="grafana-dashboard"><a class="header" href="#grafana-dashboard">Grafana Dashboard</a></h2>
<p>Import the dashboard from <code>deploy/grafana/neumann-dashboard.json</code>.</p>
<p>Panels include:</p>
<ul>
<li>Cluster overview (leader, term, members)</li>
<li>Transaction throughput and latency</li>
<li>Replication lag</li>
<li>Memory and disk usage</li>
<li>Deadlock rate</li>
</ul>
<h2 id="alerting-rules"><a class="header" href="#alerting-rules">Alerting Rules</a></h2>
<p>See <code>docs/book/src/operations/runbooks/</code> for alert definitions.</p>
<pre><code class="language-yaml">groups:
  - name: neumann
    rules:
      - alert: NoLeader
        expr: sum(tensor_chain_raft_state{state="leader"}) == 0
        for: 30s
        labels:
          severity: critical

      - alert: HighReplicationLag
        expr: tensor_chain_commit_index - tensor_chain_applied_index &gt; 1000
        for: 1m
        labels:
          severity: warning

      - alert: HighDeadlockRate
        expr: rate(tensor_chain_deadlocks_total[5m]) &gt; 1
        for: 5m
        labels:
          severity: warning
</code></pre>
<h2 id="health-endpoint"><a class="header" href="#health-endpoint">Health Endpoint</a></h2>
<pre><code class="language-bash">curl http://node:9090/health
</code></pre>
<p>Response:</p>
<pre><code class="language-json">{
  "status": "healthy",
  "raft_state": "leader",
  "term": 42,
  "commit_index": 12345,
  "members": 3,
  "healthy_members": 3
}
</code></pre>
<h2 id="logging-1"><a class="header" href="#logging-1">Logging</a></h2>
<p>Configure log level:</p>
<pre><code class="language-bash">RUST_LOG=tensor_chain=debug neumann
</code></pre>
<p>Log levels: <code>error</code>, <code>warn</code>, <code>info</code>, <code>debug</code>, <code>trace</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h1>
<h2 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h2>
<h3 id="node-wont-start"><a class="header" href="#node-wont-start">Node Won’t Start</a></h3>
<p><strong>Symptom</strong>: Node exits immediately or fails to bind</p>
<p><strong>Check</strong>:</p>
<pre><code class="language-bash"># Port already in use
lsof -i :7878
lsof -i :9090

# Permissions
ls -la /var/lib/neumann

# Config syntax
neumann --config /etc/neumann/config.toml --validate
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Kill conflicting process</li>
<li>Fix directory permissions: <code>chown -R neumann:neumann /var/lib/neumann</code></li>
<li>Fix config syntax errors</li>
</ul>
<h3 id="cant-connect-to-cluster"><a class="header" href="#cant-connect-to-cluster">Can’t Connect to Cluster</a></h3>
<p><strong>Symptom</strong>: Client connections timeout</p>
<p><strong>Check</strong>:</p>
<pre><code class="language-bash"># Network connectivity
nc -zv node1 7878

# Firewall rules
iptables -L -n | grep 7878

# Node health
curl http://node1:9090/health
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Open firewall ports 7878, 7879, 9090</li>
<li>Check DNS resolution</li>
<li>Verify node is running</li>
</ul>
<h3 id="slow-performance"><a class="header" href="#slow-performance">Slow Performance</a></h3>
<p><strong>Symptom</strong>: High latency, low throughput</p>
<p><strong>Check</strong>:</p>
<pre><code class="language-bash"># Metrics
curl http://node1:9090/metrics | grep -E "(latency|throughput)"

# Disk I/O
iostat -x 1

# Memory
free -h

# CPU
top -p $(pgrep neumann)
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Increase memory allocation</li>
<li>Use faster storage (NVMe)</li>
<li>Tune Raft parameters</li>
<li>Add more nodes for read scaling</li>
</ul>
<h3 id="data-inconsistency"><a class="header" href="#data-inconsistency">Data Inconsistency</a></h3>
<p><strong>Symptom</strong>: Different nodes return different data</p>
<p><strong>Check</strong>:</p>
<pre><code class="language-bash"># Compare commit indices
for node in node1 node2 node3; do
  curl -s http://$node:9090/metrics | grep commit_index
done

# Check for partitions
neumann-admin cluster-status
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Wait for replication to catch up</li>
<li>Check network connectivity</li>
<li>Follow <a href="operations/runbooks/split-brain.html">split-brain runbook</a> if partitioned</li>
</ul>
<h3 id="high-memory-usage"><a class="header" href="#high-memory-usage">High Memory Usage</a></h3>
<p><strong>Symptom</strong>: OOM kills, swap usage</p>
<p><strong>Check</strong>:</p>
<pre><code class="language-bash"># Memory breakdown
curl http://node1:9090/metrics | grep memory

# Process memory
ps aux | grep neumann
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Increase <code>max_memory_mb</code> config</li>
<li>Trigger snapshot to reduce log size</li>
<li>Add more nodes to distribute load</li>
</ul>
<h3 id="wal-growing-too-large"><a class="header" href="#wal-growing-too-large">WAL Growing Too Large</a></h3>
<p><strong>Symptom</strong>: Disk filling up</p>
<p><strong>Check</strong>:</p>
<pre><code class="language-bash"># WAL size
du -sh /var/lib/neumann/wal/

# Snapshot status
ls -la /var/lib/neumann/snapshots/
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Trigger manual snapshot: <code>curl -X POST http://node:9090/admin/snapshot</code></li>
<li>Reduce <code>snapshot_interval</code></li>
<li>Add more disk space</li>
</ul>
<h2 id="debug-logging"><a class="header" href="#debug-logging">Debug Logging</a></h2>
<p>Enable detailed logging:</p>
<pre><code class="language-bash">RUST_LOG=tensor_chain=debug,tower=warn neumann
</code></pre>
<p>For specific modules:</p>
<pre><code class="language-bash">RUST_LOG=tensor_chain::raft=trace,tensor_chain::gossip=debug neumann
</code></pre>
<h2 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h2>
<ol>
<li>Check the <a href="operations/runbooks/index.html">runbooks</a> for specific scenarios</li>
<li>Search <a href="https://github.com/Shadylukin/Neumann/issues">GitHub issues</a></li>
<li>Open a new issue with:
<ul>
<li>Neumann version</li>
<li>Configuration (redact secrets)</li>
<li>Relevant logs</li>
<li>Steps to reproduce</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="example-configurations"><a class="header" href="#example-configurations">Example Configurations</a></h1>
<p>This page provides complete configuration examples for different deployment
scenarios.</p>
<h2 id="development-single-node"><a class="header" href="#development-single-node">Development (Single Node)</a></h2>
<p>Minimal configuration for local development and testing.</p>
<pre><code class="language-toml">[node]
id = "dev-node"
data_dir = "./data"

[cluster]
# Single node cluster - no seeds needed
seeds = []
port = 9100

# Disable TLS for development
[tls]
enabled = false

# Minimal rate limiting
[rate_limit]
enabled = false

# No compression for easier debugging
[compression]
enabled = false

# Shorter timeouts for faster feedback
[transactions]
timeout_ms = 1000
lock_timeout_ms = 500

# Verbose logging
[logging]
level = "debug"
format = "pretty"
</code></pre>
<h2 id="production-3-node-cluster"><a class="header" href="#production-3-node-cluster">Production (3-Node Cluster)</a></h2>
<p>Standard production configuration with TLS, rate limiting, and tuned
timeouts.</p>
<pre><code class="language-toml"># === Node Configuration ===
[node]
id = "node1"
data_dir = "/var/lib/neumann/data"
# Bind to all interfaces
bind_address = "0.0.0.0"

# === Cluster Configuration ===
[cluster]
seeds = ["node1.example.com:9100", "node2.example.com:9100", "node3.example.com:9100"]
port = 9100
# Cluster name for identification
name = "production"

# === TLS Configuration ===
[tls]
enabled = true
cert_path = "/etc/neumann/node1.crt"
key_path = "/etc/neumann/node1.key"
ca_cert_path = "/etc/neumann/ca.crt"
# Require mutual TLS
require_client_auth = true
# Verify node identity matches certificate
node_id_verification = "CommonName"

# === TCP Transport ===
[tcp]
# Connections per peer
pool_size = 4
# Connection timeout
connect_timeout_ms = 5000
# Read/write timeout
io_timeout_ms = 30000
# Enable keepalive
keepalive = true
keepalive_interval_secs = 30
# Maximum message size (16 MB)
max_message_size = 16777216
# Outbound queue size
max_pending_messages = 1000

# === Rate Limiting ===
[rate_limit]
enabled = true
# Burst capacity
bucket_size = 100
# Tokens per second
refill_rate = 50.0

# === Compression ===
[compression]
enabled = true
method = "Lz4"
# Only compress messages &gt; 256 bytes
min_size = 256

# === Transactions ===
[transactions]
# Transaction timeout
timeout_ms = 5000
# Lock timeout
lock_timeout_ms = 30000
# Default embedding dimension
embedding_dimension = 128

# === Conflict Detection ===
[consensus]
# Similarity threshold for conflict
conflict_threshold = 0.5
# Threshold for orthogonal merge
orthogonal_threshold = 0.1
# Merge window
merge_window_ms = 60000

# === Deadlock Detection ===
[deadlock]
enabled = true
detection_interval_ms = 100
max_cycle_length = 10

# === Snapshots ===
[snapshots]
# Memory threshold before disk spill
max_memory_bytes = 268435456  # 256 MB
# Snapshot interval
interval_secs = 3600
# Retention count
retain_count = 3

# === Metrics ===
[metrics]
enabled = true
# Prometheus endpoint
endpoint = "0.0.0.0:9090"
# Include detailed histograms
detailed = true

# === Logging ===
[logging]
level = "info"
format = "json"
# Log to file
file = "/var/log/neumann/neumann.log"
# Rotate logs
max_size_mb = 100
max_files = 10
</code></pre>
<h2 id="high-throughput-5-node"><a class="header" href="#high-throughput-5-node">High-Throughput (5-Node)</a></h2>
<p>Optimized configuration for maximum write throughput.</p>
<pre><code class="language-toml">[node]
id = "node1"
data_dir = "/var/lib/neumann/data"

[cluster]
seeds = [
    "node1.example.com:9100",
    "node2.example.com:9100",
    "node3.example.com:9100",
    "node4.example.com:9100",
    "node5.example.com:9100",
]
port = 9100
name = "high-throughput"

# === TLS (same as production) ===
[tls]
enabled = true
cert_path = "/etc/neumann/node1.crt"
key_path = "/etc/neumann/node1.key"
ca_cert_path = "/etc/neumann/ca.crt"
require_client_auth = true

# === TCP - Optimized for throughput ===
[tcp]
# More connections for parallelism
pool_size = 8
# Shorter timeouts for faster failover
connect_timeout_ms = 2000
io_timeout_ms = 10000
keepalive = true
keepalive_interval_secs = 15
# Larger message size for batching
max_message_size = 67108864  # 64 MB
# Larger queues for buffering
max_pending_messages = 5000
recv_buffer_size = 5000

# === Rate Limiting - Permissive ===
[rate_limit]
enabled = true
bucket_size = 500
refill_rate = 250.0

# === Compression - Aggressive ===
[compression]
enabled = true
method = "Lz4"
# Compress even small messages
min_size = 64

# === Transactions - Fast ===
[transactions]
timeout_ms = 2000
lock_timeout_ms = 5000
embedding_dimension = 64  # Smaller for speed

# === Consensus - Optimized ===
[consensus]
# Lower thresholds for more merging
conflict_threshold = 0.7
orthogonal_threshold = 0.2
merge_window_ms = 30000

# === Deadlock - Frequent checks ===
[deadlock]
enabled = true
detection_interval_ms = 50

# === Raft - Tuned for throughput ===
[raft]
# Batch more entries
max_entries_per_append = 1000
# Shorter election timeout
election_timeout_ms = 500
# Faster heartbeats
heartbeat_interval_ms = 100

# === Snapshots - Less frequent ===
[snapshots]
max_memory_bytes = 536870912  # 512 MB
interval_secs = 7200
retain_count = 2
</code></pre>
<h2 id="geo-distributed-multi-region"><a class="header" href="#geo-distributed-multi-region">Geo-Distributed (Multi-Region)</a></h2>
<p>Configuration for clusters spanning multiple geographic regions with higher
latency tolerance.</p>
<pre><code class="language-toml">[node]
id = "node1-us-east"
data_dir = "/var/lib/neumann/data"
region = "us-east-1"

[cluster]
seeds = [
    "node1-us-east.example.com:9100",
    "node2-us-west.example.com:9100",
    "node3-eu-west.example.com:9100",
]
port = 9100
name = "geo-distributed"

# === TLS (same as production) ===
[tls]
enabled = true
cert_path = "/etc/neumann/node1-us-east.crt"
key_path = "/etc/neumann/node1-us-east.key"
ca_cert_path = "/etc/neumann/ca.crt"
require_client_auth = true

# === TCP - WAN optimized ===
[tcp]
pool_size = 4
# Longer timeouts for cross-region latency
connect_timeout_ms = 10000
io_timeout_ms = 60000
keepalive = true
# More frequent keepalives to detect failures
keepalive_interval_secs = 10
max_message_size = 16777216

# === Rate Limiting - Standard ===
[rate_limit]
enabled = true
bucket_size = 100
refill_rate = 50.0

# === Compression - Always on for WAN ===
[compression]
enabled = true
method = "Lz4"
min_size = 128

# === Transactions - Longer timeouts ===
[transactions]
# Higher timeout for cross-region coordination
timeout_ms = 15000
lock_timeout_ms = 60000
embedding_dimension = 128

# === Consensus - Relaxed for latency ===
[consensus]
conflict_threshold = 0.5
orthogonal_threshold = 0.1
# Longer merge window for slow convergence
merge_window_ms = 120000

# === Deadlock - Less frequent for WAN ===
[deadlock]
enabled = true
detection_interval_ms = 500

# === Raft - WAN tuned ===
[raft]
max_entries_per_append = 100
# Longer election timeout for WAN latency
election_timeout_ms = 3000
heartbeat_interval_ms = 500
# Enable pre-vote to prevent disruption during partitions
pre_vote = true

# === Snapshots ===
[snapshots]
max_memory_bytes = 268435456
interval_secs = 3600
retain_count = 5

# === Reconnection - Aggressive ===
[reconnection]
enabled = true
initial_backoff_ms = 500
max_backoff_ms = 60000
multiplier = 2.0
jitter = 0.2

# === Region awareness ===
[region]
# Prefer local reads
local_read_preference = true
# Region priority for leader election
priority = 1
</code></pre>
<h2 id="configuration-reference"><a class="header" href="#configuration-reference">Configuration Reference</a></h2>
<h3 id="environment-variables-3"><a class="header" href="#environment-variables-3">Environment Variables</a></h3>
<p>All configuration values can be overridden with environment variables:</p>
<pre><code class="language-bash">NEUMANN_NODE_ID=node1
NEUMANN_CLUSTER_PORT=9100
NEUMANN_TLS_ENABLED=true
NEUMANN_LOGGING_LEVEL=debug
</code></pre>
<h3 id="configuration-precedence"><a class="header" href="#configuration-precedence">Configuration Precedence</a></h3>
<ol>
<li>Environment variables (highest)</li>
<li>Command-line arguments</li>
<li>Configuration file</li>
<li>Default values (lowest)</li>
</ol>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<ul>
<li><a href="operations/configuration.html">Configuration Reference</a></li>
<li><a href="operations/monitoring.html">Monitoring</a></li>
<li><a href="operations/troubleshooting.html">Troubleshooting</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="runbooks"><a class="header" href="#runbooks">Runbooks</a></h1>
<p>Operational runbooks for managing Neumann clusters, focusing on tensor_chain
distributed operations.</p>
<h2 id="available-runbooks"><a class="header" href="#available-runbooks">Available Runbooks</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Runbook</th><th>Scenario</th><th>Severity</th></tr></thead><tbody>
<tr><td><a href="operations/runbooks/leader-election.html">Leader Election</a></td><td>Cluster has no leader</td><td>Critical</td></tr>
<tr><td><a href="operations/runbooks/split-brain.html">Split-Brain Recovery</a></td><td>Network partition healed</td><td>Critical</td></tr>
<tr><td><a href="operations/runbooks/node-recovery.html">Node Recovery</a></td><td>Node crash or disk failure</td><td>High</td></tr>
<tr><td><a href="operations/runbooks/backup-restore.html">Backup and Restore</a></td><td>Data backup and disaster recovery</td><td>High</td></tr>
<tr><td><a href="operations/runbooks/capacity-planning.html">Capacity Planning</a></td><td>Resource sizing and scaling</td><td>Medium</td></tr>
<tr><td><a href="operations/runbooks/deadlock-resolution.html">Deadlock Resolution</a></td><td>Transaction deadlocks</td><td>Medium</td></tr>
</tbody></table>
</div>
<h2 id="how-to-use-these-runbooks"><a class="header" href="#how-to-use-these-runbooks">How to Use These Runbooks</a></h2>
<ol>
<li><strong>Identify the symptom</strong> from alerts or monitoring</li>
<li><strong>Find the matching runbook</strong> in the table above</li>
<li><strong>Follow the diagnostic steps</strong> to confirm root cause</li>
<li><strong>Execute the resolution steps</strong> in order</li>
<li><strong>Verify recovery</strong> using the provided checks</li>
</ol>
<h2 id="alerting-rules-1"><a class="header" href="#alerting-rules-1">Alerting Rules</a></h2>
<p>Each runbook includes Prometheus alerting rules. Deploy them to your monitoring
stack:</p>
<pre><code class="language-bash"># Copy alerting rules
cp docs/book/src/operations/alerting-rules.yml /etc/prometheus/rules/neumann.yml

# Reload Prometheus
curl -X POST http://prometheus:9090/-/reload
</code></pre>
<h2 id="emergency-contacts"><a class="header" href="#emergency-contacts">Emergency Contacts</a></h2>
<p>For production incidents:</p>
<ol>
<li>Page the on-call engineer</li>
<li>Start an incident channel</li>
<li>Follow the relevant runbook</li>
<li>Document actions taken</li>
<li>Schedule post-incident review</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="node-management"><a class="header" href="#node-management">Node Management</a></h1>
<p>This runbook covers adding and removing nodes from a tensor_chain cluster.</p>
<h2 id="adding-a-node"><a class="header" href="#adding-a-node">Adding a Node</a></h2>
<h3 id="prerequisites-checklist"><a class="header" href="#prerequisites-checklist">Prerequisites Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
New node has network connectivity to existing cluster members</li>
<li><input disabled="" type="checkbox"/>
TLS certificates are configured (if using TLS)</li>
<li><input disabled="" type="checkbox"/>
Node has sufficient disk space for snapshot transfer</li>
<li><input disabled="" type="checkbox"/>
Firewall rules allow traffic on cluster port (default: 9100)</li>
<li><input disabled="" type="checkbox"/>
DNS/hostname resolution configured for the new node</li>
</ul>
<h3 id="symptoms-why-add-a-node"><a class="header" href="#symptoms-why-add-a-node">Symptoms (Why Add a Node)</a></h3>
<ul>
<li>Cluster capacity insufficient for workload</li>
<li>Need additional replicas for fault tolerance</li>
<li>Geographic distribution requirements</li>
<li>Performance scaling requirements</li>
</ul>
<h3 id="procedure"><a class="header" href="#procedure">Procedure</a></h3>
<h4 id="step-1-prepare-the-new-node"><a class="header" href="#step-1-prepare-the-new-node">Step 1: Prepare the new node</a></h4>
<pre><code class="language-bash"># Install Neumann on the new node
cargo install neumann --version X.Y.Z

# Create configuration directory
mkdir -p /etc/neumann
mkdir -p /var/lib/neumann/data

# Copy TLS certificates (if using TLS)
scp admin@existing-node:/etc/neumann/ca.crt /etc/neumann/
# Generate node-specific certificates
./scripts/generate-node-cert.sh node4
</code></pre>
<h4 id="step-2-configure-the-new-node"><a class="header" href="#step-2-configure-the-new-node">Step 2: Configure the new node</a></h4>
<p>Create <code>/etc/neumann/config.toml</code>:</p>
<pre><code class="language-toml">[node]
id = "node4"
data_dir = "/var/lib/neumann/data"

[cluster]
# Existing cluster members for initial discovery
seeds = ["node1:9100", "node2:9100", "node3:9100"]
port = 9100

[tls]
cert_path = "/etc/neumann/node4.crt"
key_path = "/etc/neumann/node4.key"
ca_cert_path = "/etc/neumann/ca.crt"
</code></pre>
<h4 id="step-3-join-the-cluster"><a class="header" href="#step-3-join-the-cluster">Step 3: Join the cluster</a></h4>
<pre><code class="language-bash"># Start the node in join mode
neumann start --join

# Monitor the join process
neumann status --watch
</code></pre>
<h4 id="step-4-verify-cluster-membership"><a class="header" href="#step-4-verify-cluster-membership">Step 4: Verify cluster membership</a></h4>
<pre><code class="language-bash"># On any existing node
neumann cluster members

# Expected output:
# ID     ADDRESS       STATE     ROLE
# node1  10.0.1.1:9100 healthy   leader
# node2  10.0.1.2:9100 healthy   follower
# node3  10.0.1.3:9100 healthy   follower
# node4  10.0.1.4:9100 healthy   follower  &lt;-- new node
</code></pre>
<h3 id="post-addition-verification"><a class="header" href="#post-addition-verification">Post-Addition Verification</a></h3>
<pre><code class="language-bash"># Verify snapshot transfer completed
neumann status node4 --verbose

# Check replication lag
neumann metrics node4 | grep replication_lag

# Verify the node participates in consensus
neumann raft status
</code></pre>
<h2 id="removing-a-node"><a class="header" href="#removing-a-node">Removing a Node</a></h2>
<h3 id="prerequisites-checklist-1"><a class="header" href="#prerequisites-checklist-1">Prerequisites Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Cluster will maintain quorum after removal</li>
<li><input disabled="" type="checkbox"/>
Node is not the current leader (trigger election first)</li>
<li><input disabled="" type="checkbox"/>
Data has been replicated to other nodes</li>
<li><input disabled="" type="checkbox"/>
No in-flight transactions involving this node</li>
</ul>
<h3 id="symptoms-why-remove-a-node"><a class="header" href="#symptoms-why-remove-a-node">Symptoms (Why Remove a Node)</a></h3>
<ul>
<li>Hardware failure requiring decommission</li>
<li>Cluster right-sizing</li>
<li>Node relocation to different region</li>
<li>Maintenance requiring extended downtime</li>
</ul>
<h3 id="pre-removal-verification"><a class="header" href="#pre-removal-verification">Pre-Removal Verification</a></h3>
<pre><code class="language-bash"># Check current cluster state
neumann cluster members

# Verify quorum will be maintained
# For N nodes, quorum = (N/2) + 1
# 5 nodes -&gt; quorum = 3, can remove 2
# 3 nodes -&gt; quorum = 2, can remove 1
</code></pre>
<h3 id="procedure-1"><a class="header" href="#procedure-1">Procedure</a></h3>
<h4 id="step-1-drain-the-node-graceful-removal"><a class="header" href="#step-1-drain-the-node-graceful-removal">Step 1: Drain the node (graceful removal)</a></h4>
<pre><code class="language-bash"># Mark node as draining (stops accepting new requests)
neumann node drain node3

# Wait for in-flight transactions to complete
neumann node wait-drain node3 --timeout 300
</code></pre>
<h4 id="step-2-transfer-leadership-if-necessary"><a class="header" href="#step-2-transfer-leadership-if-necessary">Step 2: Transfer leadership if necessary</a></h4>
<pre><code class="language-bash"># Check if node is leader
neumann raft status

# If leader, trigger election
neumann raft transfer-leadership --to node1
</code></pre>
<h4 id="step-3-remove-from-cluster"><a class="header" href="#step-3-remove-from-cluster">Step 3: Remove from cluster</a></h4>
<pre><code class="language-bash"># Remove the node from cluster configuration
neumann cluster remove node3

# Verify removal
neumann cluster members
</code></pre>
<h4 id="step-4-stop-the-node"><a class="header" href="#step-4-stop-the-node">Step 4: Stop the node</a></h4>
<pre><code class="language-bash"># On the removed node
neumann stop

# Clean up data (optional)
rm -rf /var/lib/neumann/data/*
</code></pre>
<h3 id="post-removal-verification"><a class="header" href="#post-removal-verification">Post-Removal Verification</a></h3>
<pre><code class="language-bash"># Verify cluster health
neumann cluster health

# Check that remaining nodes have correct membership
neumann cluster members

# Verify no pending transactions for removed node
neumann transactions pending
</code></pre>
<h2 id="emergency-removal"><a class="header" href="#emergency-removal">Emergency Removal</a></h2>
<p>Use emergency removal only when a node is unresponsive and cannot be drained
gracefully.</p>
<h3 id="symptoms"><a class="header" href="#symptoms">Symptoms</a></h3>
<ul>
<li>Node is unreachable (network partition, hardware failure)</li>
<li>Node is unresponsive (hung process, resource exhaustion)</li>
<li>Need to restore quorum quickly</li>
</ul>
<h3 id="procedure-2"><a class="header" href="#procedure-2">Procedure</a></h3>
<pre><code class="language-bash"># Force remove unresponsive node
neumann cluster remove node3 --force

# The cluster will:
# 1. Remove node from membership
# 2. Abort any transactions involving the node
# 3. Re-elect leader if necessary
</code></pre>
<h3 id="resolution"><a class="header" href="#resolution">Resolution</a></h3>
<p>After emergency removal:</p>
<ol>
<li>Investigate root cause of node failure</li>
<li>Repair or replace hardware if needed</li>
<li>Re-add node using the addition procedure above</li>
</ol>
<h3 id="prevention"><a class="header" href="#prevention">Prevention</a></h3>
<ul>
<li>Monitor node health with alerting</li>
<li>Configure appropriate timeouts</li>
<li>Maintain sufficient cluster size for fault tolerance</li>
</ul>
<h2 id="quorum-considerations"><a class="header" href="#quorum-considerations">Quorum Considerations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Cluster Size</th><th>Quorum</th><th>Fault Tolerance</th><th>Notes</th></tr></thead><tbody>
<tr><td>1</td><td>1</td><td>0</td><td>Development only</td></tr>
<tr><td>2</td><td>2</td><td>0</td><td>Not recommended</td></tr>
<tr><td>3</td><td>2</td><td>1</td><td>Minimum for production</td></tr>
<tr><td>5</td><td>3</td><td>2</td><td>Recommended for HA</td></tr>
<tr><td>7</td><td>4</td><td>3</td><td>Maximum practical size</td></tr>
</tbody></table>
</div>
<h3 id="quorum-formula"><a class="header" href="#quorum-formula">Quorum Formula</a></h3>
<pre><code class="language-text">quorum = (cluster_size / 2) + 1
fault_tolerance = cluster_size - quorum
</code></pre>
<h3 id="best-practices-8"><a class="header" href="#best-practices-8">Best Practices</a></h3>
<ul>
<li>Always maintain odd number of nodes</li>
<li>Never remove nodes if it would violate quorum</li>
<li>Plan node additions/removals during low-traffic periods</li>
<li>Test failover scenarios regularly</li>
</ul>
<h2 id="see-also-1"><a class="header" href="#see-also-1">See Also</a></h2>
<ul>
<li><a href="operations/runbooks/cluster-upgrade.html">Cluster Upgrade</a></li>
<li><a href="operations/runbooks/leader-election.html">Leader Election</a></li>
<li><a href="operations/runbooks/node-recovery.html">Node Recovery</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cluster-upgrade"><a class="header" href="#cluster-upgrade">Cluster Upgrade</a></h1>
<p>This runbook covers upgrading tensor_chain clusters with minimal downtime.</p>
<h2 id="upgrade-types"><a class="header" href="#upgrade-types">Upgrade Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Downtime</th><th>Complexity</th><th>Use Case</th></tr></thead><tbody>
<tr><td>Rolling</td><td>None</td><td>Low</td><td>Minor version upgrades</td></tr>
<tr><td>Blue-Green</td><td>Minimal</td><td>Medium</td><td>Major version upgrades</td></tr>
<tr><td>Canary</td><td>None</td><td>High</td><td>Risk-sensitive environments</td></tr>
</tbody></table>
</div>
<h2 id="rolling-upgrade"><a class="header" href="#rolling-upgrade">Rolling Upgrade</a></h2>
<p>Upgrade nodes one at a time while maintaining cluster availability.</p>
<h3 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Cluster has 3+ nodes for quorum during upgrades</li>
<li><input disabled="" type="checkbox"/>
New version is backwards compatible with current version</li>
<li><input disabled="" type="checkbox"/>
Upgrade tested in staging environment</li>
<li><input disabled="" type="checkbox"/>
Backup of cluster state completed</li>
</ul>
<h3 id="symptoms-why-upgrade"><a class="header" href="#symptoms-why-upgrade">Symptoms (Why Upgrade)</a></h3>
<ul>
<li>Security patches available</li>
<li>New features required</li>
<li>Bug fixes needed</li>
<li>Performance improvements available</li>
</ul>
<h3 id="upgrade-sequence"><a class="header" href="#upgrade-sequence">Upgrade Sequence</a></h3>
<pre class="mermaid">sequenceDiagram
    participant F1 as Follower 1
    participant F2 as Follower 2
    participant L as Leader
    participant A as Admin

    Note over A: Start rolling upgrade
    A-&gt;&gt;F1: upgrade
    F1-&gt;&gt;F1: restart with new version
    F1-&gt;&gt;L: rejoin cluster
    Note over F1: Follower 1 upgraded

    A-&gt;&gt;F2: upgrade
    F2-&gt;&gt;F2: restart with new version
    F2-&gt;&gt;L: rejoin cluster
    Note over F2: Follower 2 upgraded

    A-&gt;&gt;L: transfer leadership
    L-&gt;&gt;F1: leadership transferred
    A-&gt;&gt;L: upgrade (now follower)
    L-&gt;&gt;F1: rejoin cluster
    Note over L: All nodes upgraded
</pre>
<h3 id="procedure-3"><a class="header" href="#procedure-3">Procedure</a></h3>
<h4 id="step-1-pre-upgrade-checks"><a class="header" href="#step-1-pre-upgrade-checks">Step 1: Pre-upgrade checks</a></h4>
<pre><code class="language-bash"># Verify cluster health
neumann cluster health

# Check current versions
neumann cluster versions

# Verify backup is current
neumann backup status
</code></pre>
<h4 id="step-2-upgrade-followers-first"><a class="header" href="#step-2-upgrade-followers-first">Step 2: Upgrade followers first</a></h4>
<pre><code class="language-bash"># For each follower node:

# 1. Drain the node
neumann node drain node2

# 2. Stop the service
ssh node2 "systemctl stop neumann"

# 3. Upgrade the binary
ssh node2 "cargo install neumann --version X.Y.Z"

# 4. Start the service
ssh node2 "systemctl start neumann"

# 5. Verify rejoin
neumann cluster members

# 6. Wait for replication catch-up
neumann metrics node2 | grep replication_lag
</code></pre>
<h4 id="step-3-upgrade-the-leader"><a class="header" href="#step-3-upgrade-the-leader">Step 3: Upgrade the leader</a></h4>
<pre><code class="language-bash"># Transfer leadership to an upgraded follower
neumann raft transfer-leadership --to node2

# Verify leadership transferred
neumann raft status

# Now upgrade the old leader (same steps as followers)
neumann node drain node1
ssh node1 "systemctl stop neumann"
ssh node1 "cargo install neumann --version X.Y.Z"
ssh node1 "systemctl start neumann"
</code></pre>
<h4 id="step-4-post-upgrade-verification"><a class="header" href="#step-4-post-upgrade-verification">Step 4: Post-upgrade verification</a></h4>
<pre><code class="language-bash"># Verify all nodes on new version
neumann cluster versions

# Expected output:
# ID     VERSION
# node1  X.Y.Z
# node2  X.Y.Z
# node3  X.Y.Z

# Run health checks
neumann cluster health

# Verify functionality with test transactions
neumann test-transaction
</code></pre>
<h2 id="version-compatibility"><a class="header" href="#version-compatibility">Version Compatibility</a></h2>
<h3 id="compatibility-matrix"><a class="header" href="#compatibility-matrix">Compatibility Matrix</a></h3>
<div class="table-wrapper"><table><thead><tr><th>From Version</th><th>To Version</th><th>Compatible</th><th>Notes</th></tr></thead><tbody>
<tr><td>0.9.x</td><td>0.10.x</td><td>Yes</td><td>Rolling upgrade supported</td></tr>
<tr><td>0.10.x</td><td>0.11.x</td><td>Yes</td><td>Rolling upgrade supported</td></tr>
<tr><td>0.8.x</td><td>0.10.x</td><td>No</td><td>Blue-green required</td></tr>
<tr><td>0.x.x</td><td>1.0.x</td><td>No</td><td>Blue-green required</td></tr>
</tbody></table>
</div>
<h3 id="version-skew-policy"><a class="header" href="#version-skew-policy">Version Skew Policy</a></h3>
<ul>
<li><strong>Maximum skew</strong>: 1 minor version during rolling upgrades</li>
<li><strong>Leader version</strong>: Must be &gt;= follower versions</li>
<li><strong>Upgrade order</strong>: Always followers first, then leader</li>
</ul>
<h2 id="rollback-procedure"><a class="header" href="#rollback-procedure">Rollback Procedure</a></h2>
<p>If issues are discovered after upgrade:</p>
<h3 id="symptoms-requiring-rollback"><a class="header" href="#symptoms-requiring-rollback">Symptoms Requiring Rollback</a></h3>
<ul>
<li>Transaction failures after upgrade</li>
<li>Performance degradation</li>
<li>Consensus failures</li>
<li>Data corruption detected</li>
</ul>
<h3 id="rollback-steps"><a class="header" href="#rollback-steps">Rollback Steps</a></h3>
<pre><code class="language-bash"># 1. Stop accepting new requests
neumann cluster pause

# 2. Identify problematic nodes
neumann cluster health --verbose

# 3. Rollback affected nodes
ssh node1 "cargo install neumann --version X.Y.Z-OLD"
ssh node1 "systemctl restart neumann"

# 4. Verify rollback
neumann cluster versions

# 5. Resume operations
neumann cluster resume
</code></pre>
<h3 id="rollback-limitations"><a class="header" href="#rollback-limitations">Rollback Limitations</a></h3>
<ul>
<li>Cannot rollback if schema changes were applied</li>
<li>Cannot rollback if new features were used</li>
<li>Always test rollback in staging first</li>
</ul>
<h2 id="canary-upgrade"><a class="header" href="#canary-upgrade">Canary Upgrade</a></h2>
<p>For risk-sensitive environments, upgrade a single node first and monitor.</p>
<h3 id="procedure-4"><a class="header" href="#procedure-4">Procedure</a></h3>
<pre><code class="language-bash"># 1. Select canary node (typically a follower)
CANARY=node3

# 2. Upgrade canary
neumann node drain $CANARY
ssh $CANARY "cargo install neumann --version X.Y.Z"
ssh $CANARY "systemctl restart neumann"

# 3. Monitor canary for 24-48 hours
neumann metrics $CANARY --watch

# 4. Compare metrics with non-canary nodes
neumann metrics compare $CANARY node1

# 5. If healthy, proceed with rolling upgrade
# If unhealthy, rollback canary
</code></pre>
<h3 id="canary-success-criteria"><a class="header" href="#canary-success-criteria">Canary Success Criteria</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Threshold</th><th>Action if Exceeded</th></tr></thead><tbody>
<tr><td>Error rate</td><td>&lt; 0.1%</td><td>Rollback</td></tr>
<tr><td>Latency p99</td><td>&lt; 2x baseline</td><td>Investigate</td></tr>
<tr><td>Replication lag</td><td>&lt; 100ms</td><td>Investigate</td></tr>
<tr><td>Memory usage</td><td>&lt; 1.5x baseline</td><td>Investigate</td></tr>
</tbody></table>
</div>
<h2 id="automated-upgrade-script"><a class="header" href="#automated-upgrade-script">Automated Upgrade Script</a></h2>
<pre><code class="language-bash">#!/bin/bash
# rolling-upgrade.sh - Automated rolling upgrade script

set -e

NEW_VERSION=$1
NODES=$(neumann cluster members --format json | jq -r '.[] | .id')
LEADER=$(neumann raft status --format json | jq -r '.leader')

echo "Upgrading cluster to version $NEW_VERSION"

# Upgrade followers first
for node in $NODES; do
    if [ "$node" == "$LEADER" ]; then
        continue
    fi

    echo "Upgrading follower: $node"
    neumann node drain $node
    ssh $node "cargo install neumann --version $NEW_VERSION"
    ssh $node "systemctl restart neumann"

    # Wait for rejoin
    sleep 10
    neumann cluster wait-healthy --timeout 120
done

# Transfer leadership and upgrade old leader
echo "Transferring leadership from $LEADER"
NEW_LEADER=$(echo $NODES | tr ' ' '\n' | grep -v $LEADER | head -1)
neumann raft transfer-leadership --to $NEW_LEADER

sleep 5

echo "Upgrading old leader: $LEADER"
neumann node drain $LEADER
ssh $LEADER "cargo install neumann --version $NEW_VERSION"
ssh $LEADER "systemctl restart neumann"

# Final verification
neumann cluster wait-healthy --timeout 120
neumann cluster versions

echo "Upgrade complete"
</code></pre>
<h2 id="see-also-2"><a class="header" href="#see-also-2">See Also</a></h2>
<ul>
<li><a href="operations/runbooks/node-management.html">Node Management</a></li>
<li><a href="operations/runbooks/backup-restore.html">Backup and Restore</a></li>
<li><a href="operations/runbooks/../configuration.html">Configuration</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="leader-election-failures"><a class="header" href="#leader-election-failures">Leader Election Failures</a></h1>
<h2 id="symptoms-1"><a class="header" href="#symptoms-1">Symptoms</a></h2>
<ul>
<li><code>NoLeader</code> alert firing</li>
<li>Continuous election attempts in logs</li>
<li>Client requests timing out with “no leader” errors</li>
<li><code>tensor_chain_elections_total</code> metric increasing rapidly</li>
</ul>
<h2 id="diagnostic-commands"><a class="header" href="#diagnostic-commands">Diagnostic Commands</a></h2>
<h3 id="check-raft-state"><a class="header" href="#check-raft-state">Check Raft State</a></h3>
<pre><code class="language-bash"># Query each node's state
for node in node1 node2 node3; do
  curl -s http://$node:9090/metrics | grep tensor_chain_raft_state
done
</code></pre>
<h3 id="inspect-logs"><a class="header" href="#inspect-logs">Inspect Logs</a></h3>
<pre><code class="language-bash"># Look for election-related entries
grep -E "(election|vote|term)" /var/log/neumann/tensor_chain.log | tail -100
</code></pre>
<h3 id="verify-network-connectivity"><a class="header" href="#verify-network-connectivity">Verify Network Connectivity</a></h3>
<pre><code class="language-bash"># From each node, verify connectivity to peers
for peer in node1 node2 node3; do
  nc -zv $peer 7878 2&gt;&amp;1 | grep -v "Connection refused" || echo "FAIL: $peer"
done
</code></pre>
<h2 id="root-causes"><a class="header" href="#root-causes">Root Causes</a></h2>
<h3 id="1-network-partition"><a class="header" href="#1-network-partition">1. Network Partition</a></h3>
<p><strong>Diagnosis</strong>: Nodes can’t reach each other</p>
<p><strong>Solution</strong>:</p>
<ul>
<li>Check firewall rules for port 7878 (Raft) and 7879 (gossip)</li>
<li>Verify network routes between nodes</li>
<li>Check for packet loss: <code>ping -c 100 peer_node</code></li>
</ul>
<h3 id="2-clock-skew"><a class="header" href="#2-clock-skew">2. Clock Skew</a></h3>
<p><strong>Diagnosis</strong>: Election timeouts inconsistent across nodes</p>
<p><strong>Solution</strong>:</p>
<ul>
<li>Ensure NTP is running: <code>timedatectl status</code></li>
<li>Max recommended skew: 500ms</li>
<li>Sync clocks: <code>chronyc makestep</code></li>
</ul>
<h3 id="3-quorum-loss"><a class="header" href="#3-quorum-loss">3. Quorum Loss</a></h3>
<p><strong>Diagnosis</strong>: Fewer than <code>(n/2)+1</code> nodes available</p>
<p><strong>Solution</strong>:</p>
<ul>
<li>For 3-node cluster: need 2 nodes</li>
<li>For 5-node cluster: need 3 nodes</li>
<li>Bring failed nodes back online or add new nodes</li>
</ul>
<h3 id="4-election-timeout-too-aggressive"><a class="header" href="#4-election-timeout-too-aggressive">4. Election Timeout Too Aggressive</a></h3>
<p><strong>Diagnosis</strong>: Frequent elections even with healthy network</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-toml">[raft]
election_timeout_min_ms = 300   # Increase from default 150
election_timeout_max_ms = 600   # Increase from default 300
</code></pre>
<h2 id="resolution-steps"><a class="header" href="#resolution-steps">Resolution Steps</a></h2>
<ol>
<li><strong>Identify partitioned nodes</strong> using gossip membership view</li>
<li><strong>Restore connectivity</strong> if network issue</li>
<li><strong>If quorum lost</strong>, follow disaster recovery procedure</li>
<li><strong>Monitor</strong> <code>tensor_chain_raft_state{state="leader"}</code> for leader emergence</li>
</ol>
<h2 id="alerting-rule"><a class="header" href="#alerting-rule">Alerting Rule</a></h2>
<pre><code class="language-yaml">- alert: NoLeader
  expr: sum(tensor_chain_raft_state{state="leader"}) == 0
  for: 30s
  labels:
    severity: critical
  annotations:
    summary: "No Raft leader elected in cluster"
    runbook_url: "https://docs.neumann.io/operations/runbooks/leader-election"
</code></pre>
<h2 id="prevention-1"><a class="header" href="#prevention-1">Prevention</a></h2>
<ul>
<li>Deploy odd number of nodes (3, 5, 7)</li>
<li>Use separate availability zones</li>
<li>Monitor <code>tensor_chain_elections_total</code> rate</li>
<li>Set up network monitoring between nodes</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="split-brain-recovery"><a class="header" href="#split-brain-recovery">Split-Brain Recovery</a></h1>
<h2 id="what-is-split-brain"><a class="header" href="#what-is-split-brain">What is Split-Brain?</a></h2>
<p>A network partition where multiple nodes believe they are the leader,
potentially accepting conflicting writes.</p>
<h2 id="symptoms-2"><a class="header" href="#symptoms-2">Symptoms</a></h2>
<ul>
<li>Multiple nodes reporting <code>raft_state="leader"</code> in metrics</li>
<li>Clients seeing different data depending on which node they connect to</li>
<li><code>tensor_chain_partition_detected</code> metric &gt; 0</li>
<li>Gossip reporting different membership views</li>
</ul>
<h2 id="how-tensor_chain-prevents-split-brain"><a class="header" href="#how-tensor_chain-prevents-split-brain">How tensor_chain Prevents Split-Brain</a></h2>
<p>Raft consensus requires majority quorum:</p>
<ul>
<li>3 nodes: 2 required (only 1 partition can have leader)</li>
<li>5 nodes: 3 required</li>
</ul>
<p>Split-brain can only occur with <strong>symmetric partition</strong> where old leader is
isolated but doesn’t realize it.</p>
<h2 id="automatic-recovery-partition-merge-protocol"><a class="header" href="#automatic-recovery-partition-merge-protocol">Automatic Recovery (Partition Merge Protocol)</a></h2>
<p>When partitions heal, tensor_chain automatically reconciles:</p>
<h3 id="phase-1-detection"><a class="header" href="#phase-1-detection">Phase 1: Detection</a></h3>
<ul>
<li>Gossip detects new reachable nodes</li>
<li>Compare Raft terms and log lengths</li>
</ul>
<h3 id="phase-2-leader-resolution"><a class="header" href="#phase-2-leader-resolution">Phase 2: Leader Resolution</a></h3>
<ul>
<li>Higher term wins</li>
<li>If same term, longer log wins</li>
<li>Losing leader steps down</li>
</ul>
<h3 id="phase-3-state-reconciliation"><a class="header" href="#phase-3-state-reconciliation">Phase 3: State Reconciliation</a></h3>
<ul>
<li>Semantic conflict detection on divergent entries</li>
<li>Orthogonal changes: vector-add merge</li>
<li>Conflicting changes: reject newer (requires manual resolution)</li>
</ul>
<h3 id="phase-4-log-synchronization"><a class="header" href="#phase-4-log-synchronization">Phase 4: Log Synchronization</a></h3>
<ul>
<li>Follower truncates divergent suffix</li>
<li>Leader replicates correct entries</li>
</ul>
<h3 id="phase-5-membership-merge"><a class="header" href="#phase-5-membership-merge">Phase 5: Membership Merge</a></h3>
<ul>
<li>Gossip merges LWW membership states</li>
<li>Higher incarnation wins for each node</li>
</ul>
<h3 id="phase-6-checkpoint"><a class="header" href="#phase-6-checkpoint">Phase 6: Checkpoint</a></h3>
<ul>
<li>Create snapshot post-merge for fast recovery</li>
</ul>
<h2 id="manual-intervention-when-automatic-fails"><a class="header" href="#manual-intervention-when-automatic-fails">Manual Intervention (When Automatic Fails)</a></h2>
<h3 id="scenario-conflicting-writes"><a class="header" href="#scenario-conflicting-writes">Scenario: Conflicting Writes</a></h3>
<pre><code class="language-bash"># 1. Identify conflicts
neumann-admin conflicts list --since "2h ago"

# 2. Export conflicting transactions
neumann-admin conflicts export --tx-id 12345 --output conflict.json

# 3. Choose resolution
neumann-admin conflicts resolve --tx-id 12345 --keep-version A

# 4. Or merge manually
neumann-admin conflicts resolve --tx-id 12345 --merge-custom merge.json
</code></pre>
<h3 id="scenario-completely-diverged-state"><a class="header" href="#scenario-completely-diverged-state">Scenario: Completely Diverged State</a></h3>
<pre><code class="language-bash"># 1. Stop all nodes
systemctl stop neumann

# 2. Identify authoritative node (longest log, highest term)
for node in node1 node2 node3; do
  ssh $node "neumann-admin raft-info"
done

# 3. On non-authoritative nodes, clear state
rm -rf /var/lib/neumann/raft/*

# 4. Restart authoritative node first
systemctl start neumann

# 5. Restart other nodes (will sync from leader)
systemctl start neumann
</code></pre>
<h2 id="post-recovery-verification"><a class="header" href="#post-recovery-verification">Post-Recovery Verification</a></h2>
<pre><code class="language-bash"># Verify single leader
curl -s http://node1:9090/metrics | grep 'raft_state{state="leader"}'

# Verify all nodes in sync
neumann-admin cluster-status

# Check for unresolved conflicts
neumann-admin conflicts list

# Verify recent transactions
neumann-admin tx-log --last 100
</code></pre>
<h2 id="prevention-2"><a class="header" href="#prevention-2">Prevention</a></h2>
<ol>
<li><strong>Network design</strong>: Avoid symmetric partitions</li>
<li><strong>Monitoring</strong>: Alert on partition detection</li>
<li><strong>Testing</strong>: Regularly run chaos engineering tests</li>
<li><strong>Backups</strong>: Regular snapshots enable point-in-time recovery</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="node-recovery"><a class="header" href="#node-recovery">Node Recovery</a></h1>
<h2 id="recovery-scenarios"><a class="header" href="#recovery-scenarios">Recovery Scenarios</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Scenario</th><th>Recovery Method</th><th>Data Loss Risk</th></tr></thead><tbody>
<tr><td>Process crash</td><td>WAL replay</td><td>None</td></tr>
<tr><td>Node reboot</td><td>WAL replay</td><td>None</td></tr>
<tr><td>Disk failure</td><td>Snapshot + log from leader</td><td>Possible (uncommitted)</td></tr>
<tr><td>Data corruption</td><td>Snapshot from leader</td><td>Possible (uncommitted)</td></tr>
</tbody></table>
</div>
<h2 id="automatic-recovery-flow"><a class="header" href="#automatic-recovery-flow">Automatic Recovery Flow</a></h2>
<pre class="mermaid">flowchart TD
    A[Node Starts] --&gt; B{WAL Exists?}
    B --&gt;|Yes| C[Replay WAL]
    B --&gt;|No| D[Request Snapshot]
    C --&gt; E{Caught Up?}
    E --&gt;|Yes| F[Join as Follower]
    E --&gt;|No| D
    D --&gt; G[Install Snapshot]
    G --&gt; H[Replay Logs After Snapshot]
    H --&gt; F
    F --&gt; I[Healthy]
</pre>
<h2 id="manual-recovery-steps"><a class="header" href="#manual-recovery-steps">Manual Recovery Steps</a></h2>
<h3 id="1-crash-recovery-wal-intact"><a class="header" href="#1-crash-recovery-wal-intact">1. Crash Recovery (WAL Intact)</a></h3>
<pre><code class="language-bash"># Just restart - WAL replay is automatic
systemctl start neumann

# Monitor recovery
journalctl -u neumann -f | grep -E "(recovery|replay|caught_up)"
</code></pre>
<h3 id="2-recovery-from-snapshot"><a class="header" href="#2-recovery-from-snapshot">2. Recovery from Snapshot</a></h3>
<pre><code class="language-bash"># 1. Stop node
systemctl stop neumann

# 2. Clear corrupted state
rm -rf /var/lib/neumann/raft/wal/*

# 3. Keep or clear snapshots (keep if valid)
ls -la /var/lib/neumann/raft/snapshots/

# 4. Restart - will fetch snapshot from leader
systemctl start neumann

# 5. Monitor snapshot transfer
watch -n1 'curl -s localhost:9090/metrics | grep snapshot_transfer'
</code></pre>
<h3 id="3-full-state-rebuild"><a class="header" href="#3-full-state-rebuild">3. Full State Rebuild</a></h3>
<pre><code class="language-bash"># 1. Stop node
systemctl stop neumann

# 2. Clear all Raft state
rm -rf /var/lib/neumann/raft/*

# 3. Clear tensor store (will be rebuilt)
rm -rf /var/lib/neumann/store/*

# 4. Restart
systemctl start neumann
</code></pre>
<h2 id="monitoring-recovery-progress"><a class="header" href="#monitoring-recovery-progress">Monitoring Recovery Progress</a></h2>
<pre><code class="language-bash"># Check sync status
curl -s localhost:9090/metrics | grep -E "(commit_index|applied_index|leader_commit)"

# Calculate lag
LEADER_COMMIT=$(curl -s http://leader:9090/metrics | grep tensor_chain_commit_index | awk '{print $2}')
MY_APPLIED=$(curl -s localhost:9090/metrics | grep tensor_chain_applied_index | awk '{print $2}')
echo "Lag: $((LEADER_COMMIT - MY_APPLIED)) entries"

# Estimated time to catch up (entries/sec)
watch -n5 'curl -s localhost:9090/metrics | grep tensor_chain_applied_index'
</code></pre>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="recovery-stuck"><a class="header" href="#recovery-stuck">Recovery Stuck</a></h3>
<p><strong>Symptom</strong>: Node not catching up, applied_index not increasing</p>
<p><strong>Causes</strong>:</p>
<ol>
<li>Network issue to leader</li>
<li>Leader overloaded</li>
<li>Snapshot transfer failing</li>
</ol>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Check leader connectivity
curl -v http://leader:7878/health

# Check snapshot transfer errors
grep "snapshot" /var/log/neumann/tensor_chain.log | grep -i error

# Manually trigger snapshot
curl -X POST http://leader:9090/admin/snapshot
</code></pre>
<h3 id="repeated-crashes-during-recovery"><a class="header" href="#repeated-crashes-during-recovery">Repeated Crashes During Recovery</a></h3>
<p><strong>Symptom</strong>: Node crashes while replaying WAL</p>
<p><strong>Causes</strong>:</p>
<ol>
<li>Corrupted WAL entry</li>
<li>Out of memory during replay</li>
<li>Incompatible schema</li>
</ol>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Skip corrupted entries (data loss!)
neumann-admin wal-repair --skip-corrupted

# Or full rebuild
rm -rf /var/lib/neumann/raft/*
systemctl start neumann
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="backup-and-restore"><a class="header" href="#backup-and-restore">Backup and Restore</a></h1>
<h2 id="backup-strategy"><a class="header" href="#backup-strategy">Backup Strategy</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Frequency</th><th>Retention</th><th>RPO</th><th>RTO</th></tr></thead><tbody>
<tr><td>Snapshots</td><td>Every 10k entries</td><td>7 days</td><td>Minutes</td><td>Minutes</td></tr>
<tr><td>Full backup</td><td>Daily</td><td>30 days</td><td>24 hours</td><td>Hours</td></tr>
<tr><td>Off-site</td><td>Weekly</td><td>1 year</td><td>1 week</td><td>Hours</td></tr>
</tbody></table>
</div>
<h2 id="creating-backups"><a class="header" href="#creating-backups">Creating Backups</a></h2>
<h3 id="snapshot-backup-hot"><a class="header" href="#snapshot-backup-hot">Snapshot Backup (Hot)</a></h3>
<pre><code class="language-bash"># Trigger snapshot on leader
curl -X POST http://leader:9090/admin/snapshot

# Wait for completion
watch 'curl -s http://leader:9090/metrics | grep snapshot'

# Copy snapshot files
rsync -av /var/lib/neumann/raft/snapshots/ backup:/backups/neumann/snapshots/

# Include metadata
neumann-admin cluster-info &gt; backup:/backups/neumann/metadata.json
</code></pre>
<h3 id="full-backup-recommended-cold"><a class="header" href="#full-backup-recommended-cold">Full Backup (Recommended: Cold)</a></h3>
<pre><code class="language-bash"># 1. Stop writes (or accept slightly inconsistent backup)
neumann-admin pause-writes

# 2. Create snapshot
curl -X POST http://leader:9090/admin/snapshot
sleep 10

# 3. Backup all state
tar -czf neumann-backup-$(date +%Y%m%d).tar.gz \
  /var/lib/neumann/raft/snapshots/ \
  /var/lib/neumann/store/ \
  /etc/neumann/

# 4. Resume writes
neumann-admin resume-writes

# 5. Verify backup integrity
tar -tzf neumann-backup-*.tar.gz | head
</code></pre>
<h3 id="continuous-wal-archiving"><a class="header" href="#continuous-wal-archiving">Continuous WAL Archiving</a></h3>
<pre><code class="language-bash"># In config.toml
[wal]
archive_command = "aws s3 cp %p s3://backups/neumann/wal/%f"
archive_timeout = 60  # seconds

# Or to local storage
archive_command = "cp %p /mnt/backup/wal/%f"
</code></pre>
<h2 id="restore-procedures"><a class="header" href="#restore-procedures">Restore Procedures</a></h2>
<h3 id="point-in-time-recovery"><a class="header" href="#point-in-time-recovery">Point-in-Time Recovery</a></h3>
<pre><code class="language-bash"># 1. Stop all nodes
ansible all -m systemd -a "name=neumann state=stopped"

# 2. Clear current state
ansible all -m shell -a "rm -rf /var/lib/neumann/raft/*"

# 3. Restore snapshot to one node
scp backup:/backups/neumann/snapshots/latest/* node1:/var/lib/neumann/raft/snapshots/

# 4. Replay WAL up to desired point
neumann-admin wal-replay \
  --wal-dir backup:/backups/neumann/wal/ \
  --until "2024-01-15T10:30:00Z"

# 5. Start first node
ssh node1 systemctl start neumann

# 6. Start remaining nodes (will sync from node1)
ansible "node2,node3" -m systemd -a "name=neumann state=started"
</code></pre>
<h3 id="full-cluster-restore"><a class="header" href="#full-cluster-restore">Full Cluster Restore</a></h3>
<pre><code class="language-bash"># 1. Extract backup
tar -xzf neumann-backup-20240115.tar.gz -C /tmp/restore/

# 2. Stop cluster
systemctl stop neumann

# 3. Restore files
rsync -av /tmp/restore/raft/ /var/lib/neumann/raft/
rsync -av /tmp/restore/store/ /var/lib/neumann/store/

# 4. Fix permissions
chown -R neumann:neumann /var/lib/neumann/

# 5. Start cluster
systemctl start neumann
</code></pre>
<h3 id="disaster-recovery-complete-loss"><a class="header" href="#disaster-recovery-complete-loss">Disaster Recovery (Complete Loss)</a></h3>
<pre><code class="language-bash"># 1. Provision new infrastructure

# 2. Install Neumann on all nodes

# 3. Restore from off-site backup
aws s3 cp s3://backups/neumann/latest.tar.gz /tmp/
tar -xzf /tmp/latest.tar.gz -C /var/lib/neumann/

# 4. Update config with new node addresses
vim /etc/neumann/config.toml

# 5. Initialize cluster
neumann-admin init-cluster --bootstrap

# 6. Verify
neumann-admin cluster-status
</code></pre>
<h2 id="verification"><a class="header" href="#verification">Verification</a></h2>
<pre><code class="language-bash"># Check data integrity
neumann-admin verify-checksums

# Compare entry counts
neumann-admin stats | grep total_entries

# Spot check recent data
neumann-admin query "SELECT COUNT(*) FROM ..."
</code></pre>
<h2 id="retention-policy"><a class="header" href="#retention-policy">Retention Policy</a></h2>
<pre><code class="language-bash"># Cron job for cleanup
0 2 * * * find /var/lib/neumann/raft/snapshots -mtime +7 -delete
0 3 * * 0 aws s3 rm s3://backups/neumann/wal/ --recursive --exclude "*.wal" --older-than 30d
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="capacity-planning"><a class="header" href="#capacity-planning">Capacity Planning</a></h1>
<h2 id="resource-requirements"><a class="header" href="#resource-requirements">Resource Requirements</a></h2>
<h3 id="memory"><a class="header" href="#memory">Memory</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Formula</th><th>Example (1M entries)</th></tr></thead><tbody>
<tr><td>Raft log (in-memory)</td><td><code>entries * avg_size * 2</code></td><td>1M <em>1KB</em> 2 = 2 GB</td></tr>
<tr><td>Tensor store index</td><td><code>entries * 64 bytes</code></td><td>1M * 64 = 64 MB</td></tr>
<tr><td>HNSW index</td><td><code>vectors * dim * 4 * ef</code></td><td>1M <em>128</em> 4 * 16 = 8 GB</td></tr>
<tr><td>Codebook</td><td><code>centroids * dim * 4</code></td><td>1024 <em>128</em> 4 = 512 KB</td></tr>
<tr><td>Connection buffers</td><td><code>peers * buffer_size</code></td><td>10 * 64KB = 640 KB</td></tr>
</tbody></table>
</div>
<p><strong>Recommended minimum</strong>: 16 GB for production</p>
<h3 id="disk"><a class="header" href="#disk">Disk</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Formula</th><th>Example</th></tr></thead><tbody>
<tr><td>WAL</td><td><code>entries * avg_size</code></td><td>10M * 1KB = 10 GB</td></tr>
<tr><td>Snapshots</td><td><code>state_size * 2</code></td><td>5 GB * 2 = 10 GB</td></tr>
<tr><td>Mmap cold storage</td><td><code>cold_entries * avg_size</code></td><td>100M * 1KB = 100 GB</td></tr>
</tbody></table>
</div>
<p><strong>Recommended</strong>: 3x expected data size for growth</p>
<h3 id="network"><a class="header" href="#network">Network</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Traffic Type</th><th>Formula</th><th>Example (100 TPS)</th></tr></thead><tbody>
<tr><td>Replication</td><td><code>TPS * entry_size * (replicas-1)</code></td><td>100 <em>1KB</em> 2 = 200 KB/s</td></tr>
<tr><td>Gossip</td><td><code>nodes * fanout * state_size / interval</code></td><td>5 <em>3</em> 1KB / 1s = 15 KB/s</td></tr>
<tr><td>Client</td><td><code>TPS * (request + response)</code></td><td>100 * 2KB = 200 KB/s</td></tr>
</tbody></table>
</div>
<p><strong>Recommended</strong>: 1 Gbps minimum, 10 Gbps for high throughput</p>
<h3 id="cpu"><a class="header" href="#cpu">CPU</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Cores Needed</th></tr></thead><tbody>
<tr><td>Consensus</td><td>O(1) per entry</td><td>1 core</td></tr>
<tr><td>Embedding computation</td><td>O(dim)</td><td>1-2 cores</td></tr>
<tr><td>HNSW search</td><td>O(log N * ef)</td><td>2-4 cores</td></tr>
<tr><td>Conflict detection</td><td>O(concurrent_txs^2)</td><td>1 core</td></tr>
</tbody></table>
</div>
<p><strong>Recommended</strong>: 8+ cores for production</p>
<h2 id="sizing-examples"><a class="header" href="#sizing-examples">Sizing Examples</a></h2>
<h3 id="small-devtest"><a class="header" href="#small-devtest">Small (Dev/Test)</a></h3>
<ul>
<li>3 nodes</li>
<li>4 cores, 8 GB RAM, 100 GB SSD each</li>
<li>Up to 1M entries, 10 TPS</li>
</ul>
<h3 id="medium-production"><a class="header" href="#medium-production">Medium (Production)</a></h3>
<ul>
<li>5 nodes</li>
<li>8 cores, 32 GB RAM, 500 GB NVMe each</li>
<li>Up to 100M entries, 1000 TPS</li>
</ul>
<h3 id="large-high-scale"><a class="header" href="#large-high-scale">Large (High-Scale)</a></h3>
<ul>
<li>7+ nodes</li>
<li>16+ cores, 64+ GB RAM, 2 TB NVMe each</li>
<li>1B+ entries, 10k+ TPS</li>
<li>Consider sharding</li>
</ul>
<h2 id="scaling-strategies"><a class="header" href="#scaling-strategies">Scaling Strategies</a></h2>
<h3 id="vertical-scaling"><a class="header" href="#vertical-scaling">Vertical Scaling</a></h3>
<p>When to use:</p>
<ul>
<li>Single-node bottleneck (CPU, memory)</li>
<li>Read latency requirements</li>
</ul>
<p>Actions:</p>
<ul>
<li>Add RAM for larger in-memory log</li>
<li>Add cores for parallel embedding computation</li>
<li>Upgrade to NVMe for faster snapshots</li>
</ul>
<h3 id="horizontal-scaling"><a class="header" href="#horizontal-scaling">Horizontal Scaling</a></h3>
<p>When to use:</p>
<ul>
<li>Throughput limited by consensus</li>
<li>Fault tolerance requirements</li>
</ul>
<p>Actions:</p>
<ul>
<li>Add read replicas (don’t participate in consensus)</li>
<li>Add consensus members (odd numbers only)</li>
<li>Implement sharding by key range</li>
</ul>
<h2 id="monitoring-for-capacity"><a class="header" href="#monitoring-for-capacity">Monitoring for Capacity</a></h2>
<pre><code class="language-yaml"># Prometheus alerts
- alert: HighMemoryUsage
  expr: tensor_chain_memory_usage_bytes / tensor_chain_memory_limit_bytes &gt; 0.85
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "Memory usage above 85%"

- alert: DiskSpaceLow
  expr: tensor_chain_disk_free_bytes &lt; 10737418240  # 10 GB
  for: 1m
  labels:
    severity: critical
  annotations:
    summary: "Less than 10 GB disk space remaining"

- alert: HighCPUUsage
  expr: rate(tensor_chain_cpu_seconds_total[5m]) &gt; 0.9
  for: 10m
  labels:
    severity: warning
  annotations:
    summary: "CPU usage above 90%"
</code></pre>
<h2 id="growth-projections"><a class="header" href="#growth-projections">Growth Projections</a></h2>
<pre><code class="language-bash"># Calculate daily growth
neumann-admin stats --since "7d ago" --format json | jq '.entries_per_day'

# Project storage needs
DAILY_GROWTH=100000  # entries
ENTRY_SIZE=1024      # bytes
DAYS=365
GROWTH=$((DAILY_GROWTH * ENTRY_SIZE * DAYS / 1024 / 1024 / 1024))
echo "Projected annual growth: ${GROWTH} GB"
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deadlock-resolution"><a class="header" href="#deadlock-resolution">Deadlock Resolution</a></h1>
<h2 id="overview-7"><a class="header" href="#overview-7">Overview</a></h2>
<p>tensor_chain automatically detects and resolves deadlocks in distributed
transactions using wait-for graph analysis. This runbook covers monitoring,
tuning, and manual intervention.</p>
<h2 id="automatic-detection"><a class="header" href="#automatic-detection">Automatic Detection</a></h2>
<p>Deadlocks are detected within <code>detection_interval_ms</code> (default: 100ms) and
resolved by aborting a victim transaction based on configured policy.</p>
<h2 id="monitoring-2"><a class="header" href="#monitoring-2">Monitoring</a></h2>
<h3 id="metrics-1"><a class="header" href="#metrics-1">Metrics</a></h3>
<pre><code class="language-promql"># Deadlock rate
rate(tensor_chain_deadlocks_total[5m])

# Detection latency
histogram_quantile(0.99, tensor_chain_deadlock_detection_seconds_bucket)

# Victim aborts by policy
tensor_chain_deadlock_victims_total{policy="youngest"}
</code></pre>
<h3 id="logs"><a class="header" href="#logs">Logs</a></h3>
<pre><code class="language-bash">grep "deadlock" /var/log/neumann/tensor_chain.log

# Example output:
# [WARN] Deadlock detected: cycle=[tx_123, tx_456, tx_789], victim=tx_789
# [INFO] Aborted transaction tx_789 (youngest in cycle)
</code></pre>
<h2 id="tuning"><a class="header" href="#tuning">Tuning</a></h2>
<h3 id="detection-interval"><a class="header" href="#detection-interval">Detection Interval</a></h3>
<pre><code class="language-toml">[deadlock]
detection_interval_ms = 100  # Lower = faster detection, higher CPU
</code></pre>
<p>Trade-off:</p>
<ul>
<li>Lower interval: Faster detection, but more CPU overhead</li>
<li>Higher interval: Less overhead, but longer deadlock duration</li>
</ul>
<h3 id="victim-selection-policy"><a class="header" href="#victim-selection-policy">Victim Selection Policy</a></h3>
<pre><code class="language-toml">[deadlock]
victim_policy = "youngest"  # Options: youngest, oldest, lowest_priority, most_locks
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Policy</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>youngest</code></td><td>Minimize wasted work (default)</td></tr>
<tr><td><code>oldest</code></td><td>Prevent starvation of long transactions</td></tr>
<tr><td><code>lowest_priority</code></td><td>Business-critical transactions survive</td></tr>
<tr><td><code>most_locks</code></td><td>Maximize system throughput</td></tr>
</tbody></table>
</div>
<h3 id="transaction-priorities"><a class="header" href="#transaction-priorities">Transaction Priorities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Set priority when starting transaction
let tx = coordinator.begin_with_priority(Priority::High)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="manual-intervention"><a class="header" href="#manual-intervention">Manual Intervention</a></h2>
<h3 id="force-abort-specific-transaction"><a class="header" href="#force-abort-specific-transaction">Force Abort Specific Transaction</a></h3>
<pre><code class="language-bash">neumann-admin tx abort --tx-id 12345 --reason "manual deadlock resolution"
</code></pre>
<h3 id="clear-all-pending-transactions"><a class="header" href="#clear-all-pending-transactions">Clear All Pending Transactions</a></h3>
<pre><code class="language-bash"># Emergency only - will lose in-flight work
neumann-admin tx clear-pending --confirm
</code></pre>
<h3 id="disable-auto-resolution"><a class="header" href="#disable-auto-resolution">Disable Auto-Resolution</a></h3>
<pre><code class="language-toml">[deadlock]
auto_abort_victim = false  # Require manual intervention
</code></pre>
<p>Then manually resolve:</p>
<pre><code class="language-bash"># List detected deadlocks
neumann-admin deadlock list

# Resolve specific deadlock
neumann-admin deadlock resolve --cycle-id abc123 --abort tx_789
</code></pre>
<h2 id="prevention-3"><a class="header" href="#prevention-3">Prevention</a></h2>
<h3 id="lock-ordering-1"><a class="header" href="#lock-ordering-1">Lock Ordering</a></h3>
<p>Acquire locks in consistent order across all transactions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: always lock in sorted key order
let mut keys = vec!["key_b", "key_a", "key_c"];
keys.sort();
for key in keys {
    tx.lock(key)?;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="timeout-based-prevention"><a class="header" href="#timeout-based-prevention">Timeout-Based Prevention</a></h3>
<pre><code class="language-toml">[transaction]
lock_timeout_ms = 5000  # Abort if can't acquire lock within 5s
</code></pre>
<h3 id="reduce-lock-scope"><a class="header" href="#reduce-lock-scope">Reduce Lock Scope</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: lock entire table
tx.lock("users/*")?;

// Good: lock specific keys
tx.lock("users/123")?;
tx.lock("users/456")?;
<span class="boring">}</span></code></pre></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="high-deadlock-rate"><a class="header" href="#high-deadlock-rate">High Deadlock Rate</a></h3>
<p><strong>Cause</strong>: Hot keys with many concurrent transactions</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Identify hot keys: <code>neumann-admin lock-stats --top 10</code></li>
<li>Consider sharding hot keys</li>
<li>Batch operations to reduce lock duration</li>
</ol>
<h3 id="detection-latency-spikes"><a class="header" href="#detection-latency-spikes">Detection Latency Spikes</a></h3>
<p><strong>Cause</strong>: Large wait-for graph from many concurrent transactions</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Increase <code>max_concurrent_transactions</code></li>
<li>Reduce transaction duration</li>
<li>Consider optimistic concurrency for read-heavy workloads</li>
</ol>
<h3 id="false-positives"><a class="header" href="#false-positives">False Positives</a></h3>
<p><strong>Cause</strong>: Network delays causing timeout-based false waits</p>
<p><strong>Solution</strong>:</p>
<ol>
<li>Increase <code>lock_wait_threshold_ms</code></li>
<li>Verify network latency between nodes</li>
<li>Check for GC pauses</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="benchmarks-2"><a class="header" href="#benchmarks-2">Benchmarks</a></h1>
<p>This section provides performance benchmarks for all Neumann crates, measured
using Criterion.rs.</p>
<h2 id="running-benchmarks"><a class="header" href="#running-benchmarks">Running Benchmarks</a></h2>
<pre><code class="language-bash"># Run all benchmarks
cargo bench

# Run benchmarks for a specific crate
cargo bench --package tensor_store
cargo bench --package relational_engine
cargo bench --package graph_engine
cargo bench --package vector_engine
cargo bench --package neumann_parser
cargo bench --package query_router
cargo bench --package neumann_shell
cargo bench --package tensor_compress
cargo bench --package tensor_vault
cargo bench --package tensor_cache
cargo bench --package tensor_chain
</code></pre>
<p>Benchmark reports are generated in <code>target/criterion/</code> with HTML visualizations.</p>
<h2 id="performance-summary"><a class="header" href="#performance-summary">Performance Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Key Metric</th><th>Performance</th></tr></thead><tbody>
<tr><td><a href="benchmarks/tensor-store.html">tensor_store</a></td><td>Concurrent writes</td><td>7.5M/sec @ 1M entities</td></tr>
<tr><td><a href="benchmarks/relational-engine.html">relational_engine</a></td><td>Indexed lookup</td><td>2.9us (1,604x vs scan)</td></tr>
<tr><td><a href="benchmarks/graph-engine.html">graph_engine</a></td><td>BFS traversal</td><td>3us/node</td></tr>
<tr><td><a href="benchmarks/vector-engine.html">vector_engine</a></td><td>HNSW search</td><td>150us @ 10K vectors</td></tr>
<tr><td><a href="benchmarks/tensor-compress.html">tensor_compress</a></td><td>TT decompose</td><td>10-20x compression</td></tr>
<tr><td><a href="benchmarks/tensor-vault.html">tensor_vault</a></td><td>AES-256-GCM</td><td>24us get, 29us set</td></tr>
<tr><td><a href="benchmarks/tensor-cache.html">tensor_cache</a></td><td>Exact lookup</td><td>208ns hit</td></tr>
<tr><td><a href="benchmarks/tensor-chain.html">tensor_chain</a></td><td>Conflict detection</td><td>52M pairs/sec @ 99% sparse</td></tr>
<tr><td><a href="benchmarks/neumann-parser.html">neumann_parser</a></td><td>Query parsing</td><td>1.9M queries/sec</td></tr>
<tr><td><a href="benchmarks/query-router.html">query_router</a></td><td>Mixed workload</td><td>455 queries/sec</td></tr>
</tbody></table>
</div>
<h2 id="hardware-notes"><a class="header" href="#hardware-notes">Hardware Notes</a></h2>
<p>Benchmarks run on:</p>
<ul>
<li>Apple M-series (ARM64) or Intel x86_64</li>
<li>Results may vary based on CPU cache sizes, memory bandwidth, and core count</li>
</ul>
<p>For consistent benchmarking:</p>
<pre><code class="language-bash"># Disable CPU frequency scaling (Linux)
sudo cpupower frequency-set --governor performance

# Run with minimal background activity
cargo bench -- --noplot  # Skip HTML report generation for faster runs
</code></pre>
<h2 id="benchmark-categories"><a class="header" href="#benchmark-categories">Benchmark Categories</a></h2>
<h3 id="storage-layer"><a class="header" href="#storage-layer">Storage Layer</a></h3>
<ul>
<li><a href="benchmarks/tensor-store.html">tensor_store</a> - DashMap concurrent storage, Bloom filters,
snapshots</li>
<li><a href="benchmarks/tensor-compress.html">tensor_compress</a> - Tensor Train, delta encoding, RLE</li>
</ul>
<h3 id="engines"><a class="header" href="#engines">Engines</a></h3>
<ul>
<li><a href="benchmarks/relational-engine.html">relational_engine</a> - SQL operations, indexes, JOINs,
aggregates</li>
<li><a href="benchmarks/graph-engine.html">graph_engine</a> - Node/edge operations, traversals, path
finding</li>
<li><a href="benchmarks/vector-engine.html">vector_engine</a> - Embeddings, SIMD similarity, HNSW index</li>
</ul>
<h3 id="extended-modules"><a class="header" href="#extended-modules">Extended Modules</a></h3>
<ul>
<li><a href="benchmarks/tensor-vault.html">tensor_vault</a> - Encrypted storage, access control</li>
<li><a href="benchmarks/tensor-cache.html">tensor_cache</a> - LLM response caching, semantic search</li>
<li><a href="benchmarks/tensor-blob.html">tensor_blob</a> - Blob storage operations</li>
</ul>
<h3 id="distributed-systems"><a class="header" href="#distributed-systems">Distributed Systems</a></h3>
<ul>
<li><a href="benchmarks/tensor-chain.html">tensor_chain</a> - Consensus, 2PC, gossip, sparse vectors</li>
</ul>
<h3 id="query-layer"><a class="header" href="#query-layer">Query Layer</a></h3>
<ul>
<li><a href="benchmarks/neumann-parser.html">neumann_parser</a> - Tokenization, parsing, expressions</li>
<li><a href="benchmarks/query-router.html">query_router</a> - Cross-engine query routing</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor_store-benchmarks"><a class="header" href="#tensor_store-benchmarks">tensor_store Benchmarks</a></h1>
<p>The tensor store uses DashMap (sharded concurrent HashMap) for thread-safe
key-value storage.</p>
<h2 id="core-operations"><a class="header" href="#core-operations">Core Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>100 items</th><th>1,000 items</th><th>10,000 items</th></tr></thead><tbody>
<tr><td><strong>put</strong></td><td>40us (2.5M/s)</td><td>447us (2.2M/s)</td><td>7ms (1.4M/s)</td></tr>
<tr><td><strong>get</strong></td><td>33us (3.0M/s)</td><td>320us (3.1M/s)</td><td>3ms (3.3M/s)</td></tr>
</tbody></table>
</div>
<h2 id="scan-operations-10k-total-items-parallel"><a class="header" href="#scan-operations-10k-total-items-parallel">Scan Operations (10k total items, parallel)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>scan 1k keys</td><td>191us</td></tr>
<tr><td>scan_count 1k keys</td><td>41us</td></tr>
</tbody></table>
</div>
<h2 id="concurrent-write-performance"><a class="header" href="#concurrent-write-performance">Concurrent Write Performance</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Threads</th><th>Disjoint Keys</th><th>High Contention (100 keys)</th></tr></thead><tbody>
<tr><td>2</td><td>795us</td><td>974us</td></tr>
<tr><td>4</td><td>1.59ms</td><td>1.48ms</td></tr>
<tr><td>8</td><td>4.6ms</td><td>2.33ms</td></tr>
</tbody></table>
</div>
<h2 id="mixed-workload"><a class="header" href="#mixed-workload">Mixed Workload</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Time</th></tr></thead><tbody>
<tr><td>4 readers + 2 writers</td><td>579us</td></tr>
</tbody></table>
</div>
<h2 id="analysis"><a class="header" href="#analysis">Analysis</a></h2>
<ul>
<li><strong>Read vs Write</strong>: Reads are ~20% faster than writes due to DashMap’s
read-optimized design</li>
<li><strong>Scaling</strong>: Near-linear scaling up to 10k items; slight degradation at scale
due to hash table growth</li>
<li><strong>Concurrency</strong>: DashMap’s 16-shard design provides excellent concurrent
performance</li>
<li><strong>Contention</strong>: Under high contention, performance actually improves at 8
threads vs 4 (lock sharding distributes load)</li>
<li><strong>Parallel scans</strong>: Uses rayon for &gt;1000 keys (25-53% faster)</li>
<li><strong>scan_count vs scan</strong>: Count-only is ~5x faster (avoids string cloning)</li>
</ul>
<h2 id="bloom-filter-optional"><a class="header" href="#bloom-filter-optional">Bloom Filter (optional)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>add</td><td>68 ns</td></tr>
<tr><td>might_contain (hit)</td><td>46 ns</td></tr>
<tr><td>might_contain (miss)</td><td>63 ns</td></tr>
</tbody></table>
</div>
<h2 id="sparse-lookups-1k-keys-in-store"><a class="header" href="#sparse-lookups-1k-keys-in-store">Sparse Lookups (1K keys in store)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Query Type</th><th>Without Bloom</th><th>With Bloom</th></tr></thead><tbody>
<tr><td>Negative lookup</td><td>52 ns</td><td>68 ns</td></tr>
<tr><td>Positive lookup</td><td>45 ns</td><td>60 ns</td></tr>
<tr><td>Sparse workload (90% miss)</td><td>52 ns</td><td>67 ns</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Note</strong>: Bloom filter adds ~15ns overhead for in-memory DashMap stores. It’s
designed for scenarios where the backing store is slower (disk, network, remote
database), where the early rejection of non-existent keys avoids expensive I/O.</p>
</blockquote>
<h2 id="snapshot-persistence-bincode"><a class="header" href="#snapshot-persistence-bincode">Snapshot Persistence (bincode)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>100 items</th><th>1,000 items</th><th>10,000 items</th></tr></thead><tbody>
<tr><td><strong>save</strong></td><td>100 us (1.0M/s)</td><td>927 us (1.08M/s)</td><td>12.6 ms (791K/s)</td></tr>
<tr><td><strong>load</strong></td><td>74 us (1.35M/s)</td><td>826 us (1.21M/s)</td><td>10.7 ms (936K/s)</td></tr>
<tr><td><strong>load_with_bloom</strong></td><td>81 us (1.23M/s)</td><td>840 us (1.19M/s)</td><td>11.0 ms (908K/s)</td></tr>
</tbody></table>
</div>
<p>Each item is a TensorData with 3 fields: id (i64), name (String), embedding
(128-dim <code>Vec&lt;f32&gt;</code>).</p>
<h2 id="snapshot-file-sizes"><a class="header" href="#snapshot-file-sizes">Snapshot File Sizes</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Items</th><th>File Size</th><th>Per Item</th></tr></thead><tbody>
<tr><td>100</td><td>~60 KB</td><td>~600 bytes</td></tr>
<tr><td>1,000</td><td>~600 KB</td><td>~600 bytes</td></tr>
<tr><td>10,000</td><td>~6 MB</td><td>~600 bytes</td></tr>
</tbody></table>
</div>
<h2 id="snapshot-analysis"><a class="header" href="#snapshot-analysis">Snapshot Analysis</a></h2>
<ul>
<li><strong>Throughput</strong>: ~1M items/second for both save and load</li>
<li><strong>Atomicity</strong>: Uses temp file + rename for crash-safe writes</li>
<li><strong>Bloom filter overhead</strong>: ~3-5% slower to rebuild filter during load</li>
<li><strong>Scaling</strong>: Near-linear with dataset size</li>
<li><strong>File size</strong>: ~600 bytes per item with 128-dim embeddings (dominated by
vector data)</li>
</ul>
<h2 id="sparse-vectors-2"><a class="header" href="#sparse-vectors-2">Sparse Vectors</a></h2>
<p>SparseVector provides memory-efficient storage for high-sparsity embeddings by
storing only non-zero values.</p>
<h3 id="construction-768d"><a class="header" href="#construction-768d">Construction (768d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Sparsity</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>50%</td><td>1.2 us</td><td>640K/s</td></tr>
<tr><td>90%</td><td>890 ns</td><td>870K/s</td></tr>
<tr><td>99%</td><td>650 ns</td><td>1.18M/s</td></tr>
</tbody></table>
</div>
<h3 id="dot-product-768d"><a class="header" href="#dot-product-768d">Dot Product (768d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Sparsity</th><th>Sparse-Sparse</th><th>Sparse-Dense</th><th>Dense-Dense</th><th>Sparse Speedup</th></tr></thead><tbody>
<tr><td>50%</td><td>2.1 us</td><td>1.8 us</td><td>580 ns</td><td>0.3x (slower)</td></tr>
<tr><td>90%</td><td>380 ns</td><td>290 ns</td><td>580 ns</td><td>1.5-2x</td></tr>
<tr><td>99%</td><td>38 ns</td><td>26 ns</td><td>580 ns</td><td><strong>15-22x</strong></td></tr>
</tbody></table>
</div>
<h3 id="memory-compression"><a class="header" href="#memory-compression">Memory Compression</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Sparsity</th><th>Dense Size</th><th>Sparse Size</th><th>Ratio</th></tr></thead><tbody>
<tr><td>768</td><td>90%</td><td>3,072 B</td><td>1,024 B</td><td><strong>3x</strong></td></tr>
<tr><td>768</td><td>99%</td><td>3,072 B</td><td>96 B</td><td><strong>32x</strong></td></tr>
<tr><td>1536</td><td>99%</td><td>6,144 B</td><td>184 B</td><td><strong>33x</strong></td></tr>
</tbody></table>
</div>
<h3 id="sparse-vector-analysis"><a class="header" href="#sparse-vector-analysis">Sparse Vector Analysis</a></h3>
<ul>
<li><strong>High sparsity sweet spot</strong>: At 99% sparsity, dot products are 15-22x faster
than dense</li>
<li><strong>Memory scaling</strong>: Compression ratio = 1 / (1 - sparsity), so 99% sparse =
~100x smaller</li>
<li><strong>Construction overhead</strong>: Negligible (~1us per vector)</li>
<li><strong>Use case</strong>: Embeddings from sparse models, one-hot encodings, pruned
representations</li>
</ul>
<h2 id="delta-vectors"><a class="header" href="#delta-vectors">Delta Vectors</a></h2>
<p>DeltaVector stores embeddings as differences from reference “archetype” vectors,
ideal for clustered embeddings.</p>
<h3 id="construction-768d-5-delta"><a class="header" href="#construction-768d-5-delta">Construction (768d, 5% delta)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>128</td><td>1.9 us</td><td>526K/s</td></tr>
<tr><td>768</td><td>12.3 us</td><td>81K/s</td></tr>
<tr><td>1536</td><td>25.1 us</td><td>40K/s</td></tr>
</tbody></table>
</div>
<h3 id="dot-product-768d-precomputed-archetype-dot"><a class="header" href="#dot-product-768d-precomputed-archetype-dot">Dot Product (768d, precomputed archetype dot)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Time</th><th>vs Dense</th></tr></thead><tbody>
<tr><td>Delta precomputed</td><td>89 ns</td><td><strong>6.5x faster</strong></td></tr>
<tr><td>Delta full</td><td>620 ns</td><td>~same</td></tr>
<tr><td>Dense baseline</td><td>580 ns</td><td>1x</td></tr>
</tbody></table>
</div>
<h3 id="same-archetype-dot-product-768d"><a class="header" href="#same-archetype-dot-product-768d">Same-Archetype Dot Product (768d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Time</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Delta-delta</td><td>145 ns</td><td><strong>4x</strong></td></tr>
<tr><td>Dense baseline</td><td>580 ns</td><td>1x</td></tr>
</tbody></table>
</div>
<h3 id="delta-memory-768d"><a class="header" href="#delta-memory-768d">Delta Memory (768d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Delta Fraction</th><th>Dense Size</th><th>Delta Size</th><th>Ratio</th></tr></thead><tbody>
<tr><td>1% diff</td><td>3,072 B</td><td>120 B</td><td><strong>25x</strong></td></tr>
<tr><td>5% diff</td><td>3,072 B</td><td>360 B</td><td><strong>8.5x</strong></td></tr>
<tr><td>10% diff</td><td>3,072 B</td><td>680 B</td><td><strong>4.5x</strong></td></tr>
</tbody></table>
</div>
<h3 id="archetype-registry-8-archetypes-768d"><a class="header" href="#archetype-registry-8-archetypes-768d">Archetype Registry (8 archetypes, 768d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>find_best_archetype</td><td>4.2 us</td></tr>
<tr><td>encode</td><td>14 us</td></tr>
<tr><td>decode</td><td>1.1 us</td></tr>
</tbody></table>
</div>
<h3 id="delta-vector-analysis"><a class="header" href="#delta-vector-analysis">Delta Vector Analysis</a></h3>
<ul>
<li><strong>Precomputed speedup</strong>: With archetype dot products cached, 6.5x faster than
dense</li>
<li><strong>Cluster-friendly</strong>: Similar vectors share archetypes, deltas are sparse</li>
<li><strong>Use case</strong>: Semantic embeddings that cluster (documents, user profiles,
products)</li>
</ul>
<h2 id="k-means-clustering"><a class="header" href="#k-means-clustering">K-means Clustering</a></h2>
<p>K-means discovers archetype vectors automatically from embedding collections.</p>
<h3 id="k-means-fit-128d-k5"><a class="header" href="#k-means-fit-128d-k5">K-means fit (128d, k=5)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Vectors</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>100</td><td>50 us</td><td>2.0M elem/s</td></tr>
<tr><td>500</td><td>241 us</td><td>2.1M elem/s</td></tr>
<tr><td>1000</td><td>482 us</td><td>2.1M elem/s</td></tr>
</tbody></table>
</div>
<h3 id="varying-k-1000-vectors-128d"><a class="header" href="#varying-k-1000-vectors-128d">Varying k (1000 vectors, 128d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>k</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>2</td><td>183 us</td><td>5.5M elem/s</td></tr>
<tr><td>5</td><td>482 us</td><td>2.1M elem/s</td></tr>
<tr><td>10</td><td>984 us</td><td>1.0M elem/s</td></tr>
<tr><td>20</td><td>14.5 ms</td><td>69K elem/s</td></tr>
</tbody></table>
</div>
<h3 id="k-means-analysis"><a class="header" href="#k-means-analysis">K-means Analysis</a></h3>
<ul>
<li><strong>K-means++ is faster</strong>: Better initial centroids mean fewer iterations to
converge</li>
<li><strong>Linear with n</strong>: Doubling vectors roughly doubles time</li>
<li><strong>Quadratic with k at high k</strong>: Each iteration is O(n*k), and more clusters
need more iterations</li>
<li><strong>Use case</strong>: Auto-discover archetypes for delta encoding, cluster analysis,
centroid-based search</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="relational_engine-benchmarks"><a class="header" href="#relational_engine-benchmarks">relational_engine Benchmarks</a></h1>
<p>The relational engine provides SQL-like operations on top of tensor_store, with
optional hash indexes for accelerated equality lookups and tensor-native
condition evaluation.</p>
<h2 id="row-insertion"><a class="header" href="#row-insertion">Row Insertion</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Count</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>100</td><td>462us</td><td>216K rows/s</td></tr>
<tr><td>1,000</td><td>3.1ms</td><td>319K rows/s</td></tr>
<tr><td>5,000</td><td>15.6ms</td><td>320K rows/s</td></tr>
</tbody></table>
</div>
<h2 id="batch-insertion"><a class="header" href="#batch-insertion">Batch Insertion</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Count</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>100</td><td>282us</td><td>355K rows/s</td></tr>
<tr><td>1,000</td><td>1.45ms</td><td>688K rows/s</td></tr>
<tr><td>5,000</td><td>7.26ms</td><td>688K rows/s</td></tr>
</tbody></table>
</div>
<h2 id="select-full-scan"><a class="header" href="#select-full-scan">Select Full Scan</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Rows</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>100</td><td>119us</td><td>841K rows/s</td></tr>
<tr><td>1,000</td><td>995us</td><td>1.01M rows/s</td></tr>
<tr><td>5,000</td><td>5.27ms</td><td>949K rows/s</td></tr>
</tbody></table>
</div>
<h2 id="select-with-index-vs-without-5000-rows"><a class="header" href="#select-with-index-vs-without-5000-rows">Select with Index vs Without (5,000 rows)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Query Type</th><th>With Index</th><th>Without Index</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Equality (2% match)</td><td>105us</td><td>4.23ms</td><td><strong>40x</strong></td></tr>
<tr><td>By _id (single row)</td><td>2.93us</td><td>4.70ms</td><td><strong>1,604x</strong></td></tr>
</tbody></table>
</div>
<h2 id="select-filtered---no-index-5000-rows"><a class="header" href="#select-filtered---no-index-5000-rows">Select Filtered - No Index (5,000 rows)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Filter Type</th><th>Time</th></tr></thead><tbody>
<tr><td>Range (20% match)</td><td>4.16ms</td></tr>
<tr><td>Compound AND</td><td>4.42ms</td></tr>
</tbody></table>
</div>
<h2 id="index-creation-parallel"><a class="header" href="#index-creation-parallel">Index Creation (parallel)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Rows</th><th>Time</th></tr></thead><tbody>
<tr><td>100</td><td>554us</td></tr>
<tr><td>1,000</td><td>2.75ms</td></tr>
<tr><td>5,000</td><td>12.3ms</td></tr>
</tbody></table>
</div>
<h2 id="updatedelete-1000-rows-10-affected"><a class="header" href="#updatedelete-1000-rows-10-affected">Update/Delete (1,000 rows, 10% affected)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>Update</td><td>1.74ms</td></tr>
<tr><td>Delete</td><td>2.14ms</td></tr>
</tbody></table>
</div>
<h2 id="join-performance-hash-join"><a class="header" href="#join-performance-hash-join">Join Performance (hash join)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Tables</th><th>Result Rows</th><th>Time</th></tr></thead><tbody>
<tr><td>50 users x 500 posts</td><td>500</td><td>1.78ms</td></tr>
<tr><td>100 users x 1000 posts</td><td>1,000</td><td>1.50ms</td></tr>
<tr><td>100 users x 5000 posts</td><td>5,000</td><td>32.2ms</td></tr>
</tbody></table>
</div>
<h2 id="join-types-10k-x-10k-rows"><a class="header" href="#join-types-10k-x-10k-rows">JOIN Types (10K x 10K rows)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>JOIN Type</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>INNER JOIN</td><td>45ms</td><td>2.2M rows/s</td></tr>
<tr><td>LEFT JOIN</td><td>52ms</td><td>1.9M rows/s</td></tr>
<tr><td>RIGHT JOIN</td><td>51ms</td><td>1.9M rows/s</td></tr>
<tr><td>FULL JOIN</td><td>68ms</td><td>1.5M rows/s</td></tr>
<tr><td>CROSS JOIN</td><td>180ms</td><td>555K rows/s</td></tr>
<tr><td>NATURAL JOIN</td><td>48ms</td><td>2.1M rows/s</td></tr>
</tbody></table>
</div>
<h2 id="aggregate-functions-1m-rows-simd-accelerated"><a class="header" href="#aggregate-functions-1m-rows-simd-accelerated">Aggregate Functions (1M rows, SIMD-accelerated)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>COUNT(*)</td><td>2.1ms</td><td>O(1) via counter</td></tr>
<tr><td>SUM(col)</td><td>8.5ms</td><td>SIMD i64x4</td></tr>
<tr><td>AVG(col)</td><td>8.7ms</td><td>SIMD i64x4</td></tr>
<tr><td>MIN(col)</td><td>12ms</td><td>Full scan</td></tr>
<tr><td>MAX(col)</td><td>12ms</td><td>Full scan</td></tr>
</tbody></table>
</div>
<h2 id="group-by-performance-100k-rows"><a class="header" href="#group-by-performance-100k-rows">GROUP BY Performance (100K rows)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Groups</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>10</td><td>15ms</td><td>Parallel aggregation</td></tr>
<tr><td>100</td><td>18ms</td><td>Hash-based grouping</td></tr>
<tr><td>1,000</td><td>25ms</td><td>Low per-group overhead</td></tr>
<tr><td>10,000</td><td>45ms</td><td>High cardinality</td></tr>
</tbody></table>
</div>
<h2 id="row-count"><a class="header" href="#row-count">Row Count</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Rows</th><th>Time</th></tr></thead><tbody>
<tr><td>100</td><td>49us</td></tr>
<tr><td>1,000</td><td>462us</td></tr>
<tr><td>5,000</td><td>2.95ms</td></tr>
</tbody></table>
</div>
<h2 id="analysis-1"><a class="header" href="#analysis-1">Analysis</a></h2>
<ul>
<li><strong>Index acceleration</strong>: Hash indexes provide O(1) lookup for equality
conditions
<ul>
<li>40x speedup for equality queries matching 2% of rows</li>
<li>1,604x speedup for single-row _id lookups</li>
</ul>
</li>
<li><strong>Full scan cost</strong>: Without index, O(n) for all queries (parallelized for
<blockquote>
<p>1000 rows)</p>
</blockquote>
</li>
<li><strong>Batch insert</strong>: 2x faster than individual inserts (688K/s vs 320K/s)</li>
<li><strong>Tensor-native evaluation</strong>: <code>evaluate_tensor()</code> evaluates conditions
directly on TensorData, avoiding Row conversion for non-matching rows</li>
<li><strong>Parallel operations</strong>: update/delete/create_index use rayon for condition
evaluation</li>
<li><strong>Index maintenance</strong>: Small overhead on insert/update/delete to maintain
indexes</li>
<li><strong>Join complexity</strong>: O(n+m) hash join for INNER/LEFT/RIGHT/NATURAL; O(n*m) for
CROSS</li>
<li><strong>Aggregate functions</strong>: SUM/AVG use SIMD i64x4 vectors for 4x throughput
improvement</li>
<li><strong>GROUP BY</strong>: Hash-based grouping with parallel per-group aggregation</li>
</ul>
<h2 id="competitor-comparison"><a class="header" href="#competitor-comparison">Competitor Comparison</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Neumann</th><th>SQLite</th><th>DuckDB</th><th>Notes</th></tr></thead><tbody>
<tr><td>Point lookup (indexed)</td><td>2.9us</td><td>~3us</td><td>~30us</td><td>B-tree optimized</td></tr>
<tr><td>Full scan (5K rows)</td><td>5.3ms</td><td>~15ms</td><td>~2ms</td><td>DuckDB columnar wins</td></tr>
<tr><td>Aggregation (1M rows)</td><td>8.5ms</td><td>~200ms</td><td>~12ms</td><td>SIMD-accelerated</td></tr>
<tr><td>Hash join (10Kx10K)</td><td>45ms</td><td>~500ms</td><td>~35ms</td><td>Parallel execution</td></tr>
<tr><td>Insert (single row)</td><td>3.1us</td><td>~2us</td><td>~5us</td><td>SQLite B-tree optimal</td></tr>
<tr><td>Batch insert (1K rows)</td><td>1.5ms</td><td>~8ms</td><td>~3ms</td><td>Neumann batch-optimized</td></tr>
</tbody></table>
</div>
<h2 id="design-trade-offs"><a class="header" href="#design-trade-offs">Design Trade-offs</a></h2>
<ul>
<li><strong>vs SQLite</strong>: Neumann trades SQLite’s proven stability for tensor-native
storage and SIMD acceleration. SQLite wins on point lookups; Neumann wins on
analytics.</li>
<li><strong>vs DuckDB</strong>: Similar columnar design. DuckDB has more mature query
optimizer; Neumann has tighter tensor integration and lower memory footprint.</li>
<li><strong>Unique to Neumann</strong>: Unified tensor storage enables cross-engine queries
(relational + graph + vector) without data movement.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graph_engine-benchmarks"><a class="header" href="#graph_engine-benchmarks">graph_engine Benchmarks</a></h1>
<p>The graph engine stores nodes and edges as tensors, using adjacency lists for
neighbor lookups.</p>
<h2 id="node-creation"><a class="header" href="#node-creation">Node Creation</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Count</th><th>Time</th><th>Per Node</th></tr></thead><tbody>
<tr><td>100</td><td>107us</td><td>1.07us</td></tr>
<tr><td>1,000</td><td>1.67ms</td><td>1.67us</td></tr>
<tr><td>5,000</td><td>9.4ms</td><td>1.88us</td></tr>
</tbody></table>
</div>
<h2 id="edge-creation-1000-edges"><a class="header" href="#edge-creation-1000-edges">Edge Creation (1,000 edges)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Time</th><th>Per Edge</th></tr></thead><tbody>
<tr><td>Directed</td><td>2.4ms</td><td>2.4us</td></tr>
<tr><td>Undirected</td><td>3.6ms</td><td>3.6us</td></tr>
</tbody></table>
</div>
<h2 id="neighbor-lookup-star-graph"><a class="header" href="#neighbor-lookup-star-graph">Neighbor Lookup (star graph)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Fan-out</th><th>Time</th><th>Per Neighbor</th></tr></thead><tbody>
<tr><td>10</td><td>16us</td><td>1.6us</td></tr>
<tr><td>50</td><td>79us</td><td>1.6us</td></tr>
<tr><td>100</td><td>178us</td><td>1.8us</td></tr>
</tbody></table>
</div>
<h2 id="bfs-traversal-binary-tree"><a class="header" href="#bfs-traversal-binary-tree">BFS Traversal (binary tree)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Depth</th><th>Nodes</th><th>Time</th><th>Per Node</th></tr></thead><tbody>
<tr><td>5</td><td>31</td><td>110us</td><td>3.5us</td></tr>
<tr><td>7</td><td>127</td><td>442us</td><td>3.5us</td></tr>
<tr><td>9</td><td>511</td><td>1.5ms</td><td>2.9us</td></tr>
</tbody></table>
</div>
<h2 id="shortest-path-bfs"><a class="header" href="#shortest-path-bfs">Shortest Path (BFS)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Graph Type</th><th>Size</th><th>Time</th></tr></thead><tbody>
<tr><td>Chain</td><td>10 nodes</td><td>8.2us</td></tr>
<tr><td>Chain</td><td>50 nodes</td><td>44us</td></tr>
<tr><td>Chain</td><td>100 nodes</td><td>96us</td></tr>
<tr><td>Grid</td><td>5x5</td><td>55us</td></tr>
<tr><td>Grid</td><td>10x10</td><td>265us</td></tr>
</tbody></table>
</div>
<h2 id="analysis-2"><a class="header" href="#analysis-2">Analysis</a></h2>
<ul>
<li><strong>Undirected edges</strong>: ~50% slower than directed (stores reverse edge
internally)</li>
<li><strong>Traversal</strong>: Consistent ~3us per node visited, good BFS implementation</li>
<li><strong>Path finding</strong>: Near-linear with path length in chains; grid explores more
nodes</li>
<li><strong>Parallel delete_node</strong>: Uses rayon for high-degree nodes (&gt;100 edges)</li>
<li><strong>Memory overhead</strong>: Each node/edge is a full TensorData (~5-10 allocations)</li>
</ul>
<h2 id="storage-model-3"><a class="header" href="#storage-model-3">Storage Model</a></h2>
<p>graph_engine stores each node and edge as a separate tensor:</p>
<pre><code class="language-text">node:{id} -&gt; TensorData { label, properties... }
edge:{id} -&gt; TensorData { from, to, label, directed, properties... }
adj:{node_id}:out -&gt; TensorData { edge_ids: [...] }
adj:{node_id}:in -&gt; TensorData { edge_ids: [...] }
</code></pre>
<h3 id="trade-offs"><a class="header" href="#trade-offs">Trade-offs</a></h3>
<ul>
<li><strong>Pro</strong>: Flexible property storage, consistent with tensor model</li>
<li><strong>Con</strong>: More key lookups than traditional adjacency list</li>
<li><strong>Pro</strong>: Each component independently updatable</li>
</ul>
<h2 id="complexity"><a class="header" href="#complexity">Complexity</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td>create_node</td><td>O(1)</td><td>Hash insert</td></tr>
<tr><td>create_edge</td><td>O(1)</td><td>Hash insert + adjacency update</td></tr>
<tr><td>get_neighbors</td><td>O(degree)</td><td>Adjacency list lookup</td></tr>
<tr><td>bfs</td><td>O(V + E)</td><td>Standard BFS</td></tr>
<tr><td>shortest_path</td><td>O(V + E)</td><td>BFS-based</td></tr>
<tr><td>delete_node</td><td>O(degree)</td><td>Removes all edges</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="vector_engine-benchmarks"><a class="header" href="#vector_engine-benchmarks">vector_engine Benchmarks</a></h1>
<p>The vector engine stores embeddings and performs k-nearest neighbor search using
cosine similarity.</p>
<h2 id="store-embedding"><a class="header" href="#store-embedding">Store Embedding</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>128</td><td>366 ns</td><td>2.7M/s</td></tr>
<tr><td>768</td><td>892 ns</td><td>1.1M/s</td></tr>
<tr><td>1536</td><td>969 ns</td><td>1.0M/s</td></tr>
</tbody></table>
</div>
<h2 id="get-embedding"><a class="header" href="#get-embedding">Get Embedding</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Time</th></tr></thead><tbody>
<tr><td>768</td><td>287 ns</td></tr>
</tbody></table>
</div>
<h2 id="delete-embedding"><a class="header" href="#delete-embedding">Delete Embedding</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>delete</td><td>806 ns</td></tr>
</tbody></table>
</div>
<h2 id="similarity-search-top-10-simd--adaptive-parallel"><a class="header" href="#similarity-search-top-10-simd--adaptive-parallel">Similarity Search (top 10, SIMD + adaptive parallel)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Dataset</th><th>Time</th><th>Per Vector</th><th>Mode</th></tr></thead><tbody>
<tr><td>1,000 x 128d</td><td>242 us</td><td>242 ns</td><td>Sequential</td></tr>
<tr><td>1,000 x 768d</td><td>367 us</td><td>367 ns</td><td>Sequential</td></tr>
<tr><td>10,000 x 128d</td><td>1.93 ms</td><td>193 ns</td><td>Parallel</td></tr>
</tbody></table>
</div>
<h2 id="cosine-similarity-computation-simd-accelerated"><a class="header" href="#cosine-similarity-computation-simd-accelerated">Cosine Similarity Computation (SIMD-accelerated)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Time</th></tr></thead><tbody>
<tr><td>128</td><td>26 ns</td></tr>
<tr><td>768</td><td>165 ns</td></tr>
<tr><td>1536</td><td>369 ns</td></tr>
</tbody></table>
</div>
<h2 id="analysis-3"><a class="header" href="#analysis-3">Analysis</a></h2>
<ul>
<li><strong>SIMD acceleration</strong>: 8-wide f32 SIMD (via <code>wide</code> crate) provides 3-9x
speedup for cosine similarity</li>
<li><strong>Adaptive parallelism</strong>: Uses rayon for parallel search when &gt;5000 vectors
(1.6x speedup at 10K)</li>
<li><strong>Linear scaling with dimension</strong>: Cosine similarity is O(d) where d is vector
dimension</li>
<li><strong>Linear scaling with dataset size</strong>: Brute-force search is O(n*d) for n
vectors</li>
<li><strong>Memory bound</strong>: For 768d vectors, ~3 KB per embedding (768 * 4 bytes)</li>
<li><strong>Search throughput</strong>: ~4M vector comparisons/second at 128d (with SIMD)</li>
<li><strong>Store/Get performance</strong>: Sub-microsecond for typical embedding sizes</li>
</ul>
<h2 id="complexity-1"><a class="header" href="#complexity-1">Complexity</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td>store_embedding</td><td>O(d)</td><td>Vector copy + hash insert</td></tr>
<tr><td>get_embedding</td><td>O(d)</td><td>Hash lookup + vector clone</td></tr>
<tr><td>delete_embedding</td><td>O(1)</td><td>Hash removal</td></tr>
<tr><td>search_similar</td><td>O(n*d)</td><td>Brute-force scan</td></tr>
<tr><td>compute_similarity</td><td>O(d)</td><td>Dot product + 2 magnitude calculations</td></tr>
</tbody></table>
</div>
<h2 id="hnsw-index-approximate-nearest-neighbor"><a class="header" href="#hnsw-index-approximate-nearest-neighbor">HNSW Index (Approximate Nearest Neighbor)</a></h2>
<p>HNSW provides O(log n) search complexity instead of O(n) brute force.</p>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Search Time (5K, 128d)</th></tr></thead><tbody>
<tr><td>high_speed</td><td>~50 us</td></tr>
<tr><td>default</td><td>~100 us</td></tr>
<tr><td>high_recall</td><td>~200 us</td></tr>
</tbody></table>
</div>
<h3 id="hnsw-vs-brute-force-10k-vectors-128d"><a class="header" href="#hnsw-vs-brute-force-10k-vectors-128d">HNSW vs Brute Force (10K vectors, 128d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Search Time</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Brute force</td><td>~2 ms</td><td>1x</td></tr>
<tr><td>HNSW default</td><td>~150 us</td><td>~13x</td></tr>
</tbody></table>
</div>
<h3 id="recommended-approach-by-corpus-size"><a class="header" href="#recommended-approach-by-corpus-size">Recommended Approach by Corpus Size</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Corpus Size</th><th>Approach</th><th>Rationale</th></tr></thead><tbody>
<tr><td>&lt; 10K</td><td>Brute force</td><td>Fast enough, pure tensor</td></tr>
<tr><td>10K - 100K</td><td>HNSW</td><td>Pragmatic, 5-13x faster</td></tr>
<tr><td>&gt; 100K</td><td>HNSW</td><td>Necessary for latency</td></tr>
</tbody></table>
</div>
<h3 id="scaling-projections-hnsw-for-10k-vectors"><a class="header" href="#scaling-projections-hnsw-for-10k-vectors">Scaling Projections (HNSW for &gt;10K vectors)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Vectors</th><th>Dimension</th><th>Search Time (est.)</th></tr></thead><tbody>
<tr><td>10K</td><td>768</td><td>~200 us</td></tr>
<tr><td>100K</td><td>768</td><td>~500 us</td></tr>
<tr><td>1M</td><td>768</td><td>~1 ms</td></tr>
</tbody></table>
</div>
<p>For production workloads at extreme scale (&gt;1M vectors), consider:</p>
<ul>
<li>Sharded HNSW across multiple nodes</li>
<li>Dimensionality reduction (PCA)</li>
<li>Quantization (int8, binary)</li>
</ul>
<h2 id="storage-model-4"><a class="header" href="#storage-model-4">Storage Model</a></h2>
<p>vector_engine stores each embedding as a tensor:</p>
<pre><code class="language-text">emb:{key} -&gt; TensorData { vector: [...] }
</code></pre>
<h3 id="trade-offs-1"><a class="header" href="#trade-offs-1">Trade-offs</a></h3>
<ul>
<li><strong>Pro</strong>: Simple storage model, consistent with tensor abstraction</li>
<li><strong>Pro</strong>: Sub-microsecond store/get operations</li>
<li><strong>Pro</strong>: HNSW index for O(log n) approximate nearest neighbor search</li>
<li><strong>Con</strong>: Brute-force O(n*d) for exact search (use HNSW for approximate)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor_compress-benchmarks"><a class="header" href="#tensor_compress-benchmarks">tensor_compress Benchmarks</a></h1>
<p>The tensor_compress crate provides compression algorithms optimized for tensor
data: Tensor Train decomposition, delta encoding, sparse vectors, and run-length
encoding.</p>
<h2 id="tensor-train-decomposition-primary-compression-method"><a class="header" href="#tensor-train-decomposition-primary-compression-method">Tensor Train Decomposition (primary compression method)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Peak RAM</th></tr></thead><tbody>
<tr><td>tt_decompose_256d</td><td>~50 us</td><td>41.8 KB</td></tr>
<tr><td>tt_decompose_1024d</td><td>~80 us</td><td>60.9 KB</td></tr>
<tr><td>tt_decompose_4096d</td><td>~120 us</td><td>137.5 KB</td></tr>
<tr><td>tt_reconstruct_4096d</td><td>~1.2 ms</td><td>67.9 KB</td></tr>
<tr><td>tt_dot_product_4096d</td><td>~400 ns</td><td>69.2 KB</td></tr>
<tr><td>tt_cosine_similarity_4096d</td><td>~1 us</td><td>69.2 KB</td></tr>
</tbody></table>
</div>
<h2 id="delta-encoding-10k-sequential-ids"><a class="header" href="#delta-encoding-10k-sequential-ids">Delta Encoding (10K sequential IDs)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th><th>Peak RAM</th></tr></thead><tbody>
<tr><td>compress_ids</td><td>8.0 us</td><td>1.25M IDs/s</td><td>~210 KB</td></tr>
<tr><td>decompress_ids</td><td>33 us</td><td>303K IDs/s</td><td>~100 KB</td></tr>
</tbody></table>
</div>
<h2 id="run-length-encoding-100k-values"><a class="header" href="#run-length-encoding-100k-values">Run-Length Encoding (100K values)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th><th>Peak RAM</th></tr></thead><tbody>
<tr><td>rle_encode</td><td>29 us</td><td>3.4M values/s</td><td>~445 KB</td></tr>
<tr><td>rle_decode</td><td>38 us</td><td>2.6M values/s</td><td>~833 KB</td></tr>
</tbody></table>
</div>
<h2 id="compression-ratios"><a class="header" href="#compression-ratios">Compression Ratios</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Data Type</th><th>Technique</th><th>Ratio</th><th>Lossless</th></tr></thead><tbody>
<tr><td>4096-dim embeddings</td><td>Tensor Train</td><td>10-20x</td><td>No (&lt;1% error)</td></tr>
<tr><td>1024-dim embeddings</td><td>Tensor Train</td><td>4-8x</td><td>No (&lt;1% error)</td></tr>
<tr><td>Sparse vectors</td><td>Native sparse</td><td>3-32x</td><td>Yes</td></tr>
<tr><td>Sequential IDs</td><td>Delta + varint</td><td>4-8x</td><td>Yes</td></tr>
<tr><td>Repeated values</td><td>RLE</td><td>2-100x</td><td>Yes</td></tr>
</tbody></table>
</div>
<h2 id="analysis-4"><a class="header" href="#analysis-4">Analysis</a></h2>
<ul>
<li><strong>TT decomposition</strong>: Achieves 10-20x compression for high-dimensional
embeddings (4096+)</li>
<li><strong>TT operations in compressed space</strong>: Dot product and cosine similarity
computed directly in TT format without full reconstruction</li>
<li><strong>Delta encoding</strong>: Asymmetric - compression is 4x faster than decompression</li>
<li><strong>Sparse format</strong>: Efficient for vectors with &gt;50% zeros, stores only non-zero
positions/values</li>
<li><strong>RLE</strong>: Best for highly repeated data (status columns, category IDs)</li>
<li><strong>Memory efficiency</strong>: All operations use &lt; 1 MB for typical data sizes</li>
<li><strong>Integration</strong>: Use <code>SAVE COMPRESSED</code> in shell or
<code>save_snapshot_compressed()</code> API</li>
</ul>
<h2 id="usage-recommendations"><a class="header" href="#usage-recommendations">Usage Recommendations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Data Characteristics</th><th>Recommended Compression</th></tr></thead><tbody>
<tr><td>High-dimensional embeddings (1024+)</td><td>Tensor Train</td></tr>
<tr><td>Sparse embeddings (&gt;50% zeros)</td><td>Native sparse format</td></tr>
<tr><td>Sequential IDs (node IDs, row IDs)</td><td>Delta + varint</td></tr>
<tr><td>Categorical columns with repeats</td><td>RLE</td></tr>
<tr><td>Mixed data snapshots</td><td>Composite (auto-detect)</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="tensor_vault-benchmarks"><a class="header" href="#tensor_vault-benchmarks">tensor_vault Benchmarks</a></h1>
<p>The tensor_vault crate provides AES-256-GCM encrypted secret storage with
graph-based access control, permission levels, TTL grants, rate limiting,
namespace isolation, audit logging, and secret versioning.</p>
<h2 id="key-derivation-argon2id"><a class="header" href="#key-derivation-argon2id">Key Derivation (Argon2id)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Peak RAM</th></tr></thead><tbody>
<tr><td>argon2id_derivation</td><td>80 ms</td><td>~64 MB</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Note</strong>: Argon2id is intentionally slow to resist brute-force attacks. The
64MB memory cost is configurable via <code>VaultConfig</code>.</p>
</blockquote>
<h2 id="encryptiondecryption-aes-256-gcm"><a class="header" href="#encryptiondecryption-aes-256-gcm">Encryption/Decryption (AES-256-GCM)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Peak RAM</th></tr></thead><tbody>
<tr><td>set_1kb</td><td>29 us</td><td>~3 KB</td></tr>
<tr><td>get_1kb</td><td>24 us</td><td>~3 KB</td></tr>
<tr><td>set_10kb</td><td>93 us</td><td>~25 KB</td></tr>
<tr><td>get_10kb</td><td>91 us</td><td>~25 KB</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Note</strong>: <code>set</code> includes versioning overhead (storing previous version
pointers). <code>get</code> includes audit logging.</p>
</blockquote>
<h2 id="access-control-graph-path-verification"><a class="header" href="#access-control-graph-path-verification">Access Control (Graph Path Verification)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Peak RAM</th></tr></thead><tbody>
<tr><td>check_shallow (1 hop)</td><td>6 us</td><td>~2 KB</td></tr>
<tr><td>check_deep (10 hops)</td><td>17 us</td><td>~3 KB</td></tr>
<tr><td>grant</td><td>18 us</td><td>~1 KB</td></tr>
<tr><td>revoke</td><td>1.07 ms</td><td>~1 KB</td></tr>
</tbody></table>
</div>
<h2 id="secret-listing"><a class="header" href="#secret-listing">Secret Listing</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Peak RAM</th></tr></thead><tbody>
<tr><td>list_100_secrets</td><td>291 us</td><td>~4 KB</td></tr>
<tr><td>list_1000_secrets</td><td>2.7 ms</td><td>~40 KB</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Note</strong>: List includes access control checks and key name decryption for
pattern matching.</p>
</blockquote>
<h2 id="analysis-5"><a class="header" href="#analysis-5">Analysis</a></h2>
<ul>
<li><strong>Key derivation</strong>: Argon2id dominates vault initialization (~80ms). This is
by design for security.</li>
<li><strong>Access check improved</strong>: Path verification is now ~6us for shallow, ~17us
for deep (85% faster than before).</li>
<li><strong>Versioning overhead</strong>: <code>set</code> is ~2x slower due to version tracking (stores
pointer array).</li>
<li><strong>Audit overhead</strong>: Every operation logs to audit store (adds ~5-10us per
operation).</li>
<li><strong>Revoke performance</strong>: ~1ms due to edge deletion, TTL tracker cleanup, and
audit logging.</li>
<li><strong>List scaling</strong>: ~2.7us per secret at 1000 (includes decryption for pattern
matching).</li>
</ul>
<h2 id="feature-performance-overhead"><a class="header" href="#feature-performance-overhead">Feature Performance Overhead</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Overhead</th></tr></thead><tbody>
<tr><td>Permission check</td><td>~1 us (edge type comparison)</td></tr>
<tr><td>Rate limit check</td><td>~100 ns (DashMap lookup)</td></tr>
<tr><td>TTL check</td><td>~50 ns (heap peek)</td></tr>
<tr><td>Audit log write</td><td>~5 us (tensor store put)</td></tr>
<tr><td>Version tracking</td><td>~10 us (pointer array update)</td></tr>
</tbody></table>
</div>
<h2 id="security-vs-performance-trade-offs"><a class="header" href="#security-vs-performance-trade-offs">Security vs Performance Trade-offs</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Key Derivation</th><th>Security</th></tr></thead><tbody>
<tr><td>Default (64MB, 3 iter)</td><td>~80 ms</td><td>High</td></tr>
<tr><td>Fast (16MB, 1 iter)</td><td>~25 ms</td><td>Medium</td></tr>
<tr><td>Paranoid (256MB, 10 iter)</td><td>~800 ms</td><td>Very High</td></tr>
</tbody></table>
</div>
<h2 id="recommendations"><a class="header" href="#recommendations">Recommendations</a></h2>
<ul>
<li><strong>Development</strong>: Use <code>Fast</code> configuration for quicker iteration</li>
<li><strong>Production</strong>: Use <code>Default</code> or <code>Paranoid</code> based on threat model</li>
<li><strong>High-throughput</strong>: Cache access decisions where possible</li>
<li><strong>Audit compliance</strong>: Accept ~5us overhead for complete audit trail</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor_cache-benchmarks"><a class="header" href="#tensor_cache-benchmarks">tensor_cache Benchmarks</a></h1>
<p>The tensor_cache crate provides LLM response caching with exact, semantic
(HNSW), and embedding caches.</p>
<h2 id="exact-cache-hash-based-o1"><a class="header" href="#exact-cache-hash-based-o1">Exact Cache (Hash-based O(1))</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>lookup_hit</td><td>208 ns</td></tr>
<tr><td>lookup_miss</td><td>102 ns</td></tr>
</tbody></table>
</div>
<h2 id="semantic-cache-hnsw-based-olog-n"><a class="header" href="#semantic-cache-hnsw-based-olog-n">Semantic Cache (HNSW-based O(log n))</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>lookup_hit</td><td>21 us</td></tr>
</tbody></table>
</div>
<h2 id="put-exact--semantic--hnsw-insert"><a class="header" href="#put-exact--semantic--hnsw-insert">Put (Exact + Semantic + HNSW insert)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Entries</th><th>Time</th></tr></thead><tbody>
<tr><td>100</td><td>49 us</td></tr>
<tr><td>1,000</td><td>47 us</td></tr>
<tr><td>10,000</td><td>53 us</td></tr>
</tbody></table>
</div>
<h2 id="embedding-cache"><a class="header" href="#embedding-cache">Embedding Cache</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>lookup_hit</td><td>230 ns</td></tr>
<tr><td>lookup_miss</td><td>110 ns</td></tr>
</tbody></table>
</div>
<h2 id="eviction-batch-processing"><a class="header" href="#eviction-batch-processing">Eviction (batch processing)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Entries in Cache</th><th>Time</th></tr></thead><tbody>
<tr><td>1,000</td><td>3.3 us</td></tr>
<tr><td>5,000</td><td>4.0 us</td></tr>
<tr><td>10,000</td><td>8.4 us</td></tr>
</tbody></table>
</div>
<h2 id="distance-metrics-raw-computation-128d"><a class="header" href="#distance-metrics-raw-computation-128d">Distance Metrics (raw computation, 128d)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>Jaccard</td><td>73 ns</td><td>Fastest, best for sparse</td></tr>
<tr><td>Euclidean</td><td>105 ns</td><td>Good for spatial data</td></tr>
<tr><td>Cosine</td><td>186 ns</td><td>Default, best for dense</td></tr>
<tr><td>Angular</td><td>193 ns</td><td>Alternative to cosine</td></tr>
</tbody></table>
</div>
<h2 id="semantic-lookup-by-metric-1000-entries"><a class="header" href="#semantic-lookup-by-metric-1000-entries">Semantic Lookup by Metric (1000 entries)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Time</th></tr></thead><tbody>
<tr><td>Jaccard</td><td>28.6 us</td></tr>
<tr><td>Euclidean</td><td>27.8 us</td></tr>
<tr><td>Cosine</td><td>28.4 us</td></tr>
</tbody></table>
</div>
<h2 id="sparse-vs-dense-80-sparsity"><a class="header" href="#sparse-vs-dense-80-sparsity">Sparse vs Dense (80% sparsity)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Time</th><th>Improvement</th></tr></thead><tbody>
<tr><td>Dense lookup</td><td>28.8 us</td><td>baseline</td></tr>
<tr><td>Sparse lookup</td><td>24.1 us</td><td><strong>16% faster</strong></td></tr>
</tbody></table>
</div>
<h2 id="auto-metric-selection"><a class="header" href="#auto-metric-selection">Auto-Metric Selection</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>Sparsity check</td><td>0.66 ns</td></tr>
<tr><td>Auto-select dense</td><td>13.4 us</td></tr>
<tr><td>Auto-select sparse</td><td>16.5 us</td></tr>
</tbody></table>
</div>
<h2 id="redis-comparison"><a class="header" href="#redis-comparison">Redis Comparison</a></h2>
<div class="table-wrapper"><table><thead><tr><th>System</th><th>In-Process</th><th>Over TCP</th></tr></thead><tbody>
<tr><td>Redis</td><td>~60 ns</td><td>~143 us</td></tr>
<tr><td>tensor_cache (exact)</td><td>208 ns</td><td>~143 us*</td></tr>
<tr><td>tensor_cache (semantic)</td><td>21 us</td><td>N/A</td></tr>
</tbody></table>
</div>
<p>*Estimated: network latency dominates (99.9% of time).</p>
<p><strong>Key Insight</strong>: For embedded use (no network), Redis is 3.5x faster for exact
lookups. Over TCP (typical deployment), both are network-bound at ~143us. Our
differentiator is <strong>semantic search</strong> (21us) which Redis cannot provide.</p>
<h2 id="analysis-6"><a class="header" href="#analysis-6">Analysis</a></h2>
<ul>
<li><strong>Exact cache</strong>: Hash-based O(1) lookup provides sub-microsecond hit/miss
detection</li>
<li><strong>Semantic cache</strong>: HNSW index provides O(log n) similarity search (~21us for
hit)</li>
<li><strong>Embedding cache</strong>: Fast O(1) lookup for precomputed embeddings</li>
<li><strong>Put performance</strong>: Consistent ~50us regardless of cache size (HNSW insert is
O(log n))</li>
<li><strong>Eviction</strong>: Efficient batch eviction with LRU/LFU/Cost/Hybrid strategies</li>
<li><strong>Distance metrics</strong>: Auto-selection based on sparsity (&gt;=70% sparse uses
Jaccard)</li>
<li><strong>Token counting</strong>: tiktoken cl100k_base encoding for accurate GPT-4 token
counts</li>
<li><strong>Cost tracking</strong>: Estimates cost savings based on model pricing tables</li>
</ul>
<h2 id="cache-layers-1"><a class="header" href="#cache-layers-1">Cache Layers</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Layer</th><th>Complexity</th><th>Use Case</th></tr></thead><tbody>
<tr><td>Exact</td><td>O(1)</td><td>Identical prompts</td></tr>
<tr><td>Semantic</td><td>O(log n)</td><td>Similar prompts</td></tr>
<tr><td>Embedding</td><td>O(1)</td><td>Precomputed embeddings</td></tr>
</tbody></table>
</div>
<h2 id="eviction-strategies-1"><a class="header" href="#eviction-strategies-1">Eviction Strategies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>Description</th></tr></thead><tbody>
<tr><td>LRU</td><td>Evict least recently accessed</td></tr>
<tr><td>LFU</td><td>Evict least frequently accessed</td></tr>
<tr><td>CostBased</td><td>Evict lowest cost efficiency</td></tr>
<tr><td>Hybrid</td><td>Weighted combination (recommended)</td></tr>
</tbody></table>
</div>
<h2 id="metric-selection-guide"><a class="header" href="#metric-selection-guide">Metric Selection Guide</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Embedding Type</th><th>Recommended Metric</th></tr></thead><tbody>
<tr><td>OpenAI/Cohere (dense)</td><td>Cosine (default)</td></tr>
<tr><td>Sparse (&gt;=70% zeros)</td><td>Jaccard (auto-selected)</td></tr>
<tr><td>Spatial/geographic</td><td>Euclidean</td></tr>
<tr><td>Custom binary</td><td>Jaccard</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="tensor_blob-benchmarks"><a class="header" href="#tensor_blob-benchmarks">tensor_blob Benchmarks</a></h1>
<p>The tensor_blob crate provides S3-style chunked blob storage with
content-addressable chunks, garbage collection, and integrity verification.</p>
<h2 id="overview-8"><a class="header" href="#overview-8">Overview</a></h2>
<p>tensor_blob focuses on correctness and durability over raw throughput.
Performance characteristics depend heavily on:</p>
<ul>
<li>Chunk size configuration</li>
<li>Storage backend (memory vs disk)</li>
<li>Network conditions for streaming operations</li>
</ul>
<h2 id="expected-performance-characteristics"><a class="header" href="#expected-performance-characteristics">Expected Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td>Put (upload)</td><td>O(size / chunk_size)</td><td>Linear with data size</td></tr>
<tr><td>Get (download)</td><td>O(size / chunk_size)</td><td>Linear with data size</td></tr>
<tr><td>Delete</td><td>O(chunk_count)</td><td>Removes metadata + orphan detection</td></tr>
<tr><td>GC</td><td>O(total_chunks)</td><td>Full chunk scan</td></tr>
<tr><td>Verify</td><td>O(size)</td><td>Re-hash entire blob</td></tr>
<tr><td>Repair</td><td>O(corrupted_chunks)</td><td>Only processes damaged chunks</td></tr>
</tbody></table>
</div>
<h2 id="chunk-deduplication"><a class="header" href="#chunk-deduplication">Chunk Deduplication</a></h2>
<p>Identical content shares chunks via SHA-256 content addressing:</p>
<ul>
<li><strong>Duplicate blobs</strong>: Store once, reference count tracked</li>
<li><strong>Partial overlap</strong>: Shared chunks deduplicated at chunk boundaries</li>
<li><strong>Storage savings</strong>: Depends on data redundancy</li>
</ul>
<h2 id="garbage-collection-1"><a class="header" href="#garbage-collection-1">Garbage Collection</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Behavior</th></tr></thead><tbody>
<tr><td><code>gc()</code></td><td>Returns <code>GcStats { deleted, freed_bytes }</code></td></tr>
<tr><td>Orphan detection</td><td>Marks unreferenced chunks</td></tr>
<tr><td>Active upload protection</td><td>GC skips in-progress uploads</td></tr>
</tbody></table>
</div>
<h2 id="streaming-operations-1"><a class="header" href="#streaming-operations-1">Streaming Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>API</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>BlobWriter</code></td><td>Streaming upload, bounded memory</td></tr>
<tr><td><code>BlobReader::next_chunk()</code></td><td>Streaming download, chunk-by-chunk</td></tr>
<tr><td><code>get_full()</code></td><td>Small blobs (&lt;10MB), loads to memory</td></tr>
</tbody></table>
</div>
<h2 id="configuration-impact"><a class="header" href="#configuration-impact">Configuration Impact</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Setting</th><th>Impact</th></tr></thead><tbody>
<tr><td>Larger chunk_size</td><td>Fewer chunks, less overhead, less dedup</td></tr>
<tr><td>Smaller chunk_size</td><td>More chunks, more overhead, better dedup</td></tr>
<tr><td>Recommended</td><td>1-4 MB chunks for most workloads</td></tr>
</tbody></table>
</div>
<h2 id="integration-notes"><a class="header" href="#integration-notes">Integration Notes</a></h2>
<ul>
<li>Blob store persists to TensorStore</li>
<li>Metadata includes checksum, size, creation time</li>
<li>Links enable blob-to-graph entity relationships</li>
<li>Tags support blob categorization and search</li>
</ul>
<h2 id="benchmarking-blob-operations"><a class="header" href="#benchmarking-blob-operations">Benchmarking Blob Operations</a></h2>
<pre><code class="language-bash"># Run blob-specific benchmarks (if available)
cargo bench --package tensor_blob

# For custom benchmarking, use the streaming API:
# - Measure upload throughput with BlobWriter
# - Measure download throughput with BlobReader
# - Test GC performance with various orphan ratios
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tensor_chain-benchmarks"><a class="header" href="#tensor_chain-benchmarks">tensor_chain Benchmarks</a></h1>
<p>The tensor_chain crate provides a tensor-native blockchain with semantic
consensus, Raft replication, 2PC distributed transactions, and sparse delta
encoding.</p>
<h2 id="block-creation"><a class="header" href="#block-creation">Block Creation</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Time</th><th>Per Transaction</th></tr></thead><tbody>
<tr><td>empty_block</td><td>171 ns</td><td>—</td></tr>
<tr><td>block_10_txns</td><td>13.4 us</td><td>1.34 us</td></tr>
<tr><td>block_100_txns</td><td>111 us</td><td>1.11 us</td></tr>
</tbody></table>
</div>
<h2 id="transaction-commit"><a class="header" href="#transaction-commit">Transaction Commit</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>single_put</td><td>432 us</td><td>2.3K/s</td></tr>
<tr><td>multi_put_10</td><td>480 us</td><td>20.8K ops/s</td></tr>
</tbody></table>
</div>
<h2 id="batch-transactions"><a class="header" href="#batch-transactions">Batch Transactions</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Count</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>10</td><td>822 us</td><td>12.2K/s</td></tr>
<tr><td>100</td><td>21.5 ms</td><td>4.7K/s</td></tr>
<tr><td>1000</td><td>1.6 s</td><td>607/s</td></tr>
</tbody></table>
</div>
<h2 id="consensus-validation"><a class="header" href="#consensus-validation">Consensus Validation</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>conflict_detection_pair</td><td>279 ns</td><td>Hybrid cosine + Jaccard</td></tr>
<tr><td>cosine_similarity</td><td>187 ns</td><td>Sparse vector</td></tr>
<tr><td>merge_pair</td><td>448 ns</td><td>Orthogonal merge</td></tr>
<tr><td>merge_all_10</td><td>632 ns</td><td>Batch merge</td></tr>
<tr><td>find_merge_order_10</td><td>9 us</td><td>Optimal ordering</td></tr>
</tbody></table>
</div>
<h2 id="codebook-operations"><a class="header" href="#codebook-operations">Codebook Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Notes</th></tr></thead><tbody>
<tr><td>global_quantize_128d</td><td>854 ns</td><td>State validation</td></tr>
<tr><td>global_compute_residual</td><td>925 ns</td><td>Delta compression</td></tr>
<tr><td>global_is_valid_state</td><td>1.28 us</td><td>State machine check</td></tr>
<tr><td>local_quantize_128d</td><td>145 ns</td><td>EMA-adaptive</td></tr>
<tr><td>local_quantize_and_update</td><td>177 ns</td><td>With EMA update</td></tr>
<tr><td>manager_quantize_128d</td><td>1.2 us</td><td>Full pipeline</td></tr>
</tbody></table>
</div>
<h2 id="delta-vector-operations"><a class="header" href="#delta-vector-operations">Delta Vector Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Improvement</th></tr></thead><tbody>
<tr><td>cosine_similarity_128d</td><td>196 ns</td><td>35% faster</td></tr>
<tr><td>add_128d</td><td>975 ns</td><td>44% faster</td></tr>
<tr><td>scale_128d</td><td>163 ns</td><td>35% faster</td></tr>
<tr><td>weighted_average_128d</td><td>982 ns</td><td>26% faster</td></tr>
<tr><td>overlaps_with</td><td>8.4 ns</td><td>35% faster</td></tr>
<tr><td>cosine_similarity_768d</td><td>1.96 us</td><td>10% faster</td></tr>
<tr><td>add_768d</td><td>2.6 us</td><td>27% faster</td></tr>
</tbody></table>
</div>
<h2 id="chain-query-operations"><a class="header" href="#chain-query-operations">Chain Query Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Improvement</th></tr></thead><tbody>
<tr><td>get_block_by_height</td><td>1.19 us</td><td>38% faster</td></tr>
<tr><td>get_tip</td><td>1.06 us</td><td>45% faster</td></tr>
<tr><td>get_genesis</td><td>852 ns</td><td>53% faster</td></tr>
<tr><td>height</td><td>0.87 ns</td><td>50% faster</td></tr>
<tr><td>tip_hash</td><td>11.4 ns</td><td>32% faster</td></tr>
<tr><td>history_key</td><td>163 us</td><td>15% faster</td></tr>
<tr><td>verify_chain_100_blocks</td><td>276 us</td><td>—</td></tr>
</tbody></table>
</div>
<h2 id="chain-iteration"><a class="header" href="#chain-iteration">Chain Iteration</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Improvement</th></tr></thead><tbody>
<tr><td>iterate_50_blocks</td><td>88 us</td><td>10% faster</td></tr>
<tr><td>get_blocks_range_0_25</td><td>35 us</td><td>27% faster</td></tr>
</tbody></table>
</div>
<h2 id="k-means-codebook-training"><a class="header" href="#k-means-codebook-training">K-means Codebook Training</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Time</th></tr></thead><tbody>
<tr><td>100 vectors, 8 clusters</td><td>123 us</td></tr>
<tr><td>1000 vectors, 16 clusters</td><td>8.4 ms</td></tr>
</tbody></table>
</div>
<h2 id="sparse-vector-performance"><a class="header" href="#sparse-vector-performance">Sparse Vector Performance</a></h2>
<h3 id="conflict-detection-by-sparsity-level-50-deltas-128d"><a class="header" href="#conflict-detection-by-sparsity-level-50-deltas-128d">Conflict Detection by Sparsity Level (50 deltas, 128d)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Sparsity</th><th>Time</th><th>Throughput</th><th>vs Dense</th></tr></thead><tbody>
<tr><td>10% (dense)</td><td>389 us</td><td>3.1M pairs/s</td><td>1x</td></tr>
<tr><td>50%</td><td>261 us</td><td>4.6M pairs/s</td><td>1.5x</td></tr>
<tr><td>90%</td><td>57 us</td><td>21.5M pairs/s</td><td><strong>6.8x</strong></td></tr>
<tr><td>99%</td><td>23 us</td><td>52.3M pairs/s</td><td><strong>16.9x</strong></td></tr>
</tbody></table>
</div>
<h3 id="individual-sparse-operations-vs-previous-dense-implementation"><a class="header" href="#individual-sparse-operations-vs-previous-dense-implementation">Individual Sparse Operations (vs previous dense implementation)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Sparse Time</th><th>Improvement</th></tr></thead><tbody>
<tr><td>cosine_similarity</td><td>16.5 ns</td><td><strong>76% faster</strong></td></tr>
<tr><td>angular_distance</td><td>28.5 ns</td><td><strong>64% faster</strong></td></tr>
<tr><td>jaccard_index</td><td>10.4 ns</td><td><strong>58% faster</strong></td></tr>
<tr><td>euclidean_distance</td><td>13.6 ns</td><td><strong>71% faster</strong></td></tr>
<tr><td>overlapping_keys</td><td>89 ns</td><td><strong>45% faster</strong></td></tr>
<tr><td>add</td><td>688 ns</td><td>19% faster</td></tr>
<tr><td>weighted_average</td><td>674 ns</td><td>12% faster</td></tr>
<tr><td>project_orthogonal</td><td>624 ns</td><td><strong>42% faster</strong></td></tr>
<tr><td>detect_conflict_full</td><td>53 ns</td><td><strong>33% faster</strong></td></tr>
</tbody></table>
</div>
<h3 id="high-dimension-sparse-performance"><a class="header" href="#high-dimension-sparse-performance">High Dimension Sparse Performance</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Cosine Time</th><th>Batch Detect (20 deltas)</th><th>Improvement</th></tr></thead><tbody>
<tr><td>128d</td><td>10.3 ns</td><td>8.9 us</td><td>57% faster</td></tr>
<tr><td>256d</td><td>19 ns</td><td>9.5 us</td><td>55% faster</td></tr>
<tr><td>512d</td><td>41 ns</td><td>17.2 us</td><td><strong>49-75% faster</strong></td></tr>
<tr><td>768d</td><td>62.5 ns</td><td>24 us</td><td><strong>55-77% faster</strong></td></tr>
</tbody></table>
</div>
<h2 id="real-transaction-delta-sparsity-analysis"><a class="header" href="#real-transaction-delta-sparsity-analysis">Real Transaction Delta Sparsity Analysis</a></h2>
<p>Measurement of actual delta sparsity for different transaction patterns (128d
embeddings):</p>
<div class="table-wrapper"><table><thead><tr><th>Pattern</th><th>Avg NNZ</th><th>Sparsity</th><th>Estimated Speedup</th></tr></thead><tbody>
<tr><td>Single Key Update</td><td>4.0</td><td>96.9%</td><td>~10x</td></tr>
<tr><td>Multi-Field Update</td><td>11.3</td><td>91.2%</td><td>~3x</td></tr>
<tr><td>New Record Insert</td><td>29.5</td><td>77.0%</td><td>~1x</td></tr>
<tr><td>Counter Increment</td><td>1.0</td><td>99.2%</td><td>~10x</td></tr>
<tr><td>Bulk Migration</td><td>59.5</td><td>53.5%</td><td>~1x</td></tr>
<tr><td>Graph Edge</td><td>7.0</td><td>94.5%</td><td>~3x</td></tr>
</tbody></table>
</div>
<p><strong>Realistic Workload Mix</strong> (70% single-key, 20% multi-field, 10% other):</p>
<ul>
<li>Average NNZ: 7.1 / 128 dimensions</li>
<li>Average Sparsity: <strong>94.5%</strong></li>
<li>Expected speedup: <strong>3-10x</strong> for typical workloads</li>
</ul>
<h2 id="analysis-7"><a class="header" href="#analysis-7">Analysis</a></h2>
<ul>
<li><strong>Sparse advantage</strong>: Real transaction deltas are 90-99% sparse, providing
3-10x speedup</li>
<li><strong>Hybrid conflict detection</strong>: Cosine + Jaccard catches both angular and
structural conflicts</li>
<li><strong>Memory savings</strong>: Sparse DeltaVector uses 8-32x less memory than dense for
typical deltas</li>
<li><strong>Network bandwidth</strong>: Sparse serialization reduces replication bandwidth by
8-10x</li>
<li><strong>High dimension scaling</strong>: Benefits increase with dimension (768d: 4-5x
faster than dense)</li>
<li><strong>Common operations optimized</strong>: Single-key updates (most common) are 96.9%
sparse</li>
</ul>
<h2 id="distributed-systems-benchmarks"><a class="header" href="#distributed-systems-benchmarks">Distributed Systems Benchmarks</a></h2>
<h3 id="raft-consensus-operations"><a class="header" href="#raft-consensus-operations">Raft Consensus Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>raft_node_create</td><td>545 ns</td><td>1.8M/sec</td></tr>
<tr><td>raft_become_leader</td><td>195 ns</td><td>5.1M/sec</td></tr>
<tr><td>raft_heartbeat_stats_snapshot</td><td>4.2 ns</td><td>238M/sec</td></tr>
<tr><td>raft_log_length</td><td>3.7 ns</td><td>270M/sec</td></tr>
<tr><td>raft_stats_snapshot</td><td>416 ps</td><td>2.4B/sec</td></tr>
</tbody></table>
</div>
<h3 id="2pc-distributed-transaction-operations"><a class="header" href="#2pc-distributed-transaction-operations">2PC Distributed Transaction Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>lock_manager_acquire</td><td>256 ns</td><td>3.9M/sec</td></tr>
<tr><td>lock_manager_release</td><td>139 ns</td><td>7.2M/sec</td></tr>
<tr><td>lock_manager_is_locked</td><td>31 ns</td><td>32M/sec</td></tr>
<tr><td>coordinator_create</td><td>46 ns</td><td>21.7M/sec</td></tr>
<tr><td>coordinator_stats</td><td>418 ps</td><td>2.4B/sec</td></tr>
<tr><td>participant_create</td><td>11 ns</td><td>91M/sec</td></tr>
</tbody></table>
</div>
<h3 id="gossip-protocol-operations"><a class="header" href="#gossip-protocol-operations">Gossip Protocol Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>lww_state_create</td><td>4.2 ns</td><td>238M/sec</td></tr>
<tr><td>lww_state_merge</td><td>169 ns</td><td>5.9M/sec</td></tr>
<tr><td>gossip_node_state_create</td><td>16 ns</td><td>62M/sec</td></tr>
<tr><td>gossip_message_serialize</td><td>36 ns</td><td>28M/sec</td></tr>
<tr><td>gossip_message_deserialize</td><td>81 ns</td><td>12M/sec</td></tr>
</tbody></table>
</div>
<h3 id="snapshot-operations"><a class="header" href="#snapshot-operations">Snapshot Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>snapshot_metadata_create</td><td>131 ns</td><td>7.6M/sec</td></tr>
<tr><td>snapshot_metadata_serialize</td><td>76 ns</td><td>13M/sec</td></tr>
<tr><td>snapshot_metadata_deserialize</td><td>246 ns</td><td>4.1M/sec</td></tr>
<tr><td>raft_membership_config_create</td><td>102 ns</td><td>9.8M/sec</td></tr>
<tr><td>raft_with_store_create</td><td>948 ns</td><td>1.1M/sec</td></tr>
</tbody></table>
</div>
<h3 id="membership-operations"><a class="header" href="#membership-operations">Membership Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>membership_manager_create</td><td>526 ns</td><td>1.9M/sec</td></tr>
<tr><td>membership_view</td><td>152 ns</td><td>6.6M/sec</td></tr>
<tr><td>membership_partition_status</td><td>19 ns</td><td>52M/sec</td></tr>
<tr><td>membership_node_status</td><td>46 ns</td><td>21.7M/sec</td></tr>
<tr><td>membership_stats_snapshot</td><td>2.9 ns</td><td>344M/sec</td></tr>
<tr><td>membership_peer_ids</td><td>71 ns</td><td>14M/sec</td></tr>
</tbody></table>
</div>
<h3 id="deadlock-detection-3"><a class="header" href="#deadlock-detection-3">Deadlock Detection</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>wait_graph_add_edge</td><td>372 ns</td><td>2.7M/sec</td></tr>
<tr><td>wait_graph_detect_no_cycle</td><td>374 ns</td><td>2.7M/sec</td></tr>
<tr><td>wait_graph_detect_with_cycle</td><td>302 ns</td><td>3.3M/sec</td></tr>
<tr><td>deadlock_detector_detect</td><td>392 ns</td><td>2.6M/sec</td></tr>
</tbody></table>
</div>
<h2 id="distributed-systems-analysis"><a class="header" href="#distributed-systems-analysis">Distributed Systems Analysis</a></h2>
<ul>
<li><strong>Lock operations are fast</strong>: Lock acquisition at 256ns and lock checks at
31ns support high-throughput 2PC</li>
<li><strong>Gossip is lightweight</strong>: State creation &lt;5ns, merges ~169ns - suitable for
high-frequency protocol rounds</li>
<li><strong>Stats access is near-free</strong>: Sub-nanosecond stats snapshots (416ps) mean
monitoring adds no overhead</li>
<li><strong>Deadlock detection is efficient</strong>: Cycle detection in ~300-400ns allows
frequent checks without blocking</li>
<li><strong>Node/manager creation is slower</strong> (500-950ns) - expected for initialization
with data structures</li>
<li><strong>Snapshot deserialization at 246ns</strong> is acceptable for fast recovery</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="neumann_parser-benchmarks"><a class="header" href="#neumann_parser-benchmarks">neumann_parser Benchmarks</a></h1>
<p>The parser is a hand-written recursive descent parser with Pratt expression
parsing for operator precedence.</p>
<h2 id="tokenization"><a class="header" href="#tokenization">Tokenization</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Query Type</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>simple_select</td><td>182 ns</td><td>99 MiB/s</td></tr>
<tr><td>select_where</td><td>640 ns</td><td>88 MiB/s</td></tr>
<tr><td>complex_select</td><td>986 ns</td><td>95 MiB/s</td></tr>
<tr><td>insert</td><td>493 ns</td><td>120 MiB/s</td></tr>
<tr><td>update</td><td>545 ns</td><td>91 MiB/s</td></tr>
<tr><td>node</td><td>625 ns</td><td>98 MiB/s</td></tr>
<tr><td>edge</td><td>585 ns</td><td>94 MiB/s</td></tr>
<tr><td>path</td><td>486 ns</td><td>75 MiB/s</td></tr>
<tr><td>embed</td><td>407 ns</td><td>138 MiB/s</td></tr>
<tr><td>similar</td><td>185 ns</td><td>118 MiB/s</td></tr>
</tbody></table>
</div>
<h2 id="parsing-tokenize--parse"><a class="header" href="#parsing-tokenize--parse">Parsing (tokenize + parse)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Query Type</th><th>Time</th><th>Throughput</th></tr></thead><tbody>
<tr><td>simple_select</td><td>235 ns</td><td>77 MiB/s</td></tr>
<tr><td>select_where</td><td>1.19 us</td><td>47 MiB/s</td></tr>
<tr><td>complex_select</td><td>1.89 us</td><td>50 MiB/s</td></tr>
<tr><td>insert</td><td>688 ns</td><td>86 MiB/s</td></tr>
<tr><td>update</td><td>806 ns</td><td>61 MiB/s</td></tr>
<tr><td>delete</td><td>464 ns</td><td>62 MiB/s</td></tr>
<tr><td>create_table</td><td>856 ns</td><td>80 MiB/s</td></tr>
<tr><td>node</td><td>837 ns</td><td>81 MiB/s</td></tr>
<tr><td>edge</td><td>750 ns</td><td>74 MiB/s</td></tr>
<tr><td>neighbors</td><td>520 ns</td><td>55 MiB/s</td></tr>
<tr><td>path</td><td>380 ns</td><td>58 MiB/s</td></tr>
<tr><td>embed_store</td><td>650 ns</td><td>86 MiB/s</td></tr>
<tr><td>similar</td><td>290 ns</td><td>76 MiB/s</td></tr>
</tbody></table>
</div>
<h2 id="expression-complexity"><a class="header" href="#expression-complexity">Expression Complexity</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Expression Type</th><th>Time</th></tr></thead><tbody>
<tr><td>simple (a = 1)</td><td>350 ns</td></tr>
<tr><td>binary_and</td><td>580 ns</td></tr>
<tr><td>binary_or</td><td>570 ns</td></tr>
<tr><td>nested_and_or</td><td>950 ns</td></tr>
<tr><td>deep_nesting</td><td>1.5 us</td></tr>
<tr><td>arithmetic</td><td>720 ns</td></tr>
<tr><td>comparison_chain</td><td>1.3 us</td></tr>
</tbody></table>
</div>
<h2 id="batch-parsing-throughput"><a class="header" href="#batch-parsing-throughput">Batch Parsing Throughput</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Batch Size</th><th>Time</th><th>Queries/s</th></tr></thead><tbody>
<tr><td>10</td><td>5.2 us</td><td>1.9M/s</td></tr>
<tr><td>100</td><td>52 us</td><td>1.9M/s</td></tr>
<tr><td>1,000</td><td>520 us</td><td>1.9M/s</td></tr>
</tbody></table>
</div>
<h2 id="large-query-parsing"><a class="header" href="#large-query-parsing">Large Query Parsing</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Query Type</th><th>Time</th></tr></thead><tbody>
<tr><td>INSERT 100 rows</td><td>45 us</td></tr>
<tr><td>EMBED 768-dim vector</td><td>38 us</td></tr>
<tr><td>WHERE 20 conditions</td><td>8.5 us</td></tr>
</tbody></table>
</div>
<h2 id="analysis-8"><a class="header" href="#analysis-8">Analysis</a></h2>
<ul>
<li><strong>Zero dependencies</strong>: Hand-written lexer and parser with no external crates</li>
<li><strong>Consistent throughput</strong>: ~75-120 MiB/s across query types</li>
<li><strong>Expression complexity</strong>: Linear scaling with expression depth</li>
<li><strong>Batch performance</strong>: Consistent 1.9M queries/second regardless of batch size</li>
<li><strong>Large vectors</strong>: 768-dim embedding parsing in ~38us (20K dimensions/second)</li>
</ul>
<h2 id="complexity-2"><a class="header" href="#complexity-2">Complexity</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time Complexity</th><th>Notes</th></tr></thead><tbody>
<tr><td>Tokenization</td><td>O(n)</td><td>Linear scan of input</td></tr>
<tr><td>Parsing</td><td>O(n)</td><td>Single pass, no backtracking</td></tr>
<tr><td>Expression parsing</td><td>O(n * d)</td><td>n = tokens, d = nesting depth</td></tr>
<tr><td>Error recovery</td><td>O(1)</td><td>Immediate error on invalid syntax</td></tr>
</tbody></table>
</div>
<h2 id="parser-design"><a class="header" href="#parser-design">Parser Design</a></h2>
<ul>
<li><strong>Lexer</strong>: Character-by-character tokenization with lookahead</li>
<li><strong>Parser</strong>: Recursive descent with Pratt parsing for expressions</li>
<li><strong>AST</strong>: Zero-copy where possible, spans track source locations</li>
<li><strong>Errors</strong>: Rich error messages with span highlighting</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="query_router-benchmarks"><a class="header" href="#query_router-benchmarks">query_router Benchmarks</a></h1>
<p>The query router integrates all engines and routes queries based on parsed AST
type.</p>
<h2 id="relational-operations-1"><a class="header" href="#relational-operations-1">Relational Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>SELECT * (100 rows)</td><td>17 us</td></tr>
<tr><td>SELECT WHERE</td><td>17 us</td></tr>
<tr><td>INSERT</td><td>290 us</td></tr>
<tr><td>UPDATE</td><td>6.5 ms</td></tr>
</tbody></table>
</div>
<h2 id="graph-operations-4"><a class="header" href="#graph-operations-4">Graph Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>NODE CREATE</td><td>2.3 us</td></tr>
<tr><td>EDGE CREATE</td><td>3.5 us</td></tr>
<tr><td>NEIGHBORS</td><td>1.8 us</td></tr>
<tr><td>PATH (1 -&gt; 10)</td><td>85 us</td></tr>
<tr><td>FIND NODE</td><td>1.2 us</td></tr>
</tbody></table>
</div>
<h2 id="vector-operations-2"><a class="header" href="#vector-operations-2">Vector Operations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th></tr></thead><tbody>
<tr><td>EMBED STORE (128d)</td><td>28 us</td></tr>
<tr><td>EMBED GET</td><td>1.5 us</td></tr>
<tr><td>SIMILAR LIMIT 5 (100 vectors)</td><td>10 ms</td></tr>
<tr><td>SIMILAR LIMIT 10 (100 vectors)</td><td>10 ms</td></tr>
</tbody></table>
</div>
<h2 id="mixed-workload-1"><a class="header" href="#mixed-workload-1">Mixed Workload</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Time</th><th>Queries/s</th></tr></thead><tbody>
<tr><td>5 mixed queries (SELECT, NEIGHBORS, SIMILAR, INSERT, NODE)</td><td>11 ms</td><td>455/s</td></tr>
</tbody></table>
</div>
<h2 id="insert-throughput"><a class="header" href="#insert-throughput">Insert Throughput</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Batch Size</th><th>Time</th><th>Rows/s</th></tr></thead><tbody>
<tr><td>100</td><td>29 ms</td><td>3.4K/s</td></tr>
<tr><td>500</td><td>145 ms</td><td>3.4K/s</td></tr>
<tr><td>1,000</td><td>290 ms</td><td>3.4K/s</td></tr>
</tbody></table>
</div>
<h2 id="analysis-9"><a class="header" href="#analysis-9">Analysis</a></h2>
<ul>
<li><strong>Parse overhead</strong>: Parser adds ~200ns-2us per query (negligible vs execution)</li>
<li><strong>Routing overhead</strong>: AST-based routing is O(1) pattern matching</li>
<li><strong>Relational</strong>: SELECT is fast (17us); UPDATE scans all rows (6.5ms for 100
rows)</li>
<li><strong>Graph</strong>: Node/edge creation ~2-3us; path finding scales with path length</li>
<li><strong>Vector</strong>: Similarity search dominates mixed workloads (~10ms for 100
vectors)</li>
<li><strong>Bottleneck identification</strong>: SIMILAR queries are the slowest operation; use
HNSW index for large vector stores</li>
</ul>
<h2 id="query-routing-flow"><a class="header" href="#query-routing-flow">Query Routing Flow</a></h2>
<pre><code class="language-text">Query String
    │
    ▼
┌─────────┐
│ Parser  │  ~500ns
└────┬────┘
     │
     ▼
┌─────────┐
│   AST   │
└────┬────┘
     │
     ▼
┌─────────────┐
│   Router    │  O(1) dispatch
└──────┬──────┘
       │
       ├──► RelationalEngine
       ├──► GraphEngine
       ├──► VectorEngine
       ├──► Vault
       ├──► Cache
       └──► BlobStore
</code></pre>
<h2 id="performance-recommendations"><a class="header" href="#performance-recommendations">Performance Recommendations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Query Type</th><th>Optimization</th></tr></thead><tbody>
<tr><td>High SELECT volume</td><td>Create hash indexes on filter columns</td></tr>
<tr><td>Large vector search</td><td>Build HNSW index</td></tr>
<tr><td>Graph traversals</td><td>Use NEIGHBORS with LIMIT</td></tr>
<tr><td>Batch inserts</td><td>Use batch_insert() API</td></tr>
<tr><td>Mixed workloads</td><td>Profile to identify bottlenecks</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="stress-tests"><a class="header" href="#stress-tests">Stress Tests</a></h1>
<p>Comprehensive stress testing infrastructure for Neumann targeting 1M entity
scale with extensive coverage of concurrency, data volume, and sustained load.</p>
<h2 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h2>
<pre><code class="language-bash"># Run all stress tests (45+ min total)
cargo test --release -p stress_tests -- --ignored --nocapture

# Run specific test suite
cargo test --release -p stress_tests --test hnsw_stress -- --ignored --nocapture

# Run with custom duration (30s instead of default)
STRESS_DURATION=30 cargo test --release -p stress_tests -- --ignored --nocapture
</code></pre>
<h2 id="test-suites"><a class="header" href="#test-suites">Test Suites</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Suite</th><th>Tests</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="stress-tests/hnsw.html">HNSW Stress</a></td><td>4</td><td>1M vector indexing, concurrent builds</td></tr>
<tr><td><a href="stress-tests/tiered-store.html">TieredStore Stress</a></td><td>3</td><td>Hot/cold migration under load</td></tr>
<tr><td><a href="stress-tests/mixed-workload.html">Mixed Workload</a></td><td>2</td><td>All engines concurrent, realistic patterns</td></tr>
<tr><td>TensorStore Stress</td><td>4</td><td>1M entities, high contention</td></tr>
<tr><td>BloomFilter Stress</td><td>3</td><td>1M keys, bit-level concurrency</td></tr>
<tr><td>QueryRouter Stress</td><td>3</td><td>Concurrent queries, sustained writes</td></tr>
<tr><td>Duration Stress</td><td>3</td><td>Long-running stability, memory leaks</td></tr>
</tbody></table>
</div>
<h2 id="key-performance-findings"><a class="header" href="#key-performance-findings">Key Performance Findings</a></h2>
<h3 id="tensorstore-dashmap"><a class="header" href="#tensorstore-dashmap">TensorStore (DashMap)</a></h3>
<ul>
<li><strong>7.5M writes/sec</strong> at 1M entities</li>
<li>Sub-microsecond median latency</li>
<li>Handles 16:1 contention ratio with 2.5M ops/sec</li>
</ul>
<h3 id="hnsw-index-4"><a class="header" href="#hnsw-index-4">HNSW Index</a></h3>
<ul>
<li><strong>3,372 vectors/sec</strong> insert rate at 1M scale</li>
<li><strong>0.11ms</strong> search latency (p50)</li>
<li><strong>99.8%</strong> recall@10 under concurrent load</li>
</ul>
<h3 id="bloomfilter-1"><a class="header" href="#bloomfilter-1">BloomFilter</a></h3>
<ul>
<li><strong>0.88% FP rate</strong> at 1M keys (target 1%)</li>
<li><strong>15M+ ops/sec</strong> bit-level operations</li>
<li>Thread-safe with AtomicU64</li>
</ul>
<h3 id="mixed-workloads"><a class="header" href="#mixed-workloads">Mixed Workloads</a></h3>
<ul>
<li>All engines can operate concurrently</li>
<li>Graph operations (5us p50) and vector ops (&lt; 1us p50) are fastest</li>
<li>Relational engine adds ~12ms p50 overhead due to schema operations</li>
</ul>
<h2 id="configuration-23"><a class="header" href="#configuration-23">Configuration</a></h2>
<h3 id="environment-variables-4"><a class="header" href="#environment-variables-4">Environment Variables</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>STRESS_DURATION</code></td><td>30 (quick) / 600 (full)</td><td>Test duration in seconds</td></tr>
<tr><td><code>STRESS_THREADS</code></td><td>16</td><td>Thread count for tests</td></tr>
</tbody></table>
</div>
<h3 id="config-presets"><a class="header" href="#config-presets">Config Presets</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Quick mode (CI): 100K entities, 4 threads, 30s
let config = quick_config();

// Full mode (local): 1M entities, 16 threads, 10min
let config = full_config();

// Endurance mode: 500K entities, 8 threads, 1 hour
let config = endurance_config();
<span class="boring">}</span></code></pre></pre>
<h2 id="latency-metrics"><a class="header" href="#latency-metrics">Latency Metrics</a></h2>
<p>All tests report percentile latencies using HdrHistogram:</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Description</th></tr></thead><tbody>
<tr><td>p50</td><td>Median latency</td></tr>
<tr><td>p99</td><td>99th percentile</td></tr>
<tr><td>p999</td><td>99.9th percentile</td></tr>
<tr><td>max</td><td>Maximum observed</td></tr>
</tbody></table>
</div>
<h2 id="running-in-ci"><a class="header" href="#running-in-ci">Running in CI</a></h2>
<p>For CI pipelines, use quick_config with limited duration:</p>
<pre><code class="language-yaml">- name: Run stress tests
  run: |
    STRESS_DURATION=30 cargo test --release -p stress_tests -- --ignored --nocapture
  timeout-minutes: 15
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hnsw-stress-tests"><a class="header" href="#hnsw-stress-tests">HNSW Stress Tests</a></h1>
<p>Stress tests for the Hierarchical Navigable Small World (HNSW) index, targeting
1M vector scale.</p>
<h2 id="test-suite"><a class="header" href="#test-suite">Test Suite</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>Scale</th><th>Description</th></tr></thead><tbody>
<tr><td><code>stress_hnsw_1m_vectors</code></td><td>1M 128d vectors</td><td>Build 1M vector index</td></tr>
<tr><td><code>stress_hnsw_100k_concurrent_build</code></td><td>100K vectors, 16 threads</td><td>Concurrent index construction</td></tr>
<tr><td><code>stress_hnsw_search_during_insert</code></td><td>50K vectors, 4+4 threads</td><td>Concurrent search during insert</td></tr>
<tr><td><code>stress_hnsw_recall_under_load</code></td><td>10K vectors</td><td>Verify recall@10 under load</td></tr>
</tbody></table>
</div>
<h2 id="results"><a class="header" href="#results">Results</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>Key Metric</th><th>Result</th></tr></thead><tbody>
<tr><td>1M vectors</td><td>Insert throughput</td><td><strong>3,372 vectors/sec</strong></td></tr>
<tr><td>1M vectors</td><td>Search latency (p50)</td><td><strong>0.11ms</strong></td></tr>
<tr><td>100K concurrent</td><td>Insert throughput</td><td><strong>1,155 vectors/sec</strong></td></tr>
<tr><td>Recall@10</td><td>Average recall</td><td><strong>99.8%</strong> (min 90%)</td></tr>
</tbody></table>
</div>
<h2 id="running"><a class="header" href="#running">Running</a></h2>
<pre><code class="language-bash"># Run all HNSW stress tests
cargo test --release -p stress_tests --test hnsw_stress -- --ignored --nocapture

# Run specific test
cargo test --release -p stress_tests stress_hnsw_1m_vectors -- --ignored --nocapture
</code></pre>
<h2 id="1m-vector-index-build"><a class="header" href="#1m-vector-index-build">1M Vector Index Build</a></h2>
<p>Tests building an HNSW index with 1 million 128-dimensional vectors.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>Memory efficiency at scale</li>
<li>Index build time scalability</li>
<li>Search accuracy after large insertions</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>Linear memory growth with vector count</li>
<li>Sub-linear search time (O(log n))</li>
<li>Recall@10 &gt; 95%</li>
</ul>
<h2 id="concurrent-index-build"><a class="header" href="#concurrent-index-build">Concurrent Index Build</a></h2>
<p>Tests building an HNSW index with 16 concurrent writer threads.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>Thread-safety of HNSW insert operations</li>
<li>Performance under contention</li>
<li>Correctness with concurrent modifications</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>All inserted vectors are findable</li>
<li>No panics or data races</li>
<li>Throughput scales with thread count (with diminishing returns)</li>
</ul>
<h2 id="search-during-insert"><a class="header" href="#search-during-insert">Search During Insert</a></h2>
<p>Tests searching the index while new vectors are being inserted concurrently.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>Read/write concurrency safety</li>
<li>Search accuracy with ongoing modifications</li>
<li>Latency stability under load</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>Searches return valid results</li>
<li>No stale or corrupted results</li>
<li>Latency remains bounded</li>
</ul>
<h2 id="recall-under-load"><a class="header" href="#recall-under-load">Recall Under Load</a></h2>
<p>Tests search recall accuracy under sustained concurrent load.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>HNSW recall guarantees under stress</li>
<li>Accuracy with high query volume</li>
<li>Configuration impact on recall</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>Average recall@10 &gt; 95%</li>
<li>Minimum recall@10 &gt; 90%</li>
<li>High_recall config &gt; default config recall</li>
</ul>
<h2 id="performance-tuning"><a class="header" href="#performance-tuning">Performance Tuning</a></h2>
<h3 id="hnsw-configuration-impact"><a class="header" href="#hnsw-configuration-impact">HNSW Configuration Impact</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Config</th><th>Insert Speed</th><th>Search Speed</th><th>Recall</th><th>Memory</th></tr></thead><tbody>
<tr><td>high_speed</td><td>Fastest</td><td>Fastest</td><td>Lower</td><td>Lower</td></tr>
<tr><td>default</td><td>Medium</td><td>Medium</td><td>Good</td><td>Medium</td></tr>
<tr><td>high_recall</td><td>Slowest</td><td>Slowest</td><td>Highest</td><td>Higher</td></tr>
</tbody></table>
</div>
<h3 id="scaling-recommendations"><a class="header" href="#scaling-recommendations">Scaling Recommendations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Scale</th><th>Recommendation</th></tr></thead><tbody>
<tr><td>&lt; 100K</td><td>Use default config</td></tr>
<tr><td>100K - 1M</td><td>Consider high_speed if latency-critical</td></tr>
<tr><td>&gt; 1M</td><td>Shard across multiple indexes</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="tieredstore-stress-tests"><a class="header" href="#tieredstore-stress-tests">TieredStore Stress Tests</a></h1>
<p>Stress tests for the two-tier hot/cold storage system with automatic data
migration.</p>
<h2 id="test-suite-1"><a class="header" href="#test-suite-1">Test Suite</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>Scale</th><th>Description</th></tr></thead><tbody>
<tr><td><code>stress_tiered_hot_only_scale</code></td><td>1M entities</td><td>Hot-only tier at scale</td></tr>
<tr><td><code>stress_tiered_migration_under_load</code></td><td>100K entities</td><td>Hot/cold migration with concurrent load</td></tr>
<tr><td><code>stress_tiered_hot_read_latency</code></td><td>100K entities</td><td>Random access read latency</td></tr>
</tbody></table>
</div>
<h2 id="results-1"><a class="header" href="#results-1">Results</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>Key Metric</th><th>Result</th></tr></thead><tbody>
<tr><td>Hot-only 1M</td><td>Throughput</td><td><strong>689K entities/sec</strong></td></tr>
<tr><td>Migration</td><td>Concurrent access</td><td>Works correctly</td></tr>
<tr><td>Read latency</td><td>p50</td><td>&lt; 3us</td></tr>
<tr><td>Read latency</td><td>p99</td><td>&lt; 500us</td></tr>
</tbody></table>
</div>
<h2 id="running-1"><a class="header" href="#running-1">Running</a></h2>
<pre><code class="language-bash"># Run all TieredStore stress tests
cargo test --release -p stress_tests --test tiered_store_stress -- --ignored --nocapture

# Run specific test
cargo test --release -p stress_tests stress_tiered_hot_only_scale -- --ignored --nocapture
</code></pre>
<h2 id="hot-only-scale-test"><a class="header" href="#hot-only-scale-test">Hot-Only Scale Test</a></h2>
<p>Tests TieredStore performance with only hot tier active (no cold storage).</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>In-memory performance at scale</li>
<li>DashMap + instrumentation overhead</li>
<li>Memory usage patterns</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>Throughput &gt; 500K entities/sec</li>
<li>Linear memory growth</li>
<li>Consistent latency distribution</li>
</ul>
<h2 id="migration-under-load"><a class="header" href="#migration-under-load">Migration Under Load</a></h2>
<p>Tests hot-to-cold data migration while concurrent reads/writes continue.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>Migration correctness during active use</li>
<li>No data loss during tier transitions</li>
<li>Read consistency during migration</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>All data accessible before and after migration</li>
<li>Reads don’t block on migration</li>
<li>Writes to migrated keys work correctly</li>
</ul>
<h2 id="hot-read-latency"><a class="header" href="#hot-read-latency">Hot Read Latency</a></h2>
<p>Tests random access read latency for hot tier data.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>Read latency distribution</li>
<li>Hot path optimization</li>
<li>Cache efficiency</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>p50 latency &lt; 3us</li>
<li>p99 latency &lt; 500us</li>
<li>No extreme outliers (p999 &lt; 10ms)</li>
</ul>
<h2 id="architecture-12"><a class="header" href="#architecture-12">Architecture</a></h2>
<pre><code class="language-text">TieredStore
    │
    ├── Hot Tier (DashMap)
    │   ├── Fast in-memory access
    │   ├── Access instrumentation
    │   └── Automatic hot shard tracking
    │
    └── Cold Tier (mmap)
        ├── Disk-backed storage
        ├── Memory-efficient for large datasets
        └── Transparent promotion on access
</code></pre>
<h2 id="migration-strategies"><a class="header" href="#migration-strategies">Migration Strategies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>Trigger</th><th>Use Case</th></tr></thead><tbody>
<tr><td>Time-based</td><td>Entries older than threshold</td><td>Aging data</td></tr>
<tr><td>Access-based</td><td>Cold shards (low access)</td><td>Infrequent data</td></tr>
<tr><td>Memory-based</td><td>Hot tier size limit</td><td>Memory pressure</td></tr>
</tbody></table>
</div>
<h2 id="configuration-24"><a class="header" href="#configuration-24">Configuration</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let config = TieredConfig {
    cold_dir: PathBuf::from("/var/lib/neumann/cold"),
    cold_capacity: 1_000_000,  // Max cold entries
    sample_rate: 0.01,         // 1% access sampling
};
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mixed-workload-stress-tests"><a class="header" href="#mixed-workload-stress-tests">Mixed Workload Stress Tests</a></h1>
<p>Stress tests that exercise all Neumann engines simultaneously with realistic
workload patterns.</p>
<h2 id="test-suite-2"><a class="header" href="#test-suite-2">Test Suite</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>Scale</th><th>Description</th></tr></thead><tbody>
<tr><td><code>stress_all_engines_concurrent</code></td><td>25K ops/thread, 12 threads</td><td>All engines under concurrent load</td></tr>
<tr><td><code>stress_realistic_workload</code></td><td>30s duration</td><td>Mixed OLTP + search + traversal</td></tr>
</tbody></table>
</div>
<h2 id="results-2"><a class="header" href="#results-2">Results</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>Key Metric</th><th>Result</th></tr></thead><tbody>
<tr><td>All engines</td><td>Combined throughput</td><td><strong>841 ops/sec</strong></td></tr>
<tr><td>All engines</td><td>Relational p50</td><td>12ms</td></tr>
<tr><td>All engines</td><td>Graph p50</td><td>5us</td></tr>
<tr><td>All engines</td><td>Vector p50</td><td>&lt; 1us</td></tr>
<tr><td>Realistic workload</td><td>Mixed throughput</td><td><strong>232 ops/sec</strong></td></tr>
<tr><td>Realistic workload</td><td>Read rate</td><td>91 reads/sec</td></tr>
<tr><td>Realistic workload</td><td>Write rate</td><td>68 writes/sec</td></tr>
<tr><td>Realistic workload</td><td>Search rate</td><td>72 searches/sec</td></tr>
</tbody></table>
</div>
<h2 id="running-2"><a class="header" href="#running-2">Running</a></h2>
<pre><code class="language-bash"># Run all mixed workload stress tests
cargo test --release -p stress_tests --test mixed_workload_stress -- --ignored --nocapture

# Run specific test
cargo test --release -p stress_tests stress_all_engines_concurrent -- --ignored --nocapture
</code></pre>
<h2 id="all-engines-concurrent"><a class="header" href="#all-engines-concurrent">All Engines Concurrent</a></h2>
<p>Tests all engines (relational, graph, vector) under simultaneous heavy load from
12 threads.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>Cross-engine concurrency safety</li>
<li>Shared TensorStore contention handling</li>
<li>No deadlocks or livelocks</li>
<li>Correct results under maximum stress</li>
</ul>
<p><strong>Workload distribution per thread:</strong></p>
<ul>
<li>Relational: INSERT, SELECT, UPDATE</li>
<li>Graph: NODE, EDGE, NEIGHBORS</li>
<li>Vector: EMBED, SIMILAR</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>No panics or assertion failures</li>
<li>All operations complete (no hangs)</li>
<li>Data consistency verified post-test</li>
</ul>
<h2 id="realistic-workload"><a class="header" href="#realistic-workload">Realistic Workload</a></h2>
<p>Simulates a production-like mixed workload over 30 seconds.</p>
<p><strong>What it validates:</strong></p>
<ul>
<li>Sustained throughput over time</li>
<li>Memory stability (no leaks)</li>
<li>Latency consistency</li>
</ul>
<p><strong>Workload pattern:</strong></p>
<ul>
<li>40% Reads (SELECT, GET, NEIGHBORS)</li>
<li>30% Writes (INSERT, UPDATE, NODE)</li>
<li>30% Searches (SIMILAR, PATH)</li>
</ul>
<p><strong>Expected behavior:</strong></p>
<ul>
<li>Throughput variance &lt; 20%</li>
<li>Memory usage stable</li>
<li>No degradation over time</li>
</ul>
<h2 id="engine-latency-breakdown"><a class="header" href="#engine-latency-breakdown">Engine Latency Breakdown</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Engine</th><th>Operation</th><th>Typical p50</th><th>Notes</th></tr></thead><tbody>
<tr><td>Relational</td><td>SELECT</td><td>1-10ms</td><td>Schema lookup overhead</td></tr>
<tr><td>Relational</td><td>INSERT</td><td>3-15ms</td><td>Index maintenance</td></tr>
<tr><td>Graph</td><td>NEIGHBORS</td><td>5-50us</td><td>Adjacency list lookup</td></tr>
<tr><td>Graph</td><td>PATH</td><td>100us-5ms</td><td>Scales with path length</td></tr>
<tr><td>Vector</td><td>EMBED</td><td>1-5us</td><td>Hash insert</td></tr>
<tr><td>Vector</td><td>SIMILAR</td><td>1-100ms</td><td>Scales with corpus size</td></tr>
</tbody></table>
</div>
<h2 id="bottleneck-identification"><a class="header" href="#bottleneck-identification">Bottleneck Identification</a></h2>
<p>When mixed workload throughput is lower than expected:</p>
<ol>
<li><strong>Vector search dominates</strong>: Use HNSW index for SIMILAR queries</li>
<li><strong>Relational scans</strong>: Add hash/B-tree indexes on filter columns</li>
<li><strong>Graph traversals</strong>: Add LIMIT to NEIGHBORS/PATH queries</li>
<li><strong>Contention</strong>: Check hot shards with instrumentation</li>
</ol>
<h2 id="scaling-considerations"><a class="header" href="#scaling-considerations">Scaling Considerations</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Bottleneck</th><th>Solution</th></tr></thead><tbody>
<tr><td>CPU-bound</td><td>Add more cores, enable rayon parallelism</td></tr>
<tr><td>Memory-bound</td><td>Enable tiered storage, use sparse vectors</td></tr>
<tr><td>I/O-bound</td><td>Use NVMe storage, increase buffer sizes</td></tr>
<tr><td>Network-bound</td><td>Batch operations, use local cache</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="integration-tests"><a class="header" href="#integration-tests">Integration Tests</a></h1>
<p>The integration test suite validates cross-engine functionality, data flow, and
system behavior. All tests use a shared <code>TensorStore</code> to verify that relational,
graph, and vector engines work correctly together.</p>
<p><strong>Test Count:</strong> 267+ tests across 22 files</p>
<h2 id="running-tests-1"><a class="header" href="#running-tests-1">Running Tests</a></h2>
<pre><code class="language-bash"># Run all integration tests
cargo test --package integration_tests

# Run specific test file
cargo test --package integration_tests --test persistence

# Run single test
cargo test --package integration_tests test_snapshot_preserves_all_data

# Run with output
cargo test --package integration_tests -- --nocapture
</code></pre>
<h2 id="test-categories"><a class="header" href="#test-categories">Test Categories</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Tests</th><th>Description</th></tr></thead><tbody>
<tr><td>Persistence</td><td>9</td><td>Snapshot/restore across all engines</td></tr>
<tr><td>Concurrency</td><td>10</td><td>Multi-threaded and async operations</td></tr>
<tr><td>Cross-Engine</td><td>10</td><td>Data flow between engines</td></tr>
<tr><td>Error Handling</td><td>10</td><td>Proper error messages</td></tr>
<tr><td>Delete Operations</td><td>7</td><td>Cleanup and consistency</td></tr>
<tr><td>Cache Invalidation</td><td>7</td><td>Cache behavior on writes</td></tr>
<tr><td>FIND Command</td><td>7</td><td>Unified query syntax</td></tr>
<tr><td>Blob Lifecycle</td><td>7</td><td>GC, repair, streaming</td></tr>
<tr><td>Cache Advanced</td><td>6</td><td>TTL, semantic, eviction</td></tr>
<tr><td>Vault Advanced</td><td>8</td><td>Grants, audit, namespacing</td></tr>
<tr><td>Edge Cases</td><td>10</td><td>Boundary conditions</td></tr>
<tr><td>Tensor Compress</td><td>10</td><td>Quantization, delta, RLE encoding</td></tr>
<tr><td>Join Operations</td><td>10</td><td>Hash-based relational JOINs</td></tr>
<tr><td>HNSW Index</td><td>13</td><td>Approximate nearest neighbor search</td></tr>
<tr><td>Vault Versioning</td><td>17</td><td>Secret history and rollback</td></tr>
<tr><td>Index Operations</td><td>18</td><td>Hash and B-tree indexes</td></tr>
<tr><td>Columnar Storage</td><td>20</td><td>Columnar scans, batch insert, projection</td></tr>
<tr><td>Entity Graph API</td><td>18</td><td>String-keyed entity edge operations</td></tr>
<tr><td>Sparse Vectors</td><td>22</td><td>Sparse vector creation and similarity</td></tr>
<tr><td>Store Instrumentation</td><td>15</td><td>Access pattern tracking</td></tr>
<tr><td>Tiered Storage</td><td>16</td><td>Hot/cold data migration</td></tr>
<tr><td>Distance Metrics</td><td>17</td><td>COSINE, EUCLIDEAN, DOT_PRODUCT similarity</td></tr>
</tbody></table>
</div>
<h2 id="test-helpers"><a class="header" href="#test-helpers">Test Helpers</a></h2>
<p>Available in <code>integration_tests/src/lib.rs</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Helper Function</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>create_shared_router()</code></td><td>Creates QueryRouter with shared TensorStore</td></tr>
<tr><td><code>create_router_with_vault(master_key)</code></td><td>Router with vault initialized</td></tr>
<tr><td><code>create_router_with_cache()</code></td><td>Router with cache initialized</td></tr>
<tr><td><code>create_router_with_blob()</code></td><td>Router with blob store initialized</td></tr>
<tr><td><code>create_router_with_all_features(master_key)</code></td><td>Router with vault, cache, and blob</td></tr>
<tr><td><code>sample_embeddings(count, dim)</code></td><td>Generates deterministic test embeddings using sin()</td></tr>
<tr><td><code>get_store_from_router(router)</code></td><td>Extracts TensorStore from router</td></tr>
<tr><td><code>create_shared_engines()</code></td><td>Creates (store, relational, graph, vector) tuple</td></tr>
<tr><td><code>create_shared_engines_arc()</code></td><td>Same as above but wrapped in Arc for concurrency</td></tr>
</tbody></table>
</div>
<h2 id="key-test-suites"><a class="header" href="#key-test-suites">Key Test Suites</a></h2>
<h3 id="persistence-tests"><a class="header" href="#persistence-tests">Persistence Tests</a></h3>
<p>Tests snapshot/restore functionality across all engines.</p>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>What It Tests</th></tr></thead><tbody>
<tr><td><code>test_snapshot_preserves_all_data</code></td><td>All engine data survives snapshot/restore</td></tr>
<tr><td><code>test_snapshot_during_writes</code></td><td>Concurrent writes don’t corrupt snapshot</td></tr>
<tr><td><code>test_restore_to_fresh_store</code></td><td>Snapshot loads into new TensorStore</td></tr>
<tr><td><code>test_compressed_snapshot_roundtrip</code></td><td>Compression works for vector data</td></tr>
<tr><td><code>test_snapshot_includes_vault_secrets</code></td><td>Vault secrets persist in snapshot</td></tr>
</tbody></table>
</div>
<h4 id="lessons-learned"><a class="header" href="#lessons-learned">Lessons Learned</a></h4>
<ul>
<li>Cache is intentionally ephemeral (internal DashMaps)</li>
<li>Vault secrets ARE persisted (encrypted in TensorStore)</li>
<li>Bloom filter must be re-initialized with same parameters on restore</li>
</ul>
<h3 id="concurrency-tests"><a class="header" href="#concurrency-tests">Concurrency Tests</a></h3>
<p>Tests multi-threaded and async access patterns.</p>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>What It Tests</th></tr></thead><tbody>
<tr><td><code>test_concurrent_writes_all_engines</code></td><td>6 threads write to relational/graph/vector simultaneously</td></tr>
<tr><td><code>test_shared_store_contention</code></td><td>4 threads write same key 1000 times each</td></tr>
<tr><td><code>test_reader_writer_isolation</code></td><td>Reads during heavy writes</td></tr>
<tr><td><code>test_blob_parallel_uploads</code></td><td>10 concurrent blob uploads with barrier sync</td></tr>
</tbody></table>
</div>
<h4 id="lessons-learned-1"><a class="header" href="#lessons-learned-1">Lessons Learned</a></h4>
<ul>
<li>DashMap provides excellent concurrent write performance</li>
<li>Node IDs are NOT guaranteed sequential - must capture actual IDs</li>
<li>Blob operations require <code>tokio::sync::Mutex</code> for shared access</li>
<li>HNSW search is thread-safe during concurrent writes</li>
</ul>
<h3 id="cross-engine-tests"><a class="header" href="#cross-engine-tests">Cross-Engine Tests</a></h3>
<p>Tests data flow and operations across multiple engines.</p>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>What It Tests</th></tr></thead><tbody>
<tr><td><code>test_unified_entity_across_engines</code></td><td>Single entity with data in all 3 engines</td></tr>
<tr><td><code>test_graph_nodes_with_embeddings</code></td><td>Graph nodes linked to vector embeddings</td></tr>
<tr><td><code>test_insert_embed_search_cycle</code></td><td>INSERT -&gt; EMBED -&gt; SIMILAR workflow</td></tr>
<tr><td><code>test_query_router_cross_engine_operations</code></td><td>Router executes across all engines</td></tr>
</tbody></table>
</div>
<h4 id="lessons-learned-2"><a class="header" href="#lessons-learned-2">Lessons Learned</a></h4>
<ul>
<li><code>execute()</code> uses <code>col:type</code> syntax; <code>execute_parsed()</code> uses SQL syntax</li>
<li><code>NEIGHBORS</code> command returns <code>QueryResult::Ids</code>, not <code>QueryResult::Nodes</code></li>
<li>Node IDs must be captured and reused, not assumed to be 0, 1, 2…</li>
</ul>
<h3 id="sparse-vector-tests-22-tests"><a class="header" href="#sparse-vector-tests-22-tests">Sparse Vector Tests (22 tests)</a></h3>
<p>Tests sparse vector creation, storage, and similarity operations.</p>
<h4 id="key-apis"><a class="header" href="#key-apis">Key APIs</a></h4>
<ul>
<li><code>TensorValue::from_embedding(dense, value_threshold, sparsity_threshold)</code></li>
<li><code>TensorValue::from_embedding_auto(dense)</code> - Auto thresholds (0.01 value, 0.7
sparsity)</li>
<li><code>TensorValue::dot(other)</code> - Dot product (sparse-sparse, sparse-dense,
dense-dense)</li>
<li><code>TensorValue::cosine_similarity(other)</code> - Cosine similarity</li>
<li><code>TensorValue::to_dense()</code> - Convert back to dense</li>
<li><code>TensorValue::dimension()</code> - Get vector dimension</li>
</ul>
<h3 id="distance-metrics-tests-17-tests"><a class="header" href="#distance-metrics-tests-17-tests">Distance Metrics Tests (17 tests)</a></h3>
<p>Tests SIMILAR queries with different distance metrics.</p>
<h4 id="key-syntax"><a class="header" href="#key-syntax">Key Syntax</a></h4>
<pre><code class="language-sql">-- Metric goes AFTER LIMIT clause
SIMILAR 'key' LIMIT 10 EUCLIDEAN
SIMILAR [0.1, 0.2] LIMIT 5 DOT_PRODUCT
</code></pre>
<h4 id="known-issues"><a class="header" href="#known-issues">Known Issues</a></h4>
<ul>
<li>Metric keyword must be AFTER LIMIT (not <code>METRIC EUCLIDEAN</code>)</li>
<li>COSINE/DOT_PRODUCT return empty for zero-magnitude queries</li>
<li>EUCLIDEAN correctly handles zero vectors</li>
</ul>
<h2 id="coverage-summary"><a class="header" href="#coverage-summary">Coverage Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Files</th><th>Tests</th><th>Key Validations</th></tr></thead><tbody>
<tr><td>Storage</td><td>4</td><td>50+</td><td>Persistence, tiering, instrumentation</td></tr>
<tr><td>Engines</td><td>5</td><td>60+</td><td>Relational, graph, vector operations</td></tr>
<tr><td>Security</td><td>2</td><td>25+</td><td>Vault, access control, versioning</td></tr>
<tr><td>Caching</td><td>2</td><td>13</td><td>Exact, semantic, invalidation</td></tr>
<tr><td>Advanced</td><td>6</td><td>80+</td><td>Compression, joins, indexes, sparse</td></tr>
<tr><td><strong>Total</strong></td><td><strong>17</strong></td><td><strong>267+</strong></td><td></td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="code-style"><a class="header" href="#code-style">Code Style</a></h1>
<p>This guide covers the coding standards for Neumann. All contributions must
follow these guidelines.</p>
<h2 id="rust-idioms"><a class="header" href="#rust-idioms">Rust Idioms</a></h2>
<ul>
<li>Prefer iterators over loops</li>
<li>Use <code>?</code> for error propagation</li>
<li>Keep functions small and focused</li>
<li>Prefer composition over inheritance patterns</li>
</ul>
<h2 id="formatting"><a class="header" href="#formatting">Formatting</a></h2>
<p>All code must pass <code>cargo fmt</code>:</p>
<pre><code class="language-bash">cargo fmt --check
</code></pre>
<h2 id="lints"><a class="header" href="#lints">Lints</a></h2>
<p>All code must pass clippy with warnings as errors:</p>
<pre><code class="language-bash">cargo clippy -- -D warnings
</code></pre>
<h2 id="comments-policy"><a class="header" href="#comments-policy">Comments Policy</a></h2>
<p>Doc comments (<code>///</code>) are for rustdoc generation. Use them sparingly.</p>
<h3 id="do-document"><a class="header" href="#do-document">DO Document</a></h3>
<ul>
<li>Types (structs, enums) - explain purpose and invariants</li>
<li>Non-obvious behavior - when a method does something unexpected</li>
<li>Complex algorithms - when the “why” isn’t clear from code</li>
</ul>
<h3 id="do-not-document"><a class="header" href="#do-not-document">DO NOT Document</a></h3>
<ul>
<li>Methods with self-explanatory names (<code>get</code>, <code>set</code>, <code>new</code>, <code>len</code>, <code>is_empty</code>)</li>
<li>Trivial implementations</li>
<li>Anything where the doc would just repeat the function name</li>
</ul>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// BAD - restates the obvious
/// Get a field value
pub fn get(&amp;self, key: &amp;str) -&gt; Option&lt;&amp;TensorValue&gt;

// GOOD - no comment needed, name is clear
pub fn get(&amp;self, key: &amp;str) -&gt; Option&lt;&amp;TensorValue&gt;

// GOOD - explains non-obvious behavior
/// Returns cloned data to ensure thread safety.
/// For zero-copy access, use get_ref().
pub fn get(&amp;self, key: &amp;str) -&gt; Result&lt;TensorData&gt;
<span class="boring">}</span></code></pre></pre>
<p>Inline comments (<code>//</code>) should explain “why”, never “what”.</p>
<h2 id="naming"><a class="header" href="#naming">Naming</a></h2>
<ul>
<li>Types: <code>PascalCase</code></li>
<li>Functions and variables: <code>snake_case</code></li>
<li>Constants: <code>SCREAMING_SNAKE_CASE</code></li>
<li>Modules: <code>snake_case</code></li>
</ul>
<h2 id="error-handling-12"><a class="header" href="#error-handling-12">Error Handling</a></h2>
<ul>
<li>Use <code>Result</code> for fallible operations</li>
<li>Define error types with <code>thiserror</code></li>
<li>Provide context with error messages</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, thiserror::Error)]
pub enum MyError {
    #[error("failed to parse config: {0}")]
    ConfigParse(String),

    #[error("connection failed: {source}")]
    Connection {
        #[from]
        source: std::io::Error,
    },
}
<span class="boring">}</span></code></pre></pre>
<h2 id="concurrency"><a class="header" href="#concurrency">Concurrency</a></h2>
<ul>
<li>Use <code>DashMap</code> for concurrent hash maps</li>
<li>Avoid <code>Mutex</code> where possible (use <code>parking_lot</code> if needed)</li>
<li>Document thread-safety in type docs</li>
</ul>
<h2 id="testing-1"><a class="header" href="#testing-1">Testing</a></h2>
<ul>
<li>Unit tests in the same file as code (<code>#[cfg(test)]</code> module)</li>
<li>Test the public API, not implementation details</li>
<li>Use descriptive names: <code>test_&lt;function&gt;_&lt;scenario&gt;_&lt;expected&gt;</code></li>
</ul>
<h2 id="commits"><a class="header" href="#commits">Commits</a></h2>
<ul>
<li>Write clear, imperative commit messages</li>
<li>No emoji in commits</li>
<li>Reference issue numbers when applicable</li>
<li>Keep commits atomic - one logical change per commit</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-2"><a class="header" href="#testing-2">Testing</a></h1>
<h2 id="test-philosophy"><a class="header" href="#test-philosophy">Test Philosophy</a></h2>
<ul>
<li>Test the public API, not implementation details</li>
<li>Include edge cases: empty inputs, boundaries, error conditions</li>
<li>Performance tests for operations that must scale (10k+ entities)</li>
<li>Concurrent tests for thread-safe code</li>
</ul>
<h2 id="running-tests-2"><a class="header" href="#running-tests-2">Running Tests</a></h2>
<pre><code class="language-bash"># All tests
cargo test

# Specific crate
cargo test -p tensor_chain

# Specific test
cargo test test_raft_election

# With output
cargo test -- --nocapture

# Run ignored tests (slow/integration)
cargo test -- --ignored
</code></pre>
<h2 id="test-organization"><a class="header" href="#test-organization">Test Organization</a></h2>
<p>Unit tests live in the same file:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn process(data: &amp;str) -&gt; Result&lt;Output&gt; {
    // implementation
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_process_valid_input() {
        let result = process("valid").unwrap();
        assert_eq!(result.status, "ok");
    }

    #[test]
    fn test_process_empty_input() {
        let result = process("");
        assert!(result.is_err());
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="test-naming"><a class="header" href="#test-naming">Test Naming</a></h2>
<p>Use the pattern: <code>test_&lt;function&gt;_&lt;scenario&gt;_&lt;expected&gt;</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_insert_duplicate_key_returns_error() { }

#[test]
fn test_search_empty_index_returns_empty() { }

#[test]
fn test_commit_after_abort_fails() { }
<span class="boring">}</span></code></pre></pre>
<h2 id="concurrent-tests"><a class="header" href="#concurrent-tests">Concurrent Tests</a></h2>
<p>For thread-safe code:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_store_concurrent_writes() {
    let store = Arc::new(TensorStore::new());
    let handles: Vec&lt;_&gt; = (0..10)
        .map(|i| {
            let store = Arc::clone(&amp;store);
            std::thread::spawn(move || {
                for j in 0..1000 {
                    store.put(format!("key_{i}_{j}"), data.clone());
                }
            })
        })
        .collect();

    for h in handles {
        h.join().unwrap();
    }

    assert_eq!(store.len(), 10000);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance-tests"><a class="header" href="#performance-tests">Performance Tests</a></h2>
<p>Mark slow tests with <code>#[ignore]</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
#[ignore]
fn test_hnsw_search_10k_vectors() {
    let mut index = HNSWIndex::new(config);
    for i in 0..10_000 {
        index.insert(format!("vec_{i}"), random_vector(128));
    }

    let start = Instant::now();
    for _ in 0..100 {
        index.search(&amp;query, 10);
    }
    let elapsed = start.elapsed();

    assert!(elapsed &lt; Duration::from_secs(1));
}
<span class="boring">}</span></code></pre></pre>
<p>Run with: <code>cargo test -- --ignored</code></p>
<h2 id="integration-tests-1"><a class="header" href="#integration-tests-1">Integration Tests</a></h2>
<p>Located in <code>integration_tests/</code>:</p>
<pre><code class="language-bash">cargo test -p integration_tests
</code></pre>
<p>These test cross-crate behavior and full workflows.</p>
<h2 id="coverage"><a class="header" href="#coverage">Coverage</a></h2>
<p>Check coverage with cargo-llvm-cov:</p>
<pre><code class="language-bash">cargo install cargo-llvm-cov
cargo llvm-cov --workspace --html
open target/llvm-cov/html/index.html
</code></pre>
<p>Target coverage thresholds:</p>
<ul>
<li>shell: 88%</li>
<li>parser: 91%</li>
<li>blob: 91%</li>
<li>router: 92%</li>
<li>chain: 95%</li>
</ul>
<h2 id="mocking"><a class="header" href="#mocking">Mocking</a></h2>
<p>Use trait objects for dependency injection:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Transport: Send + Sync {
    fn send(&amp;self, msg: Message) -&gt; Result&lt;()&gt;;
}

// In tests
struct MockTransport {
    sent: Mutex&lt;Vec&lt;Message&gt;&gt;,
}

impl Transport for MockTransport {
    fn send(&amp;self, msg: Message) -&gt; Result&lt;()&gt; {
        self.sent.lock().unwrap().push(msg);
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="documentation"><a class="header" href="#documentation">Documentation</a></h1>
<h2 id="documentation-structure-1"><a class="header" href="#documentation-structure-1">Documentation Structure</a></h2>
<p>Neumann documentation consists of:</p>
<ol>
<li><strong>mdBook</strong> (<code>docs/book/</code>) - Conceptual docs, tutorials, operations</li>
<li><strong>rustdoc</strong> - API reference generated from source</li>
<li><strong>README.md</strong> per crate - Quick overview</li>
</ol>
<h2 id="writing-mdbook-pages"><a class="header" href="#writing-mdbook-pages">Writing mdBook Pages</a></h2>
<h3 id="file-location"><a class="header" href="#file-location">File Location</a></h3>
<pre><code class="language-text">docs/book/src/
├── SUMMARY.md          # Table of contents
├── introduction.md     # Landing page
├── getting-started/    # Tutorials
├── architecture/       # Module deep dives
├── concepts/           # Cross-cutting concepts
├── operations/         # Deployment, monitoring
└── contributing/       # Contribution guides
</code></pre>
<h3 id="page-structure"><a class="header" href="#page-structure">Page Structure</a></h3>
<pre><code class="language-markdown"># Page Title

Brief introduction (1-2 paragraphs).

## Section 1

Content with examples.

### Subsection

More detail.

## Section 2

Use tables for structured data:

| Column 1 | Column 2 |
|----------|----------|
| Value 1  | Value 2  |

Use mermaid for diagrams:

\`\`\`mermaid
flowchart LR
    A --&gt; B --&gt; C
\`\`\`
</code></pre>
<h3 id="admonitions"><a class="header" href="#admonitions">Admonitions</a></h3>
<p>Use mdbook-admonish syntax:</p>
<pre><code class="language-markdown">```admonish note
This is a note.
</code></pre>
<div id="admonition-warning" class="admonition admonish-warning" role="note" aria-labelledby="admonition-warning-title">
<div class="admonition-title">
<div id="admonition-warning-title">
<p>Warning</p>
</div>
<a class="admonition-anchor-link" href="contributing/documentation.html#admonition-warning"></a>
</div>
<div>
<p>This is a warning.</p>
</div>
</div>
<div id="admonition-danger" class="admonition admonish-danger" role="note" aria-labelledby="admonition-danger-title">
<div class="admonition-title">
<div id="admonition-danger-title">
<p>Danger</p>
</div>
<a class="admonition-anchor-link" href="contributing/documentation.html#admonition-danger"></a>
</div>
<div>
<p>This is dangerous.</p>
</div>
</div>
<pre><code class="language-bash">
## Writing Rustdoc

### Module Documentation

```rust
//! # Module Name
//!
//! Brief description (one line).
//!
//! ## Overview
//!
//! Longer explanation of purpose and design decisions.
//!
//! ## Example
//!
//! ```rust
//! // Example code
//! ```
</code></pre>
<h3 id="type-documentation"><a class="header" href="#type-documentation">Type Documentation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Brief description of the type.
///
/// Longer explanation if needed.
///
/// # Example
///
/// ```rust
/// let value = MyType::new();
/// ```
pub struct MyType { ... }
<span class="boring">}</span></code></pre></pre>
<h3 id="when-to-document"><a class="header" href="#when-to-document">When to Document</a></h3>
<p>Document:</p>
<ul>
<li>All public types</li>
<li>Non-obvious behavior</li>
<li>Complex algorithms</li>
</ul>
<p>Don’t document:</p>
<ul>
<li>Self-explanatory methods (<code>get</code>, <code>set</code>, <code>new</code>)</li>
<li>Trivial implementations</li>
</ul>
<h2 id="building-documentation"><a class="header" href="#building-documentation">Building Documentation</a></h2>
<h3 id="mdbook"><a class="header" href="#mdbook">mdBook</a></h3>
<pre><code class="language-bash">cd docs/book
mdbook build
mdbook serve  # Local preview at localhost:3000
</code></pre>
<h3 id="rustdoc"><a class="header" href="#rustdoc">rustdoc</a></h3>
<pre><code class="language-bash">cargo doc --workspace --no-deps --open
</code></pre>
<h3 id="full-build"><a class="header" href="#full-build">Full Build</a></h3>
<pre><code class="language-bash"># mdBook
cd docs/book &amp;&amp; mdbook build

# rustdoc
cargo doc --workspace --no-deps

# Combine
cp -r target/doc docs/book-output/api/
</code></pre>
<h2 id="link-checking"><a class="header" href="#link-checking">Link Checking</a></h2>
<pre><code class="language-bash">cd docs/book
mdbook-linkcheck --standalone
</code></pre>
<h2 id="adding-mermaid-diagrams"><a class="header" href="#adding-mermaid-diagrams">Adding Mermaid Diagrams</a></h2>
<p>Supported diagram types:</p>
<ul>
<li><code>flowchart</code> - Flow diagrams</li>
<li><code>sequenceDiagram</code> - Sequence diagrams</li>
<li><code>stateDiagram-v2</code> - State machines</li>
<li><code>classDiagram</code> - Class diagrams</li>
<li><code>gantt</code> - Gantt charts</li>
</ul>
<p>Example:</p>
<pre><code class="language-markdown">\`\`\`mermaid
sequenceDiagram
    participant C as Client
    participant S as Server
    C-&gt;&gt;S: Request
    S-&gt;&gt;C: Response
\`\`\`
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fuzzing-1"><a class="header" href="#fuzzing-1">Fuzzing</a></h1>
<p>Neumann uses cargo-fuzz (libFuzzer-based) for coverage-guided fuzzing.</p>
<h2 id="setup-3"><a class="header" href="#setup-3">Setup</a></h2>
<pre><code class="language-bash"># Install cargo-fuzz (requires nightly)
cargo install cargo-fuzz

# List available targets
cd fuzz &amp;&amp; cargo +nightly fuzz list
</code></pre>
<h2 id="running-fuzz-targets"><a class="header" href="#running-fuzz-targets">Running Fuzz Targets</a></h2>
<pre><code class="language-bash"># Run a specific target for 60 seconds
cargo +nightly fuzz run parser_parse -- -max_total_time=60

# Run without sanitizer (2x faster for safe Rust)
cargo +nightly fuzz run parser_parse --sanitizer none

# Reproduce a crash
cargo +nightly fuzz run parser_parse artifacts/parser_parse/crash-xxx
</code></pre>
<h2 id="available-targets"><a class="header" href="#available-targets">Available Targets</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Target</th><th>Module</th><th>What it tests</th></tr></thead><tbody>
<tr><td><code>parser_parse</code></td><td>neumann_parser</td><td>Statement parsing</td></tr>
<tr><td><code>parser_parse_all</code></td><td>neumann_parser</td><td>Multi-statement parsing</td></tr>
<tr><td><code>parser_parse_expr</code></td><td>neumann_parser</td><td>Expression parsing</td></tr>
<tr><td><code>parser_tokenize</code></td><td>neumann_parser</td><td>Lexer/tokenization</td></tr>
<tr><td><code>compress_ids</code></td><td>tensor_compress</td><td>Varint ID compression</td></tr>
<tr><td><code>compress_rle</code></td><td>tensor_compress</td><td>RLE encode/decode</td></tr>
<tr><td><code>compress_snapshot</code></td><td>tensor_compress</td><td>Snapshot serialization</td></tr>
<tr><td><code>vault_cipher</code></td><td>tensor_vault</td><td>AES-256-GCM roundtrip</td></tr>
<tr><td><code>checkpoint_state</code></td><td>tensor_checkpoint</td><td>Checkpoint bincode</td></tr>
<tr><td><code>storage_sparse_vector</code></td><td>tensor_store</td><td>Sparse vector roundtrip</td></tr>
<tr><td><code>slab_entity_index</code></td><td>tensor_store</td><td>EntityIndex operations</td></tr>
<tr><td><code>consistent_hash</code></td><td>tensor_store</td><td>Consistent hash partitioner</td></tr>
<tr><td><code>tcp_framing</code></td><td>tensor_chain</td><td>TCP wire protocol codec</td></tr>
<tr><td><code>membership</code></td><td>tensor_chain</td><td>Cluster config serialization</td></tr>
</tbody></table>
</div>
<h2 id="adding-a-new-fuzz-target"><a class="header" href="#adding-a-new-fuzz-target">Adding a New Fuzz Target</a></h2>
<ol>
<li>Create target file in <code>fuzz/fuzz_targets/&lt;name&gt;.rs</code>:</li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>#![no_main]

<span class="boring">fn main() {
</span>use libfuzzer_sys::fuzz_target;

fuzz_target!(|data: &amp;[u8]| {
    // Your fuzzing code here
    if let Ok(input) = std::str::from_utf8(data) {
        let _ = my_crate::parse(input);
    }
});
<span class="boring">}</span></code></pre></pre>
<ol>
<li>Add entry to <code>fuzz/Cargo.toml</code>:</li>
</ol>
<pre><code class="language-toml">[[bin]]
name = "my_target"
path = "fuzz_targets/my_target.rs"
test = false
doc = false
bench = false
</code></pre>
<ol>
<li>Add seed corpus files to <code>fuzz/corpus/&lt;name&gt;/</code>:</li>
</ol>
<pre><code class="language-bash">mkdir -p fuzz/corpus/my_target
echo "valid input 1" &gt; fuzz/corpus/my_target/seed1
echo "valid input 2" &gt; fuzz/corpus/my_target/seed2
</code></pre>
<ol>
<li>Update CI matrix in <code>.github/workflows/fuzz.yml</code></li>
</ol>
<h2 id="structured-fuzzing"><a class="header" href="#structured-fuzzing">Structured Fuzzing</a></h2>
<p>For complex input types, use <code>arbitrary</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use arbitrary::Arbitrary;

#[derive(Arbitrary, Debug)]
struct MyInput {
    field1: u32,
    field2: String,
}

fuzz_target!(|input: MyInput| {
    let _ = my_crate::process(&amp;input);
});
<span class="boring">}</span></code></pre></pre>
<h2 id="investigating-crashes"><a class="header" href="#investigating-crashes">Investigating Crashes</a></h2>
<pre><code class="language-bash"># View crash input
xxd artifacts/my_target/crash-xxx

# Minimize crash
cargo +nightly fuzz tmin my_target artifacts/my_target/crash-xxx

# Debug
cargo +nightly fuzz run my_target artifacts/my_target/crash-xxx -- -verbosity=2
</code></pre>
<h2 id="ci-integration"><a class="header" href="#ci-integration">CI Integration</a></h2>
<p>Fuzz tests run in CI for 60 seconds per target. See
<code>.github/workflows/fuzz.yml</code>.</p>
<h2 id="best-practices-9"><a class="header" href="#best-practices-9">Best Practices</a></h2>
<ol>
<li><strong>Add corpus seeds</strong>: Real-world inputs help fuzzer find paths</li>
<li><strong>Use structured fuzzing</strong>: For complex inputs</li>
<li><strong>Run locally</strong>: Before pushing changes to fuzzed code</li>
<li><strong>Minimize crashes</strong>: Smaller inputs are easier to debug</li>
<li><strong>Keep targets focused</strong>: One functionality per target</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-reference-7"><a class="header" href="#api-reference-7">API Reference</a></h1>
<p>This document provides detailed public API documentation for all Neumann crates.
For auto-generated rustdoc, see <a href="api-reference.html#building-locally">Building Locally</a>.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="api-reference.html#tensor_store">tensor_store</a> - Core storage layer</li>
<li><a href="api-reference.html#relational_engine">relational_engine</a> - SQL-like tables</li>
<li><a href="api-reference.html#graph_engine">graph_engine</a> - Graph operations</li>
<li><a href="api-reference.html#vector_engine">vector_engine</a> - Embeddings and similarity</li>
<li><a href="api-reference.html#tensor_chain">tensor_chain</a> - Distributed consensus</li>
<li><a href="api-reference.html#neumann_parser">neumann_parser</a> - Query parsing</li>
<li><a href="api-reference.html#query_router">query_router</a> - Query execution</li>
<li><a href="api-reference.html#tensor_cache">tensor_cache</a> - LLM response caching</li>
<li><a href="api-reference.html#tensor_vault">tensor_vault</a> - Encrypted storage</li>
<li><a href="api-reference.html#tensor_blob">tensor_blob</a> - Blob storage</li>
<li><a href="api-reference.html#tensor_checkpoint">tensor_checkpoint</a> - Snapshots</li>
</ul>
<hr />
<h2 id="tensor_store"><a class="header" href="#tensor_store">tensor_store</a></h2>
<p>Core key-value storage with HNSW indexing, sparse vectors, and tiered storage.</p>
<h3 id="core-types-9"><a class="header" href="#core-types-9">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TensorStore</code></td><td>Thread-safe key-value store with slab routing</td></tr>
<tr><td><code>TensorData</code></td><td>HashMap-based entity with typed fields</td></tr>
<tr><td><code>TensorValue</code></td><td>Field value: Scalar, Vector, Sparse, Pointer(s)</td></tr>
<tr><td><code>ScalarValue</code></td><td>Null, Bool, Int, Float, String, Bytes</td></tr>
</tbody></table>
</div>
<h3 id="tensorstore"><a class="header" href="#tensorstore">TensorStore</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::{TensorStore, TensorData, TensorValue, ScalarValue};

let store = TensorStore::new();

// Store entity
let mut data = TensorData::new();
data.set("name", TensorValue::Scalar(ScalarValue::String("Alice".into())));
data.set("embedding", TensorValue::Vector(vec![0.1, 0.2, 0.3]));
store.put("user:1", data)?;

// Retrieve
let entity = store.get("user:1")?;
assert!(entity.has("name"));

// Check existence
store.exists("user:1");  // -&gt; bool

// Delete
store.delete("user:1")?;

// Scan by prefix
let count = store.scan_count("user:");
<span class="boring">}</span></code></pre></pre>
<h3 id="tensordata-2"><a class="header" href="#tensordata-2">TensorData</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut data = TensorData::new();

// Set fields
data.set("field", TensorValue::Scalar(ScalarValue::Int(42)));

// Get fields
let value = data.get("field");  // -&gt; Option&lt;&amp;TensorValue&gt;

// Check field existence
data.has("field");  // -&gt; bool

// Field names
let fields: Vec&lt;&amp;str&gt; = data.keys().collect();
<span class="boring">}</span></code></pre></pre>
<h3 id="hnsw-index-5"><a class="header" href="#hnsw-index-5">HNSW Index</a></h3>
<p>Hierarchical Navigable Small World graph for approximate nearest neighbor search.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::{HNSWIndex, HNSWConfig, DistanceMetric};

// Create with config
let config = HNSWConfig {
    m: 16,              // Connections per node
    ef_construction: 200,
    ef_search: 50,
    max_elements: 10000,
    distance_metric: DistanceMetric::Cosine,
    ..Default::default()
};
let index = HNSWIndex::new(128, config);  // 128 dimensions

// Insert vector
index.insert("doc:1", &amp;embedding)?;

// Search
let results = index.search(&amp;query_vector, 10)?;
for (key, distance) in results {
    println!("{}: {}", key, distance);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="sparse-vectors-3"><a class="header" href="#sparse-vectors-3">Sparse Vectors</a></h3>
<p>Memory-efficient sparse embeddings with 15+ distance metrics.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::SparseVector;

// Create from dense (auto-detects sparsity)
let sparse = SparseVector::from_dense(&amp;[0.0, 0.5, 0.0, 0.3, 0.0]);

// Create from indices and values
let sparse = SparseVector::new(vec![1, 3], vec![0.5, 0.3], 5)?;

// Operations
let dense = sparse.to_dense();
let dot = sparse.dot(&amp;other_sparse);
let cosine = sparse.cosine_similarity(&amp;other_sparse);
<span class="boring">}</span></code></pre></pre>
<h3 id="tiered-storage-2"><a class="header" href="#tiered-storage-2">Tiered Storage</a></h3>
<p>Automatic hot/cold storage with mmap backing.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::{TieredStore, TieredConfig};
use std::path::Path;

let config = TieredConfig {
    hot_capacity: 10000,
    cold_path: Path::new("/data/cold").to_path_buf(),
    migration_threshold: 0.8,
    ..Default::default()
};
let store = TieredStore::new(config)?;

// Automatic migration based on access patterns
store.put("key", data)?;
let value = store.get("key")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="cache-ring"><a class="header" href="#cache-ring">Cache Ring</a></h3>
<p>Fixed-size eviction cache with multiple strategies.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::{CacheRing, EvictionStrategy};

let cache = CacheRing::new(1000, EvictionStrategy::LRU);

cache.put("key", value);
let hit = cache.get("key");  // -&gt; Option&lt;V&gt;

// Statistics
let stats = cache.stats();
println!("Hit rate: {:.2}%", stats.hit_rate() * 100.0);
<span class="boring">}</span></code></pre></pre>
<h3 id="consistent-hash-partitioner"><a class="header" href="#consistent-hash-partitioner">Consistent Hash Partitioner</a></h3>
<p>Partition routing with virtual nodes.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::{ConsistentHashPartitioner, ConsistentHashConfig};

let config = ConsistentHashConfig {
    virtual_nodes: 150,
    replication_factor: 3,
};
let partitioner = ConsistentHashPartitioner::new(config);

partitioner.add_node("node1");
partitioner.add_node("node2");

let partition = partitioner.partition("user:123");
let replicas = partitioner.replicas("user:123");
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="relational_engine"><a class="header" href="#relational_engine">relational_engine</a></h2>
<p>SQL-like table operations with SIMD-accelerated filtering.</p>
<h3 id="core-types-10"><a class="header" href="#core-types-10">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>RelationalEngine</code></td><td>Main engine with TensorStore backend</td></tr>
<tr><td><code>Schema</code></td><td>Table schema with column definitions</td></tr>
<tr><td><code>Column</code></td><td>Column name, type, nullability</td></tr>
<tr><td><code>ColumnType</code></td><td>Int, Float, String, Bool, Bytes, Json</td></tr>
<tr><td><code>Value</code></td><td>Typed query value</td></tr>
<tr><td><code>Condition</code></td><td>Composable filter predicate</td></tr>
<tr><td><code>Row</code></td><td>Row with ID and values</td></tr>
</tbody></table>
</div>
<h3 id="table-operations-1"><a class="header" href="#table-operations-1">Table Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::{RelationalEngine, Schema, Column, ColumnType};

let engine = RelationalEngine::new();

// Create table
let schema = Schema::new(vec![
    Column::new("name", ColumnType::String),
    Column::new("age", ColumnType::Int),
    Column::new("email", ColumnType::String).nullable(),
]);
engine.create_table("users", schema)?;

// Check existence
engine.table_exists("users")?;  // -&gt; bool

// List tables
let tables = engine.list_tables();  // -&gt; Vec&lt;String&gt;

// Get schema
let schema = engine.get_schema("users")?;

// Row count
engine.row_count("users")?;  // -&gt; usize

// Drop table
engine.drop_table("users")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="crud-operations-1"><a class="header" href="#crud-operations-1">CRUD Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::{Condition, Value};
use std::collections::HashMap;

// INSERT
let mut values = HashMap::new();
values.insert("name".to_string(), Value::String("Alice".into()));
values.insert("age".to_string(), Value::Int(30));
let row_id = engine.insert("users", values)?;

// BATCH INSERT (59x faster)
let rows: Vec&lt;HashMap&lt;String, Value&gt;&gt; = vec![/* ... */];
let row_ids = engine.batch_insert("users", rows)?;

// SELECT with condition
let rows = engine.select("users",
    Condition::Ge("age".into(), Value::Int(18)))?;

// UPDATE
let mut updates = HashMap::new();
updates.insert("age".to_string(), Value::Int(31));
let count = engine.update("users",
    Condition::Eq("name".into(), Value::String("Alice".into())),
    updates)?;

// DELETE
let count = engine.delete_rows("users",
    Condition::Lt("age".into(), Value::Int(18)))?;
<span class="boring">}</span></code></pre></pre>
<h3 id="conditions-1"><a class="header" href="#conditions-1">Conditions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::{Condition, Value};

// Simple conditions
Condition::True                           // Match all
Condition::Eq("col".into(), Value::Int(1))  // col = 1
Condition::Ne("col".into(), Value::Int(1))  // col != 1
Condition::Lt("col".into(), Value::Int(10)) // col &lt; 10
Condition::Le("col".into(), Value::Int(10)) // col &lt;= 10
Condition::Gt("col".into(), Value::Int(0))  // col &gt; 0
Condition::Ge("col".into(), Value::Int(0))  // col &gt;= 0

// Compound conditions
let cond = Condition::Ge("age".into(), Value::Int(18))
    .and(Condition::Lt("age".into(), Value::Int(65)));

let cond = Condition::Eq("status".into(), Value::String("active".into()))
    .or(Condition::Gt("priority".into(), Value::Int(5)));
<span class="boring">}</span></code></pre></pre>
<h3 id="indexes-1"><a class="header" href="#indexes-1">Indexes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Hash index (O(1) equality)
engine.create_index("users", "email")?;
engine.has_index("users", "email");  // -&gt; bool
engine.drop_index("users", "email")?;

// B-tree index (O(log n) range)
engine.create_btree_index("users", "age")?;
engine.has_btree_index("users", "age");  // -&gt; bool
engine.drop_btree_index("users", "age")?;

// List indexed columns
engine.get_indexed_columns("users");        // -&gt; Vec&lt;String&gt;
engine.get_btree_indexed_columns("users");  // -&gt; Vec&lt;String&gt;
<span class="boring">}</span></code></pre></pre>
<h3 id="joins-1"><a class="header" href="#joins-1">Joins</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// INNER JOIN
let joined = engine.join("users", "posts", "_id", "user_id")?;
// -&gt; Vec&lt;(Row, Row)&gt;

// LEFT JOIN
let joined = engine.left_join("users", "posts", "_id", "user_id")?;
// -&gt; Vec&lt;(Row, Option&lt;Row&gt;)&gt;

// RIGHT JOIN
let joined = engine.right_join("users", "posts", "_id", "user_id")?;
// -&gt; Vec&lt;(Option&lt;Row&gt;, Row)&gt;

// FULL JOIN
let joined = engine.full_join("users", "posts", "_id", "user_id")?;
// -&gt; Vec&lt;(Option&lt;Row&gt;, Option&lt;Row&gt;)&gt;

// CROSS JOIN
let joined = engine.cross_join("users", "posts")?;
// -&gt; Vec&lt;(Row, Row)&gt;

// NATURAL JOIN
let joined = engine.natural_join("users", "profiles")?;
// -&gt; Vec&lt;(Row, Row)&gt;
<span class="boring">}</span></code></pre></pre>
<h3 id="aggregates"><a class="header" href="#aggregates">Aggregates</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// COUNT
let count = engine.count("users", Condition::True)?;
let count = engine.count_column("users", "email", Condition::True)?;

// SUM
let total = engine.sum("orders", "amount", Condition::True)?;

// AVG
let avg = engine.avg("orders", "amount", Condition::True)?;  // Option&lt;f64&gt;

// MIN/MAX
let min = engine.min("products", "price", Condition::True)?;  // Option&lt;Value&gt;
let max = engine.max("products", "price", Condition::True)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="transactions-1"><a class="header" href="#transactions-1">Transactions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::{TransactionManager, TxPhase};

let tx_manager = TransactionManager::new();

// Begin transaction
let tx_id = tx_manager.begin();

// Check state
tx_manager.is_active(tx_id);  // -&gt; bool
tx_manager.get(tx_id);        // -&gt; Option&lt;TxPhase&gt;

// Acquire row locks
tx_manager.lock_manager().try_lock(tx_id, &amp;[
    ("users".to_string(), 1),
    ("users".to_string(), 2),
])?;

// Commit or rollback
tx_manager.set_phase(tx_id, TxPhase::Committed);
tx_manager.release_locks(tx_id);
tx_manager.remove(tx_id);
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="graph_engine"><a class="header" href="#graph_engine">graph_engine</a></h2>
<p>Directed graph operations with BFS traversal and shortest path.</p>
<h3 id="core-types-11"><a class="header" href="#core-types-11">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>GraphEngine</code></td><td>Main engine with TensorStore backend</td></tr>
<tr><td><code>Node</code></td><td>Graph node with label and properties</td></tr>
<tr><td><code>Edge</code></td><td>Directed edge with type and properties</td></tr>
<tr><td><code>Direction</code></td><td>Outgoing, Incoming, Both</td></tr>
<tr><td><code>PropertyValue</code></td><td>Null, Int, Float, String, Bool</td></tr>
<tr><td><code>Path</code></td><td>Sequence of nodes and edges</td></tr>
</tbody></table>
</div>
<h3 id="node-operations-1"><a class="header" href="#node-operations-1">Node Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use graph_engine::{GraphEngine, PropertyValue};
use std::collections::HashMap;

let engine = GraphEngine::new();

// Create node
let mut props = HashMap::new();
props.insert("name".to_string(), PropertyValue::String("Alice".into()));
let node_id = engine.create_node("person", props)?;

// Get node
let node = engine.get_node(node_id)?;
println!("{}: {:?}", node.label, node.properties);

// Update node
let mut updates = HashMap::new();
updates.insert("age".to_string(), PropertyValue::Int(30));
engine.update_node(node_id, updates)?;

// Delete node
engine.delete_node(node_id)?;

// Find nodes by label
let people = engine.find_nodes_by_label("person")?;
<span class="boring">}</span></code></pre></pre>
<h3 id="edge-operations-1"><a class="header" href="#edge-operations-1">Edge Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use graph_engine::Direction;

// Create edge
let edge_id = engine.create_edge(from_id, to_id, "follows", HashMap::new())?;

// Get edge
let edge = engine.get_edge(edge_id)?;

// Get neighbors
let neighbors = engine.neighbors(node_id, Direction::Outgoing)?;
let neighbors = engine.neighbors(node_id, Direction::Incoming)?;
let neighbors = engine.neighbors(node_id, Direction::Both)?;

// Get edges
let edges = engine.edges(node_id, Direction::Outgoing)?;

// Delete edge
engine.delete_edge(edge_id)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="traversal"><a class="header" href="#traversal">Traversal</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// BFS traversal
let visited = engine.bfs(start_id, |node| {
    // Return true to continue traversal
    true
})?;

// Shortest path (Dijkstra)
let path = engine.shortest_path(from_id, to_id)?;
if let Some(path) = path {
    for node_id in path.nodes {
        println!("-&gt; {}", node_id);
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="property-indexes"><a class="header" href="#property-indexes">Property Indexes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use graph_engine::{IndexTarget, RangeOp};

// Create index on node property
engine.create_property_index(IndexTarget::Node, "age")?;

// Create index on edge property
engine.create_property_index(IndexTarget::Edge, "weight")?;

// Range query using index
let results = engine.find_by_range(
    IndexTarget::Node,
    "age",
    &amp;PropertyValue::Int(18),
    RangeOp::Ge,
)?;
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="vector_engine"><a class="header" href="#vector_engine">vector_engine</a></h2>
<p>Embedding storage and similarity search.</p>
<h3 id="core-types-12"><a class="header" href="#core-types-12">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>VectorEngine</code></td><td>Main engine for embedding operations</td></tr>
<tr><td><code>SearchResult</code></td><td>Key and similarity score</td></tr>
<tr><td><code>DistanceMetric</code></td><td>Cosine, Euclidean, DotProduct</td></tr>
<tr><td><code>FilterCondition</code></td><td>Metadata filter (Eq, Ne, Lt, Gt, And, Or, In, etc.)</td></tr>
<tr><td><code>FilterValue</code></td><td>Filter value type (Int, Float, String, Bool, Null)</td></tr>
<tr><td><code>FilterStrategy</code></td><td>Filter strategy (Auto, PreFilter, PostFilter)</td></tr>
<tr><td><code>FilteredSearchConfig</code></td><td>Configuration for filtered search</td></tr>
<tr><td><code>VectorCollectionConfig</code></td><td>Configuration for collections</td></tr>
<tr><td><code>MetadataValue</code></td><td>Simplified metadata value type</td></tr>
</tbody></table>
</div>
<h3 id="basic-operations-4"><a class="header" href="#basic-operations-4">Basic Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::{VectorEngine, DistanceMetric};

let engine = VectorEngine::new();

// Store embedding (auto-detects sparse)
engine.store_embedding("doc:1", vec![0.1, 0.2, 0.3])?;

// Get embedding
let vector = engine.get_embedding("doc:1")?;

// Check existence
engine.exists("doc:1");  // -&gt; bool

// Delete
engine.delete_embedding("doc:1")?;

// Count embeddings
engine.count();  // -&gt; usize
<span class="boring">}</span></code></pre></pre>
<h3 id="similarity-search-2"><a class="header" href="#similarity-search-2">Similarity Search</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Search similar embeddings
let query = vec![0.1, 0.2, 0.3];
let results = engine.search_similar(&amp;query, 10)?;

for result in results {
    println!("{}: {:.4}", result.key, result.score);
}

// Search with metric
let results = engine.search_similar_with_metric(
    &amp;query,
    10,
    DistanceMetric::Euclidean,
)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="filtered-search-1"><a class="header" href="#filtered-search-1">Filtered Search</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::{FilterCondition, FilterValue, FilteredSearchConfig};

// Build filter
let filter = FilterCondition::Eq("category".into(), FilterValue::String("science".into()))
    .and(FilterCondition::Gt("year".into(), FilterValue::Int(2020)));

// Search with filter
let results = engine.search_similar_filtered(&amp;query, 10, &amp;filter, None)?;

// With explicit strategy
let config = FilteredSearchConfig::pre_filter();
let results = engine.search_similar_filtered(&amp;query, 10, &amp;filter, Some(config))?;
<span class="boring">}</span></code></pre></pre>
<h3 id="metadata-storage-1"><a class="header" href="#metadata-storage-1">Metadata Storage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_store::TensorValue;
use std::collections::HashMap;

// Store embedding with metadata
let mut metadata = HashMap::new();
metadata.insert("category".into(), TensorValue::from("science"));
metadata.insert("year".into(), TensorValue::from(2024i64));
engine.store_embedding_with_metadata("doc:1", vec![0.1, 0.2], metadata)?;

// Get metadata
let meta = engine.get_metadata("doc:1")?;

// Update metadata
let mut updates = HashMap::new();
updates.insert("year".into(), TensorValue::from(2025i64));
engine.update_metadata("doc:1", updates)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="collections-1"><a class="header" href="#collections-1">Collections</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use vector_engine::VectorCollectionConfig;

// Create collection
let config = VectorCollectionConfig::default()
    .with_dimension(768)
    .with_metric(DistanceMetric::Cosine);
engine.create_collection("documents", config)?;

// Store in collection
engine.store_in_collection("documents", "doc:1", vec![0.1; 768])?;

// Search in collection
let results = engine.search_in_collection("documents", &amp;query, 10)?;

// List/delete collections
let collections = engine.list_collections();
engine.delete_collection("documents")?;
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="tensor_chain"><a class="header" href="#tensor_chain">tensor_chain</a></h2>
<p>Distributed consensus with Raft and 2PC transactions.</p>
<h3 id="core-types-13"><a class="header" href="#core-types-13">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Chain</code></td><td>Block chain with graph-based linking</td></tr>
<tr><td><code>Block</code></td><td>Block with header and transactions</td></tr>
<tr><td><code>Transaction</code></td><td>Put, Delete, Update operations</td></tr>
<tr><td><code>RaftNode</code></td><td>Raft consensus state machine</td></tr>
<tr><td><code>DistributedTxCoordinator</code></td><td>2PC transaction coordinator</td></tr>
</tbody></table>
</div>
<h3 id="chain-operations-1"><a class="header" href="#chain-operations-1">Chain Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::{Chain, Transaction, Block};
use graph_engine::GraphEngine;
use std::sync::Arc;

let graph = Arc::new(GraphEngine::new());
let chain = Chain::new(graph, "node1".to_string());
chain.initialize()?;

// Create block
let builder = chain.new_block()
    .add_transaction(Transaction::Put {
        key: "user:1".into(),
        data: vec![1, 2, 3],
    })
    .add_transaction(Transaction::Delete {
        key: "user:0".into(),
    });

let block = builder.build();
chain.append(block)?;

// Query chain
let height = chain.height();
let block = chain.get_block(1)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="raft-consensus-3"><a class="header" href="#raft-consensus-3">Raft Consensus</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::{RaftNode, RaftConfig, RaftState};

let config = RaftConfig {
    election_timeout_min: 150,
    election_timeout_max: 300,
    heartbeat_interval: 50,
    ..Default::default()
};

let raft = RaftNode::new("node1".into(), config);

// State queries
raft.is_leader();     // -&gt; bool
raft.current_term();  // -&gt; u64
raft.state();         // -&gt; RaftState

// Statistics
let stats = raft.stats();
<span class="boring">}</span></code></pre></pre>
<h3 id="distributed-transactions-1"><a class="header" href="#distributed-transactions-1">Distributed Transactions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::{DistributedTxCoordinator, DistributedTxConfig};

let config = DistributedTxConfig {
    prepare_timeout_ms: 5000,
    commit_timeout_ms: 5000,
    max_retries: 3,
    ..Default::default()
};

let coordinator = DistributedTxCoordinator::new(config);

// Begin distributed transaction
let tx_id = coordinator.begin()?;

// Prepare phase
coordinator.prepare(tx_id, keys, participants).await?;

// Commit phase
coordinator.commit(tx_id).await?;

// Or abort
coordinator.abort(tx_id).await?;
<span class="boring">}</span></code></pre></pre>
<h3 id="membership-management"><a class="header" href="#membership-management">Membership Management</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_chain::{MembershipManager, ClusterConfig, HealthConfig};

let config = ClusterConfig {
    local: LocalNodeConfig { id: "node1".into(), addr: "127.0.0.1:9000".parse()? },
    peers: vec![],
    health: HealthConfig::default(),
};

let membership = MembershipManager::new(config);

// Add/remove nodes
membership.add_node("node2", "127.0.0.1:9001".parse()?)?;
membership.remove_node("node2")?;

// Health status
let health = membership.node_health("node2");
let status = membership.partition_status();
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="neumann_parser"><a class="header" href="#neumann_parser">neumann_parser</a></h2>
<p>Hand-written recursive descent parser for the Neumann query language.</p>
<h3 id="core-types-14"><a class="header" href="#core-types-14">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Statement</code></td><td>Parsed statement with span</td></tr>
<tr><td><code>StatementKind</code></td><td>Select, Insert, Update, Delete, Node, Edge, etc.</td></tr>
<tr><td><code>Expr</code></td><td>Expression AST node</td></tr>
<tr><td><code>Token</code></td><td>Lexer token with span</td></tr>
<tr><td><code>ParseError</code></td><td>Error with source location</td></tr>
</tbody></table>
</div>
<h3 id="parsing"><a class="header" href="#parsing">Parsing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::{parse, parse_all, parse_expr, tokenize};

// Parse single statement
let stmt = parse("SELECT * FROM users WHERE id = 1")?;

// Parse multiple statements
let stmts = parse_all("SELECT 1; SELECT 2")?;

// Parse expression only
let expr = parse_expr("1 + 2 * 3")?;

// Tokenize
let tokens = tokenize("SELECT id, name FROM users");
<span class="boring">}</span></code></pre></pre>
<h3 id="error-handling-13"><a class="header" href="#error-handling-13">Error Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let result = parse("SELCT * FROM users");
if let Err(err) = result {
    // Format with source context
    let formatted = err.format_with_source("SELCT * FROM users");
    eprintln!("{}", formatted);

    // Access error details
    println!("Line: {}", err.line());
    println!("Column: {}", err.column());
}
<span class="boring">}</span></code></pre></pre>
<h3 id="span-utilities"><a class="header" href="#span-utilities">Span Utilities</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use neumann_parser::{line_number, line_col, get_line, BytePos};

let source = "SELECT\nFROM\nWHERE";

// Get line number (1-indexed)
let line = line_number(source, BytePos(7));  // -&gt; 2

// Get line and column
let (line, col) = line_col(source, BytePos(7));  // -&gt; (2, 1)

// Get line text
let text = get_line(source, BytePos(7));  // -&gt; "FROM"
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="query_router"><a class="header" href="#query_router">query_router</a></h2>
<p>Unified query routing across all engines.</p>
<h3 id="core-types-15"><a class="header" href="#core-types-15">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>QueryRouter</code></td><td>Main router handling all query types</td></tr>
<tr><td><code>QueryResult</code></td><td>Result variants for different query types</td></tr>
<tr><td><code>RouterError</code></td><td>Error types from all engines</td></tr>
</tbody></table>
</div>
<h3 id="query-execution-4"><a class="header" href="#query-execution-4">Query Execution</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use query_router::{QueryRouter, QueryResult};

let router = QueryRouter::new();

// Execute query
let result = router.execute("SELECT * FROM users")?;

match result {
    QueryResult::Rows(rows) =&gt; { /* relational result */ }
    QueryResult::Nodes(nodes) =&gt; { /* graph result */ }
    QueryResult::Similar(results) =&gt; { /* vector result */ }
    QueryResult::Success(msg) =&gt; { /* command result */ }
    _ =&gt; {}
}
<span class="boring">}</span></code></pre></pre>
<h3 id="distributed-queries"><a class="header" href="#distributed-queries">Distributed Queries</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use query_router::{QueryPlanner, MergeStrategy, ResultMerger};

let planner = QueryPlanner::new(partitioner);

// Plan distributed query
let plan = planner.plan("SELECT * FROM users WHERE region = 'us'")?;

// Execute on shards
let shard_results = execute_on_shards(&amp;plan).await?;

// Merge results
let merger = ResultMerger::new(MergeStrategy::Union);
let final_result = merger.merge(shard_results)?;
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="tensor_cache"><a class="header" href="#tensor_cache">tensor_cache</a></h2>
<p>LLM response cache with exact and semantic matching.</p>
<h3 id="core-types-16"><a class="header" href="#core-types-16">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Cache</code></td><td>Multi-layer LLM response cache</td></tr>
<tr><td><code>CacheConfig</code></td><td>Configuration for cache behavior</td></tr>
<tr><td><code>CacheHit</code></td><td>Successful lookup result</td></tr>
<tr><td><code>CacheLayer</code></td><td>Exact, Semantic, Embedding</td></tr>
<tr><td><code>EvictionStrategy</code></td><td>LRU, LFU, CostBased, Hybrid</td></tr>
</tbody></table>
</div>
<h3 id="operations-3"><a class="header" href="#operations-3">Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_cache::{Cache, CacheConfig, EvictionStrategy};

let mut config = CacheConfig::default();
config.embedding_dim = 384;
config.eviction_strategy = EvictionStrategy::Hybrid;
let cache = Cache::with_config(config)?;

// Store response
let embedding = vec![0.1, 0.2, /* ... */];
cache.put(
    "What is 2+2?",
    &amp;embedding,
    "The answer is 4.",
    "gpt-4",
    None,  // version
)?;

// Lookup (tries exact, then semantic)
if let Some(hit) = cache.get("What is 2+2?", Some(&amp;embedding)) {
    println!("Response: {}", hit.response);
    println!("Layer: {:?}", hit.layer);
    println!("Cost saved: ${:.4}", hit.cost_saved);
}

// Statistics
let stats = cache.stats();
println!("Hit rate: {:.2}%", stats.hit_rate() * 100.0);
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="tensor_vault"><a class="header" href="#tensor_vault">tensor_vault</a></h2>
<p>Encrypted secret storage with graph-based access control.</p>
<h3 id="core-types-17"><a class="header" href="#core-types-17">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>Vault</code></td><td>Main vault API</td></tr>
<tr><td><code>VaultConfig</code></td><td>Configuration for security settings</td></tr>
<tr><td><code>Permission</code></td><td>Read, Write, Admin</td></tr>
<tr><td><code>MasterKey</code></td><td>Derived encryption key</td></tr>
</tbody></table>
</div>
<h3 id="operations-4"><a class="header" href="#operations-4">Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_vault::{Vault, VaultConfig, Permission};

let config = VaultConfig::default();
let vault = Vault::new(config)?;

// Store secret
vault.set("requester", "db/password", b"secret123", Permission::Admin)?;

// Get secret
let secret = vault.get("requester", "db/password")?;

// Grant access
vault.grant("admin", "user", "db/password", Permission::Read)?;

// Revoke access
vault.revoke("admin", "user", "db/password")?;

// List secrets
let secrets = vault.list("requester", "db/")?;

// Delete secret
vault.delete("admin", "db/password")?;
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="tensor_blob"><a class="header" href="#tensor_blob">tensor_blob</a></h2>
<p>S3-style object storage with content-addressable chunks.</p>
<h3 id="core-types-18"><a class="header" href="#core-types-18">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>BlobStore</code></td><td>Main blob storage API</td></tr>
<tr><td><code>BlobConfig</code></td><td>Configuration for chunk size, GC</td></tr>
<tr><td><code>PutOptions</code></td><td>Options for storing artifacts</td></tr>
<tr><td><code>ArtifactMetadata</code></td><td>Metadata for stored artifacts</td></tr>
<tr><td><code>BlobWriter</code></td><td>Streaming upload</td></tr>
<tr><td><code>BlobReader</code></td><td>Streaming download</td></tr>
</tbody></table>
</div>
<h3 id="operations-5"><a class="header" href="#operations-5">Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_blob::{BlobStore, BlobConfig, PutOptions};

let config = BlobConfig::default();
let store = BlobStore::new(tensor_store, config).await?;

// Store artifact
let artifact_id = store.put(
    "report.pdf",
    &amp;file_bytes,
    PutOptions::new()
        .with_created_by("user:alice")
        .with_tag("quarterly"),
).await?;

// Get artifact
let data = store.get(&amp;artifact_id).await?;

// Streaming upload
let mut writer = store.writer("large-file.bin", PutOptions::new()).await?;
writer.write(&amp;chunk1).await?;
writer.write(&amp;chunk2).await?;
let artifact_id = writer.finish().await?;

// Streaming download
let mut reader = store.reader(&amp;artifact_id).await?;
let chunk = reader.read(1024).await?;

// Delete
store.delete(&amp;artifact_id).await?;

// Metadata
let metadata = store.metadata(&amp;artifact_id).await?;
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="tensor_checkpoint"><a class="header" href="#tensor_checkpoint">tensor_checkpoint</a></h2>
<p>Snapshot and rollback system.</p>
<h3 id="core-types-19"><a class="header" href="#core-types-19">Core Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>CheckpointManager</code></td><td>Main checkpoint API</td></tr>
<tr><td><code>CheckpointConfig</code></td><td>Configuration for checkpoints</td></tr>
<tr><td><code>DestructiveOp</code></td><td>Delete, Update operations</td></tr>
<tr><td><code>OperationPreview</code></td><td>Preview of affected data</td></tr>
<tr><td><code>ConfirmationHandler</code></td><td>Custom confirmation logic</td></tr>
</tbody></table>
</div>
<h3 id="operations-6"><a class="header" href="#operations-6">Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_checkpoint::{CheckpointManager, CheckpointConfig, AutoConfirm};
use std::sync::Arc;

let config = CheckpointConfig::new()
    .with_max_checkpoints(10)
    .with_auto_checkpoint(true);

let manager = CheckpointManager::new(blob_store, config).await;
manager.set_confirmation_handler(Arc::new(AutoConfirm));

// Create checkpoint
let checkpoint_id = manager.create(Some("before-migration"), &amp;store).await?;

// List checkpoints
let checkpoints = manager.list().await?;

// Restore from checkpoint
manager.restore(&amp;checkpoint_id, &amp;mut store).await?;

// Delete checkpoint
manager.delete(&amp;checkpoint_id).await?;
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="error-handling-14"><a class="header" href="#error-handling-14">Error Handling</a></h3>
<p>All crates use the <code>Result</code> type with crate-specific error enums:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use relational_engine::{RelationalEngine, RelationalError};

let result = engine.create_table("users", schema);
match result {
    Ok(()) =&gt; println!("Table created"),
    Err(RelationalError::TableAlreadyExists) =&gt; println!("Already exists"),
    Err(e) =&gt; eprintln!("Error: {}", e),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="thread-safety-2"><a class="header" href="#thread-safety-2">Thread Safety</a></h3>
<p>All engines use <code>parking_lot</code> and <code>DashMap</code> for concurrent access:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Arc;
use std::thread;

let engine = Arc::new(RelationalEngine::new());

let handles: Vec&lt;_&gt; = (0..4).map(|i| {
    let engine = Arc::clone(&amp;engine);
    thread::spawn(move || {
        engine.insert("users", values).unwrap();
    })
}).collect();

for handle in handles {
    handle.join().unwrap();
}
<span class="boring">}</span></code></pre></pre>
<h3 id="async-operations"><a class="header" href="#async-operations">Async Operations</a></h3>
<p><code>tensor_blob</code>, <code>tensor_cache</code>, and <code>tensor_checkpoint</code> use async APIs:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::runtime::Runtime;

let rt = Runtime::new()?;
rt.block_on(async {
    let store = BlobStore::new(tensor_store, config).await?;
    store.put("file.txt", &amp;data, options).await?;
    Ok(())
})?;
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="building-locally"><a class="header" href="#building-locally">Building Locally</a></h2>
<p>Generate documentation from source:</p>
<pre><code class="language-bash"># Basic documentation
cargo doc --workspace --no-deps --open

# With all features and private items
cargo doc --workspace --no-deps --all-features --document-private-items

# With scraped examples (nightly)
RUSTDOCFLAGS="--cfg docsrs" cargo +nightly doc \
  -Zunstable-options \
  -Zrustdoc-scrape-examples \
  --all-features
</code></pre>
<h2 id="online-documentation"><a class="header" href="#online-documentation">Online Documentation</a></h2>
<p>When deployed, the API reference is available at:</p>
<ul>
<li><a href="api/tensor_store/index.html">tensor_store</a></li>
<li><a href="api/relational_engine/index.html">relational_engine</a></li>
<li><a href="api/graph_engine/index.html">graph_engine</a></li>
<li><a href="api/vector_engine/index.html">vector_engine</a></li>
<li><a href="api/tensor_chain/index.html">tensor_chain</a></li>
<li><a href="api/neumann_parser/index.html">neumann_parser</a></li>
<li><a href="api/query_router/index.html">query_router</a></li>
<li><a href="api/tensor_cache/index.html">tensor_cache</a></li>
<li><a href="api/tensor_vault/index.html">tensor_vault</a></li>
<li><a href="api/tensor_blob/index.html">tensor_blob</a></li>
<li><a href="api/tensor_checkpoint/index.html">tensor_checkpoint</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="mode-rust.js"></script>
        <script src="editor.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
