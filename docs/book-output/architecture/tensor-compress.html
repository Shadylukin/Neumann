<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Tensor Compress - Neumann</title>


        <!-- Custom HTML head -->

        <meta name="description" content="Unified tensor-based runtime for relational, graph, and vector data">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "rust";
            const default_dark_theme = "coal";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Neumann</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/Shadylukin/Neumann" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/Shadylukin/Neumann/edit/main/docs/book/src/architecture/tensor-compress.md" title="Suggest an edit" aria-label="Suggest an edit" rel="edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="tensor-compress"><a class="header" href="#tensor-compress">Tensor Compress</a></h1>
<p>Module 8 of Neumann. Provides tensor-native compression exploiting the
mathematical structure of high-dimensional embeddings.</p>
<p>The primary compression method is Tensor Train (TT) decomposition, which
decomposes vectors reshaped as tensors into a chain of smaller 3D cores using
successive SVD truncations. This achieves 10-40x compression for 1024+ dimension
vectors while enabling similarity computations directly in compressed space.</p>
<h2 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h2>
<ol>
<li><strong>Tensor Mathematics</strong>: Uses Tensor Train decomposition to exploit low-rank
structure</li>
<li><strong>Higher Dimensions Are Lower</strong>: Decomposes vectors into products of smaller
tensors</li>
<li><strong>Streaming I/O</strong>: Process large snapshots without loading entire dataset</li>
<li><strong>Incremental Updates</strong>: Delta snapshots for efficient replication</li>
<li><strong>Pure Rust</strong>: No external LAPACK/BLAS dependencies - fully portable</li>
</ol>
<h2 id="key-types"><a class="header" href="#key-types">Key Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TTVector</code></td><td>Complete TT-decomposition of a vector with cores, shape, and ranks</td></tr>
<tr><td><code>TTCore</code></td><td>Single 3D tensor core (left_rank x mode_size x right_rank)</td></tr>
<tr><td><code>TTConfig</code></td><td>Configuration for TT decomposition (shape, max_rank, tolerance)</td></tr>
<tr><td><code>CompressionConfig</code></td><td>Snapshot compression settings (tensor mode, delta, RLE)</td></tr>
<tr><td><code>TensorMode</code></td><td>Compression mode enum (currently TensorTrain variant)</td></tr>
<tr><td><code>RleEncoded&lt;T&gt;</code></td><td>Run-length encoded data with values and run lengths</td></tr>
<tr><td><code>DeltaSnapshot</code></td><td>Snapshot containing only changes since a base snapshot</td></tr>
<tr><td><code>DeltaChain</code></td><td>Chain of deltas with efficient lookup and compaction</td></tr>
<tr><td><code>StreamingWriter</code></td><td>Memory-bounded incremental snapshot writer</td></tr>
<tr><td><code>StreamingReader</code></td><td>Iterator-based snapshot reader</td></tr>
<tr><td><code>StreamingTTWriter</code></td><td>Streaming TT-compressed vector writer</td></tr>
<tr><td><code>StreamingTTReader</code></td><td>Streaming TT-compressed vector reader</td></tr>
<tr><td><code>Matrix</code></td><td>Row-major matrix for SVD operations</td></tr>
<tr><td><code>SvdResult</code></td><td>Truncated SVD result (U, S, Vt matrices)</td></tr>
<tr><td><code>TensorView</code></td><td>Zero-copy logical view of tensor data</td></tr>
<tr><td><code>DeltaBuilder</code></td><td>Builder for creating delta snapshots</td></tr>
</tbody></table>
</div>
<h2 id="error-types"><a class="header" href="#error-types">Error Types</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Error</th><th>Description</th></tr></thead><tbody>
<tr><td><code>TTError::ShapeMismatch</code></td><td>Vector dimension doesn’t match reshape target</td></tr>
<tr><td><code>TTError::EmptyVector</code></td><td>Cannot decompose empty vector</td></tr>
<tr><td><code>TTError::InvalidRank</code></td><td>TT-rank must be &gt;= 1</td></tr>
<tr><td><code>TTError::IncompatibleShapes</code></td><td>TT vectors have different shapes for operation</td></tr>
<tr><td><code>TTError::InvalidShape</code></td><td>Shape contains zero or is empty</td></tr>
<tr><td><code>TTError::InvalidTolerance</code></td><td>Tolerance must be 0 &lt; tol &lt;= 1</td></tr>
<tr><td><code>TTError::Decompose</code></td><td>SVD decomposition failed</td></tr>
<tr><td><code>FormatError::InvalidMagic</code></td><td>File magic bytes don’t match expected</td></tr>
<tr><td><code>FormatError::UnsupportedVersion</code></td><td>Format version is newer than supported</td></tr>
<tr><td><code>FormatError::Serialization</code></td><td>Bincode serialization/deserialization error</td></tr>
<tr><td><code>DeltaError::BaseNotFound</code></td><td>Referenced base snapshot doesn’t exist</td></tr>
<tr><td><code>DeltaError::SequenceGap</code></td><td>Delta sequence numbers have gaps</td></tr>
<tr><td><code>DeltaError::ChainTooLong</code></td><td>Delta chain exceeds maximum length</td></tr>
<tr><td><code>DecomposeError::EmptyMatrix</code></td><td>Cannot decompose empty matrix</td></tr>
<tr><td><code>DecomposeError::DimensionMismatch</code></td><td>Matrix dimensions don’t match for operation</td></tr>
<tr><td><code>DecomposeError::SvdNotConverged</code></td><td>SVD iteration didn’t converge</td></tr>
</tbody></table>
</div>
<h2 id="architecture"><a class="header" href="#architecture">Architecture</a></h2>
<pre class="mermaid">graph TD
    subgraph tensor_compress
        TT[tensor_train.rs&lt;br/&gt;TT-SVD decomposition]
        DC[decompose.rs&lt;br/&gt;SVD implementation]
        FMT[format.rs&lt;br/&gt;Snapshot format]
        STR[streaming.rs&lt;br/&gt;Streaming I/O]
        STT[streaming_tt.rs&lt;br/&gt;Streaming TT]
        INC[incremental.rs&lt;br/&gt;Delta snapshots]
        DLT[delta.rs&lt;br/&gt;Delta + varint encoding]
        RLE[rle.rs&lt;br/&gt;Run-length encoding]
    end

    TT --&gt; DC
    FMT --&gt; TT
    FMT --&gt; DLT
    FMT --&gt; RLE
    STR --&gt; FMT
    STT --&gt; TT
    INC --&gt; FMT
</pre>
<h2 id="tensor-train-decomposition"><a class="header" href="#tensor-train-decomposition">Tensor Train Decomposition</a></h2>
<h3 id="algorithm-overview"><a class="header" href="#algorithm-overview">Algorithm Overview</a></h3>
<p>The TT-SVD algorithm (Oseledets 2011) decomposes a vector by:</p>
<ol>
<li><strong>Reshape</strong>: Convert 1D vector to multi-dimensional tensor</li>
<li><strong>Left-to-right sweep</strong>: For each mode k from 1 to n-1:
<ul>
<li>Left-unfold the current tensor into a matrix</li>
<li>Compute truncated SVD: A = U <em>S</em> Vt</li>
<li>Store U as the k-th core</li>
<li>Multiply S * Vt to get the remainder for next iteration</li>
</ul>
</li>
<li><strong>Final core</strong>: The last remainder becomes the final core</li>
</ol>
<pre class="mermaid">graph LR
    subgraph &quot;TT-SVD Algorithm&quot;
        V[Vector 4096-dim] --&gt; R[Reshape to 8x8x8x8]
        R --&gt; U1[Unfold mode 1&lt;br/&gt;64 x 64]
        U1 --&gt; SVD1[SVD truncate&lt;br/&gt;rank=8]
        SVD1 --&gt; C1[Core 1&lt;br/&gt;1x8x8]
        SVD1 --&gt; R2[Remainder&lt;br/&gt;8x512]
        R2 --&gt; SVD2[SVD truncate]
        SVD2 --&gt; C2[Core 2&lt;br/&gt;8x8x8]
        SVD2 --&gt; R3[Remainder]
        R3 --&gt; SVD3[SVD truncate]
        SVD3 --&gt; C3[Core 3&lt;br/&gt;8x8x8]
        SVD3 --&gt; C4[Core 4&lt;br/&gt;8x8x1]
    end
</pre>
<h3 id="compression-example"><a class="header" href="#compression-example">Compression Example</a></h3>
<p>For a 4096-dim embedding reshaped to (8, 8, 8, 8):</p>
<pre><code class="language-text">Original: 4096 floats = 16 KB
TT-cores: 1x8x8 + 8x8x8 + 8x8x8 + 8x8x1 = 64 + 512 + 512 + 64 = 1152 floats
With max_rank=8: 1x8x4 + 4x8x4 + 4x8x4 + 4x8x1 = 32 + 128 + 128 + 32 = 320 floats = 1.25 KB
Compression: 12.8x
</code></pre>
<h3 id="svd-implementation-details"><a class="header" href="#svd-implementation-details">SVD Implementation Details</a></h3>
<p>The module implements two SVD algorithms:</p>
<h4 id="1-power-iteration-with-deflation-small-matrices"><a class="header" href="#1-power-iteration-with-deflation-small-matrices">1. Power Iteration with Deflation (small matrices)</a></h4>
<p>Used when matrix dimensions are &lt;= 32 or rank is close to matrix size:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simplified power iteration
fn power_iteration(a: &amp;Matrix, max_iter: usize, tol: f32) -&gt; (sigma, u, v) {
    // Initialize v randomly (deterministic seed)
    let mut v: Vec&lt;f32&gt; = (0..cols).map(|i| ((i * 7 + 3) % 13) as f32 / 13.0 - 0.5).collect();
    normalize(&amp;mut v);

    for _ in 0..max_iter {
        // u = A * v, then normalize
        u = matmul(a, v);
        new_sigma = normalize(&amp;mut u);

        // v = A^T * u, then normalize
        v = matmul_transpose(a, u);
        normalize(&amp;mut v);

        // Check convergence
        if (new_sigma - sigma).abs() &lt; tol * sigma.max(1.0) {
            return (new_sigma, u, v);
        }
        sigma = new_sigma;
    }
}
<span class="boring">}</span></code></pre></pre>
<p>After finding each singular triplet, the algorithm deflates: A = A - sigma <em>u</em>
vT</p>
<h4 id="2-randomized-svd-large-matrices"><a class="header" href="#2-randomized-svd-large-matrices">2. Randomized SVD (large matrices)</a></h4>
<p>Uses the Halko-Martinsson-Tropp 2011 algorithm for matrices &gt; 32 dimensions:</p>
<pre class="mermaid">graph TD
    subgraph &quot;Randomized SVD Pipeline&quot;
        A[Input Matrix A&lt;br/&gt;m x n] --&gt; OMEGA[Generate Gaussian&lt;br/&gt;Omega n x k+p]
        A --&gt; SAMPLE[Y = A * Omega&lt;br/&gt;m x k+p]
        SAMPLE --&gt; QR[QR decompose Y&lt;br/&gt;Q = orth basis]
        QR --&gt; PROJECT[B = Q^T * A&lt;br/&gt;k+p x n]
        PROJECT --&gt; SMALL_SVD[SVD of small B&lt;br/&gt;power iteration]
        SMALL_SVD --&gt; RECONSTRUCT[U = Q * U_small]
    end
</pre>
<p>Key implementation details:</p>
<ul>
<li><strong>Gaussian matrix generation</strong>: Uses a Linear Congruential Generator (LCG)
with Box-Muller transform for deterministic, portable random numbers</li>
<li><strong>QR orthonormalization</strong>: Modified Gram-Schmidt for numerical stability</li>
<li><strong>Oversampling</strong>: Adds 5 extra columns to improve accuracy</li>
<li><strong>Convergence</strong>: 20 iterations max (sufficient for embedding vectors)</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// LCG parameters from Numerical Recipes
fn lcg_next(state: &amp;mut u64) -&gt; u64 {
    *state = state.wrapping_mul(6_364_136_223_846_793_005)
                  .wrapping_add(1_442_695_040_888_963_407);
    *state
}

// Box-Muller transform for Gaussian
fn box_muller(u1: f32, u2: f32) -&gt; (f32, f32) {
    let r = (-2.0 * u1.ln()).sqrt();
    let theta = 2.0 * PI * u2;
    (r * theta.cos(), r * theta.sin())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="optimal-shape-selection"><a class="header" href="#optimal-shape-selection">Optimal Shape Selection</a></h3>
<p>The module includes hardcoded optimal shapes for common embedding dimensions:</p>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Shape</th><th>Why</th></tr></thead><tbody>
<tr><td>64</td><td><code>[4, 4, 4]</code></td><td>3 balanced factors</td></tr>
<tr><td>128</td><td><code>[4, 4, 8]</code></td><td>Near-balanced</td></tr>
<tr><td>256</td><td><code>[4, 8, 8]</code></td><td>Near-balanced</td></tr>
<tr><td>384</td><td><code>[4, 8, 12]</code></td><td>all-MiniLM-L6-v2</td></tr>
<tr><td>512</td><td><code>[8, 8, 8]</code></td><td>Perfect cube</td></tr>
<tr><td>768</td><td><code>[8, 8, 12]</code></td><td>BERT dimension</td></tr>
<tr><td>1024</td><td><code>[8, 8, 16]</code></td><td>Common LLM size</td></tr>
<tr><td>1536</td><td><code>[8, 12, 16]</code></td><td>OpenAI ada-002</td></tr>
<tr><td>2048</td><td><code>[8, 16, 16]</code></td><td>Near-balanced</td></tr>
<tr><td>3072</td><td><code>[8, 16, 24]</code></td><td>Large models</td></tr>
<tr><td>4096</td><td><code>[8, 8, 8, 8]</code></td><td>4D balanced</td></tr>
<tr><td>8192</td><td><code>[8, 8, 8, 16]</code></td><td>Extra large</td></tr>
</tbody></table>
</div>
<p>For non-standard dimensions, <code>factorize_balanced</code> finds factors close to the nth
root:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn factorize_balanced(n: usize) -&gt; Vec&lt;usize&gt; {
    // Target 2-6 factors based on log2(n)
    let target_factors = (ln(n) / ln(2)).ceil().clamp(2, 6);
    let target_size = n^(1/target_factors);

    // Greedily find factors close to target_size
    // ...
}
<span class="boring">}</span></code></pre></pre>
<h3 id="tt-operations"><a class="header" href="#tt-operations">TT Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th><th>Complexity</th></tr></thead><tbody>
<tr><td><code>tt_decompose</code></td><td>Decompose vector to TT format</td><td>O(n <em>d</em> r^2)</td></tr>
<tr><td><code>tt_decompose_batch</code></td><td>Parallel batch decomposition (4+ vectors)</td><td>O(batch <em>n</em> d * r^2 / threads)</td></tr>
<tr><td><code>tt_reconstruct</code></td><td>Reconstruct vector from TT</td><td>O(d^n * r^2)</td></tr>
<tr><td><code>tt_dot_product</code></td><td>Dot product in TT space</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_dot_product_batch</code></td><td>Batch dot products</td><td>Parallel when &gt;= 4 targets</td></tr>
<tr><td><code>tt_cosine_similarity</code></td><td>Cosine similarity in TT space</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_cosine_similarity_batch</code></td><td>Batch cosine similarities</td><td>Parallel when &gt;= 4 targets</td></tr>
<tr><td><code>tt_euclidean_distance</code></td><td>Euclidean distance in TT space</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_euclidean_distance_batch</code></td><td>Batch Euclidean distances</td><td>Parallel when &gt;= 4 targets</td></tr>
<tr><td><code>tt_norm</code></td><td>L2 norm of TT vector</td><td>O(n <em>d</em> r^4)</td></tr>
<tr><td><code>tt_scale</code></td><td>Scale TT vector by constant</td><td><code>O(cores[0].size)</code></td></tr>
</tbody></table>
</div>
<p>Where: n = number of modes, d = mode size, r = TT-rank</p>
<h3 id="tt-gram-matrix-computation"><a class="header" href="#tt-gram-matrix-computation">TT Gram Matrix Computation</a></h3>
<p>Computing dot products and norms in TT space uses the Gram matrix approach:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Gram matrix propagation for dot product
fn tt_dot_product(a: &amp;TTVector, b: &amp;TTVector) -&gt; f32 {
    let mut gram = vec![1.0f32];  // Start with 1x1 identity

    for (core_a, core_b) in a.cores.iter().zip(b.cores.iter()) {
        let (r1a, n, r2a) = core_a.shape;
        let (r1b, _, r2b) = core_b.shape;
        let mut new_gram = vec![0.0; r2a * r2b];

        // Contract: new_gram[a,b] = sum_{k,i,j} gram[i,j] * A[i,k,a] * B[j,k,b]
        for a_idx in 0..r2a {
            for b_idx in 0..r2b {
                for k in 0..n {
                    for ia in 0..r1a {
                        for ib in 0..r1b {
                            let g = gram[ia * r1b + ib];
                            new_gram[a_idx * r2b + b_idx] +=
                                g * core_a.get(ia, k, a_idx) * core_b.get(ib, k, b_idx);
                        }
                    }
                }
            }
        }
        gram = new_gram;
    }

    gram[0]  // Final 1x1 Gram matrix
}
<span class="boring">}</span></code></pre></pre>
<h3 id="usage"><a class="header" href="#usage">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{tt_decompose, tt_reconstruct, tt_cosine_similarity, TTConfig};

let embedding: Vec&lt;f32&gt; = get_embedding();  // 4096-dim
let config = TTConfig::for_dim(4096)?;

// Decompose
let tt = tt_decompose(&amp;embedding, &amp;config)?;
println!("Compression: {:.1}x", tt.compression_ratio());
println!("Storage: {} floats", tt.storage_size());
println!("Max rank: {}", tt.max_rank());

// Reconstruct
let restored = tt_reconstruct(&amp;tt);

// Compute similarity without reconstruction
let tt2 = tt_decompose(&amp;other_embedding, &amp;config)?;
let sim = tt_cosine_similarity(&amp;tt, &amp;tt2)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-operations"><a class="header" href="#batch-operations">Batch Operations</a></h3>
<p>Batch operations use rayon for parallel processing when handling 4+ vectors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{tt_decompose_batch, tt_cosine_similarity_batch, TTConfig};

let vectors: Vec&lt;Vec&lt;f32&gt;&gt; = load_embeddings();
let config = TTConfig::for_dim(4096)?;

// Batch decompose (parallel for 4+ vectors)
let refs: Vec&lt;&amp;[f32]&gt; = vectors.iter().map(|v| v.as_slice()).collect();
let tts = tt_decompose_batch(&amp;refs, &amp;config)?;

// Batch similarity search
let query_tt = &amp;tts[0];
let similarities = tt_cosine_similarity_batch(query_tt, &amp;tts[1..])?;

// Find top-k
let mut indexed: Vec&lt;_&gt; = similarities.iter().enumerate().collect();
indexed.sort_by(|a, b| b.1.partial_cmp(a.1).unwrap());
let top_5: Vec&lt;_&gt; = indexed.iter().take(5).collect();
<span class="boring">}</span></code></pre></pre>
<p>The parallel threshold constant is:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const PARALLEL_THRESHOLD: usize = 4;
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="ttconfig-presets"><a class="header" href="#ttconfig-presets">TTConfig Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>max_rank</th><th>tolerance</th><th>Use Case</th></tr></thead><tbody>
<tr><td><code>for_dim(d)</code></td><td>8</td><td>1e-4</td><td>Balanced compression/accuracy</td></tr>
<tr><td><code>high_compression(d)</code></td><td>4</td><td>1e-2</td><td>Maximize compression (2-3x more)</td></tr>
<tr><td><code>high_accuracy(d)</code></td><td>16</td><td>1e-6</td><td>Maximize accuracy (&lt;0.1% error)</td></tr>
</tbody></table>
</div>
<h3 id="ttconfig-validation"><a class="header" href="#ttconfig-validation">TTConfig Validation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl TTConfig {
    pub fn validate(&amp;self) -&gt; Result&lt;(), TTError&gt; {
        if self.shape.is_empty() {
            return Err(TTError::InvalidShape("empty shape".into()));
        }
        if self.shape.contains(&amp;0) {
            return Err(TTError::InvalidShape("shape contains zero".into()));
        }
        if self.max_rank &lt; 1 {
            return Err(TTError::InvalidRank);
        }
        if self.tolerance &lt;= 0.0 || self.tolerance &gt; 1.0 || !self.tolerance.is_finite() {
            return Err(TTError::InvalidTolerance(self.tolerance));
        }
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="compressionconfig"><a class="header" href="#compressionconfig">CompressionConfig</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CompressionConfig {
    pub tensor_mode: Option&lt;TensorMode&gt;,  // TT compression for vectors
    pub delta_encoding: bool,             // For sorted ID lists
    pub rle_encoding: bool,               // For repeated values
}

// Presets
CompressionConfig::high_compression()  // max_rank=4, all encodings enabled
CompressionConfig::balanced(dim)       // max_rank=8, all encodings enabled
CompressionConfig::high_accuracy(dim)  // max_rank=16, all encodings enabled
<span class="boring">}</span></code></pre></pre>
<h3 id="dimension-presets"><a class="header" href="#dimension-presets">Dimension Presets</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Constant</th><th>Value</th><th>Model</th></tr></thead><tbody>
<tr><td><code>SMALL</code></td><td>64</td><td>MiniLM and small models</td></tr>
<tr><td><code>MEDIUM</code></td><td>384</td><td>all-MiniLM-L6-v2</td></tr>
<tr><td><code>STANDARD</code></td><td>768</td><td>BERT, sentence-transformers</td></tr>
<tr><td><code>LARGE</code></td><td>1536</td><td>OpenAI text-embedding-ada-002</td></tr>
<tr><td><code>XLARGE</code></td><td>4096</td><td>LLaMA and large models</td></tr>
</tbody></table>
</div>
<h2 id="streaming-operations"><a class="header" href="#streaming-operations">Streaming Operations</a></h2>
<h3 id="state-machine"><a class="header" href="#state-machine">State Machine</a></h3>
<pre class="mermaid">stateDiagram-v2
    [*] --&gt; Created: new()
    Created --&gt; Writing: write_entry() / write_vector()
    Writing --&gt; Writing: write_entry() / write_vector()
    Writing --&gt; Finishing: finish()
    Finishing --&gt; [*]: success

    note right of Created
        Magic bytes written
        entry_count = 0
    end note

    note right of Writing
        Length-prefixed entries
        entry_count incremented
    end note

    note right of Finishing
        Trailer written with:
        - entry_count
        - config
        - data_start offset
    end note
</pre>
<h3 id="file-format"><a class="header" href="#file-format">File Format</a></h3>
<p>Uses a trailer-based header so entry count is known at the end:</p>
<pre><code class="language-text">+------------------------+
| Magic (NEUS/NEUT)  4B  |  Identifies streaming snapshot/TT
+------------------------+
| Entry 1 length     4B  |  Little-endian u32
+------------------------+
| Entry 1 data      var  |  Bincode-serialized entry
+------------------------+
| Entry 2 length     4B  |
+------------------------+
| Entry 2 data      var  |
+------------------------+
| ...                    |
+------------------------+
| Trailer           var  |  Bincode-serialized header
+------------------------+
| Trailer size       8B  |  Little-endian u64
+------------------------+
</code></pre>
<p><strong>Security limits:</strong></p>
<ul>
<li>Maximum trailer size: 1 MB (<code>MAX_TRAILER_SIZE</code>)</li>
<li>Maximum entry size: 100 MB (<code>MAX_ENTRY_SIZE</code>)</li>
</ul>
<h3 id="usage-1"><a class="header" href="#usage-1">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::streaming::{StreamingWriter, StreamingReader};

// Write entries one at a time
let mut writer = StreamingWriter::new(file, config)?;
for entry in entries {
    writer.write_entry(&amp;entry)?;
}
writer.finish()?;

// Read entries one at a time (iterator-based)
let reader = StreamingReader::open(file)?;
println!("Entry count: {}", reader.entry_count());
for entry in reader {
    process(entry?);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="streaming-tt-operations"><a class="header" href="#streaming-tt-operations">Streaming TT Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody>
<tr><td><code>StreamingTTWriter::new</code></td><td>Create TT streaming writer</td></tr>
<tr><td><code>StreamingTTWriter::write_vector</code></td><td>Decompose and write vector</td></tr>
<tr><td><code>StreamingTTWriter::write_tt</code></td><td>Write pre-decomposed TT</td></tr>
<tr><td><code>StreamingTTWriter::finish</code></td><td>Finalize with trailer</td></tr>
<tr><td><code>StreamingTTReader::open</code></td><td>Open TT streaming file</td></tr>
<tr><td><code>streaming_tt_similarity_search</code></td><td>Search streaming TT file</td></tr>
<tr><td><code>convert_vectors_to_streaming_tt</code></td><td>Batch convert vectors</td></tr>
<tr><td><code>read_streaming_tt_all</code></td><td>Load all TT vectors</td></tr>
</tbody></table>
</div>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::streaming_tt::{StreamingTTWriter, StreamingTTReader,
    streaming_tt_similarity_search};

// Create streaming TT file
let config = TTConfig::for_dim(768)?;
let mut writer = StreamingTTWriter::new(file, config.clone())?;

for vector in vectors {
    writer.write_vector(&amp;vector)?;  // Decompose on-the-fly
}
writer.finish()?;

// Similarity search without loading all into memory
let query_tt = tt_decompose(&amp;query, &amp;config)?;
let top_10 = streaming_tt_similarity_search(file, &amp;query_tt, 10)?;
// Returns Vec&lt;(index, similarity)&gt; sorted by descending similarity
<span class="boring">}</span></code></pre></pre>
<h3 id="merge-and-convert-operations"><a class="header" href="#merge-and-convert-operations">Merge and Convert Operations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::streaming::{convert_to_streaming, read_streaming_to_snapshot,
    merge_streaming};

// Convert non-streaming snapshot to streaming format
let count = convert_to_streaming(&amp;snapshot, output_file)?;

// Read streaming format into full snapshot (for compatibility)
let snapshot = read_streaming_to_snapshot(file)?;

// Merge multiple streaming snapshots
let count = merge_streaming(vec![file1, file2, file3], output, config)?;
<span class="boring">}</span></code></pre></pre>
<h2 id="incremental-updates"><a class="header" href="#incremental-updates">Incremental Updates</a></h2>
<h3 id="delta-snapshot-architecture"><a class="header" href="#delta-snapshot-architecture">Delta Snapshot Architecture</a></h3>
<pre class="mermaid">graph TD
    subgraph &quot;Delta Chain&quot;
        BASE[Base Snapshot&lt;br/&gt;Seq 0] --&gt; D1[Delta 1&lt;br/&gt;Seq 1-10]
        D1 --&gt; D2[Delta 2&lt;br/&gt;Seq 11-25]
        D2 --&gt; D3[Delta 3&lt;br/&gt;Seq 26-30]
    end

    subgraph &quot;Compaction&quot;
        BASE2[Base] --&gt; COMPACT[Compacted&lt;br/&gt;Snapshot]
        D1_2[Delta 1] --&gt; COMPACT
        D2_2[Delta 2] --&gt; COMPACT
        D3_2[Delta 3] --&gt; COMPACT
    end
</pre>
<h3 id="delta-entry-types"><a class="header" href="#delta-entry-types">Delta Entry Types</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum ChangeType {
    Put,    // Entry was added or updated
    Delete, // Entry was deleted
}

pub struct DeltaEntry {
    pub key: String,
    pub change: ChangeType,
    pub value: Option&lt;CompressedEntry&gt;,  // None for Delete
    pub sequence: u64,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="usage-2"><a class="header" href="#usage-2">Usage</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::incremental::{DeltaBuilder, DeltaChain, apply_delta,
    merge_deltas, diff_snapshots};

// Create delta
let mut builder = DeltaBuilder::new("base_snapshot_id", sequence);
builder.put("key1", entry1);
builder.delete("key2");
let delta = builder.build();

// Apply delta
let new_snapshot = apply_delta(&amp;base, &amp;delta)?;

// Chain management
let mut chain = DeltaChain::new(base_snapshot);
chain.push(delta1)?;
chain.push(delta2)?;
let value = chain.get("key1");  // Checks chain then base

// Compact when chain grows long
if chain.should_compact(10) {
    let compacted = chain.compact()?;
}

// Compare two snapshots
let delta = diff_snapshots(&amp;old_snapshot, &amp;new_snapshot, "old_id")?;

// Merge multiple deltas into one
let merged = merge_deltas(&amp;[delta1, delta2, delta3])?;
<span class="boring">}</span></code></pre></pre>
<h3 id="delta-operations"><a class="header" href="#delta-operations">Delta Operations</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Function</th><th>Description</th></tr></thead><tbody>
<tr><td><code>DeltaBuilder::new</code></td><td>Create delta builder with base ID and start sequence</td></tr>
<tr><td><code>DeltaBuilder::put</code></td><td>Record a put (add/update) change</td></tr>
<tr><td><code>DeltaBuilder::delete</code></td><td>Record a delete change</td></tr>
<tr><td><code>DeltaBuilder::build</code></td><td>Build the delta snapshot</td></tr>
<tr><td><code>apply_delta</code></td><td>Apply delta to base snapshot</td></tr>
<tr><td><code>merge_deltas</code></td><td>Merge multiple deltas (keeps latest state per key)</td></tr>
<tr><td><code>diff_snapshots</code></td><td>Compute delta between two snapshots</td></tr>
<tr><td><code>DeltaChain::get</code></td><td>Get current state of key (checks chain then base)</td></tr>
<tr><td><code>DeltaChain::compact</code></td><td>Compact all deltas into new base</td></tr>
<tr><td><code>DeltaChain::should_compact</code></td><td>Check if compaction is recommended</td></tr>
</tbody></table>
</div>
<h3 id="delta-format"><a class="header" href="#delta-format">Delta Format</a></h3>
<pre><code class="language-text">+------------------------+
| Magic (NEUD)       4B  |
+------------------------+
| Version            2B  |
+------------------------+
| Base ID           var  |  String (length-prefixed)
+------------------------+
| Sequence Range     16B |  (start, end) u64 pair
+------------------------+
| Change Count        8B |
+------------------------+
| Created At          8B |  Unix timestamp
+------------------------+
| Entries           var  |  Bincode-serialized Vec&lt;DeltaEntry&gt;
+------------------------+
</code></pre>
<h2 id="lossless-compression"><a class="header" href="#lossless-compression">Lossless Compression</a></h2>
<h3 id="delta--varint-encoding"><a class="header" href="#delta--varint-encoding">Delta + Varint Encoding</a></h3>
<p>For sorted integer sequences (node IDs, timestamps):</p>
<pre class="mermaid">graph LR
    subgraph &quot;Delta + Varint Pipeline&quot;
        IDS[IDs: 100, 101, 102, 105, 110] --&gt; DELTA[Delta encode:&lt;br/&gt;100, 1, 1, 3, 5]
        DELTA --&gt; VARINT[Varint encode]
        VARINT --&gt; OUT[Bytes: ~7 bytes&lt;br/&gt;vs 40 bytes raw]
    end
</pre>
<p><strong>Algorithm:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Delta encoding: store first value, then differences
pub fn delta_encode(ids: &amp;[u64]) -&gt; Vec&lt;u64&gt; {
    let mut result = vec![ids[0]];
    for window in ids.windows(2) {
        result.push(window[1].saturating_sub(window[0]));
    }
    result
}

// Varint encoding: 7 bits per byte, high bit = continuation
pub fn varint_encode(values: &amp;[u64]) -&gt; Vec&lt;u8&gt; {
    let mut result = Vec::with_capacity(values.len() * 2);
    for &amp;value in values {
        let mut v = value;
        loop {
            let byte = (v &amp; 0x7f) as u8;
            v &gt;&gt;= 7;
            if v == 0 {
                result.push(byte);  // Final byte (no continuation)
                break;
            }
            result.push(byte | 0x80);  // Continuation bit set
        }
    }
    result
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Usage:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{compress_ids, decompress_ids};

let ids: Vec&lt;u64&gt; = (1000..2000).collect();
let compressed = compress_ids(&amp;ids);  // ~100 bytes vs 8000

let restored = decompress_ids(&amp;compressed);
assert_eq!(ids, restored);
<span class="boring">}</span></code></pre></pre>
<p><strong>Varint byte sizes:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Value Range</th><th>Bytes</th></tr></thead><tbody>
<tr><td>0 - 127</td><td>1</td></tr>
<tr><td>128 - 16,383</td><td>2</td></tr>
<tr><td>16,384 - 2,097,151</td><td>3</td></tr>
<tr><td>2,097,152 - 268,435,455</td><td>4</td></tr>
<tr><td>… up to u64::MAX</td><td>10</td></tr>
</tbody></table>
</div>
<h3 id="run-length-encoding"><a class="header" href="#run-length-encoding">Run-Length Encoding</a></h3>
<p>For repeated values:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{rle_encode, rle_decode};

let statuses = vec!["active"; 1000];
let encoded = rle_encode(&amp;statuses);
assert_eq!(encoded.runs(), 1);  // Single run

// Storage: 1 string + 1 u32 = ~12 bytes vs 6000+ bytes
<span class="boring">}</span></code></pre></pre>
<p><strong>Internal representation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct RleEncoded&lt;T: Eq&gt; {
    pub values: Vec&lt;T&gt;,      // Unique values in order
    pub run_lengths: Vec&lt;u32&gt;, // Count for each value
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Compression scenarios:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Data Pattern</th><th>Runs</th><th>Compression</th></tr></thead><tbody>
<tr><td><code>[5, 5, 5, 5, 5]</code> (1000x)</td><td>1</td><td>500x</td></tr>
<tr><td><code>[1, 2, 3, 4, 5]</code> (all different)</td><td>5</td><td>0.8x (overhead)</td></tr>
<tr><td><code>[1, 1, 2, 2, 2, 3, 1, 1, 1, 1]</code></td><td>4</td><td>2.5x</td></tr>
<tr><td>Status column (pending/active/done)</td><td>~300 per 10000</td><td>~33x</td></tr>
</tbody></table>
</div>
<h3 id="sparse-vector-format"><a class="header" href="#sparse-vector-format">Sparse Vector Format</a></h3>
<p>For vectors with &gt;50% zeros:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tensor_compress::{compress_sparse, compress_dense_as_sparse,
    should_use_sparse, should_use_sparse_threshold};

// Direct sparse compression
let positions = vec![0, 50, 99];
let values = vec![1.0, 2.0, 3.0];
let compressed = compress_sparse(100, &amp;positions, &amp;values);

// Auto-detect and compress
if should_use_sparse_threshold(&amp;vector, 0.5) {
    let compressed = compress_dense_as_sparse(&amp;vector);
}

// Check if sparse is beneficial
if should_use_sparse(dimension, non_zero_count) {
    // Use sparse format
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Storage calculation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// sparse_storage_size = 8 + 8 + nnz*2 + nnz*4 = 16 + nnz*6
// Dense storage = dimension * 4

// Sparse is better when: 16 + nnz*6 &lt; dimension*4
// Solving: nnz &lt; (dimension*4 - 16) / 6 = dimension*0.67 - 2.67
<span class="boring">}</span></code></pre></pre>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Max NNZ for Sparse</th><th>Sparsity Threshold</th></tr></thead><tbody>
<tr><td>100</td><td>64</td><td>64%</td></tr>
<tr><td>1000</td><td>664</td><td>66.4%</td></tr>
<tr><td>4096</td><td>2728</td><td>66.6%</td></tr>
</tbody></table>
</div>
<h2 id="compressed-value-types"><a class="header" href="#compressed-value-types">Compressed Value Types</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum CompressedValue {
    Scalar(CompressedScalar),           // Int, Float, String, Bool, Null
    VectorRaw(Vec&lt;f32&gt;),                // Uncompressed
    VectorTT { cores, original_dim, shape, ranks },  // TT-compressed
    VectorSparse { dimension, positions, values },   // Sparse
    IdList(Vec&lt;u8&gt;),                    // Delta + varint encoded
    RleInt(RleEncoded&lt;i64&gt;),            // RLE encoded integers
    Pointer(String),                    // Single pointer
    Pointers(Vec&lt;String&gt;),              // Multiple pointers
}
<span class="boring">}</span></code></pre></pre>
<h3 id="automatic-format-selection"><a class="header" href="#automatic-format-selection">Automatic Format Selection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn compress_vector(vector: &amp;[f32], key: &amp;str, field_name: &amp;str,
    config: &amp;CompressionConfig) -&gt; Result&lt;CompressedValue, FormatError&gt; {

    // 1. Check for embedding-like keys
    let is_embedding = key.starts_with("emb:") ||
                       field_name == "_embedding" ||
                       field_name == "vector";

    if is_embedding {
        if let Some(TensorMode::TensorTrain(tt_config)) = &amp;config.tensor_mode {
            return Ok(CompressedValue::VectorTT { ... });
        }
    }

    // 2. Check for ID list pattern
    if config.delta_encoding &amp;&amp; looks_like_id_list(vector, field_name) {
        return Ok(CompressedValue::IdList(...));
    }

    // 3. Fall back to raw
    Ok(CompressedValue::VectorRaw(vector.to_vec()))
}
<span class="boring">}</span></code></pre></pre>
<h2 id="performance"><a class="header" href="#performance">Performance</a></h2>
<p>Benchmarks on Apple M4 (aarch64, MacBook Air 24GB), release build:</p>
<div class="table-wrapper"><table><thead><tr><th>Dimension</th><th>Decompose</th><th>Reconstruct</th><th>Similarity</th><th>Compression</th></tr></thead><tbody>
<tr><td>64</td><td>6.2 us</td><td>29.5 us</td><td>1.1 us</td><td>2.0x</td></tr>
<tr><td>256</td><td>13.4 us</td><td>113.0 us</td><td>1.5 us</td><td>4.6x</td></tr>
<tr><td>768</td><td>26.9 us</td><td>431.7 us</td><td>2.4 us</td><td>10.7x</td></tr>
<tr><td>1536</td><td>62.0 us</td><td>709.8 us</td><td>2.0 us</td><td>16.0x</td></tr>
<tr><td>4096</td><td>464.5 us</td><td>2142.2 us</td><td>2.4 us</td><td>42.7x</td></tr>
</tbody></table>
</div>
<p>Batch operations (768-dim, 1000 vectors):</p>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Time</th><th>Per-vector</th></tr></thead><tbody>
<tr><td><code>tt_decompose_batch</code></td><td>21 ms</td><td>21.0 us</td></tr>
<tr><td><code>tt_cosine_similarity_batch</code></td><td>11.3 ms</td><td>11.4 us</td></tr>
</tbody></table>
</div>
<p>Throughput: <strong>39,318 vectors/sec</strong> (768-dim decomposition)</p>
<h3 id="industry-comparison"><a class="header" href="#industry-comparison">Industry Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Compression</th><th>Recall</th><th>Notes</th></tr></thead><tbody>
<tr><td><strong>Tensor Train (this)</strong></td><td>10-42x</td><td>~99%</td><td>Similarity in compressed space</td></tr>
<tr><td>Scalar Quantization</td><td>4x</td><td>99%+</td><td>Industry default</td></tr>
<tr><td>Product Quantization</td><td>16-64x</td><td>56-90%</td><td>Requires training</td></tr>
<tr><td>Binary Quantization</td><td>32x</td><td>80-95%</td><td>Speed-optimized</td></tr>
</tbody></table>
</div>
<h2 id="edge-cases-and-gotchas"><a class="header" href="#edge-cases-and-gotchas">Edge Cases and Gotchas</a></h2>
<h3 id="vector-content-patterns"><a class="header" href="#vector-content-patterns">Vector Content Patterns</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Pattern</th><th>Compression</th><th>Reconstruction</th><th>Notes</th></tr></thead><tbody>
<tr><td>Constant (all same)</td><td>Excellent (&gt;5x)</td><td>Accurate</td><td>Rank-1 structure</td></tr>
<tr><td>All zeros</td><td>Good</td><td>Accurate</td><td>Degenerate case</td></tr>
<tr><td>Single spike</td><td>Poor</td><td>Moderate</td><td>No low-rank structure</td></tr>
<tr><td>Linear ramp</td><td>Good (&gt;2x)</td><td>Good</td><td>Low-rank</td></tr>
<tr><td>Alternating +1/-1</td><td>Poor</td><td>Moderate</td><td>High-frequency needs high rank</td></tr>
<tr><td>Random dense</td><td>Good</td><td>Good (&gt;0.9 cosine)</td><td>Typical embeddings</td></tr>
<tr><td>90% zeros</td><td>Consider sparse instead</td><td>n/a</td><td>Use <code>compress_dense_as_sparse</code></td></tr>
</tbody></table>
</div>
<h3 id="numerical-edge-cases"><a class="header" href="#numerical-edge-cases">Numerical Edge Cases</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Very small values (denormalized floats)
let tiny: Vec&lt;f32&gt; = (0..64).map(|i| (i as f32) * 1e-38).collect();
// Works, but may lose precision

// Large values (1e6 range)
let large: Vec&lt;f32&gt; = (0..64).map(|i| (i as f32) * 1e6).collect();
// Works, no overflow

// Prime dimensions
let prime_127: Vec&lt;f32&gt; = (0..127).map(|i| (i as f32 * 0.1).sin()).collect();
// Works but may have poor compression
<span class="boring">}</span></code></pre></pre>
<h3 id="streaming-gotchas"><a class="header" href="#streaming-gotchas">Streaming Gotchas</a></h3>
<ol>
<li>
<p><strong>Incomplete files</strong>: Magic bytes are written first, but entry count is in
trailer. If writer crashes before <code>finish()</code>, the file is corrupt.</p>
</li>
<li>
<p><strong>Memory limits</strong>: <code>MAX_ENTRY_SIZE = 100MB</code> and <code>MAX_TRAILER_SIZE = 1MB</code>
prevent allocation attacks. Exceeding these returns an error.</p>
</li>
<li>
<p><strong>Seek requirement</strong>: <code>StreamingReader::open</code> requires <code>Seek</code> to read the
trailer. For non-seekable streams, use <code>read_streaming_to_snapshot</code> which
buffers.</p>
</li>
</ol>
<h3 id="delta-chain-gotchas"><a class="header" href="#delta-chain-gotchas">Delta Chain Gotchas</a></h3>
<ol>
<li>
<p><strong>Chain length</strong>: Default <code>max_chain_len = 100</code>. After this, <code>push()</code> returns
<code>ChainTooLong</code> error. Call <code>compact()</code> periodically.</p>
</li>
<li>
<p><strong>Sequence gaps</strong>: Deltas should have contiguous sequences. The
<code>merge_deltas</code> function only keeps the latest state per key.</p>
</li>
<li>
<p><strong>Base reference</strong>: Deltas store a <code>base_id</code> string but don’t validate it
exists. Your application must track base snapshots.</p>
</li>
</ol>
<h2 id="performance-tips-and-best-practices"><a class="header" href="#performance-tips-and-best-practices">Performance Tips and Best Practices</a></h2>
<h3 id="choosing-configuration"><a class="header" href="#choosing-configuration">Choosing Configuration</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// For search/retrieval (similarity queries)
let config = TTConfig::for_dim(dim)?;  // Balanced

// For archival/cold storage
let config = TTConfig::high_compression(dim)?;  // Smaller, slower queries

// For real-time applications
let config = TTConfig::high_accuracy(dim)?;  // Larger, faster queries
<span class="boring">}</span></code></pre></pre>
<h3 id="batch-size-optimization"><a class="header" href="#batch-size-optimization">Batch Size Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Below parallel threshold (4), sequential is faster
// due to thread spawn overhead
let small_batch = tt_decompose_batch(&amp;vectors[..3], &amp;config);  // Sequential

// At threshold, parallel kicks in
let large_batch = tt_decompose_batch(&amp;vectors, &amp;config);  // Parallel if &gt;= 4
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-efficiency"><a class="header" href="#memory-efficiency">Memory Efficiency</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Load all, then process
let all_vectors = read_streaming_tt_all(file)?;  // Loads all into memory

// Good: Stream process
for tt in StreamingTTReader::open(file)? {
    process(tt?);  // One at a time
}

// Best: Use streaming search
let results = streaming_tt_similarity_search(file, &amp;query_tt, 10)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="delta-compaction-strategy"><a class="header" href="#delta-compaction-strategy">Delta Compaction Strategy</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut chain = DeltaChain::new(base);

// After N deltas or M total changes
if chain.len() &gt;= 10 || total_changes &gt;= 10000 {
    let new_base = chain.compact()?;
    chain = DeltaChain::new(new_base);
}
<span class="boring">}</span></code></pre></pre>
<h2 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h2>
<ul>
<li><code>serde</code>: Serialization traits</li>
<li><code>bincode</code>: Binary format</li>
<li><code>thiserror</code>: Error types</li>
<li><code>rayon</code>: Parallel batch operations</li>
</ul>
<p>No external LAPACK/BLAS - pure Rust SVD implementation.</p>
<h2 id="related-modules"><a class="header" href="#related-modules">Related Modules</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Module</th><th>Relationship</th></tr></thead><tbody>
<tr><td><a href="tensor-store.html">tensor_store</a></td><td>Uses compression for snapshot I/O</td></tr>
<tr><td><a href="tensor-chain.html">tensor_chain</a></td><td>Delta compression for state replication</td></tr>
<tr><td><a href="tensor-checkpoint.html">tensor_checkpoint</a></td><td>Snapshot format integration</td></tr>
</tbody></table>
</div>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../architecture/vector-engine.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../architecture/tensor-vault.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../architecture/vector-engine.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../architecture/tensor-vault.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../editor.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../mermaid.min.js"></script>
        <script src="../mermaid-init.js"></script>



    </div>
    </body>
</html>
